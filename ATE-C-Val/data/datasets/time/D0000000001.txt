Towards the Implementation of First-Order Temporal Resolution: the Expanding Domain Case
Boris Konevff
Department of Computer Science
University of Liverpool
Liverpool L69 7ZF, U.K.
B.Konev@csc.liv.ac.uk
Anatoli Degtyarev
Department of Computer Science
Kings College London
Strand, London WC2R 2LS, U.K.
Anatoli@dcs.kcl.ac.uk
Clare Dixon
Department of Computer Science
University of Liverpool
Liverpool L69 7ZF, U.K.
C.Dixon@csc.liv.ac.uk
Michael Fisher
Department of Computer Science
University of Liverpool
Liverpool L69 7ZF, U.K.
M.Fisher@csc.liv.ac.uk
Ullrich Hustadt
Department of Computer Science
University of Liverpool
Liverpool L69 7ZF, U.K.
U.Hustadt@csc.liv.ac.uk
Abstract
First-order temporal logic is a concise and powerful notation, with many potential applications in both Computer Science and Artificial Intelligence. While the full logic is highly complex, recent work on monodic first-order temporal logics has identified important enumerable and even decidable fragments. In this paper, we develop a clausal resolution method for the monodic fragment of first-order temporal logic over expanding domains. We first define a normal form for monodic formulae and then introduce novel resolution calculi that can be applied to formulae in this normal form.
We state correctness and completeness results for the method. We illustrate the method on a comprehensive example. The method is based on classical first-order resolution and can, thus, be efficiently implemented.
1. Introduction
In its propositional form, linear, discrete temporal logic has been widely used in the formal specification and verification of reactive systems. Although recognised a powerful formalism, first-order temporal logic hasff Onleave from Steklov Institute of Mathematics at St.Petersburggenerally been avoided due to complexity problems (e.g. there is no finite axiom system for general first-order temporal logic). However, recent work by Hodkinson et al.   has showed that a particular fragment of first-order temporal logic, termed the monodic fragment, has completeness (sometimes even decidability) properties. This breakthrough has led to considerable research activity examining the monodic fragment, in terms of decidable classes, extensions, applications and mechanisation, etc.
Concerning the mechanisation of monodic temporal logics, general tableau and resolution calculi have already been defined, in   and, respectively. However, neither of these is particularly practical: the tableau method requires representation of all possible first-order models, while the resolution method requires the maximal combination of all temporal clauses. In this paper, we focus on an important subclass of temporal models, having a wide range of applications, for example in spatio-temporal logics   and temporal description logics, namely those models that have expanding domains. In such models, the domains over which first-order terms range can increase at each temporal step. The focus on this class of models allows us to produce a simplified clausal resolution calculus, termed a fine-grained calculus, which is more amenable to efficient implementation.
Thus, we will define the expanding domain monodic fragment, a fine-grained resolution calculus, and provide completeness results for the fine-grained calculus relative to the completeness of the general resolution calculus.
A number of examples will be given, showing how the finegrained calculus works in practice and, finally, conclusions and future work will be provided.understanding of temporal operators:
Mn j=a g
Mn j=a fiiff iff
Mn j=a
Mn j=a ( U )iff iff
Mn j=a ( W ) iff
2. First-Order Temporal Logic
First-Order (discrete linear time) Temporal Logic, FOTL, is an extension of classical first-order logic with operators that deal with a linear and discrete model of time(isomorphic to, and the most commonly used model of time). The first-order temporal language is constructed in a standard way   from: predicate symbols P0 ; P1 ; : : : each of which is of some fixed arity (null-ary predicate symbols are called propositions); individual variables x0 ; x1 ; : : :; individual constants c0 ; c1 ; : : :; Boolean operators ^, :, _, ), , true (true), false (false); quantifiers 8 and 9; together with temporal operators(always in the future), fi (sometime in the future), g(at the next moment), U(until), and W (weak until). There are no function symbols or equality in this FOTL language, but it does contain constants. For a given formula,, const () denotes the set of constants occurring in. We write (x) to indicate that(x) has at most one free variable x (if not explicitly stated otherwise).
N
Formulae in FOTL are interpreted in first-order temporal structures of the form M = hDn ; In i, n 2, where every
Dn is a non-empty set such that whenever n < m, Dn  Dm, and In is an interpretation of predicate and constant symbols over Dn. We require that the interpretation of constants is rigid. Thus, for every constant c and all moments of time i; j  0, we have Ii (c) = I j (c).
N
A (variable) assignment a is a function from the set of individual variables to [n2N Dn. (This definition implies that variable assignments are rigid as well.) We denote the set of all assignments by V.
For every moment of time n, there is a corresponding first-order structure, Mn = hDn ; In i; the corresponding set of variable assignments Vn is a subset of the set of all assignments, Vn = fa 2 V j a(x) 2 Dn for every variable xg; clearly, Vn  Vm if n < m. Intuitively, FOTL formulae are interpreted in sequences of worlds, M0 ; M1 ; : : : with truth values in different worlds being connected via temporal operators.
The truth relation Mn j=a  in a structure M, only for those assignments a that satisfy the condition a 2 Vn, is defined inductively in the usual way under the following
Mn+1 j=a ; there exists m  n such that
Mm j=a ; for all m  n, Mm j=a ; there exists m  n, such that
Mm j=a ; and for all i 2 ; n  i < m implies Mi j=a ;
Mn j=a ( U ) or Mn j=a :
N
M is a model for a formula  (or  is true in M) if there exists an assignment a in D0 such that M0 j=a. A formula is satisfiable if it has a model. A formula is valid if it is true in any temporal structure M under any assignment a in D0.
The models introduced above are known as models with expanding domains. Another important class of models consists of models with constant domains in which the class of first-order temporal structures, where FOTL formulae are interpreted, is restricted to structures M = hDn ; In i, n 2, such that Di = D j for all i; j 2. The notions of truth and validity are defined similarly to the expanding domain case.
It is known   that satisfiability over expanding domains can be reduced to satisfiability over constant domains.
N
N
Example 1 The formula 8xP(x) ^(8xP(x) ) g8xQ(x)) ^ fi:Q(c) is unsatisfiable over both expanding and constant domains; the formula
8xP(x) ^(8x(P(x) ) gQ(x))) ^ fi:Q(c) is unsatisfiable over constant domains but has a model with an expanding domain.
This logic is complex. It is known that even small fragments of FOTL, such as the two-variable monadic fragment (all predicates are unary), are not recursively enumerable. However, the set of valid monodic formulae(see Definition 1 below) is known to be finitely axiomatisable.
Definition 1 An FOTL-formula  is called monodic if any subformulae of the form T, where T is one of g,, fi(or 1 T 2, where T is one of U, W ), contains at most one free variable.
3. Divided Separated Normal Form (DSNF)
Definition 2 A temporal step clause is a formula either of the form p ) gl, where p is a proposition and l is a propositional literal, or (P(x) ) gM (x)), where P(x) is a unary predicate and M (x) is a unary literal. We call a clause of the the first type an (original) ground step clause, and of the second type an (original) non-ground step clause.
Definition 3 A monodic temporal problem in Divided Separated Normal Form (DSNF) is a quadruple hU ; I ; S ; E i, where 1. the universal part, U, is given by a set of arbitrary closed first-order formulae;
2. the initial part, I, is, again, given by a set of arbitrary closed first-order formulae;
Let P be a monodic temporal problem, and let
Pi1 (x) )
The sets U, I, S, and S are finite.
Note that, in a monodic temporal problem, we do not allow two different temporal step clauses with the same left-hand sides. A problem with the same left-hand sides can be easily transformed by renaming into one without.
In what follows, we will not distinguish between a fiV nite set of formulae X and the conjunction X of formulae within the set. With each monodic temporal problem, we associate the formula
I^
U^
8xS ^
^
Pi j (c)gMi j (c);
)g9x ^ Mi j (x);kx
9
Pi j (x)
)j =1x
8
_k(2)k(3)j =1g8x _ Mi j (x) k
Pi j (x)
)j =1(4)j =1are called derived step clauses, where c 2 const (P) and j = 1 : : : k. Formulae of the form (2) and (3) are called ederived step clauses. Note that formulae of the form (2) and(3) are logical consequences of (1) in the expanding domain case; while formulae of the form (2), (3), and (4) are logical consequences of (1) in the constant domain case. As
Example 1 shows, (4) is not a logical consequence of (1) in the expanding domain case.
Let f1 ) g1 ; : : : ; n ) gn g be a set of derived(e-derived) step clauses or original ground step clauses.
Then
^nxE :
8g^ i ni )i=1
Now, when we talk about particular properties of a temporal problem (e.g., satisfiability, validity, logical consequences etc) we mean properties of the associated formula.
Arbitrary monodic FOTL-formulae can be transformed into DSNF in a satisfiability equivalence preserving way using a renaming technique replacing non-atomic subformulae with new propositions and removing all occurrences of the U and W operators.(1)be a subset of the set of its original non-ground step clauses.
Then formulae of the form
3. the step part, S, is given by a set of original (ground and non-ground) temporal step clauses; and 4. the eventuality part, E, is given by a set of eventuality clauses of the form fiL(x) (a non-ground eventuality clause) and fil (a ground eventuality clause), where l is a propositional literal and L(x) is a unary non-ground literal.gMi1 (x); : : : ; Pi (x) ) gMi (x) k ki=1is called a merged derived step clause (and merged ederived step clause, resp.).
Let A ) gB be a merged derived (e-derived) step clause, let P1 (x) ) gM1 (x); : : : ; Pk (x) ) gMk (x) be a subset of the original step clauses, and let A (x) ff A ^
Vk P (x) ii=1
;
B (x) ff B ^
Vk M (x) ix(A (x) )
8
:
Theni=1gB (x))
4. Completeness Calculus
A resolution-like procedure for the monodic fragment over constant domains has been introduced in. Although satisfiability over expanding domains can be reduced to satisfiability over constant domains, it has been proved in   that a simple modification of the procedure can be directly applied to the expanding domain case. We sketch the monodic temporal resolution system here to make the paper self-contained. We use this completeness calculus to show relative completeness of the calculus presented in the next section. More details on the completeness calculus, as well as proofs of the properties stated below, can be found in   and   for the constant and expanding domain cases, respectively.is called a full merged step clause (full e-merged step clause, resp.).
Let P be a monodic temporal problem, Pc = P [ ffiL(c) j fiL(x) 2 E ; c 2 const (P)g is the constant flooded form of P. Evidently, Pc is satisfiability equivalent to P.
We present now two calculi, Ic and Ie, aimed at the constant and expanding domain cases, respectively. The inference rules of these calculi coincide; the only difference is in the merging operation. The calculus Ic utilises merged derived and full merged step clauses; whereas Ie utilises merged e-derived and full e-merged step clauses.
Inference Rules. In what follows, A ) gB and Ai ) gBi denote merged derived (e-derived) step clauses, g(B (x))) and 8x(Ai(x) ) g(Bi (x))) denote
8x(A (x) ) full merged (full e-merged) step clauses, and U denotes the(current) universal part of the problem.

Step resolution rule w.r.t. U :
A ) gB
:A(gU res ) ;where U [ fB g `?.


Initial termination rule w.r.t. U : The contradiction
? is derived and the derivation is (successfully) terminated if U [ I `?.
Eventuality resolution rule w.r.t. U :g(B1 (x)))x(A1 (x) )...
8g(Bn (x)))x(An (x) )
8x
8
VnfiL(x)fi( U res ) ;
Ai (x)
:i=1where 8x(Ai (x) ) gBi (x)) are full merged (full emerged) step clauses such that for all i 2 f1; : : : ; ng, the loop side conditions 8x(U ^ Bi (x) ) :L(x)) and x(U ^ Bi (x) )
8
Wn (A (x))) are both valid1. jj =1
The set of full merged (full e-merged) step clauses, satisfying the loop side conditions, is called a loop in Wn A (x) is called a loop forfiL(x) and the formulajj =1mula.

Ground eventuality resolution rule w.r.t. U :
A1 ) gB1
:::
Vn
An ) gBnfilfi( U res ) ;
Ai
:i=1where Ai ) gBi are merged derived (e-derived) step clauses such that the loop side conditions U ^ Bi ` l
:and U ^ Bi `
Wn Ajfor alli 2 f1; : : : ; ng arej =1both valid. Ground loop and ground loop formula are defined similarly to the case above.
A derivation is a sequence of universal parts, U = U0 
U1  U2  : : :, extended little by little by the conclusions of the inference rules. Successful termination means that the given problem is unsatisfiable. The I, S and E parts of the temporal problem are not changed in a derivation.
Theorem 1 (see, theorems 2 and 3) The rules of Ic preserve satisfiability over constant domains. If a monodic
`8 :
)
1 In the case U etrue, can x L(x), the degenerate clause, true be considered as a premise of this rule; the conclusion of the rule is then true and the derivation successfully terminates.
:temporal problem P is unsatisfiable over constant domains, then there exists a successfully terminating derivation in Ic from Pc.
Theorem 2 (see, theorems 2 and 3) The rules of Ie preserve satisfiability over expanding domains.
If a monodic temporal problem P is unsatisfiable over expanding domains, then there exists a successfully terminating derivation in Ie from Pc.
Example 2 The need for constant flooding can be demonstrated by the following example. None of the rules of temporal resolution can be applied directly to the (unsatisfiable) temporal problem given by
I = fP(c)g;
S = fq ) gqg;
U = fq  P(c)g; E = ffi:P(x)g:
If, however, we add to the problem an eventuality clausefil and a universal clause l ) :P(c), the step clause q ) gq will be a loop in fil, and the eventuality resolution rule would derive :true2.
5. Fine-Grained Resolution for the Expanding
Domain Case
The main drawback of the calculi introduced in the previous section is that the notion of a merged step clause is quite involved and the search for appropriate merging of simpler clauses is computationally hard. Finding sets of such full merged step clauses needed for the temporal resolution rule is even more difficult.
From now on we focus on the expanding domain case.
This is simpler firstly because merged e-derived step clauses are simpler (formulae of the form (4) do not contribute to them) and, secondly, because conclusions of all inference rules of Ie are first-order clauses.
We now introduce a calculus where the inference rules of Ie are refined into smaller steps, more suitable for effective implementation. First, we concentrate on the implementation of the step resolution inference rule; then we show how to effectively find premises for the eventuality resolution rule by means of step resolution.
The calculus is inspired by the following consideration:
Suppose that Ie applies the step resolution rule to a merged e-derived step clause A ) gB. The rule can be applied if B [ U `? and this fact can be established by a firstorder resolution procedure (that would skolemise the universal part). Then the conclusion of the rule, :A, is added to U resulting in a new universal part U 0. Suppose that the :
2 Note that the non-ground eventuality fi P(x) is not used. It was shown in   that if all step clauses are ground, for constant flooded problems we can neglect non-ground eventualities.step resolution rule is applied to another merged e-derived step clause, A 0 ) gB 0. The side condition, B 0 [ U 0 `?, again can be checked by a first-order resolution procedure.
Since we never add new existential formulae, U 0 can be skolemised in exactly the same way as U. Therefore, we can actually keep U in clausal form.
Note further that we are not only going to check side conditions for the rules of the Ie by means of first-order resolution but also search for clauses to merge at the same time.
Fine-grained resolution might generate additional step clauses of the form
C)gD:(5)
Here, C is a conjunction of propositions, unary predicates of the form P(x), and ground formulae of the form P(c), where P is a unary predicate symbol and c is a constant occurring in the originally given problem; D is a disjunction of arbitrary literals.
Definition 4 Let P be a constant flooded temporal problem; the set of clauses S(P), called the result of preprocessing, consists of step clauses from P and Deduction rules
1. Arbitrary (first-order) resolution between universal clauses. The result is a universal clause.
2. Arbitrary (first-order) resolution between initial and universal clauses (or just between initial clauses). The result is an initial clause.
3. Fine-grained (restricted) step resolutiong(D1 _ L) C2 ) g(D2 _ :M)(C1 ^ C2 ) ) g(D1 _ D2 )
C1 )
;where C1 ) g(D1 _ L) and C2 ) g(D2 _ :M ) are step clauses and  is an mgu of the literals L and M such that  does not map variables from C1 or C2 into a constant or a functional term.3
C1 ) g(D1 _ L) D2 _ :N
C1  ) g(D1 _ D2 )
;where C1 ) g(D1 _ L) is an step clause, D2 _ :N is a universal clause, and  is an mgu of the literals L and N such that  does not map variables from C1 into a constant or a functional term.
4. Right factor
1. For every original non-ground step clause
P(x) )
C ) g(D _ L _ M )
C ) g(D _ L)gM(x)and every constant c 2 const (P), the clause
P(c) )gM(c)(6)where  is an mgu of the literals L and M such that does not map variables from C into a constant or a functional term.
5. Left factoris in S(P).
2. Clauses obtained by clausification of the universal and initial parts, as if there is no connection with temporal logic at all, are in S(P). The resulting clauses are called universal clauses and initial clauses resp. Originally, universal and initial clauses do not have common
Skolem constants and functions. Initial and universal clauses are kept separately.
In sections 5.1 and 5.2, we assume that a given problem is preprocessed.
5.1. Fine-grained step resolution
Fine-grained step resolution consists of a set of deduction and deletion rules. We implicitly assume that different premises and conclusion of the deduction rules have no variables in common; variables are renamed if necessary.
;gD gD(C ^ L ^ M ) )(C ^ L) )
;where  is an mgu of the literals L and M such that does not map variables from C into a constant or a functional term.
6. Clause conversion a step clause of the form C ) the universal clause :C.gfalse is rewritten into
Deletion rules
1. First-order deletion: (first-order) subsumption and tautology deletion in universal clauses; subsumption and tautology deletion in initial clauses; subsumption of initial clauses by universal clauses (but not vice versa).
3 This restriction justifies skolemisation: Skolem constants and functions do not sneak in the left-hand side of step clauses, and, hence, Skolem constants from different moments of time do not mix.
2. Temporal deletion:
A universal clause D2 subsumes a step clause C1 ) gD1 if D2 subsumes D1 or D2 subsumes4 :C1.
A step clause C1 ) gD1 subsumes a step clause
C2 ) gD2 if there exists a substitution  such that
D1   D2 and :C1   :C2.
A step clause C ) gD is a tautology if D is a tautology. (Note that, since we do not have negative occurrences to the left-hand side of step clauses, C cannot be false). Tautologies are deleted.
We adopt the terminology from. A (linear) proof by fine-grained resolution of a clause C from a set of clauses
S is a sequence of clauses C1 ; : : : ; Cm such that C = Cm and each clause Ci is either an element of S or else the conclusion by a deduction rule from C1 ; : : : ; Ci 1. A proof of false is called a refutation. A (theorem proving) derivation by fine-grained resolution is a sequence of sets of clauses
S0 ff S1 ff : : : such that every Si+1 differs from Si by either adding the conclusion of a deduction rule or else deleting a clause by a deletion rule. We say that a clause C is derived by fine-grained resolution from S0 if C 2 Si for some i.
Note 1 Fine-grained step resolution without the restriction on substitutions would, certainly, lead to unsoundness: The monodic problem given by
U = fu1 : 9x:Q(x); u2 : 8x(P(x) _ Q(x))g; I = 0/ ;
S = fs1 : P(x) ) gQ(x)g;
E = 0/ ; which is satisfiable, would wrongly be declared unsatisfiable without this restriction (After skolemisation, U s = fus1 : :Q(c); us2 : P(x) _ Q(x)g, then unrestricted resolution would derive us3 : :P(c) from us1 and s1, and then the contradiction from us1, us2, and us3.)
Example 3 It might seem that the restriction on mgus is too strong and destroys completeness of the calculus. For example, at first glance it may appear that under this restriction it is not possible to deduce a contradiction from the following (unsatisfiable) temporal problem P given by
I = f8xP(x)g;
U = f:Q(c)g;
S = fP(x) ) gQ(x)g; E = 0/ :
However we can derive a contradiction because we apply our calculus to S(P) which contains an additional step clause
P(c) ) gQ(c):
:Lk (x)).and further, : L x ^ ^L( 1( )
:::k (x))abbreviates
Lemma 3 Let P = hU ; I ; S ; E i be a monodic temporal problem and S = S(P) be the result of preprocessing. Let
C ) gfalse be an arbitrary final clause derived by finegrained step resolution from S. Then there exists a derivation U = U0  U1  : : : by the step resolution rule of Ie and a merged e-derived step clause A ) gB such that
B [ Ui `?, for some i  0, and A = e9C, where e9 means existential quantification over all free variables.
Proof (Sketch). Since C ) gfalse is derivable, there exists its proof  by fine-grained resolution. We prove the lemma by induction on the number of applications of the clause conversion rule in. Suppose we proved the lemma for proofs containing less than n applications of the clause conversion rule, and let  contains n such applications.
Then every conclusion of the clause conversion rule is also a conclusion by the step resolution rule of Ie. It can be shown that both the induction basis and induction step follow from the following claim.
Claim. Let  be a proof of C ) gfalse by the rules of finegrained resolution, except the clause conversion rule, from a set of step clauses S and a set of universal clauses U. Then there exists a merged e-derived step clause A ) gB such
9C. that B [ U `? and A = e
Let
Pi (xi ) f pif
)
)gMi (xi ) j i = 1 : : : K g gli j i = 1 : : : Lgbe the set of all step clauses from S involved in  where pi ) gli denotes either a ground step clause, or an ederived step-clause of the form (6) added by preprocessing (w.l.o.g., we assumed that all the variables x1,.., xK are pairwise distinct). We assume that  is tree-like, that is, no clause in  is used more than once as an assumption for an inference rule; we may make copies of the clauses in  in order to make it tree-like.
Note that (by accumulating the mgus used in the proof) it is possible to construct a finite set of instances of these clauses (and universal clauses) such that there exists a treelike proof of C ) gfalse from this new set of clauses and all mgus used in the proof are empty5. That is, there exist substitutions fi; j j i = 1 : : : K ; j = 1 : : : si g such that
Pi (xi )i; j f pif
)
)gMi (xi )i j j i = 1 : : : K ; j = 1 : : : si g gli j i = 1 : : : Lg
;(7)
A formal statement of completeness follows.
4 Here, Definition 5 A clause of the form C ) gfalse; where C is of the same form as in (5), is called a final clause.
:L x _ _(
1( )
:::
5 The condition that premises of the non-ground binary resolution rule should be variable disjoint may be violated here; note, however, that this condition is needed for completeness, not correctness.(together with some instances of universal clauses) contribute to the proof of C ) gfalse where all mgus used in the proof are empty, and, furthermore, s
K ^
^ i
C=i=1 j =1
Pi (xi )i; j ^
^Lx
9pi :i=1
Note further (induction) that due to our restriction on the step resolution rule, for any i; j, the substitution i; j maps xi into a free variable.
Let us group the instances of the step clauses according to the value of the substitutions.
We introduce an equivalence relation  on the clauses from (7) as follows: For every i; j; i0 ; j0 we have

Pi (xi )i; j ) gMi (xi )i; j ; Pi0 (xi0 )i0 ; j0 ) gMi0 (xi0 )i0 ; j0 2 iff xi i; j = xi0 i0 ; j0 (it can be easily checked that  is indeed an equivalence relation). Let N be the number of equivalence classes of (7) by ; let Ik be the set of indexes of the k-th equivalence class (we refer to clauses from (7) by indexes of the corresponding substitutions).
V
Let Ck = (i; j)2Ik Pi (xi )i; j, for every k, 1  k  N; let
V
V
C0 = Li=1 pi. Note that C = Nk=1 Ck ^ C0 and this parV tition of C is disjoint. Let Dk = (i; j)2Ik Mi (xi )i; j, let
Vform (2) are in S ought to preprocessing. Let for every derived rule of the form (3), V
8D ^ U `?.
D0 = Li=1 li, let D = Nk=1 Dk ^ D0. Note that e
Note further that if we replace the free variable of Dk with aV fresh constant, ck, there still exists a refutation from
N k=1 D(ck ) ^ D0 and universal clauses (with mgus applied to and intermediate clauses only). It follows that
VNuniversal k=1 9xDk (x) ^ D0 ^ U `?.
V
It suffices to note that ( Nk=1 9xCk (x) ^ C0 ) )
V g( Nk=1 9xDk (x) ^ D0 ) is a merged e-derived step
2 clause.
Lemma 4 Let P = hU ; I ; S ; E i be a monodic temporal problem and S = S(P) be the result of preprocessing. Let
U = U0  U1  : : : be a derivation by the step resolution rule of Ie. Let A ) gB be a merged e-derived step clause such that B [ Ui `?, for some i  0. Then there exists a final clause C ) gfalse, derived by fine-grained resolution
9C. from S, such that A ) e
Proof (Sketch). As in the proof of the previous lemma, it suffices to prove that under conditions of the lemma there exists a proof of a final clause C ) gfalse from the set of step clauses from S and the (current) universal part, Un, by the rules of fine-grained resolution, except the clause con9C. version rule, such that A ) e
The clause A ) gB is merged from derived clauses of the form (2) and (3). Note that all derived clauses of the ^sg9x ^ Mi j (x); s
Pi j (x) )j =1j =1consider a set of instances of non-ground step clauses from
S, fPi j (c) ) Mi j (c) j j = 1 : : : sg; where c is a new constant.
Since B [ Un `?, there exists a set of instances of step clauses (we simplify indexing for the sake of presentation)
Pj (ci ) f pif
)
)gM j (ci )g j i = 1 : : : K ; j = 1 : : : si g gli j i = 1 : : : Lg;where constants, such that
VK Vsci 1 ; :M: : ;(ccK) ^areVLnewl ^(Skolem)
U
`?(again, as in the proof n i=1 j =1 j i i=1 i of Lemma 3, pi ) gli denotes either an original ground step clause or a clause of the form (6) added by preprocessing).
Let  be a (first-order) resolution proof of ? from Un and the following set of clauses fM j (ci ) j i = 1 : : : K ; j =
1 : : : si g [ fli j i = 1 : : : Lg. Let fM j (ci ) j (i; j) 2 I g [ fli j i 2
J g, for some sets of indexes I and J, be its subset containing all clauses involved in  (and only the clauses involved in ). Then there exists a proof  by fine-grained step resolution fromgM j (ci ) j (i; j) 2 I g gli j i 2 J g
)(and V universal clauses) of a final clause C ) gfalse, where V
C = (i j)2I Pj (ci ) ^ j2J pi.
P j (c i ) f pif
)
;
We assume, for simplicity of the proof, that the lifting theorem (cf. e.g.  ) holds for, that is, there exists a non-ground (first-order) refutation 0 from fM j (x j ) j (i; j) 2
I g [ fli j i 2 J g, such that  s 0 in the terminology of  :
Every clause Ci0 of 0 is a generalisation of the corresponding clause Ci of.
It can be seen that the lifting theorem can be transfered to fine-grained inferences, and there exists a proof 0 from the set of original step clausesgM j (x j ) j (i; j) 2 I g gli j i 2 J g
)(and universal clauses) of a final clause C0 ) gfalse such that 0 s, that is, every intermediate clause Ci0 ) gD0i from 0 is a generalisation of a corresponding clause from
Pj (x j ) f pif
). (The only difficulty is to ensure the requirement on mgus imposed by our inference system. Note that none of the(Skolem) constants c1 ; : : : ; cK occurs in 0. If, in the proof
0, a constant or a functional term was substituted into a variable occurring in the left-hand side of a clause, this clause would not be a generalisation of any clause from.)
This implies the conclusion of the lemma.
2
Lemma 3 ensures soundness of fine-grained step resolution.
Lemma 4 says that the conclusion of an application of the clause conversion rule, :C, subsumes the conclusion of an application of the step resolution rule of Ie, :A.
Theorem 5 The calculus consisting of the rules of finegrained step resolution, together with the (both ground and non-ground) eventuality resolution rule, is sound and complete for the monodic fragment over expanding domains.
Note 2 The proof of completeness given above might be hard to fulfil in the presence of various refinements of resolution and/or redundancy deletion. As a remedy, we suggest considering constrained calculi, like e.g. resolution over constrained clauses with constraint inheritance. It is known that such inference systems are complete and moreover compatible with redundancy elimination rules and many(liftable) refinements (see e.g., theorems 5.11 and 5.12, subsections 5.4 and 5.5, resp.). Here we take into account that there are no clauses with equality, and therefore all sets are well-constrained in the terminology of.
Then instead of ground clauses of the form
Pj (ci )
)gM j (ci )we consider their constrained representations
Pj (xi )
)gM j (xi )  fxi = ci g:
Recall that in accordance with the semantics of constrained clauses, a clause C  T represents the set of all ground instances C where  is a solution of T. In our case, there is exactly one solution of xi = ci given by the substitution fxi 7! ci g. So, the semantics of Pj (xi )
)gM j (xi )  fxi = ci gis just
Pj (ci )
)gM j (ci ):
So, all clauses originating from the universal part have empty constraints and all temporal clauses have constraints defined above, and there exists a non-ground proof of a constrained final clause with constraint inheritance. Note that the (Skolem) constants c1 ; : : : ; ck may only occur in constraints but not in clauses themselves. It suffices to note that in this case inferences with constraint inheritance admit only two kinds of substitutions into xi : either fxi 7! ci g(however it is impossible because ci occurs only in constraints), or fxi 7! xi0 g where xi0 is bound by the same constraint fxi0 = ci g. The case of matching xi and y where y originates from the universal part is solved by the substitution fy 7! xi g. A non-ground inference of a final clause, satisfying the conditions on substitutions in the fine-grained resolution rules, can be extracted from this constrained proof implying, thus, the conclusion of Lemma 4.
5.2. Loop search
Next we use fine-grained step resolution to find the appropriate set of full e-merged clauses to apply the (ground or non-ground) eventuality resolution rule. It has been noticed in   that in order to effectively find a loop in fiL(x) 2 E, given a formula with one free variable (x) we have to be able to find the set of all full e-merged clauses of the form gB (x)) such that the formula
8x(A (x) ) x(B (x) ^ U ) (x))
8is valid (where (x) = H (x) ^ :L(x) and H (x) is a disjunction of the left-hand sides of some full e-merged step clauses).
Let 8x(A (x) ) gB (x)) be a full e-merged step clause such that 8x(B (x) ^ U ) (x)). Note that 8x(B (x) ^ U )(x)) is valid iff 9x(B (x) ^ U ^ :(x)) is unsatisfiable.
Definition 6 Let cl be a distinguished constant to be used in loop search that we call the loop constant. We assume that the loop constant does not occur in a given problem and is not used for skolemisation.
Definition 7 Let us define a transformation for loop search on a set of universal and step clauses S as follows. LT(S) is the minimal set of clauses containing S such that for every original non-ground step clause (P(x) ) gM (x)) 2 S, the set LT(S) contains the clause
P(cl ) )gM(cl ):(8)
We add the clause6 true ) g:(cl ) to LT(S) and apply the rules of fine-grained step resolution except the clause conversion rule to it.
Lemma 6 Let S be a set of universal and step clauses, and let C ) gfalse be a final clause derived by the rules of fine-grained step resolution except the clause conversion rule from LT(S) [ ftrue ) g:(cl )g such that at least one of the clauses originating from true ) g:(cl ) is involved in the derivation. Then there exists a full e-merged(from S) clause 8x(A (x) ) gB (x)) such that the formula l
8x(B(x) ^ U ) (x)) is valid and A (x) = (e
9C )fc ! xg.
Proof (Sketch). By Lemma 3, there exists a merged (from
LT (S)) e-derived clause A ) gB such that f:(cl )g [
B [ U `? and A = e9C. It suffices to notice that 8x((A ) gB )fcl ! xg) is a full merged (from S) step clause and l
9x((x) ^ B fc ! xg ^ U ) is unsatisfiable.
2
:
:
6 In fact, a set of clauses since H (x), and (x), is a set of first-order clauses.
Function BFS
Input: A set S of universal and step clauses, saturated by fine-grained resolution and an eventuality clause fiL(x) 2 E.
Output: A formula H (x) with at most one free variable.
/ i = 0.
Method: 1. Let H0 (x) = true; N0 = 0;
2. Let Si+1 = LT(S) [ ftrue ) f(:Hi (cl ) _ L(cl ))g. Apply the rules of fine-grained step resolution except the clause conversion rule to Si+1. If we obtain a contradiction, then return the loop true (in this case 8x:L(x) is implied by the universal part). Otherwise let Ni+1 = fC j ) ffalsegkj=1 be the set of all new final clauses from Si+1.
/ return false; else let Hi+1 (x) =
3. If Ni+1 = 0, 4. If 8x(Hi (x) ) Hi+1 (x)) return Hi+1 (x).
5. i = i + 1; goto 2.
Wkl j=1 C j fc
! xg.
Figure 1. Breadth-first search using fine-grained step resolution.
Lemma 7 Let S be a set of universal and step clauses, and let 8x(A (x) ) gB (x)) be a full e-merged (from S) step clause such that 8x(B (x) ^ U ) (x)). Then there exists a derivation by the rules of fine-grained step resolution except the clause conversion rule from LT(S) of a final clause C ) gfalse such that 8x(A (x) ) (e9Cfcl ! xg)).
: A(x) ) gB(x)g, E = fe1 : fiL(x); e2 : fil g. We especially chose such a trivial example to be able to demonstrate thoroughly the steps of our proof search algorithm.
We clausify U resulting in U s = fu1 : (:B(x) _ A(x)); u2 :(:B(x) _ :L(x)); u3 : :l _ A(c)g.
S
= fs1

Proof (Sketch). The proof is analogous to the proof of Lemma 4. As we already noticed, 9x(B (x) ^ U ^ :(x)) is unsatisfiable, and this can be checked by a first-order resolution procedure. Since cl does not occur in the problem, we can skolemise this existential quantifier with cl. We lift now all Skolem constants but cl.
2
Then the loop search algorithm from   can be reformulated as shown in Fig. 1. (This algorithm is essentially based on the BFS algorithm for propositional temporal resolution.)
Lemma 8 The BFS algorithm terminates provided that all calls of saturation by step resolution terminate. If BFS returns non-false value, its output is a loop formula in L(x).
Note 3 Termination of calls by step resolution can be achieved for the cases when there exists a (first-order) resolution decision procedure   for formulae in the universal part, see also.
Theorem 9 The calculus consisting of the rules of finegrained step resolution, together with the (both ground and non-ground) eventuality resolution rule, is complete for the monodic fragment over expanding domains even if we restrict ourselves to loops found by the BFS algorithm.
5.3. Example
Let us consider a monodic temporal problem P given
/ U = f8x(B(x) ) A(x) ^ :L(x)); l ) 9xA(x)g, by I = 0, Step resolution
We can deduce the following clauses by fine-grained step resolution: s2 : A(x) ) s3 : A(x) )
gA(x) ( s1, u1) g:L(x) ( s1, u2)
The set of clauses is saturated. Now we try finding a loop in fiL(x).
Loop search
The set S = fu1; u2; u3; s1; s2; s3g; H0 (x) = true; N0 =
/ i = 0. LT(S) = flt1 : A(cl ) ) gB(cl )g.
0;
We deduce the following clauses by fine-grained step resolution (except the clause conversion rule) from
S1 = LT(S) [ fl1 : true ) gL(cl )g: l2 : A(cl ) ) l3 : A(cl ) ) l4 : true ) l5 : A(cl ) )gA(cl ) g:L(cl ) g:B(cl ) gfalse( lt1, u1)( lt1, u2)( u2, l1)( l3, l1)
The set of clauses is saturated. Then N1 = fA(cl ) ) gfalseg, H1 (x) = A(x). Obviously, 8x(H0 (x) )
H1 (x)) is not true.
Now the set S2 = LT(S) [ fl6 : true ) g(:A(cl ) _
L(cl ))g and we deduce from it the following: l7 : A(cl ) ) gA(cl ) l8 : A(cl ) ) g:L(cl ) l9 : true ) g(:B(cl ) _ L(cl )) l10 : true ) g(:B(cl ) _ :A(cl )) l11 : A(cl ) ) gL(cl ) l12 : A(cl ) ) g:A(cl ) l13 : true ) g:B(cl ) l14 : A(cl ) ) g:B(cl ) l15 : A(cl ) ) gfalse( lt1, u1)( lt1, u2)( u1, l6)( u2, l6)( l7, l6)( l8, l6)( u2, l9)( l8, l9)( l8, l11)

The set of clauses is saturated. N2 = fA(cl ) ) gfalseg, H2 (x) = A(x).
As 8x(H1 (x) ) H2 (x)), the loop is A(x).
Eventuality resolution
We can apply now the eventuality resolution rule whose conclusion is u4 : :A(x):

Step resolution u5 : :l

Loop search
S = fu1; u2; u3; u4; u5; s1; s2; s3g; H0 (x) = true; N0 =
/ i = 0; LT(S) = flt1 : A(cl ) ) gB(cl )g; S1 =
0;
LT(S) [ fl16 : true ) gl g; and we can deduce: l17 : true )
( u3, u4)gfalse ( l16, u5)that is, a contradiction. The loop is true.
Eventuality resolution
We can apply now the eventuality resolution rule whose conclusion is :true. The problem is unsatisfiable.
Note 4 As the example shows, the presence of clauses of the form (6), introduced by preprocessing, and (8), introduced by the transformation for loop search, might lead to repeated derivations (with free variables and with constants). This can be avoided, however, if instead of generating these clauses, we relax the conditions on substitutions in the definition of rules of fine-grained resolution by allowing original constants and the loop constant to be substituted to variables occurring in the left-hand side of a step clause. It can be seen that the set of derived final clauses would be the same.
Taking into consideration this note, we do not use the reduction for loop search, and clauses l2, l3, l7, l8 would not be derived. Instead, at the first iteration of BFS on L(x), we would deduce the following clauses from S1 = S [ fl1 : true ) gL(cl )g: l40 : true ) g:B(cl ) ( u2, l1) l50 : A(cl ) ) gfalse ( s3, l1); and at the second iteration from S2 = LT(S) [ fl6 : true ) g(:A(cl ) _ L(cl ))g: l90 : true ) g(:B(cl ) _ L(cl )) l100 : true ) g(:B(cl ) _ :A(cl )) l110 : A(cl ) ) gL(cl ) l120 : A(cl ) ) g:A(cl ) l130 : true ) g:B(cl ) l140 : A(cl ) ) g:B(cl ) l150 : A(cl ) ) gfalse( u1, l6)( u2, l6)( s2, l6)( s3, l6)( u2, l90 )( s3, l90 )( s3, l110 ):
6. Conclusion
We have described a fine-grained resolution calculus for monodic first order temporal logics over expanding domains. Soundness of the fine-grained inference steps is easy to prove and completeness is shown relative to the completeness proof for the expanding domain for the non-fine grained version. While the implementation based on the general calculus would involve generating all subsets of the step clauses with which to apply the step and eventuality resolution rules, the fine-grained resolution inference rules can be implemented directly using any appropriate firstorder theorem prover for classical logics. This makes the new calculus presented here particularly amenable to efficient implementation.
As part of our future work, we will examine the extension of this approach to the case of temporal models with constant domains. We also aim to implement and test the calculus defined here.
Finally, we wish to acknowledge support for this work from EPSRC via research grant GR/R45376/01.
References
  A. Artale, E. Franconi, F. Wolter, and M. Zakharyaschev. A temporal description logic for reasoning over conceptual schemas and queries. In Proceedings of JELIA02, volume 2424 of LNCS, pages 98
110. Springer, 2002.
  L. Bachmair and H. Ganzinger. Resolution theorem proving. In A. Robinson and A. Voronkov, editors, Handbook of Automated Reasoning, chapter 2, pages
1999. Elsevier, 2001.
  A. Degtyarev and M. Fisher. Towards first-order temporal resolution. In KI 2001, Proceedings, volume
2174 of LNCS, pages 1832. Springer, 2001.
  A. Degtyarev, M. Fisher, and B. Konev.
Exploring the monodic fragment of first-order temporal logic using clausal temporal resolution. Technical Report ULCS-03-012, University of Liverpool, Department of Computer Science, 2003. http://www.csc.liv.ac.uk/research/.
  A. Degtyarev, M. Fisher, and B. Konev.
Monodic temporal resolution.
In Proc. CADE19, to appear, LNAI. Springer, 2003.
Available as Technical report ULCS-03-001 from http://www.csc.liv.ac.uk/research/.
  A. Degtyarev, M. Fisher, and B. Konev. Monodic temporal resolution: the expanding domain case.
Technical Report ULCS-03-004, University of Liverpool, Department of Computer Science, 2003. http://www.csc.liv.ac.uk/research/.
  F. Wolter and M. Zakharyaschev. Axiomatizing the monodic fragment of first-order temporal logic. Annals of Pure and Applied logic, 118:133145, 2002.
  C. Dixon. Temporal resolution using a breadth-first search algorithm. Annals of Mathematics and Artificial Intelligence, 22:87115, 1998.
  F. Wolter and M. Zakharyaschev. Qualitative spatiotemporal representation and reasoning: a computational perspective. In Exploring Artificial Intelligence in the New Millenium, pages 175216. Morgan Kaufmann, 2002.
  C. Fermuller, A. Leitsch, U. Hustadt, and T. Tammet.
Resolution decision procedures. In A. Robinson and A. Voronkov, editors, Handbook of Automated Reasoning, volume II, chapter 25, pages 17911850. Elsevier, 2001.
  M. Fisher. A normal form for temporal logics and its applications in theorem proving and execution. Journal of Logic and Computation, 7(4):429456, 1997.
  D. Gabelaia, R. Kontchakov, A. Kurucz, F. Wolter, and M. Zakharyaschev. On the computational complexity of spatio-temporal logics. To appear in the proceedings of FLAIRS, 2003.
  I. Hodkinson, F. Wolter, and M. Zakharyaschev. Decidable fragments of first-order temporal logics. Annals of Pure and Applied Logic, 106:85134, 2000.
  G. J. Holzmann. The model checker Spin. IEEE Trans. on Software Engineering, 23(5):279295, 1997.
  R. Kontchakov, C. Lutz, F. Wolter, and M. Zakharyaschev. Temporalising tableaux. Studia Logica, to appear.
  Alexander Leitsch.
Springer, 1997.
The Resolution Calculus.
  Z. Manna and A. Pnueli. The Temporal Logic of Reactive and Concurrent Systems: Specification. Springer, 1992.
  S. Merz. Decidability and incompleteness results for first-order temporal logic of linear time. Journal of Applied Non-Classical Logics, 2:139156, 1992.
  R. Nieuwenhuis and A. Rubio. Paramodulation-based theorem proving. In A. Robinson and A. Voronkov, editors, Handbook of Automated Reasoning, chapter 7, pages 371443. Elsevier, 2001.
  A Pnueli. The Temporal Logic of Programs. In Proceedings of the Eighteenth Symposium on the Foundations of Computer Science, 1977.
  F. Wolter and M. Zakharyaschev. Decidable fragments of first-order modal logics. Journal of Symbolic Logic, 66:14151438, 2001.2012 19th International Symposium on Temporal Representation and Reasoning
Compositional Renement for Real-Time Systems with Priorities
Abdeldjalil Boudjadar, Jean-Paul Bodeveix, Mamoun Filali
IRIT-UPS, Universite de Toulouse
Toulouse, France
{boudjada, bodeveix, lali}@irit.fr
Sifi is an abstraction of Si. With the above fact, checking that S satises a property P becomes more tractable and simply consists of checking that each component Sifi satises a property Pi, where P is a composition of Pi. That is what happen in compositional verication   and abstractionbased verication. Dening the parallel composition and nding a suitable renement relation for real-time systems with communication, priorities and variables is a tough task.
Real-time system properties are often formalized using timeconstraints and priorities. To consider such concepts, we introduce real-time systems with a global space (variables and clocks) and priorities (static and dynamic). Similarly to process algebras, to deal with hierarchical design and specications, real-time formalisms have known a large number of composition approaches. However, a compositional framework with high-level concepts like variables, communication and priorities is still lacking. Several works,,,   have focused on this subject by analyzing thoroughly the problem and criticizing existing solutions. In fact, this paper is a follow up of   where we have revisited the composition of timed systems, without priorities, and proposed a new communication mechanism for UPPAAL timed automata.
In, we have dened an original composition operator endowed with good properties (associativity, renement, etc.), and supporting communications via synchronization of actions and shared variables. Through the introduction of priority, we revisit the framework dened in   for reasoning about the composition of timed systems. Thereafter, our framework, dened with priorities, will be instantiated for UPPAAL timed automata with three priority orders : static priority, priority on channels and priority on processes, where we will analyze different priority relations, and give both operational semantics and renement of timed automata TA and networks of timed automata NTA (in compositional way). The rest of our paper is organized as follows: Section 2 presents the existing related work. In Section 3, we present the formal basis of our work, where we introduce Communicating Labelled Transition
Systems with location Invariants and Priorities (CLTSIP). We give a sufcient condition for the bisimilarity and dene an associative product of CLTSIPs. Moreover, we dene ETTSs as CLTSIPs which synchronize on time instants. Section 4 introduces UPPAAL TA and NTA with committed locations, priority on channels and priority on processes. Here, we show the compositionality of NTA semantics in terms of ETTSs, where the two corresponding ETTS-based semantics
AbstractHigh-level requirements of real-time systems like as time constraints, communications and execution schedulability make the verication of real-time models arduous, where a system is the interaction of a possibly unbounded set of components.
Priorities have been introduced to resolve execution conicts, and by that, prevent the combinatorial explosion of state space. In this paper, we are interested in the composition and renement of timed systems by considering static and dynamic priorities.
Firstly, we propose a revised denition of the product of extended timed transition systems with static and dynamic priorities associated to individual transitions. Afterwards, we study the(compositional) renement of compound extended timed systems.
Without sacricing compositionality, we instantiate this framework for the case of UPPAAL networks of timed automata with static priority Committedness, dynamic priority between channels and priority between processes. Moreover, we show how to associate an Extended Timed Transition System (ETTS) to timed automata (TA), where an unique generalized dynamic priority system of ETTS is derived from both dynamic priority orders: priority between channels and priority between processes.
Keywords-Timed systems; composition; renement; priorities.
I. I NTRODUCTION
The concurrency theory   is an extremely helpful concept whereby the design of complex systems becomes as far as tractable. It has by now established itself as an extensive research eld for mastering the schedulability of executions.
However, concurrency has a real impact on model checking of real-time systems, where conicts and non-determinism of executions are greatly diverging together with the number of system (competing) processes, which often leads to combinatorial explosion of the state space, the reason for this being that time is considered as part of the state. To tackle non-determinism and execution conicts, priorities have been introduced as a scheduling order. Composition, renement and model-checking of timed systems with priorities have been intensively studied,,,,,,. The ultimate goal of these work is to deal with details resulted from the use of clock variables and evolutive data structures, required by real-time applications. Abstraction renement   plays a key role in the design and verication of real-time systems. It enables to abstract unbounded data structures and implementation details whereby, we are able to perform model checking on a system S fi = S1fi fi... fi Snfi instead of the original complex system S = S1 fi... fi Sn, where each
1530-1311/12 $26.00  2012 IEEE
DOI 10.1109/TIME.2012.21
57priority orders on channels and on processes, and establish their compositional semantics in terms of ETTSs.are equivalent: a direct one (an ETTS associated to the NTA) and the product of ETTSs, associated to individual timed automata, composed with a restriction. We also establish an interesting renement property stating that: the renement of a NTA consists in the renements (separately) of its individual
TA. Finally, we show an application of our framework to rene a version of the Alternating Bit Protocol, and conclude with future work.
III. T RANSITION S YSTEM E XTENSIONS
In this section, after introducing priorities, we give a brief recall of one of the fundamental models of concurrency, transition systems, originally introduced in   and since then studied extensively by   and others. Roughly speaking, transition systems are an elegant model for representing the behavioral aspects. Due to their safety properties veriable using model-checking, transition systems have been intensively applied to the modelling of complex systems, as well as for giving semantics to synchronous languages and realtime formalisms. In what follows, we dene composable symbolic transition systems (CLTSIP) as a modeling framework.
Thereafter, we give their associative product and study the renement of their parallel composition.
II. R ELATED W ORK
Composition and renement of real-time systems with priorities have been intensively studied,,,,   during the last two decades. However, a compositional framework merging different priority systems is still relatively lacking. Several works of Sifakis,,, Cleaveland,   and UPPAAL team,   have focused on the modeling and synthesis of timed systems with priorities. They represent a common theoretical basis for the modeling with priorities.
The authors of   dene a design framework for both safety and deadlock-freedom requirements. The framework consists of a priority system, where an action ai has (dynamic) priority over another action aj once a condition cij is satised together with the enabledness of actions. In the same way,   denes a dynamic priority on actions, where an action ai has a priority on an action aj during a certain time interval.
In fact, such dynamic priority relations are a partial function because they are only applied under the satisfaction of an extra condition on comparable actions.
In, the authors dene an extension of timed automata with a dynamic priority order between actions and another priority order between processes. They give an efcient algorithm to compute subtractions of DBMs (Difference Bounded
Matrices). The authors dene a non compositional semantics of networks of extended TA, in terms of timed transition systems. Under certain restrictions, they show how an unique generalized priority order can be derived from both action and process priority orders.
In, the authors describe a modeling framework for real-time systems, using dynamic priorities, which essentially extends CCS (Calculus of Communicating Systems) algebra
  with dynamic priorities. Such a proposal reduces drastically the state space of systems and preserves their functional behavior. In fact, action priorities are not constant and may change when the system evolves. Formally, each action priority is inferred from delays preceding that action. Accordingly, the longer is the delay preceding an action, the lower is its priority.
In this paper, we present a compositional framework for the composition and renement of timed systems with both static and dynamic priorities. To this end, we consider an extended structure of timed transition systems ETTS with variables, location invariants and communication where each transition possesses a static priority s and a dynamic one d. We dene an associative parallel product of ETTSs together with a compositional renement property. Moreover, we instantiate our framework for the case of UPPAAL networks of timed automata, with the static priority committedness and dynamic
A. Priority Systems
Priorities,,,,,   have been introduced as a way to structure and control the usage of shared resources, by specifying that some actions or behavior are privileged over others. They offer a scheduling order to deal with nondeterminism and execution conicts. The BIP language   and ACSR algebra   provide a powerful mechanism to express different sort of priorities. Mainly, we distinguish static and dynamic priorities:
Static priorities,,   dene an order between transition executions regardless of their enabledness. With such priorities, non-enabled higher-priority transitions hide enabled lower-priority transitions, which often leads to a deadlock. In UPPAAL timed automata, the static priority is represented by the notion of Committedness(two priority levels) where committed transitions, those outgoing from a committed location, have priority over non-committed ones.
Dynamic priorities,,,   state that an enabled transition hides a lower-priority transition.   introduces a conditional dynamic priority relation, where an enabled transition hides a lower-priority one if a given condition holds. Another class of priority relations   consists to restrict the applicability of priority to a given time interval. The semantics of priority relations,, dened over timed systems, is given by a model transformation where only dynamically higher-priority transitions are held.
Denition 1 (Priority system): A priority system P is a triplet ffP, , fffi where ffP, fi is a join semi-lattice, andff : P  P  P is an associative and commutative operator dening the maximum of two values. We also use ffi pi to represent the maximum of a nite non empty set of values.
In fact, the join semi-lattice ffP, fi represents a partially ordered set of priority values, where each subset of P has a least upper bound.
58
B. Labelled Transition Systems
Labelled transition systems   are the reference model used to express and compare behaviors through simulations.
They offer a strong notion of equivalence that can be checked efciently. Firstly, let us start with a brief recall of classical labelled transition systems (LTS).
Denition 2 (LTS): A labelled transition system (LTS) over an alphabet  is a tuple ffQ, Q0, T r,,, fi where:
0
Q is the state space such that Q  Q is the set of initial states, T r is the set of transitions, : T r  Q and  : T r  Q are functions associating, respectively, source and target states to each transition, : T r   is a function associating to each transition a label. l
For the sake of simplicity, we write t : q  q fi for t  T rfi with (t) = q, (t) = q, (t) = l. If useless, the name of a transition will be omitted. Moreover, projection functions,  and  can be omitted and systematically inferred from the transition relation. By now, we give LTSs simulation to check that a concrete LTS implements an abstract one.
Denition 3 (Simulation): Given two labelled transition systems Tc = ffQc, Q0c, T rc fi (concrete) and Ta =ffQa, Q0a, T ra fi (abstract), Ta simulates Tc through a relation
R  Qc  Qa, denoted by Tc
R Ta, if:
0
0 qc  Qc, there exists qa  Qa such that R(qc, qa ). lfififi qc qc qa l, if qc c qc and R(qc, qa ) there exists qa lfififi
Qa such that qa a qa and R(qc, qa ).
Accordingly, two LTSs Ti and Tj are bisimilar through a relation R  Qi  Qj, denoted by Ti R Tj, if Ti
R Tj and Tj
R1 Ti.
Static priority expresses that a higher-priority transition hides a lower-priority one. The hiding is supposed to be static: a non-rable high-priority transition can hide a rable lower-priority transition.
Dynamic priority states that an enabled priority transition hides lower-priority ones. An enabled transition is rable if it is not hidden by another higher-priority enabled transition.
Throughout this paper, the static priority is considered rst.
We have also introduced location invariants over the global space to restrict the set of states, by reducing the global space valuations.
Denition 4 (CLTSIP): Given two priority systems Ps =ffPs, s, ffs fi (static) and Pd = ffPd, d, ffd fi (dynamic), a composable LTS with location invariants and priorities (CLTSIP) over a shared space G, an action language A 1, a set of one-to-one channels C and a set of synchronization events M is a tuple ffQ, q 0, G0, I, T r,,, fi where:
C. Composable LTS with Location Invariants and Priorities
Q is the set of locations (local states), q 0 is the initial location, G0 is the set of initial global states, I : Q  2G associates an invariant to each location, T r is the set of transitions, : T r  Q and  : T r  Q are functions associating, respectively, the source and target locations of each transition, : T r  LAPs Pd is a function associating to each transition the corresponding label, action, static priority value and dynamic one, where L = C?  C!  M  { } is the set of labels. C! and C? correspond respectively to send and receive labels over channels C. M is the set of multiple (many to many) synchronization events and  is the internal event.
Moreover, a CLTSIP must satisfy the wellformedness condition: n-ary synchronization transitions, with a label in M, are supposed to have the lowest static and dynamic priorities.
In this section, we dene composable LTS with location invariants and priorities (CLTSIPs), as an extension of labelled transition systems with shared variables, communication, static priority, dynamic priority and location invariants. Moreover, we specialize both state space and alphabet to allow several communication protocols between transition systems: via a shared space: we distinguish local and global state spaces, and introduce abstract actions that update the global state space. These actions can be non-deterministic and blocking. via CCS-like channels  : we introduce a set C of sendreceive channels, where two transitions synchronize if their actions are complementary. The resulting transition, of such a synchronization, corresponds to an internal transition in the composition. via CSP (Communicating Sequential Processes)-like synchronization  : we introduce a set M of many-to-many synchronization events, which enable to model a system transition where all processes perform a lock-step.
Throughout this paper, we use such a synchronization to model time-evolution transitions.
Furthermore, to reduce the non-determinism and execution conicts, we consider the following priority mechanisms.l/a
Here and elsewhere, we write t : q s,d q fi for a transition t  T r with (t) = q, (t) = q fi, (t) = ffl, a, s, dfi. If not needed, the name of a transition will be omitted. Again, the set of transitions T r is often denoted by the transition relation, which enables to omit the projection functions,  and. The semantics [[.]] of the action language A is given by
[[.]] : A  2GG. Let us consider the following predicates:l/a
A transition t : q s,d q fi is said to be enabled in a global state G if Gfi | (G, Gfi )  [[a]] and Gfi |= I(q fi ). l/a
A transition t : q s,d q fi is said to be statically hiddenfifil /aif tfi : q sfi,dfi q fifi such that s s sfi.l/a
A transition t : q s,d q fi is said to be dynamicallyfil /afihidden if tfi : q sfi,dfi q fifi enabled and non statically hidden such that d d dfi.
Accordingly, a transition is said to be hidden if it is statically and dynamically hidden.
1 This action language is abstract here. It will be made more precise in section IV-B
59
Denition 5 (Semantics of a CLTSIP): Given a global space G, a static priority system Ps = ffPs, s, ffs fi, a dynamic priority system Pd = ffPd, d, ffd fi and an action language semantics [[.]] : A  2GG. The semantics of the CLTSIP ffQ, q 0, G0, I, T rfi is the LTS:
Q  G, 0
0
0
{q }  (G  I(q )), fil/afifrom a location corresponding to q in the abstract CLTSIP
T2. The universal quantier given in Item (2) dissociates the condition on priorities from that of renement and makes, by that, the proofs further simpler than that of the LTS-based renement.
Proof. Straightforward.
1) Restriction of a CLTSIP: The restriction   of a CLTSIP, over a set of channels, is a CLTSIP where transitions composable over these channels have been removed together with transitions of lower static priority.
Denition 7 (CLTSIPs restriction): Given a CLTSIP T =ffQ, q 0, G0, I, fi over a shared space G and a set of channels
C. Let C fi  C, we dene the restriction of T over C fi, denoted l/a by T \C fi, to be the CLTSIP ffQ, q 0, G0, I, {t : q s,d q fi |fi
{(q, G), l, (q, G ) | t : q s,d q  T r, G |= I(q), enabled(t, G), statically hidden(t) and dynamically hidden(t)}
In fact, LTS states correspond to the product of both locations and space valuations of the CLTSIP. Namely, an enabled transition t, of CLTSIP, is held if it is not statically hidden by a higher-priority transition tfi, i.e. s s sfi, and if it is not again dynamically hidden by another enabled non-hidden transition, i.e enabled(tfi, G)  statically hidden(tfi )  d d dfi.
Denition 6 (Similarity): A CLTSIP Ti is said to be(bi)similar to CLTSIP Tj if their associated LTSs are(bi)similar.
The presence of both static and dynamic priorities makes the semantics of CLTSIPs rather complex. It would be much more readable if we could get rid of managing priorities during simulation proofs. To this end, we consider a sufcient condition for the renement of CLTSIPs, expressed as the simulation of the corresponding LTSs. Firstly, we introduce the predicatelfi /afil
/ C fi  tfi : q sfi,dfi q fifi, lfi  C fi  sfi ffs s}fi.
In fact, from each location, a transition is held if it is neither labelled by a communication l  C fi, nor statically hidden by another communicating transition (over C fi ) outgoing from that location.
Theorem 2 (Renement and restriction): Let Tc, Ta be two
CLTSIPs dened on the same set of channels C, then Tc
Ta  Tc \C
Ta \C.
Proof. It consists to show that each non-hidden concrete transition of Tc \C, labelled by  or m  M, has a corresponding abstract transition non-hidden in Ta \C.
2) Product of CLTSIPs: In what follows, we dene an associative n-ary product of CLTSIPs, where locations of composition are simply obtained by the product of individual
CLTSIP locations. Moreover, our product is parameterized by two internal operations dened on the action language: a1 fi a2 is used to compose actions associated to sendreceive communication. a1  a2 is used to compose actions associated to global synchronizations (lock-step). This operation is supposed to be commutative, respectively associative, in order to establish the commutativity, respectively associativity, of the product.
Denition 8 (N-ary product of a family of CLTSIPs):
Given an indexed family Ti = ffQi, qi0, G0i, Ii, i fi1..n of n CLTSIPs dened over the same shared space G, action language A, static priority system Ps and dynamic priority system
Pd, their productfiff 1..n Ti is dened by the CLTSIPff i Qi ff, ffq10,..., qn0 fi, i G0i, I, fi over G, Ps and Pd where I(q) = i Ii (qi ) and  is the smallest relation such that:lfi /afil/a
Ismax ts (t : q s,d q fi ) fi tfi : q sfi,dfi q fifi (s s sfi ) dening a higher static priority transition outgoing from lol/a cation q. In the same way, Ismax td (t : q s,d q fi ) fi lfi /afitfi : q sfi,dfi q fifi ((d d dfi )  enabled(tfi, G)), with(G, Gfi )  [[afi ]], is a predicate dening a higher dynamic priority transition outgoing from location q.
Theorem 1 (Renement of CLTSIPs): Given two CLTSIPs
T1 and T2 with their respective static and dynamic priority systems (Ps1, Pd1 ) and (Ps2, Pd2 ). T1 renes T2 through the renement relations Rl  Q1 Q2 and Rg  G1 G2, denoted
T1
Rl,Rg T2, if 1) The associated LTSs satisfy the sufcient condition for simulation, i.e:
0 0
Rl (q1, q2 ), 0
0 x  G1, y  G2 | Rg (x, y), l/a1t : q1 s1,d1 q1fi, q2 x xfi y such that(x, xfi )  [[a1 ]]. If Rl (q1, q2 ) and Rg (x, y) then there exist q2fi  Q2, a2, y fi, s2  Ps2, d2  Pd2 such that l/a2q2 s2,d2 q2fi  (y, y fi )  [[a2 ]]  Rl (q1fi, q2fi )
Rg (xfi, y fi ), q1  Q1 q2  Q2, Rl (q1, q2 )  I2 (q2 )  I1 (q1 ), 2) For all t1  T r1 and t2  T r2 such that Rl (1 (t1 ), 2 (t2 )) and Rl (1 (t1 ), 2 (t2 )), then
Ismax ts (t1 )  Ismax ts (t2 ), Ismax td (t1 )  Ismax td (t2 ).
Roughly speaking, the renement consists of establishing a mapping between the transitions of rening and rened
CLTSIPs. In fact, from each location q of the concrete CLTSIP
T1, the presence of a transition t1, with a maximal priority, states the presence of a maximal-priority transition outgoingti :qi s,d qifi l/alC!C?{ }q s,d q[iqifi ] l/a
Async(ti )m/ai(i) qi si,di qifi m  M m/
Ji aiqffs sq,ffd d i i ifi
Syncc?/ajc!/aiti : qi si,di qifi tj : qj sj,dj qjfi(P C) i =
 j
/ai ffajq s
60q[iqifi,jqjfi ] s d i ff sj,di ff dj
SR(ti, tj )where (P C) is a priority condition stating that if static, respectively dynamic, priorities of transitions ti and tj are increased upto the maximum si ffs sj, respectively di ffd dj, no new hiding may occur. For example, the static priority condition for CLTSIP Ti can be formally expressed as  t : l/a qi s,d qififi | (s s si )  (s ffs si ffs sj ).
The notation q[i  qifi ] states the replacement of the ith location of vector q by location qifi. If we consider UPPAAL
TA, in which transition priorities are assigned to channels, then di = dj = di ffd dj. About transition rules, Async(ti ) represents internal transitions and potential synchronizations that a CLTSIP may be willing to engage in with its environment.
Rule Sync denes a n-ary synchronization of a set of transitions on the same event m, which will be instantiated by a time-transition in the ETTS. Rule SR(ti, tj ), for send/receive, corresponds to a synchronized communication of both Ti and Tj on compatible events through a channel c  C. Let us mention that n-ary synchronization transitions, labelled by m, cannot block or be blocked. One may remark that our product is syntactical, whereby, all of the CLTSIP non-composable transitions are held.
Theorem 3 (Generalized associativity): If  is associative, i.e. iI jJi ai,j = iI,jJi ai,j, the product of CLTSIPs is associative, i.e.: iI (jJi Ti,j )  iI,jJi Ti,j
Proof. It essentially consists of dening an isomorphism between the two structures, state space and transitions, preserving labels and priorities. ff
3) Compositional Renement of CLTSIPs Product: Modelchecking of real-time systems suffers from the state explosion problem, the reason for this being that time is considered as part of the state, leading then to a widely large or even innite state space of the system. Abstraction renement plays a key role in the model-checking of complex systems where unbounded data structures can be abstracted. However, for compound systems, dening the renement of the whole system is an arduous task. In what follows, we show how the(compositional) renement   of CLTSIPs product has been brought to a set of simpler renements of individual CLTSIPs.
Theorem 4 (Compositional renement): Given two products of CLTSIPs T1 fi... fi Tn and T1fi fi... fi Tnfi dened on the same priority systems (with total orders). T1fi fi... fi Tnfi renes
T1 fi... fi Tn, denoted by T1fi fi... fi Tnfi i Rli,Rg T1 fi... fi Tn where Rli  Rlj (qi, qj )(qifi, qjfi ) = Rli (qi, qifi )  Rlj (qj, qjfi ), if:fii Ti
Ri,Rg Ti, l each concrete transition and its corresponding abstract one have the same priorities (morphism),  renement preserves deadlock-freeness, where deadlockfreeness is dened by the existence of rable transitions.
Through this theorem, we are able to perform model checking on the composition of CLTSIPs, T1fi fi... fi Tnfi, instead of the original composition T1 fi... fi Tn. In fact, through the last two conditions of this theorem, we may reduce the renement of CLTSIPs to classical renement relations of transition systems, and by that, the proof would be much more tractable (note that we do not claim that composition preserves deadlock freeness).
Proof. Given a transition of the concrete product, it is either asynchronous from some Tifi and has a corresponding abstracttransition in Ti with the same priority, which is in turn present in the abstract product, or a synchronization SR of two transitions from Tifi and Tjfi that have abstractions in Ti and Tj which synchronize in the abstract product with the same priority, or again an n-ary synchronization Sync which, as previously stated, leads to an n-ary synchronization in the abstract product. Moreover, if a concrete transition has priority over ready 2 transitions, then the corresponding abstract one has also priority. ff
D. Timed Transition System Extensions
Timed transition systems   are the reference model to dene the semantics of real-time formalisms such as time Petri nets and timed automata. Basically, a Timed Transition System(TTS) is a labeled transition system where labels can be events or durations. In this section, we dene extended timed transition systems (ETTS) as CLTSIPs which synchronize on time.
ETTS actions are considered as a pair (guard, assignment) of CLTSIPs. Furthermore, we consider the global state space structured as valued variables.
Denition 9 (ETTS): An Extended Timed Transition System (ETTS) on a set of variables V valued over a domain
D, a static priority system Ps, a dynamic priority system Pd and a set of channels C is a CLTSIP over the global space
G = DV where the synchronization events m  M are time instants of  = R0. Its action language is dened as the set of pairs (guard, assignment), where a guard is a predicate over variables of V and an assignment is a partial function mapping variables to expressions built on V.
The semantics of an ETTS depends on its action language semantics. Here, we have chosen the following denition for the (guard, assignment) pairs:
Action a:=language g/ fivV v := ev
| afia
| jJ aj
Semanticsfi
[[g/ fivV
 v := fiev ]](x, x ) = g(x)  vV x (v) = [[ev ]](x)
The notation g/ fivV states the parallel update of variables of V as an assignment guarded by g. Both action composition operators  and fi are left undened. Their semantics will be chosen to conform with the semantics of timed automata action composition.
IV. I NSTANTIATION FOR UPPAAL
UPPAAL   is an integrated tool environment for modeling, validation and model checking of real-time systems modeled as networks of timed automata. The tool has been used successfully and routinely for many industrial case studies. In this section, we consider UPPAAL timed automata (TA)   as an instantiation of CLTSIPs. The UPPAAL language   considers 3 priority orders: a static binary priority so-called
Committedness associated to locations, a dynamic priority order on channels and another dynamic priority order between 2 Transitions outgoing from the same state and, for dynamic priority, enabled.
61processes. In fact, location committedness is a high level mechanism dening two priority levels, where transitions outgoing from committed locations have priority over transitions outgoing from non-committed locations, independently of their enabledness.
In UPPAAL, committedness is associated to states where systems cannot delay if the current state is committed.
In order to dene a compositional semantics of timed automata composition, using a products of TTSs (Timed
Transition Systems),   proposes a restriction on UPPAAL so that a committed state has always a rable outgoing transition.
With respect to our previous work, we do not require such a restriction but we use a slightly modied structure of TTSs. Location committedness is considered as a static priority system with two priority values {true, f alse}.
Moreover, the dynamic priority order on channels,,   states that a synchronizing transition t on a channel c, which has priority over a channel cfi, has priority over transitions composable on cfi if it is rable, i.e. the guard of t is satised. We also consider the priority order on TA processes, which is a dynamic relation stating that the executions of a timed automaton have priority over the executions of other
TA. In what follows, we introduce UPPAAL TA with the three priority orders (committedness, priority on channels and priority on TA) and dene their ETTS-based semantics, where an unique generalized dynamic priority system is derived from both priority on channels and priority on TA. To this end, on a composition, static priority is checked rst and if the conict is not solved we may refer to the priority order on channels. Again, if the choice of a transition from a conict cannot be made, we compare then the dynamic priorities associated to the involved TA.of the static priority system with two values. Moreover, the unique dynamic priority system of ETTS semantics is derived from a merge of both priority orders c and ta.
Denition 11 (Priority systems corresponding to TA):
Given a timed automaton T  TA dened on a total priority order c on channels and a total priority order ta on elements of TA, where TA is the set of timed automata names, the static priorityff system associated to T is dened by Ps = ff{, fl},, fi and the dynamic one is dened by Pd = ff({, default}  C)  TA, d, ffd fi where(x, y) d (xfi, y fi ) fi x c xfi  (x = xfi  y ta y fi ).
Since the orders c and ta are total in UPPAAL, the priority order d is total. default is the UPPAAL priority level assigned to  -transitions and  is the lowest priority level. In fact, the static priority system is straightforward, whereas the dynamic priority system consists in checking rst the priority on channels and if the choice of a transition cannot be made, we refer then to priorities of the corresponding TA. By now, we give the semantics of TA in terms of ETTSs where ETTS locations are TA locations.
Denition 12 (ETTS of a TA): Given a set of channels C, a priority order c on channels, a priority order ta on TA and a set  of clocks. The semantics of a timed automaton with committed locations and priorities T = ffQ, q 0, K, I, ta fi is dened by the ETTS ffQ, q 0, G0, I, fi over the global space, static priority system Ps and dynamic priority system Pd where G0 =   {0} and  is the smallest relation such that: q ta qfi g/ /rg/ /xr x:=0q qK,(default,T ) qfig/l/rfi q lC ta q g/l/xr x:=0 qK,(l,T )qqK
A. TA with Committed Locations and Priorities
Timed automata   have been introduced as a modeling framework to support the description and analysis of timed systems. In fact, a timed automaton is structured as a nitestate machine extended with a nite collection of real-valued clocks initialized to zero and increased synchronously.
Denition 10 (TA with committedness and priorities):
Given a set of clocks, a set of channels C, a priority order
c on channels of C and a priority order ta on TA, a timed automaton with committedness and priorities is a tupleffQ, q 0, K, I, fi where:
0
Q is a set of locations where q  Q is the initial location, K  Q is a set of committed locations, I : Q  2 associates a clock invariant (a set of clock valuations) to each location, Q  2
2    Q is the transition relation dened with a clock guard, a reset set and an event l.
= C?  C!  { } is the set of transition labels.
/ /skipq
,(default,T ) q
Tau
Com qfi
Emptyq	K
[x x:=x+]I(q)//x x:=x+q,(fi,T ) q
Time
For transition rules T au and Com, both guards and labels of T transitions are still unchanged in the corresponding ETTS transitions. The semantics of a reset r consists in a parallel reinitialization of clocks x  r. Moreover, the static priority of each ETTS transition corresponds to the committedness of the TA source location q, whereas the dynamic priority is the pair of label l for a communication, respectively default for internal and Empty transitions and  for Time transitions, and the name of the automaton T. Empty transitions are not rable and especially introduced to hold the committedness of TA locations, when that locations do not have outgoing transitions. From each non committed location q, we may perform a Time-transition adding an amount, respecting the invariant of q, to each clock x. One may distinguish that no transition can be blocked by Time-transitions because they have the lowest static and dynamic priority values.g/l/r
We write q  q fi for (q, g, r, l, q fi ). Different semantics of TA with priorities in terms of TTS have been proposed,,,. Here, we dene the semantics of TA with priorities in terms of ETTSs where committedness is an instance
Simulation: a timed automaton Tc renes another TA
62
Ta if the simulation relation holds between their associated
ETTSs: Tc
Ta fi ET T S(Tc )
ET T S(Ta ).qi  K i
/ /skipq,(def ault,Ti ) q

B. Networks of TA with Committedness and Priorities
In order to model concurrency and communication, TA have been extended with parallel compositions, giving rise to the NTA. Several semantics for TA composition have been studied,,,,   and various parallel composition operators have been proposed, the well known ones are those of CCS   and CSP. The UPPAAL language
  has adopted the CCS parallel composition which allows interleaving of actions as well as hand-shake synchronization.
In this section, to compare NTA through simulation and bisimulation relations, we dene their semantics in terms of ETTS and establish a compositionality result.
Denition 13 (Networks of timed automata): A network of timed automata with committed locations, priority on channels
c and priority on TA ta is a nite collection of TA.
First, let us choose the following action language and its underlying semantics for ETTS.q
The semantics of NTA is parameterized by the way guarded actions are composed on a send/receive synchronization, i.e.(gs /as ) fi (gr /ar ). The semantics [[a fi a]], depends on the semantics chosen for TA composition, is still unspecied.
Denition 14 (NTA semantics): Given a set of clocks, a set of channels C, a priority order c on C and a priority order ta on timed automata, the semantics of an
0
NTAfi N = ffQi, qi, Ki, Ii, i fi1..n is dened by the ETTSff i Qi, ffq10,..., qn0 fi,   {0}, I,  fi over the global space, static and dynamic priorityff systems Ps and Pd given in Denition 11 where I(q) = i Ii (qi ) and  is the smallest relation such that: g/ /rff jq j  K j  qi  K ig/ / xr x:=0q qi Ki,(def ault,Ti ) q[i  qifi ] gi /c!/rig/ /r
Tauigj /c?/rjqi i qifi qj j qjfi i = j g/r = gi /ri fi gj /rjff q
Kk  (qi  Ki  qj  Kj ) k k q qi Ki qj Kj,(c,max(Ti,Tj )) q fii qi  Ki xi :=xi +,(ff,max({Ti |i1..n}) g//
Time
Jiqfifi where, for rule SRi,j (c), q fi =fiq[i  qi, j  qj ] and for Time transitions, the guard g = [ i xi := xi + ]I(q) states that the location invariant I(q) should be respected after updating clocks. Such an invariant corresponds to the intersection of individual TA location invariants. Through rule Tau, an internal(statically) non-hidden transition of a TA corresponds to an internal transition of the ETTS semantics. Hiding is not local, i.e not only attached to a given TA. In fact, from each TA location, after checking that such a location of the NTA state vector does not have the weakest committedness, we check then whether the current TA transition is not hidden by another transition outgoing from that location. Rule SRi,j (c) describes the synchronization of TA Ti and Tj on a channel c, where the input transition guard is only checked after taking into account the effect of the output transition action. Such a synchronization is held if either the send or the receive transition is not statically hidden. The dynamic priority of the resulting transition corresponds to that of channel c and the maximum process priority of both Ti and Tj. Finally, both
Empty and Time rules have been earlier explained.
Denition 15 (NTA renement): The renement between networks of timed automata is dened as the renement between their associated ETTSs. Formally, given two NTA
Nc and Na ; then: Nc
Na fi ET T S(Nc )
ET T S(Na ).
Accordingly, we establish the following theorems:
Theorem 5 (Compositionality of NTA semantics): The ETTS of a NTA is bisimilar to the restriction to Time and Tau-transitions of the product of ETTSs associated to individual TA, i.e. ET T S(N T A)  i ET T S(T Ai )\C.
Proof. It is direct because we have the same composition rules in both sides. The difference resides in the occurrence of unmatched communication transitions in the ETTSs product, but these transitions will be suppressed by the restriction.
This proof has been formalized and validated using the C OQ theorem prover. ff
Theorem 6 (Renement and parallel composition): Given
2 networks of TA N = ffT1,.., Tn fi and N fi = ffT1fi,.., Tnfi fi dened on the same set of channels, N renes N fi if:fii Ti
Ri,Rg Ti, lfi channel priority orders of N and N are equivalent, each concrete process and its corresponding abstract one have the same priority (morphism), fififi q q, Rl (q, q )  Comm(q)  Comm(q ),  renement preserves deadlock-freeness.
Proof. It follows from theorems 4 and 5 together with the restriction theorem 2.
Action language a:= a fi a | jJ aj
| (g/r)
| (g/c := c + d)
| (g/skip)
Semantics a fi a is still unspecied

[[j aj ]](x, xfi ) = j [[aj ]](x, xfi )

fifi
[[g/r]](x, x ) = g(x)  cr xfi (c) = 0  cr
/ x (c) = x(c)fifi
[[g/c := c + d]](x, x ) = g(x)  x (c) = x(c) + d
[[g/skip]](x, xfi ) = g(x)  (xfi = x)qi i qifi
Empty
SRi,j (c)
C. Experiments
In this section, we give an application of our compositional framework to rene a version of the well known Alternating
63
Bit Protocol   (ABP). In fact, we aim to verify that the number of correctly received messages is less than the number of correctly sent ones, and their difference is bounded by one.
To send a new message, the TA Sender synchronizes with the TA Mmedium on channel send and increments the shared variable s. The TA Receiver receives the sent message via a synchronization with the Mmedium on channel receive and updates the shared variable r by adding one. The intended property is represented by the auxiliary Boolean variable
Ok fi s == r  s == (r + 1). This property cannot be veried using the UPPAAL toolbox on the NTA formed by Sender, Receiver, Mmedium, Amedium because of the unboundedness3 of s and r. To deal with the unboundedness, a clever idea consists in the replacement of both Sender and Receiver automata by nite abstractions, where the evolutions of variables s and r are respectively modeled by two shared
Boolean variables b1 = (s == r), initialized to true, and b2 = (s == r+1), initialized to f alse, with a slight modication of the corresponding involved transitions. The abstraction renement of processes Mmedium and Amedium is the identity relation. Accordingly, the new property Ok = b1  b2 can be checked. The abstraction renement of each TA by its corresponding nite abstraction has been checked using a manual proof of the renement ref in between their ETTSbased semantics, where both local and global spaces have been considered. The local space renement Rl consists in:(a) the correspondence of local states; (b) the identity of local variables values. However, for the global space, the renement
Rg consists to: (a) match the values of b1 and b2 of the abstract system to the corresponding expressions computed through s and r in the concrete system; (b) check the identity between the other shared variables values. We may write then ref in = RlSender RlReceiver RlM medium RlAmedium Rg.
This result has been checked using UPPAAL and a manual proof of renement using observers.
Acknowledgment. We wish to thank the anonymous referee for his scrutinous reading and valuable remarks.
R EFERENCES
  R. Alur. Timed automata. In 11th International Conference on Computer
Aided Verication, volume 1633 of LNCS, pages 822. 1999.
  A. Arnold. Finite transition systems: semantics of communicating systems. Prentice Hall International Ltd., Hertfordshire, UK, 1994.
  A. Basu, M. Bozga, and J. Sifakis. Modeling heterogeneous real-time components in BIP. In SEFM06, pages 312. IEEE Computer Society, 2006.
  G. Behrmann, A. David, and K. G. Larsen. A Tutorial on Uppaal.
Department of computer science, Aalborg university, 2004.
  J. Bengtsson and W. Yi. Timed automata: Semantics, algorithms and tools. In Lectures on Concurrency and Petri Nets, pages 87124. volume
3098 of LNCS, Springer-Verlag, 2004.
  B. Berard, M. Bidoit, A. Finkel, F. Laroussinie, A. Petit, L. Petrucci, and P. Schnoebelen. Systems and Software Verication - Model-Checking
Techniques and Tools. Springer-Verlag Berlin, 2001.
  J. Berendsen and F. Vaandrager. Compositional Abstraction in RealTime Model Checking. In FORMATS08, pages 233249, 2008.
  B. Berthomieu, J. Bodeveix, M. Filali, H. Garavel, F. Lang, F. Peres, R. Saad, J. Stoecker, F. Vernadat, P. Gaullet, and F. Lang. The syntax and semantics of FIACRE. Technical report, 2009.
  G. Bhat, R. Cleaveland, and G. Luttgen. Dynamic priorities for modeling real-time. In FORTE X/PSTV XVII 97, Osaka, pages 321
336. Chapman and Hall, 1996.
  J. P. Bodeveix, A. Boudjadar, and M. Filali. An alternative denition for timed automata composition. In ATVA11, pages 105 119, Taiwan, 2011. LNCS 6996.
  S. Bornot, G. Gossler, and J. Sifakis. On the construction of live timed systems. In TACAS00, pages 109126, 2000.
  A. Boudjadar, J.-P. Bodeveix, and M. Filali. Revising and extending the UPPAAL communication mechanism. In SC12, volume LNCS 7306, pages 114  131. Springer Heidelberg, 2012.
  P. Bremond-Gregoire, I. Lee, and R. Gerber. ACSR: An algebra of communicating shared resources with dense time and priorities. In
CONCUR, pages 417431, 1993.
  E. M. Clarke, D. E. Long, and K. L. McMillan. Compositional model checking. In LICS89, pages 353362, 1989.
  R. Cleaveland, G. Luttgen, and V. Natarajan. Priority in process algebras. Information and Computation, 87:5877, 1999.
  A. David, J. Hakansson, K. G. Larsen, and P. Pettersson. Model checking Timed Automata with Priorities Using DBM Subtraction. In
FORMAT06, pages 128142. LNCS volume 4202, 2006.
  E. Fersman, P. Pettersson, and W. Yi. Timed Automata with asynchronous processes: Schedulability and decidability. In TACAS02, pages
6782. Volume LNCS 2280, Springer-Verlag, 2002.
  G. Gossler and J. Sifakis. Priority systems. In FMCO03, pages 314
329, 2003.
  F. He, H. Zhu, W. Hung, X. Song, and M. Gu. Compositional abstraction renement for timed systems. In TASE10, pages 168 176, 2010.
  T. A. Henzinger, Z. Manna, and A. Pnueli. Timed transition systems.
1992.
  C. A. R. Hoare. Communicating Sequential Processes. Prentice-Hall, 1985.
  P.-A. Hsiung and S.-W. Lin. Model checking timed systems with priorities. In RTCSA05, pages 539544, USA, 2005.
  H. E. Jensen, K. G. Larsen, and A. Skou. Scaling up Uppaal:
Automatic Verication of Real-Time Systems using Compositionality and Abstraction. In FTRTFT00, pages 1930, 2000.
  K. G. Larsen, P. Pettersson, and W. Yi. Uppaal in a nutshell. In Journal on software tools for technology transfert, 1997.
  R. Milner. Communication and Concurrency. Prentice Hall Ltd., 1989.
  M. Nielsen, G. Rozenberg, and P. Thiagarajan. Transition-systems, event structures, and unfoldings. Information and Computation, 118:191
207, 1995.
  M. Nielsen, G. Rozenberg, and P. S. Thiagarajan. Elementary transition systems. Theoritical Computer Science, pages 333, 1992.
  G. J. Veltink and S. Mauw. Algebraic Specication of Communication
Protocols. Cambridge Tracts in Theoretical Computer Science No. 36, 2008.
  S. Yovine. Model checking Timed Automata. In Lectures on Embedded
Systems. Lecture Notes in Computer Science 1494, Springer-Verlag, 1998.
V. C ONCLUSION
In this paper, we have studied the renement and composition of different timed systems with priorities. For the parallel composition operator we have dened, we give a corresponding (compositional) renement relation. As a semantic model, our compositional framework has been successfully instantiated to dene a compositional semantics of networks of timed automata, in which an unique generalized dynamic priority system of ETTS is dened from both NTA priority orders (channels, TA) with an important renement property stating that: if each individual TA of an NTA renes another individual TA of another NTA, then the ETTS corresponding to the semantics of the rst NTA renes the ETTS corresponding to the semantics of the second NTA. Furthermore, the theorems established within our framework have been proved
4. In the future, we wish to extend our framework by other concepts, like assume-guarantee properties, in order to model and to analyze the semantics of the Fiacre language.
3 In fact, it is checked upto the size of UPPAAL integers, then UPPAAL throws an out of range exception.
4 Proofs will be available in the forthcoming PhD thesis of Abdeldjalil
Boudjadar.
64Ockhamistic Logics and True Futures of Counterfactual Moments
Torben Braunerff
Centre for Philosophy and Science-Theory
Aalborg University
Langagervej 6
9220 Aalborg East, Denmark torbenb@hum.auc.dk
Per Hasle
Centre for Cultural Research
University of Aarhus
Finlandsgade 28
8200 Aarhus N, Denmark
Phasle@cfk.hum.aau.dk
Peter hrstrm
Centre for Philosophy and Science-Theory
Aalborg University
Langagervej 6
9220 Aalborg East, Denmark poe@hum.auc.dk
Abstract
In this paper various Ockhamistic logics are compared with the aim of making clear the role of true futures of counterfactual moments, that is, true futures of moments outside the true chronicle. First we give an account of Priors original Ockhamistic semantics where truth of a formula is relative to a moment and a chronicle. We prove that this is equivalent to a semantics put forward by Thomason and Gupta where truth is relative to a moment and a so-called chronicle function which assigns a chronicle to each moment. This is the case because true futures of counterfactual moments do not matter in Thomason and Guptas semantics. Later we discuss how two options considered by
Belnap and Green might be formalised. They come about by assuming either a chronicle or a chronicle function to be given once and for all. The first of the two options is unable to give an account of certain statements from natural language and the second option invalidates an intuitively valid formula. We propose a new Ockhamistic semantics where the formula in question is valid, and furthermore, where true futures of counterfactual moments are taken into account. Finally, we discuss possible applications within Artificial Intelligence.ff This author is supported by the Danish Natural Science Research
Council.
1. Introduction
This paper is concerned with certain logics which are
Ockhamistic in the sense of involving a notion of true future. The logics in question are compared with the aim of making clear the role of true futures of counterfactual moments, that is, true futures of moments outside the true future.
The paper is structured as follows. In the second section of this paper Priors original Ockhamistic semantics is introduced. See also, p. 126 ff. A notable feature of this semantics is a notion of temporal routes or temporal branches, called chronicles. Here truth of a formula is relative to a moment as well as a chronicle - which is to be understood as truth being relative to a provisionally given true future. In the third section, we give an account of the semantics put forward by Thomason and Gupta in. Here truth of a formula is relative to a moment as well as a socalled chronicle function which assigns a chronicle to each moment - this is to be understood as truth being relative to a provisionally given true future of each moment. We prove that this is equivalent to Priors original semantics. This is so because true futures of counterfactual moments do not matter in the semantics - despite the fact that truth is relative to a moment as well as a chronicle function. In section four we give an account of two options considered by Belnap and Green in. They come about by assuming either a chronicle or a chronicle function to be given once and for all. We discuss how such assumptions might give rise to formal semantics. The first of the two mentioned options is unable to give an account of certain statements from natural language in which there are references to true futures of counterfactual moments. The second option invalidates the intuitively
HFq. In the fifth section we propose a valid formula q new semantics where the model provides a chronicle function once and for all. Compared to the other Ockhamistic semantics given in this paper, it is a notable feature that the HFq is valid here, and furthermore, true fuformula q tures of counterfactual moments are taken into account. An essential difference between this new semantics and the traditional Ockhamistic semantics is that the involved notion of possibility only refers to what might happen now whereas possibility in the traditional sense refers to what might happen from now on in general. This new notion of necessity may be called immediate necessity. In the last section we discuss possible applications of the logics presented in this paper within the area of Artificial Intelligence.
)
)
2. Priors notion of Ockhamistic necessity
In what follows, we shall give an account of the semantics which was put forward by Arthur N. Prior in, p.
126 ff., with the aim of formalising some ideas of William of Ockham (ca. 1285 - 1349).
To define Priors Ockhamistic semantics, we need a set
T equipped with a relation < together with a function V which assigns a truth value V t; p to each pair consisting of an element t of T and a propositional letter p. The elements of T are to be thought of as moments and < as the beforerelation. It is assumed that < is irreflexive and transitive.
Furthermore, to account for the branchingness of time it is assumed that < satisfies the condition( )
8t; t ; t : (t < t ^ t
0
00
0
00
< t ) ) (t < t
0
00
_t
00
< t _ t = t ):
00
A relation satisfying this condition is said to be backwards linear. An important feature of the semantics is a notion of temporal routes or temporal branches which are to be thought of as possible courses of events. We shall call such branches chronicles1. Formally, chronicles are maximal linear subsets in T; <. The set of chronicles induced by T; < will be denoted C T; <, and moreover, for any moment t we let t denote the set of chronicles to which t belongs. Note that the conditions of transitivity and backwards linearity make each chronicle c backwards-closed, c and t0 < t then t0 c. Truth is relative that is, if t to a moment as well as to a chronicle to which the moment belongs - which is to be understood as truth being relative((
( )
)
)(
2
1 Some authors call them histories.
)
2to a provisionally given true future of the moment in question. In, p. 126, Prior calls it a prima facie assignment. By induction, we define the valuation operator Prior as follows:
Prior(t; c; p), V (t; p), where p is a prop. letter
Prior(t; c; p ^ q), Prior(t; c; p) ^ Prior(t; c; q)
Prior(t; c; :p), :Prior(t; c; p)
Prior(t; c; Pp), 9t < t: Prior(t ; c; p)
Prior(t; c; Fp), 9t > t: t 2 c ^ Prior(t ; c; p)
Prior(t; c; 2p), 8c 2 (t): Prior(t; c ; p)
So Prior(t; c; p) amounts to p being true at the moment t in the chronicle c. A formula p is said to be Prior-valid if and only if p is Prior-true in any structure (T; <; V ), that is, we have Prior(t; c; p) for any moment t and chronicle c such that t 2 c.
For instance, let us consider the formula q ) HFq(where Hp is an abbreviation for :P :p). From the above definitions it is obvious that Prior(t; c; q ) HFq) for any t and any c with t 2 c. Therefore q ) HFq is valid in this system. Likewise, the formula q ) 2q, where the tense operator F does not occur in q, is valid. This formula is in 0
0
0
0
0
0
0good accordance with the medieval dictum unumquodque, quando est, oportet esse (anything, when it is, is necessary), see, p. 191.
It may be doubted whether Priors Ockhamistic system is in fact an accurate representation of the temporal logical ideas propagated by William of Ockham. According to
Ockham, God knows the contingent future, so it seems that he would accept an idea of absolute truth, also when regarding a statement Fq about the contingent future - and not only prima facie assignments like Prior t; c; Fq. That is, such a proposition can be made true by fiat simply by constructing a concrete structure which satisfies it. But Ockham would say that Fq can be true at t without being relativised to any chronicle. It is possible to establish a system which seems a bit closer to Ockhams ideas by taking chronicles to be disjoint and having a relation between chronicles corresponding to identity up to a certain moment. A system along these lines is in   called Leibnizian.(
)
3. Thomason and Guptas notion of Ockhamistic necessity
In this section, we shall compare the traditional Ockhamistic semantics given by Prior to the semantics given by Richmond Thomason and Anil Gupta in. An essential difference is that in the traditional semantics truth is relative to a moment as well as a chronicle whereas in Thomason and Guptas semantics, truth is relative to a moment as well as a so-called chronicle function which to each moment assigns a chronicle. We shall prove that the two semantics are equivalent. This is the case because true futuresof counterfactual moments do not matter in the semantics
- despite the fact that truth is relative to a moment as well as a chronicle function. It should be mentioned that besides the usual Ockhamistic connectives the semantics given in Thomason and Guptas paper also interprets counterfactual implication - in such a context true futures of counterfactual moments do make a difference.
A formal account of Thomason and Guptas semantics is based on the same notion of a structure as the one used previously in this paper. So we need a set T equipped with an irreflexive, transitive and backwards linear relation < together with a function V which assigns a truth value to each pair consisting of a moment and a propositional letter. Furthermore, it involves a relation on T relating copresent (or pseudo-simultanous) moments and also certain additional machinery to interpret counterfactual implication. Here we do not consider counterfactual implication so we shall disregard such machinery, and moreover, we adapt Thomason and Guptas semantics to the previous setting of this paper where no notion of copresentness is taken into account.
In the traditional semantics, truth is relative to a moment and a chronicle to which the moment belongs. In Thomason and Guptas semantics, truth is relative to a moment and a chronicle function. A chronicle function is a function
C which assigns to each moment a chronicle such that the following two conditions are satisfied:
8t: t 2 C (t).(C2) 8t; t : (t < t ^ t 2 C (t)): ) C (t) = C (t )(C1)
0
0
0
0
The first condition says that the chronicle assigned to a moment has as element the moment itself. The second condition says that chronicles assigned to later moments of a chronicle coincide with chronicles assigned to earlier ones.
The definition of truth of a formula as relative to a moment and a chronicle function is to be understood as truth being relative to a moment and a provisionally given true future of each moment. The chronicle function with respect to which truth is relative, is assumed to be normal at the moment at hand. Given a moment t, a chronicle function C is said to be normal at t if and only if 8t < t: C (t ) = C (t):
0()
0
We let N t denote the set of chronicle functions which are normal at the moment t. Normality at a moment means that the moment is in the true future of any earlier moment.
Without restricting attention to chronicle functions normal
HFq would not be at a given moment, the formula q valid.
How should 2p be interpreted? As Thomason and Gupta explains in, p. 311, one should not simply say that 2p is true at t with respect to C normal at t if and only if p is true at t with respect to all chronicle functions C 0 normal
)at t. This is because 2p is supposed to say that p holds no matter how things will be. Hence, C 0 should differ from C at most at t and moments in the future of t. It follows from normality at t that C 0 also has to be allowed to differ from
C at moments in the past of t. This leads to the following definition: The chronicle functions C and C 0 are said to differ at most at t and its past and future if and only if 8t : (t 6= t ^ t  t ^ t  t ) ) C (t ) = C (t ):
0
0
0
0
0
0
0
 ( )
We let P;F t; C denote the set of chronicle functions which differ from C at most at t and moments in the past and future of t. By induction, we define the valuation operator V as follows:
V (t; C; p), V (t; p), where p is a prop. letter
V (t; C; p ^ q), V (t; C; p) ^ V (t; C; q)
V (t; C; :p), :V (t; C; p)
V (t; C; Pp), 9t < t: V (t ; C; p)
V (t; C; Fp), 9t > t: t 2 C (t) ^ V (t ; C; p)
V (t; C; 2p), 8C 2 N (t) \  (t; C ): V (t; C ; p)
A formula p is said to be valid if and only if p is true in any structure (T; <; V ), that is, we have V (t; C; p) for any moment t and chronicle function C normal at t.
0
0
0
0
0
0
P;F
0
We shall now show that this notion of validity is equivalent to the traditional notion of Ockhamistic validity. As alluded to above, this is so because true futures of counterfactual moments do not matter. In the semantics above, 2q says that q holds no matter how things will be, where things do not only refer to the true future of the present moment but also to true futures of future moments. Thus, even if an Ockhamistic model does provide true futures of counterfactual moments, these futures do not matter if things will be different (and obviously not if things will be the same either). With the aim of proving the two notions of validity equivalent, we shall first prove a theorem which essentially says that chronicles can be mimicked by chronicle functions.
82
Theorem 3.1 Given a chronicle function C such that t c: C tc there exists a chronicle( ) = c.
Proof: In this proof we shall use Zermelos Theorem and Zorns Lemma which are both equivalent to the Axiom of Choice. Zermelos Theorem says that any set can be wellordered, that is, it can be equipped with a linear partial order such that any non-empty subset has a least element. By
Zermelos Theorem, we can assume that T is well-ordered by a relation. For any non-empty subset T 0 of T we let
T 0 denote its -least element. Zorns Lemma says that if each linear subset of a non-empty partially ordered set A has an upper bound, then A has a maximal element. By Zorns
Lemma, we can assume that for any moment t there exists a chronicle c0 such that t c0, and hence, by the Axiom ofuv v
2
Choice, we can assume that there exists a function f which to any moment t assigns a chronicle c0 such that t c0. By transfinite induction using, we define a function
2v
C : T ! C (T; <)
8< c
C (t) = : C (uft @ tjt 2 C (t )g) f (t) such that
0
0
2if t c if t0 @ t: t otherwise
9()
2 C (t )
0
2, 2
2 v
2
= uf j 2 ( )g
2 () v( ) = ()
2 ( ) 2 () v
= uf j 2 ( )g v( )= ( )
2 ( ) v( )= ( )
Corollary 3.2 Let a chronicle function C be given. For any c there exists a moment t and chronicle c such that t c and chronicle function C 0 normal at t such that C 0 t
C 0 P;F t; C.
2()=
2 ( )
Proof: Let K = ft jt 6= t ^ t  t ^ t  t g and note that T n K is itself a structure, that is, irreflexive, transitive and backwards linear. We have c \ K = ; because t 2 c, so the preceeding theorem can be applied to c considered as a chronicle in T n K to obtain a chronicle function C as appropriate. Note that any chronicle in T n K is also a chronicle in T. Furthermore, note that T n K is forwards
0
0
0
0
0closed.
QED.
The lemma we shall prove now essentially says that given a chronicle function, the semantics does not take into account true futures of counterfactual moments.
Lemma 3.3 Let a formula q be given. For any chronicle c and chronicle functions C and C 0 normal at a moment t such that C t C 0 t it is the case that V t; C; q
V t; C 0; q.(()= ()
)(
), Proof: Induction on the structure of q. We only check the 2 case; the other cases are straightforward. Assume that V t; C; 2p. By definition of the semantics we have
V t; C 0; 2p if((
)
)
8C 2 N (t) \  (t; C ): V (t; C ; p):
00
P;F
0
00
It follows from Corollary 3.2 that for any
C
00
2 N (t) \  (t; C )
P;F
0
000
2 N (t) \  (t; C )
P;F()= ()(
), ((
)
8C 2 N (t) \  (t; C ): V (t; C ; p):
Thus, it is the case that V (t; C ; p).
)such that C t
C t. But V t; C 000; p V t; C 00; p according to the induction hypothesis. By definition of the semantics we have V t; C; 2p only if 000
00
000
P;F
00()=
=
C
000for any moment t. We only have to check that C satisfies the conditions (C1) and (C2). Clearly, (C1) is ok. Assume that t < t0 and t0 C t. We then have to prove that C t
C t0. It is straightforward to check that t c t0 c, so without loss of generality we can assume that t = c and t0 = c. Let t0 u t C u. Thus, t0 is the -least moment where t belongs to the assigned chronicle. Hence, t C t0 and t0 t, and furthermore, C t0 C t.
C t0 as t0 C t so t00 t0 where t00
Now, t0
0 v t C v. Thus, t00 t0 and C t00 C t0. But t < t0 so t C t00 and hence t0 t00 by definition of t0.
C t0.
QED.
We conclude that t0 t00 so C t
The theorem above gives rise to an important corollary.
2 ()there is a QED.
An important consequence of the preceeding results is the following lemma.
Lemma 3.4 Let a formula q be given. For any chronicle c and moment t such that t c the existence of a chronicle c and V t; C; q function C normal at t such that C t is equivalent to V t; C 0; q being the case for any chronicle c. function C 0 normal at t such that C 0 t
2(
)()=()=(
)
Proof: Follows from Theorem 3.1 and Lemma 3.3. QED.
We now prove a theorem making clear how truth in the traditional Ockhamistic semantics is related to truth in the new semantics.
Theorem 3.5 Let a formula q be given. Also, let a moc be given. Then ment t and a chronicle c such that t
Prior t; c; q if and only if for any chronicle function C normal at t such that C t c it is the case that V t; C; q.(
2
)()=(
)
Proof: Induction on the structure of q. We proceed on a case by case basis. The case where q is a propositional letter follows from Theorem 3.1. The case is straightforward. The case follows immediately from Lemma 3.4.
The P and F cases follow from Lemma 3.4. The 2 case goes as follows: By definition Prior t; c; 2p is equivalent to Prior t; c0; p being the case for any c0 such that t c0.
By the induction hypothesis this is equivalent to V t; C 0; p being the case for any C 0 normal at t such that C 0 t c0
0
0 where c is any chronicle such that t c. This is equivalent to V t; C 0; p being the case for any C 0 normal at t. But cf. Corollary 3.2 this is equivalent to V t; C; 2p being the c.
QED. case for any C normal at t such that C t
The theorem above enables us to conclude that the traditional semantics is equivalent to Thomason and Guptas semantics.
^
:((
)
)(
)
2(
)()=
2(( )=
)
Corollary 3.6 A formula is Prior-valid if and only if it is valid in Thomason and Guptas semantics.
Proof: Straightforward by the preceeding theorem. QED.
4. Belnap and Greens argument
In the interesting paper, Nuel Belnap and Mitchell
Green consider a model where a chronicle is given onceand for all - the true chronicle. They denote such a chronicle TRL (Thin Red Line). Belnap and Green argue that this kind of model is unable to give an account of certain statements from ordinary language in which there are references to true futures of counterfactual moments. This is remedied by assuming that instead of just one true chronicle the model provides one true chronicle for each moment. But also in this case problems apparently crop up. In this section we shall discuss how Belnap and Greens arguments might be formalised.
We will first consider the case where the model provides a chronicle once and for all. Belnap and Green have based their arguments on the following example of a statement from ordinary language:
The coin will come up heads. It is possible, though, that it will come up tails, and then later(*) it will come up tails again (though at that moment it could come up heads), and then, inevitably, still later it will come up tails yet again.(, p. 379)
As Belnap and Green explain in, p. 379, the trouble is that at (*) the example says that tails will happen. The point is here that (*) is future relative to a counterfactual moment, that is, a moment outside the true chronicle. Now, how should tenses and possibility in the sentence above be interpreted? Belnap and Green give the following informal account of the semantics they have in mind:
In the semantic theory of branching+TRL the future tense moves you forward along TRL and the past tense moves you backward along it. Any talk of possibility or necessity or inevitability refers to some histories other than TRL. (, p. 379)
So any future tensed sentence has to be interpreted with respect to the true chronicle. But this does obviously not make sense outside the true chronicle. We agree with Belnap and Green that this is problematic.
Belnap and Green remedies this deficiency by assuming that instead of just one true chronicle the model provides a function which to each moment assigns one true chronicle. They discuss which conditions such a function C has to satisfy, but rather than condition (C2) they assume the condition
8t; t : t < t ) C (t) = C (t )
0
0
0to be satisfied - which amounts to the function being normal at every moment of the model. This is problematic because it forces the before-relation to be forwards linear, as they do indeed point out2. In what follows, we shall therefore
2 In   we remedied this by suggesting the more appropriate condition(C2). Later, we realized that this condition was introduced in. In fact, it occurs already in the paper   by Vaughn McKim and Charles Davis where, however, it is formulated in a different way.restrict our attention to chronicle functions in the previous sense of this paper unless otherwise is indicated. Using a chronicle function, truth of the statement above amounts to truth at the left-most moment of the structure heads,,,@, heads, @@R,tails
@
@@R tails
@@
@R tailswhere we have used a thick line to represent the future part of a chronicle (the past part needs no representation as it is uniquely determined).
Belnap and Green have argued that the formulae FFq
Fq and q PFq should be valid. They do not give a formal semantics but it is clear that they interpret tenses by moving in the appropriate direction along the true chronicle of the moment at hand. It is not clear how the interpretation of possibility goes in their semantic theory, but it seems unavoidable to take into account chronicle functions which are different from the given chronicle function at the moment at hand (if that was not the case then the interpretation of possibility could not refer to chronicles other than the true chronicle of the moment at hand). Hence, truth has to be relative to a moment as well as a chronicle function. This suggests a semantics like the one put forward by Thomason and Gupta except that a chronicle function is given once and for all and 2p is true at t with respect to C if and only if p is true at t with respect to all chronicle functions C 0 such that C 0 differ from C at most at the moment t. Formally, the chronicle functions C and C 0 are said to differ at most at t if and only if )
)
8t : t 6= t ) C (t ) = C (t ):
0
0
0
0
0
( )
We let t; C denote the set of chronicle functions which differ from C at most at t. Then the valuation operator V is defined as follows:
V (t; C; p), V (t; p), where p is a prop. letter
V (t; C; p ^ q), V (t; C; p) ^ V (t; C; q)
V (t; C; :p), :V (t; C; p)
V (t; C; Pp), 9t < t: V (t ; C; p)
V (t; C; Fp), 9t > t: t 2 C (t) ^ V (t ; C; p)
V (t; C; 2p), 8C 2 (t; C ): V (t; C ; p)
A formula p is then said to be valid if and only if p is true in any structure (T; <; V; C ), that is, we have V (t; C; p) for any moment t.
0
0
0
0
0
)
0
0
Given such a semantics, it is straightforward to check
Fq is valid whereas it is not valid if (C2) is that FFq
)left out. But q
PFq is invalid. We agree that this is trouHFq is invalid; it blesome. Furthermore, the formula q is not true at the upper-most moment of the structure
)q
,,, @@
R :q
@leads to the following definition: C and C 0 are said to differ at most at t and its past if and only if it is the case that
8t : (t 6= t ^ t  t) ) C (t ) = C (t ):
0
0
0
0
0
0
 ( )
We let P t; C denote the set of chronicle functions which differ from C at most at t and moments in the past of t. We now define the valuation operator V as follows:
Faced with the mentioned problems, Belnap and Green simply abandon the idea of assuming a chronicle function to be given once and for all.
V (t; C; p), V (t; p), where p is a prop. letter
V (t; C; p ^ q), V (t; C; p) ^ V (t; C; q)
V (t; C; :p), :V (t; C; p)
V (t; C; Pp), 9t < t: V (t ; C; p)
V (t; C; Fp), 9t > t: t 2 C (t) ^ V (t ; C; p)
V (t; C; 2p), 8C 2 N (t) \  (t; C ): V (t; C ; p)
A formula p is said to be valid if and only if p is true in any structure (T; <; V; C ), that is, we have V (t; C; p) for any moment t at which C is normal.
0
0
0
0
0
5. The new semantics
Also in this section we assume that the model provides a chronicle function once and for all - the true chronicle function. What we are after here is a semantics where the HFq is valid, and furthermore, where true formula q futures of counterfactual moments are taken into account.
With this goal in mind we shall propose a new semantics.
A notable difference between this new semantics and the traditional Ockhamistic semantics is that in the new semantics the involved notion of possibility just refers to what might happen now whereas possibility in the traditional sense refers to what might happen from now on in general. In other words, in the traditional semantics 2q means that q is true no matter what happens now and in the future whereas in the new semantics 2q means that q is true no matter what happens now. This new notion of necessity may be called immediate necessity. The new semantics corresponds to considering the first occurrence of the word possible in Belnap and Greens example as referring to the first tossing of the coin rather than the whole sequence of tossings. We find this very natural.
In what follows, we shall give an account of the new semantics. What we do is we take the semantics of the last section where a chronicle function is given once and for all and where truth is relative to a moment and a chronicle function (note that conditions (C1) and (C2) are satisfied here). We then add the condition that the chronicle function has to be normal at the moment at hand. This makes the HFq. The resulting semantics validate the formula q restriction to normal chronicle functions forces us to change the semantics of necessity such that it takes into account not only chronicle functions differing from the given chronicle function at the moment at hand but also chronicle functions differing at moments in the past of the moment at hand.
Thus, the key feature of the semantics is that 2p is true at t with respect to C normal at t if and only if p is true at t with respect to all chronicle functions C 0 normal at t such that
C 0 differ from C at most at the moment t and its past. This
)
)
)
0
P
0
)
It is straightforward to check that both of the formulae
Fq and q HFq are valid. The fact that the last mentioned formula is validated makes us believe that the formal semantics given here is not the one Belnap and Green had in mind when writing the paper. Now, consider the structures
FFq, :p,,@, :p
@@R,, @@
@R p, :p,,@, :p
@@R,, @@
@R p
Clearly, the formula 3Fp (where 3q is an abbreviation for
2 q) is true in the left-most moment of the first structure whereas it is false in the corresponding moment of the second structure. But the structures are identical except that the involved chronicle functions differ at a counterfactual moment. This shows that true futures of counterfactual moments do make a difference in this new semantics.
The new semantics is not equivalent to Priors Ockhamistic semantics (and thus neither to Thomason and Guptas semantics). The new semantics invalidates the formula
::
F3Fp ) 3FFp
)which is valid in Priors semantics (note that in the context of dense time, this formula is equivalent with F3Fp
3Fp). The formula is not true in the left-most moment of the structurep, 
-:p,@, @@R :p
So Prior-validity does not imply validity in the sense proposed above. However, it should be mentioned that all axioms of the modal logic S5 are validated (for an introduction to S5, see  ).
The invalidity of the above mentioned formula actually reveals a notable feature of this new semantics: It allows for the emergence of possibility in time, that is, it allows for a situation in which the truth of a proposition is possible in the future whereas the future truth of the proposition is impossible.
In   we suggested another semantics which also has the property that it allows for the emergence of possibility in time. The two semantics are not equivalent. The semantics of the mentioned paper invalidates the formula
H (Gq ) 3Gq)(where Gp is an abbreviation for :F :p).
It is not true inthe lower-most moment of the structure
:q, ,, @@,,  :q
R
@ q, @@
Rq
@
On the other hand, the formula is valid with respect to the new semantics given above. We find the formula intuitively valid wherefore we consider the semantics of the present paper as an improvement compared to the one of.
6. The relevance to Artificial Intelligence
The main concern of this paper has been to work out the formalities of a revised Ockham-semantics as a basis for AIresearch and -applications, rather than actually investigating its use for various purposes. That remains to be done, but we shall briefly mention some points and areas of application, where an Ockhamistic logic enhanced as suggested is likely to be useful.
This is a distinction arguably required for natural language understanding, regardless of any different metaphysical assumptions one might have about time and the contingent future. Secondly, within the same frame, linguistic examples as the one given by Belnap and Green can be dealt with.
This also makes the system promising for evaluating counterfactual statements (see also  ).
6.2. Planning
Branching time temporal logics are used for formalising temporal aspects of planning problems. Roughly, planning amounts to choosing appropriate actions with the aim of achieving a desirable outcome. Notable in this respect are the papers   and. See also   which besides temporal notions also involves chance. The model of the last mentioned paper differs from the models of the present paper by having disjoint chronicles - which corresponds to the Leibniz system of. The above mentioned applications do not explicitly involve true futures of counterfactual moments, but we conjecture that this notion - and also the naturally associated notion of immediate necessity put forward in the previous section - does have a place in such contexts.
6.3. Partial information reasoning
Branching time as well as chronicle functions occur naturally within the area of partial information reasoning, which recently has been pointed out in the paper. In this context the notion of branching time comes about when considering the future courses of events which are compatible with given (partial) knowledge. In such a situation one particular future course of events can be singled out by using various criteria such as minimal change principles, probability and typicality. As explained in, such criteria simply correspond to chronicle functions on the underlying branching time structure. Our notion of immediate necessity is therefore readily available in such contexts.
6.4. Causal and counterfactual reasoning
6.1. Natural language understanding
Our version of Ockhamistic semantics can at the same time provide two advantages in this field: Firstly, an Ockhamistic logic can, as pointed out in for example, make a genuine distinction between the following three statements:
1. Possibly, Mr. Smith will commit suicide.
2. Necessarily, Mr. Smith will commit suicide.
3. Mr. Smith will commit suicide.
The close relation between causal and counterfactual reasoning has been pointed out by a number of authors.
Moreover, both of these areas have a clearly temporal component. Thus, David Lewis possible world semantics for counterfactuals   was related to branching time in.
In   it was shown how Lewis possible world semantics for counterfactuals related to non-monotonic reasoning, and how this could be utilized in AI-contexts (among other things fault diagnosis). In   Shoham made further progress in this direction (subsequently refined in several papers), and showed its relevance in non-monotonicreasoning - a crucial area in current AI-research. In   hrstrm and Hasle presented a system which integrates counterfactual, causal and temporal reasoning, based on an
Ockhamistic logic. See also. The idea of true futures at conterfactual moments plays an important role in these systems, but only for finite models and not explicitly worked out as here. However, in our view the line of development in causal and counterfactual reasoning since   makes it credible that much can be gained from the study of how to apply the logic presented here to current problems in AI, especially those related to causal, counterfactual and temporal non-monotonic reasoning.
6.5. Knowledge representation
From the area of knowledge representation it is relevant to mention Javier Pinto and Raymond Reiters work on the situation calculus, which is a formalism for representation and reasoning about actions and their effects. Compared to the formalisms of the present paper, this formalism is based on predicate logic rather than modalities. In the situation calculus, a branching time structure is implicitly present where the branches are possible sequences of situations starting from an initial situation. Such a branching time structure is in   endowed with a preferred branch describing the worlds true evolution. This is obtained by extending the situation calculus with a predicate singling out situations belonging to the preferred branch. Given this, it is possible to express and answer certain hypothetical queries like:
At time Tp in the past, when you put A on B, could A have been put on C instead? (, p. 7)
However, it is not possible to express counterfactual queries such as:
If I had not paid the bookie, would I have lived to bet again? (, p. 12)
This is so because the situation calculus of   do not take into account true futures of counterfactual moments which the authors call hypothetical actual lines of situations. In fact, they write:
The present formalism allows us to express knowledge about what happens in the world....
Unfortunately, we do not have hypothetical actual lines that would allow us to express knowledge about what would occur if certain non-actual actions were to be performed, for example, counterfactuals in which alternative action occurrences can be postulated. (, p. 7)
It seems that formalisation of hypothetical actual lines would (explicitly or implicitly) have to involve the notionof a chronicle function. This would make the considerations of the present paper relevant.
Acknowledgements: Thanks to Alberto Zanardo for stimulating discussions on topics related to this paper.
References
  B. Barcellan and A. Zanardo. Actual futures in Peircean brancing-time logic. Draft manuscript, 1997.
  N. Belnap and M. Green. Indeterminism and the thin red line. Philosophical Perspectives, 8:365-88, 1994.
  T. Brauner, P. Hasle, and P. hrstrm. Determinism and the origins of temporal logic. In Proceedings of Second International Conference on Temporal Logic, Applied Logic Series.
Kluwer Academic Publishers, 1998. 22 pages. To appear.
  M. L. Ginsberg. Counterfactuals. Artificial Intelligence, 30:35-81, 1986.
  P. Haddawy. A logic of time, chance, and action for representing plans. Artificial Intelligence, 80:243-308, 1996.
  P. Hasle and P. hrstrm. Counterfactuals and branching time in automated text understanding. In S. Jansen et al., editor, Computational Approaches to Text Understanding. Museum Tusculanum, Copenhagen, 1992. pp. 13-27.
  G. E. Hughes and M. J. Cresswell. An Introduction to Modal
Logic. Methuen, 1968.
  D. Lewis. Counterfactuals. Harvard University Press, Cambridge MA., 1973.
  D. Lewis. Counterfactual dependence and times arrow.
NOUS, 13:455-76, 1979.
  D. V. McDermott. A temporal logic for reasoning about processes and plans. Cognitive Science, 6:101-55, 1982.
  V. R. McKim and C. C. Davis. Temporal modalities and the future. Notre Dame Journal of Formal Logic, 17:233-38, 1976.
  P. hrstrm and P. Hasle. Temporal Logic: from Ancient
Ideas to Artificial Intelligence. Kluwer Academic Publishers, 1995.
  S. A. Pedersen, P. hrstrm, and M. Elvang-Goranson. The structure of causal reasoning in medicine and engineering.
In J. Faye, U. Scheffler, and M. Urchs, editors, Logic and Causal Reasoning. Akademie Verlag, Berlin, 1994. pp. 23153.
  R. N. Pelavin and J. F. Allen. A formal logic of plans in temporally rich domains. In Proceedings of the IEEE, volume
74:1364-82, 1986.
  J. Pinto and R. Reiter. Reasoning about time in the situation calculus. Annals of Mathematics and Artificial Intelligence, 14:251-268, 1995.
  A. N. Prior. Past, Present and Future. Oxford, 1967.
  N. Rescher and A. Urquhart. Temporal Logic. Springer, 1971.
  Y. Shoham. Nonmonotonic reasoning and causation. Cognitive Science, 14:213-52, 1990.
  R. H. Thomason and A. Gupta. A theory of conditionals in the context of branching time. In W. L. Harper, R. Stalnaker, and G. Pearse, editors, Ifs: Conditionals, Belief, Decision, Chance, and Time. Reidel, Dordrecht, 1980. pp. 299-322.Automatic resolution rule assignment to multilingual Temporal Expressions using annotated corpora
E. Saquete P. Martinez-Barco R. Muiioz gPLSI
DLSI. UA
Alicante, Spain
{stela,patricio,rafael) @dlsi.ua.es
Abstract
The knowledge-based system TERSEO was originally developedfor the Recognition and Normalization of temporal expressions in Spanish and then extended to other languages: to English first, through the automatic translation of the temporal expressions, and then to Italian, applying a porting process where the automatic translation of the rules was combined with the extraction of expressionsfrom an annotated corpus.
In this paper we present a new automatic porting procedure, where resolution rules are atltomatically assigned to the tenporal expressions that have been acquired in a new language, thus eliminating the need for automatic translation and consequently minimizing the errors produced. This is achieved by exploiting the rules of the temporal model, which are language independent, and the information extracted &om the annotated corpus. Evaluation results of the updated version of TERSEO for English show a considerable improvement in recognitionperlformance (+ 14%
F-Measure) with respect to the original system.
1 Introduction
Recently, the Natural Language Processing community has become more and more interested in developing language independent systems, in an effort to break the language barrier hampering their application in real use scenarios. Such a strong interest towards multilinguality is demonstrated by the growing number of international conferences and initiatives putting systems' multilingual/crosslanguage capabilities among the hottest research topics.
Among these, for instance, the European Cross-Language
Evaluation Forum' (CLEF) is a successful evaluation campaign which aims at fostering research in different areas
M. Negri M. Speranza
ITC-irst
Povo (TN), Italy
{negri,manspera) @itc.itof multilingual information retrieval. Started in 2000, the CLEF initiative has rapidly grown over the years in terms of tasks, languages covered, and participating systems. At the same time, in the temporal expressions recognition and normalization field, systems featuring multilingual capabilities have been proposed. Among others,,  and   emphasized the potentialities of such applications in different information retrieval related tasks.
As in many other NLP areas, research in automated temporal reasoning has recently seen the emergence of machine learning approaches trying to overcome the difficulties of extending a language model to other languages [I, 41. In this direction, the outcomes of the first Time Expression
Recognition and Normalization Workshop (TERN 20042) provide a clear indication of the state of the field. In spite of the good results obtained in the recognition task, normalization by means of machine learning techniques still shows relatively poor results with respect to rule-based approaches, and still remains an unresolved problem.
The difficulty of porting systems to new languages (or domains) affects both rule-based and machine learning approaches. With rule-based approaches [12, 31, the main problems are related to the fact that the porting process requires rewriting from scratch, or adapting to each new language, large numbers of rules, which is a costly and timeconsuming process. Machine learning approaches [13, 51, on the other hand, can be extended with little human intervention through the use of language corpora. However, the large annotated corpora that are necessary to obtain high performance are not always available. In this paper we describe a new procedure to build temporal models for new languages, starting from previously defined ones. While still adhering to the rule-based paradigm, its main contribution is the proposal of a simple, but effective, methodology to automate the porting of a system from one language to another. To accomplish this, we take advantage of Proceedingsof the Thirteenth International Symposium on Temporal Representation and Reasoning (TIME'O6)
1530-1311/06 $20.00 O 2006
IEEE
R. Sprugnoli
CELCT
Trento, Italy sprugnoli @celct.it
C ~SOCIETY
EQ
~PUTERthe architecture of an existing system developed for Spanish (TERSEO, see [I I]), where the recognition model is language-dependent but the normalizing procedure is completely independent. In this way, the approach is capable of automatically learning the recognition model, adjusting the set of normalization rules.
The paper is structured as follows: Section 2 provides a short overview of TERSEO; Section 3 describes the automatic extension of the system to other languages using automatic translation of the expressions; Section 4 presents the new procedure to automatically assign normalization rules to new temporal expressions using annotated corpora;
Section 5 shows the results of evaluation experiments performed on this automatic assignment, and finally Section
6 compares the performance of TERSEO before and after adding the new procedure of using this automatic assignment of resolution rules with Chronos, which is a languagespecific system.
Once the parser has recognized the TEs in an input text, in the second step they are resolved by the normalization unit, which updates the value of the reference according to the date they refer to, and generates the XML tags for each expression. The normalization unit uses an inference engine in order to resolve all the deleted temporal expressions. This inference engine exploits a centralized unit (TER-ILI unit) that contains a set of general resolution rules, as is shown in Figure 1. Unlike the rules used in the recognition phase, the resolution rules are language independent and will be common for all the sets of temporal expressions in any multilingual extension of TERSEO.
2 Existing versions of TERSEO
2.1
TERSEO for Spanish: architecture
At first, TERSEO was developed in order to automatically recognize temporal expressions (TEs) appearing in a Spanish written text, and normalize them according to the temporal model proposed in, which is compatible with the ACE annotation standards for temporal expressions.
In this formalism TEs are annotated with a TIMEX2 XML tag (recognition) and, for each TE, values are assigned for a set of attributes (normalization). The meaning of the attributes, which will be evaluated in Section 6, is explained as:
VAL: contains the value of a TE (e.g. VAL="2004-0506" for "May 6th, 2004")
ANCHOR-VAL: Contains a normalized form of an anchoring date-time.
ANCHORDIR: Captures the relative directionorientation between VAL and ANCHOR-VAL.
MOD: Captures temporal modifiers (possible values are approximately, more than, less then)
SET: Identifies expressions denoting sets of times (e.g.
"every year").
The first step of the system (recognition) includes a preprocessing of the input texts, which are tagged with lexical and morphological information that arc given as input to the temporal parser. The temporal parser is implemented using an ascending technique (chart parser) and is based on a temporal grammar.
Figure 1. Multilingual TERSEO
Moreover, TERSEO has been extended to other languages with the automatic creation of temporal models for new languages starting from previously defined ones, so as to overcome the problems that are inherent in the rule-based paradigm. With the rule-based approach, the porting implies a big effort due to the necessity of rewriting rules from scratch.
2.2
Original English version of TERSEO
In a first experiment, for English language, the model was obtained automatically from the Spanish one, through the automatic translation of the Spanish temporal expressions into English. The development of the procedure for the automatic porting required 1 person during 1 week in order to developed the software necessary to perform it and less than an hour to obtain the new model using this new application. This platform can be reused to any language without any modification. The resulting system for the recognition and normalization of English TEs obtained good results both in terms of precision (P) and recall (R) [lo].
2.3
Porting of TERSEO to Italian
In the case of Italian, we developed a new procedure which exploits both the Spanish and the English models alProceedings of the Thirteenth International Symposium on Temporal Representationand Reasoning (TIME'O6)
1530-1311/06 $20.00 O 2006 IEEE
Q
CO~PUTER
SOCIETYready available and an Italian corpus annotated with temporal expressions. The software required to obtained new expressions from an annotated corpora was developed in less than 1 day and can be used to extract new temporal expressions in any language without any modification.
The reason for considering both models is the fact that they complement each other: on the one hand, the Spanish model was obtained manually and showed high precision values in detection (88%); on the other hand, although the English model showed lower precision results in detection(77%), the on-line translators from English to Italian form better than translators from Spanish to Italian. combined exploitation of two models works as followslected from the corpus. This generalization process has a double effect. On the one hand, it reduces the number of recognition rules. On the other hand, it allows to identify new expressions that were not previously learned; for instance, the expression "Dieci nlesi dopo " (i.e. "Ten months later") can be recognized as a generalization of "Nove rnesi dopo" (i.e. "Nine months later").
The multilingual extension procedure (figure 2) was carried out in three phases:
An Italian corpus with temporal annotations is cessed in order to collect a set of Italian tempora pressions. The selected c o ~ p u sbelongs to the t ing part of the Italian Content Annotation Ban1
CAB).
Each single Italian TE is related to the appropriat ready existing normalization rule. In order to do all the expressions are first translated both into En; and into spanish3. Then, the normalization mle lated to the translated expressions are taken into sideration. If both the Spanish and English expres: are found in their respective models in relation tc same normalization lule, then this rule is assigned to the Italian expression. When only one of the ti lated expressions is found in the existing model! normalization rule is assigned. In case of discre cies, i.e. if both translated expressions are found not coinciding in the same normalization rule, then ~r has been chosen to prioritize the Spanish rules, as the Spanish model was obtained manually and showed a higher precision. In other cases, the expression is reserved to a manual assignment. a The set of Italian temporal expressions is augmented by automatically translating into Italian the Spanish and English TEs. In this case, a filtering module has been developed to guarantee the correctness of the new
Italian TEs by searching the web with Google4: if the translated expression is not found by Google it is given up, otherwise it is included in the model, and related to the same normalization rule assigned to the Spanish or English temporal expression.
The entire translation process has been completed with an automatic generalization process, oriented to obtain generalized rules from the concrete cases that have been colh he on-line lnachine translation systellls used are InterTran(http~//www.tranexp.con1:2OOO~ranslate/result.sht) for Spanish-Italian and Altavista (http://world.a1tavista.c01l1/) for English-Italian
4http://www.google.com/
New N o m l l z
Figure 2. Multilingual extension procedure.a
Phase 1: TE Collection. The Italian temporal expressions are collected (i) from the I-CAB Corpus and(ii) with the automatic translation into Italian of the sets of Spanish and English TEs (and subsequent filter through Google).a
Phase 2: Phase 2: TE Generalization. In this phase, the TEs Gramatics Generator uses the morphological and syntactical information from the collected TEs to automatically generate the grammatical rules that generalize the recognition of the TEs. These grammatical rules allow TERSE0 to ignore the information from the text that is not susceptible to be a temporal expression. In this step, the information that has to be analyzed and resolved is being reduced by the system. In addition to this, the keyword uilit extracts a list of temporal keywords and, after augmenting them with their synonyms in EuroWordNet, uses them to extract
Proceedings of the Thirteenth International Sympos~umon Temporal Representation and Reasoning (TIME'O6)
1530-1311/06 $20.00 0 2006 IEEE
SOCIETYnew TEs from a non-annotated corpus in the target language.
There are two types of temporal keywords:
- IIigh ten~poralitykeywords: words that always atemporal meaning, such as "January", "day" and "days".In order to develop the procedure, all the temporal expressions and the values assigned to the different attributes have been extracted from the TERN 2 0 0 4 ~training corpus of newspaper articles, improving the English database of TERSEO.
The new procedure has been carried out in four steps, that are described next, and it is shown in Figure 3.
Low temporality keywords: words with high probability of being part of a temporal expression, such as "next", "last" and "ago".
In order to extract new TEs, any sequence of keywords found in the corpus is considered as a possible temporal expression. For example, in "There were two accidents days ago", the keyword unit will first find a high temporality keyword ("days"), then look for more tern.poral words (high and low) preceeding or following this word, and finally return the expression "days ago".
All the candidate temporal expression are checked for correctness using Google. In Phase 3, this new found expression should be translated in order to obtain the resolution rule for it.
Phase 3: TE Normalizing Rule Assignment. In the last phase, the translators are used to relate the recognizing rule to the appropriate normalization rule. For this purpose, the system takes advantage of the previously defined Spanish and English temporal models.
3 A new porting procedure: automatic assignment of normalizing rules through annotated corpora
The problem with the automatic extension proposed in the previous section appears when the normalizing rules need to be assigned to the expressions that have been automatically extracted from the annotated corpus, as automatic translators are not completely accurate and a wrong assignment may happen as a consequence of an incorrect translation. The consequences of this are especially remarkable for languages other than English, for which less tools are available. In the porting to Italian, for example, a total of 2474 temporal expressions were extracted from the corpus.
However, after the automatic translation and a manual debugging of the expressions, only 252 where left to be stored in the set of Italian temporal expressions.
To overcome this problem, a new procedure has been developed, which does not require the translation of the temporal cxprcssions extracted from the corpus, but exploits more deeply the corpus annotations by taking into consideration also the information provided by the normalization attributes (see Section 2 for a description of such attributes).
:................
: Step...............................,... j Stepi
:
~ " d, r hT E ~.........................
3
Figure 3. Automatic assignment of resolution rules
3.1
TE collection
As it was performed for the Italian extension of the system, all the annotated temporal expressions in English are extracted from an annotated corpus. However, not only the expressions are extracted and stored, but also the values of the normallization attributes of the TIMEX2 tags for each expression and the newspaper date (these values will be used for the automatic assignment of the resolution mle).
After the TE-Collection phase, 25 13 temporal expressions have been obtained. For example, the following annotation has been extracted: "<TIMEX2 val="2000-W44" mod="" set="" anchorual="" anchor-dir="" comment="">this week< /TIMEX2>"; in this case, the temporal expression "this week" as well as the values of its attributes are extracted and the expression is resolved as "2000-W44". If this annotation is taken from the file "MNB20001102.2100.2766.tmx.sgml", the newspapers date, e.g. 20001 102, is also extracted and attached to this ihttp://timex2.m~ue.org/corporaltimex2~coqora.htd
Proceedings of the Thirteenth International Symposium on Temporal Representation and Reasoning (TIME'O6)
1530-1311/06 $20.00 o 2006
IEEE
SOCIETY
Resolution Rule
WEEK,PAST
WEEK,PRESENT
WEEK, FUTUREexpression as well as to every expression collected from the same article.
3.2
TE granularity
Due to the fact that the resolution rules in the TER-ILI unit are classified based on the granularity that the rule is referring to, it is necessary to determine the granularity of the new found expression to limit the search of the possible resolution rule for that expression. Some possible granularities stored in the database are: DAY, MONTH,YEAR, WEEK,...
The granularity is obtained using two factors associated with the expression:
Temporal trigger words of the expression, such as, "day","months","January"
The value assigned to the attribute VAL in the TIMEX2 tag of the expression.
For example, the TE "the last 10 years" has the attribute
VAL="PlOY".This expression contains the temporal keyword "years" in the expression, and besides, the value of the VAL attribute contains "Y", that means year as well. So, the TE granularity unit is assigning "YEAR" for the expression of the example.
3.3 Voting unit of resolution rules
In this step, all the possible resolution rules related with the granularity of the temporal expression are obtained.
Every possible rule is resolved for the temporal expression, using the newspaper date associated to the expression as a referent. The resolution obtained is compared with the values of the attributes of the TIMEX2 tag and a weight of similarity is assigned to every resolution rule.
Finally, the resolution rule with the most similar results is assigned to the temporal expression. For example, for the expression "this week", the original tag extracted from the text was: "<TIMEX2 val="2000-W44" mod="" set="" anchor-val="" anchor-dir="" comment="">this week<
/TIMEX2>". In this step, all the resolution rules related with weeks are obtained from the database and applied to the newspaper's date (20001102). After the resolution of this kind of rules, only a value for the VAL attribute was obtained, as it is shown in Table 1.
The weight is calculated as the sum of coincident attributes between the original TIMEX2 tag and the resulting tags after applying the different rules. So, in the example, for the expression "this week" the resolution rule
"WEEK,PRESENT" is assigned.
Weight
0
1
0
Table 1. Example of Step 3
All the temporal expressions are transformed into patterns of temporal expression. For example, the expression
"the last 10 years" is stored as "the last NUM years" in the database. The new found patterns are stored in the set of English temporal expressions, in order to be used by TERSE0 system. The same process can be applied to other extensions of the language, such as Italian, without the necessity of the automatic translation of the new temporal expressions. In our experiments with the TERN 2004 training corpus, 1096 patterns of temporal expressions were obtained with its associated resolution rule.
This automatic assignment of the resolution rule will be evaluated in the next section.
4
Evaluation
In order to evaluate the automatic assignment of resolution rules for the new temporal expressions found in the TERN 2004 corpus, two different sets of expressions have been considered separately: expressions that were obtained from the annotated corpus and expressions that were obtained from the direct translation of Spanish expressions.
In the first case, the automatic assignment of the resolution rules resulted in a set of 994 expressions out of a total of 1096 expressions recognized by the system. These were considered as good new temporal expressions and could therefore be directly added to the English temporal expressions database.
In the case of the remaining 102 expressions, obtained from the direct translation of Spanish expressions, the resolution rule obtained automatically was compared with the one obtained by the translation and both were checked manually. Results are as follows:
In 41 expressions out of a total of 102, both systems agreed in the resolution rule assigned to the expressions
For the 61 expressions whose resolution rule differs from the one previously assigned, the results are: in 3 expressions, the new procedure assigns a better resolution rule than the older one; in 41 expressions, the old procedure assigns a better resolution rule than the new one; finally, there are 17 expressions whose assigned
Proceedings of the Thirteenth International Symposium on Temporal Representationand Reasoning (TIME'O6)
1530-1311/06 $20.00 o 2006 IEEE
Attribute values
VAL=2000-W43
VAL=2000-W44
VALz2000-W45
Q
CO~IPUTER
SOCIETY
Tag timex2 anchor-dir anchor-va1 set val
Original TERSEO
P
R
F
0.673 0.728 0.699
0.658 0.877 0.752
0.684 0.912 0.782
0.800 0.667 0.727
0.757 0.735 0.746
Updated TERSEO
P
R
F
0.780 0.924 0.846
0.512 0.621 0.561
0.568 0.689 0.623
0.737 0.583 0.651
0.586 0.567 0.577
ENG-Chronos
P
R
F
0.976 0.880 0.926
0.833 0.698 0.760
0.683 0.775 0.726
0.880 0.564 0.688
0.875 0.870 0.872
Table 2. Results obtained over TERN corpus by TERSEO and Chronos. resolution rule is different but the annotation tag is the same after applying both rules.
The improvement that this new procedure adds to the automatic extension of the system is the possibility of obtaining temporal expressions that were not in the Spanish database. Besides, when the temporal expressions are extracted from the corpus, there is no necessity to automatically translate these expressions to other languages in order to obtain the resolution rule, which means avoiding the errors provoked by the lack of accuracy of the current automatic translators.
5
Comparative evaluation of the proposed approach
As a final evaluation experiment, we compared the automatic extension procedure described in the previous sections, with (i) the original English system based on the automatic translation of the Spanish rules, and (ii) a state of the art system developed for English.
Comparison with the original English version of TERSEO. When the original version of TERSEO participated in TERN 2004, the English temporal expressions handled by the system were only obtained through the automatic translation of the Spanish ones, sharing with them the corresponding resolution rule. The results obtained were high, taking into account that the English part of the system was automatically obtained from the existing knowledge for
Spanish. However, with this methodology the number of TEs recognized by the system was limited to such existing(language specific) knowledge. In the new porting procedure, taking advantage of an annotated corpus, our primary goal was to increment the knowledge available to the system, thus increasing the number of TEs in the target language handled by TERSEO. In this direction, results reported in Table 2 show an improvement of more than 14% in recognition (first row) in the updated version of TERSEO, which confirms the viability of the proposed solution. It's worth noting that such improvement on recognition will be even more noticeable for languages other than English, where the poorer quality of the available translation tools represents an additional source of errors.
Comparison with Chronos. As a reference system for our comparative evaluation we adopted Chronos (Negri and Marseglia, 2004). a multilingual system for the recognition and normalization of time expressions in Italian and English. Like all the other state of the art systems addressing the recognition/normalization task, Chronos is a rulebased system. from a design point of view, it shares with
TERSEO a rather similar architecture which relies on different sets of rules. These are regular expressions that check for specific features of an input text, such as the presence of particular word senses, lemmas, parts of speech, symbols, or strings satisfying specific predicates (e.g. "Weekdayp" and "Time-Unit-p", which are respectively satisfied by strings such as "Monday", "Tuesday",...,"Sunday", and "second", "minute", "hour", "day",..., "century"). Each set of rules is in charge of dealing with different aspects of the problem. In particular, a set of around 130 rules is designed for TE recognition, and is capable of recognizing with high Precision/Recall rates both explicit and anaphoric
TEs. Other sets of regular expressions, for a total of around
700 rules, are used in the normalization phase, and are in charge of handling each specific TIMEX2 attribute (Le.
VAL, SET, ANCHOR-VAL, and ANCHORDIR). The results obtained by the English version of Chronos over the TERN 2004 training corpus are shown in the last three columns of Table 2. As expected, the distance between the results obtained by TERSEO and Chronos is considerable. However, the great difference, both in terms of the required time and effort, in the development of the two systems should be taken into account. In fact, while the implementation of the manual one took several months, the porting procedure of TERSEO to English is a very fast process that can be accomplished in less than an hour. This makes the proposed procedure a viable solution which allows for a rapidporting of the system to other languages, while just requiring an annotated corpus.
6 Conclusions
In this paper, a complete automatic extension to other languages of a system that recognizes and normalizes temporal expression is presented. When these kind of knowlProceedings of the Thirteenth InternationalSymposium on Temporal Representation and Reasoning (TIME'O6)
1530-1311/06 $20.00 o 2006
IEEE
Q
COMPUTER
SOCIETYedge based systems are implemented manually, the development could last several months. However, the porting procedure of TERSEO to other language (English, Italian) is a very fast process that can be accomplished in less than an hour. Moreover, even if an annotated corpus for a new language is not available, the automatic porting procedure we present still remains feasible. This makes the proposed approach a viable solution which allows for a rapid porting of the system to other languages, while just requiring an online translator (note that the Altavista Babel Fish translator6 provides translations from English to 12 target languages) and/or an annotated corpora. In light of these considerations, the results obtained by TERSEO are encouraging. In addition, a set of different approaches to automatic extending the system are being performed in order to improve the automatic extension as much as possible.
[lo]
[I 11
[I21
 
 
References
[l] B. Carpenter. Phrasal Queries with LingPipe and Lucene. In
13th Text REtrieval Conference, NIST Special Publication.
National Institute of Standards and Technology, 2004.
  L. Ferro, L. Gerber, I. Mani, B. Sundheim, and G. Wilson.
Tides.2005 standard for the annotation of temporal expressions. Technical report, MITRE, 2005.
  E. Filatova and E. Hovy. Assigning time-stamps to eventclauses. In ACL, editor, Proceedings of the 2001 ACL
Workshop on Temporal and Spatial Information Processing, pages 88-95, Toulouse,France, 2001.
  A. Ittycheriah, L. Lita, N. Kambhatla, N. Nicolov, S. Roukos, and M. Stys. Identifying and Tracking Entity
Mentions in a Maximum Entropy Framework. In ACL, editor, Proceedrngs of the NorthAmerican Chapter Association for Computational Linguistic (NAACL) Workshop WordNet and Other Lexical Resources: Applications, Extensions and Customizations,2003.
  G. Katz and F. Arosio. The annotation of temporal information in natural language sentences. In ACL, editor, Proceedings of the 2001 ACL Workshop on Temporal and Spatial
Information Processing, pages 104-1 11, Toulouse,France, 2001.
  A Lavelli, B. Magnini, M. Negri, E. Pianta, M. Speranza, and R. Sprugnoli. Italian content annotation bank (i-cab):
Temporal expressions (v. 1.0.): T-0505-12. Technical report, ITC-irst, Trento, 2005.
  T. Moia. Telling apart temporal locating adverbials and time-denoting expressions. In ACL, editor, Proceedings of the 2001 ACL Workshop on Temporal and Spatial Infonnation Processing, Toulouse,France, 2001.
  M. Negri and L. Marseglia. Recognition and normalization of time expressions: Itc-irst at tern 2004. Technical report, ITC-irst, Trento, 2004.
  E. Saquete. Temporal information Resolution and its application to Temporal Question Answering. Phd, Departamento
 de Lenguages y Sistemas Informtiticos. Universidad de Alicante, June 2005.
E. Saquete, P. Martinez-Barco, and R. Munoz. Evaluation of the automatic multilinguality for time expression resolution.
In DEXA Workshops,pages 25-30. IEEE Computer Society, 2004.
E. Saquete, R. Munoz, and P. Martinez-Barco. Event ordering using terseo system. Data and Knowledge Engineering
Journal, page (To be published), 2005.
F. Schilder and C. Habel. From temporal expressions to temporal information: Semantic tagging of news messages.
In ACL, editor, Proceedings of the 2001 ACL Workshop on
Temporal and Spatial Inforn~ationProcessing, pages 65-72, Toulouse,France, 2001.
A. Setzer and R. Gaizauskas. On the importance of annotating event-event temporal relations in text. In L W C,editor, Proceedings of the LREC Workshop on Temporal Annotation Standards, 2002, pages 52-60, Las Palmas de Gran Canaria,Spain, 2002.
P. Vossen. EuroWordNet: Building a Multilingual Database with WordNets in 8 European Languages. The ELRA
Newsletter, 5(1):9-10,2000.
G. Wilson, I. Mani, B. Sundheim, and L. Ferro. A multilingual approach to annotating and extracting temporal information. In ACL, editor, Proceedings of the 2001 ACL
Worksho]~ on Tentporal and Spatial Information Processing, pages 8 1-87, Toulouse,France, 2001.
6http://world.altavista.coml
Proceedings of the Thirteenth International Symposium on Temporal Representationand Reasoning (TIME'O6)
1530-1311/06 $20.00
2006
IEEE
Q
COMPUTER
SOCIETYThis is an author-produced version of an article in the Annals of Mathematics and Artificial Intelligence (Springer), DOI 10.1007/s10472-013-9356-8.
The final publication is available at link.springer.com.
Compositional reasoning using intervals and time reversal
Ben Moszkowski
Received: 19 April 2012 / Final revision received: 26 April 2013 /
Accepted: 29 April 2013 / Available online: 5 June 2013
Abstract Interval Temporal Logic (ITL) is an established formalism for reasoningabout time periods. We investigate some simple kinds of ITL formulas which have application to compositional reasoning and furthermore are closed under conjunction and the conventional temporal operator known both as box and always.
Such closures help us modularly construct formulas from simple building blocks in a way which preserves useful compositional properties. The most important class considered here is called the 2-to-1 formulas. They offer an attractive framework for analysing sequential composition in ITL and provide the formal basis for most of the subsequent presentation. A key contribution of this work concerns a useful and apparently new and quite elementary mathematical theorem that 2-to-1 formulas are closed under box. We also use a natural form of time symmetry with
2-to-1 formulas. This extends known facts about such formulas by looking at them in reverse. An important example of this involves showing that 2-to-1 formulas are also closed under a variant of box for prefix subintervals rather than suffix ones. We then apply the compositional formulas obtained with time symmetry to analyse concurrent behaviour involving mutual exclusion in both Petersons algorithm and a new and more abstract one. At present, our study of mutual exclusion mainly serves as a kind of experimental proof of concept and research tool to develop and illustrate some of the logical frameworks promising features. We also discuss how time symmetry sometimes assists in reducing reasoning in ITL to conventional linear-time temporal logic.
Keywords Interval Temporal Logic  compositional reasoning  formal verification  time reversal  symmetry  mutual exclusion  Petersons algorithm
Software Technology Research Laboratory
De Montfort University
Leicester, UK
E-mail: benm@dmu.ac.uk
2
Ben Moszkowski
1 Introduction
Intervals and discrete linear state sequences offer a compellingly natural and flexible way to model computational processes involving hardware or software. Interval
Temporal Logic (ITL)   is an established formalism for reasoning about such phenomena. It has operators for sequentially combining formulas. For example, if A and B are formulas, so are AB (chop ) and A (chop-star ). These are somewhat analogous to the concatenation and Kleene star operators for regular languages and expressions. ITL can express some imperative programming constructs (e.g., while-loops) and has executable subsets.
We first summarise the primary contributions of this presentation and then discuss them in more detail:
Several classes of compositional ITL formulas which all share the importantproperty that they are closed under conjunction and the conventional temporal operator always (2).
Various syntactic and semantic applications of time symmetry to such formulas.
Some useful techniques for compositionally manipulating a number of suitable sequential and parallel combinations of the formulas with others.
A detailed application of these ideas to mutual exclusion, including the analysis of a novel abstract algorithm as well as Petersons well-known concrete one.
All of results are accompanied by rigorous, detailed mathematical theorems, lemmas and associated proofs, which are moreover themselves a quite indispensable part in the development of the framework.
Our main contribution concerns a novel categorisation and mathematical analysis of various simple classes of compositional formulas in Propositional ITL(PITL)   which are closed under conjunction and the conventional temporal operator always (2). The main class we consider consists of what we call
2-to-1 formulas (which are formally defined in Sect. 4). Briefly, a PITL formula
A is defined to be 2-to-1 if the implication (A; A)  A if valid, where ; is a second variant of chop. So if two portions of a system both ensure such a formulas behaviour, then their sequential composition is guaranteed to as well. The 2-to-1 formulas play a quite central role in almost all of the techniques presented here.
For example, we can show that for the propositional variables p and q, the conventional temporal logic formula p  3q (if p is true in the initial state, then q is true in some state ) is 2-to-1. Our new closure theorem immediately guarantees that the liveness formula 2(p  3q ) (whenever p is true, q is true then or later ) is 2-to-1 as well. Such a formula is suitable for forward analysis from a state satisfying p to one satisfying q. The many compositional properties we identify and rigorously prove clearly show that further systematic research about 2-to-1 formulas and other such classes of formulas closed under conjunction and 2, including the relationship between them, is compelling required.
We also propose here a second significant research contribution which exploits the symmetry of finite linear time to transform 2-to-1 formulas for forward analysis such as 2(p  3q ) into others for backward analysis from a state to its predecessors (as described in Sects. 5 and 6). This involves a two-stage approach.
In the first stage, our mathematical framework takes some suitable 2-to-1 formulas and views them in reverse in finite time to obtain more formulas which are 2-to-1 in finite time. In the second stage, these formulas are then shown to even be 2-to-1 in Compositional reasoning using intervals and time reversal
3infinite time. The process of transforming formulas demonstrates the significance of both syntactic and semantic forms of time symmetry.
The relationship between our use of time symmetry and some relevant earlier work using it is primarily discussed later in Sect. 16.1. We postpone a comparison until then in order that readers will have a better understanding of our framework.
The approach here based on 2-to-1 formulas and time symmetry further develops our ITL-based compositional techniques described in   since, for example, it helps to systematically obtain additional properties for sequential composition. Moreover, a number of results about 2-to-1 formulas and time symmetry are also applicable to the first-order version of ITL used in our earlier work, but we do not delve into this further.
We will consider a variety of relevant properties and other related categories of PITL formulas for compositional reasoning about sequential and parallel behaviour. The main techniques here can be summarised as Introduction, Sequential combining, Extension leftward or rightward, Parallel combining and Iteration (see
Sect. 4.1). This is abbreviated with the shorthand ISEPI.
The 2-to-1 formulas and time symmetry are then applied (in Sects. 1113) to showing by means of backward analysis the correctness of a new high-level abstract algorithm for mutual exclusion as well as the much studied one of Peterson.
It is first of all quite important to emphasise that the study of mutual exclusion led us in the first place to the 2-to-1 formulas and time symmetry. However, at present, our study of mutual exclusion mainly serves as a kind of experimental proof of concept. It has significantly influenced the development of virtually all aspects of the presentation here and moreover helps to illustrate some of the logical frameworks promising features. Nevertheless, we do not claim that it is sufficientlymature for practical deployment. Readers may indeed experience some difficulties with the intuition behind some formulas. Therefore, the material on mutual exclusion must be regarded, at least at present, as being primarily a powerful research tool for the intriguing compositional frameworks evolving theory rather than a distinct and independent application on its own. As such, it is for the moment indispensable for understanding the work.
Our presentation also shows (in Sect. 14) how time symmetry can assist in reducing satisfiability of suitable 2-to-1 formulas and some other PITL formulas to finite-time satisfiability of formulas in lower-level point-based temporal logic. This might help provide a way to extend the scope of some algorithms, implemented software tools and mathematical techniques for conventional temporal logic to eventually include suitable subsets of PITL involving 2-to-1 formulas as well.
The proofs given about PITL formulas are semantically based and so do not use a formal axiom system. However, an analysis could in principle include deductions in our complete axiom system for PITL with finite time   (see also Bowman and Thompson  ) and our newer one with infinite time.
Readers new to interval-based reasoning will find the approach quite different from those using point-based temporal logics. This applies even to our use of a conventional temporal logic formula such as 2(p  3q ), when, for example, we explain whyit is 2-to-1 or use time symmetry on it. In fact, we believe that even readers having experience with intervals will find our presentation quite novel. They should however keep in mind that time symmetry can be rather subtle. It requires an investment of patience and effort to be understood.
4
Ben Moszkowski
For the particular benefit of readers unfamiliar with ITL, we now briefly mention some recent publications by others which reflect current topics where ITL is being applied. They arguably contribute to making a case for the study of ITLs mathematical foundations, which naturally include such issues as compositionality and time symmetry.
The KIV interactive theorem prover   has for a number of years included a slightly extended version of ITL for interactive theorem proving via symbolic execution both by itself (e.g., for concurrent algorithms and lock-free techniques  ) and also as a backend notation which supports Statecharts   and UML.
The concluding remarks of   note the following advantages of ITL:
Our ITL variant supports classic temporal logic operators as well as program operators.
The interactive verifier KIV allows us to directly verify parallel programs in a rich programming language using the intuitive proof principle of symbolic execution. An additional translation to a special normal form (as e.g. in TLA [Temporal Logic of Actions  ]) using explicit program counters is not necessary.
The Duration Calculus (DC) of Zhou, Hoare and Ravn   extends ITL to real-time. Zhou and Hansen   give a comprehensive presentation of various aspects of DC and its application. They include a large bibliography of literature on DC. Olderog and Dierks recent textbook   uses DC as the formal logic in a framework for seamless design flow from specification to verified implementation.
This approach also includes timed automata and automata for programmable logic controllers (PLC-automata).
Duan and his group have been investigating the theory and application of Projection Temporal Logic, an ITL extension with operators for temporal granularities and framing   (our later Sect. 13.1 gives an explanation of framing). Some of their recent work on applications such as the specification and verification of asynchronous communication is described in   and.
Our presentation is a revised and greatly extended version of the earlier one by us in   that readers might benefit from because of its much briefer and more superficial format. The focus here differs from that in   by concentrating more on the general compositional issues. This is because we have subsequently come to realise that the theory of 2-to-1 formulas and related classes is much more central than its application to time symmetry, which is nevertheless quite intriguing. As a consequence, we have now added various definitions, explanations and other material. The topics we consider have many interesting aspects of relevance to compositional reasoning with and without time symmetry.
More recently, in   we present in a concise manner new techniques for systematically and incrementally elucidating connections between 2-to-1 formulas and some associated compositional classes. These are a direct outcome of the research described here and can serve as a quick introduction to the mathematics of such classes. However, the compositional ISEPI techniques, time symmetry and applications to mutual exclusion are not discussed in.
Here is our presentations structure:
Section 2 overviews PITL.
Section 3 presents some important point-based subsets of PITL used later onin our analysis.
Compositional reasoning using intervals and time reversal
5
Section 4 introduces 2-to-1 formulas, presents various kinds of them and proves that they are closed under conjunction, the temporal operator 2 (always) as well as the time-wise symmetric operator 2f, which concerns finite prefixsubintervals instead of suffix subintervals. As we discuss there, 2-to-1 formulas can be used for reasoning about various safety and liveness properties. A categorisation is given of general compositional ISEPI techniques for Introduction, Sequential combining, Extension leftward or rightward, Parallel combining and Iteration.
Section 5 starts our discussion about the application to 2-to-1 formulas of both time symmetry and reductions from infinite time to finite time. It therefore shows how to relate some of the time reversed formulas to other semantically comparable ones expressed in a version of conventional Propositional LinearTime Temporal Logic (PTL) with past time because this is much better known than PITL.
Section 6 uses time symmetry to obtain a versatile class of 2-to-1 formulas for backward analysis from other 2-to-1 formulas for forward analysis. Such formulas are extensively used in all subsequent sections.
Sections 710 primarily concern versions of the various ISEPI techniques suitable for compositionally combining 2-to-1 formulas for backward analysis:
Section 7 provides ways to compositionally introduce such 2-to-1 formulas.
Section 8 deals with a compositional technique for sequentially extending the scope of the 2-to-1 formulas for backward analysis from an intervals prefix subinterval to the entire interval.
Section 9 concerns the parallel combining of such 2-to-1 formulas.
Section 10 presents techniques for compositional reasoning involving the sequential iteration of these 2-to-1 formulas.
Sections 1113 concern mutual exclusion:
Section 11 looks at an abstract mutual exclusion algorithm. The section applies to the algorithm the results from the previous sections concerning
2-to-1 formulas for backward analysis and ISEPI techniques for sequential and parallel composition of such formulas.
Section 12 considers in more detail an individual process in the abstract mutual exclusion algorithm and also its relation to a process in Petersons algorithm.
Section 13 analyses Petersons algorithm. This is done by formally relating it to the abstract algorithm.
Section 14 examines further reductions using time symmetry to transform some
PITL formulas into ones in conventional point-based temporal logic.
Section 15 discusses various pertinent issues.
Section 16 surveys related work.
Our view is that the separation of the underlying mathematics from the subsequent application to mutual exclusion helps make the foundational theoretical aspects of the framework clearer. One could indeed even take this a stage further and argue that in principle the more purely theoretical material on compositionality in Sects. 210 could be studied somewhat independently of its application to mutual exclusion in Sects. 1113. However, in practice, our investigation of the abstract theory and its application to mutual exclusion have been done simultaneously with much cross-fertilisation involving experimentation and trial and error.
6
Ben Moszkowski
As a result, the theory and application of 2-to-1 formulas for backward analysis seem quite interrelated. Indeed, it appears virtually impossible for us to have developed either of them in isolation. We therefore believe they are best understood and appreciated when studied together in a way which offers a more complete picture of the approach in its current form.
The evolution of this work is moreover inextricably connected with the rigorous construction of many theorems, lemmas and associated proofs. This also seems to be an inseparable and quite invaluable and essential part of the exploration process. What we present here gives a picture of the current state of the approach. It continues to progress as we gain more knowledge about the remarkable and extensive mathematical terrain of 2-to-1 formulas for forward and backward analysis.
2 Propositional Interval Temporal Logic
We now describe the version of (quantifier-free) PITL used here. More on ITL and PITL can be found in   (see also Kroger and Merz, Fisher   and the ITL web pages  ).
Below is the syntax of PITL formulas in BNF, where p is any propositional variable:
A ::= true | p | A | A  A | skip | AA | A.(1)
The last two constructs are called chop and chop-star, respectively. The boolean operators false, A  B, A  B (implies ) and A  B (equivalence ) are defined as usual. We refer to A B as strong chop and likewise refer to A as strong chopstar. Weak versions are discussed shortly when we present some derived operators.
Time within PITL is modelled by discrete, linear intervals. An interval  is any finite or  -sequence of one or more states 0, 1,... (which are not necessarily distinct from one another). Each i maps every propositional variable p to true or false. This mapping is denoted as i (p). Let  denote the set of all states. An interval  has interval length ||  0, which, if  is finite, is the number of  s states minus 1 and otherwise. So if  is finite, it has states 0,..., ||. If the same state occurs twice in, it is counted twice for determining  s interval length.
Let  + denote the set of finite intervals and   denote the set of infinite ones.
The (standard) version of PITL used here with state-based propositional variables is called local PITL. A subinterval of  is any interval which is a contiguous subsequence of  s states. This includes  itself.
The notation  |= A, defined shortly by induction on As syntax, denotes that interval  satisfies formula A. Moreover, A is valid, denoted |= A, if all intervals satisfy it.
Below are the semantics of the first five PITL constructs in (1):
True:  |= true trivially holds for any.
A variable p:  |= p iff 0 (p)=true (initially p).
Negation:  |= A iff  |6 = A.
Disjunction:  |= A  B iff  |= A or  |= B.
Skip:  |= skip iff  has exactly two states (i.e., || = 1).
Note that an interval  satisfies skip even if  s two states are identical to each other. For natural numbers i, j with 0  i  j  ||, let i:j be the finite subinterval i... j (i.e., j  i + 1 states). Define i to be  s suffix subinterval from state i.
Compositional reasoning using intervals and time reversal
7
Below are semantics for strong chop and chop-star:
A B :  |= A B iff for some natural number i: 0  i  ||, both 0:i |= A and i |= B.
Note that in the case where || =, we actually have i < ||.
A :  |= A iff one of the following holds:(1) The interval  has only one state.(2)  is finite and either itself satisfies A or can be split into a finite number of(finite-length) subintervals which share end-states (like chop) and all satisfy
A.(3) || =  and  can be split into  finite-length intervals sharing end-states(like chop) and each satisfying A.
Case (3) is called chop-omega and denoted as A.
We depict below the behaviour of variable p in a sample 5-state interval  and denote true and false by t and f. p
0 t
1 f
2 t
3 f
4 t
This interval satisfies the following formulas: pskip  pp  (true  p)(p  (skip  skip )).
For instance, the formula skip  p is true because 0 1 satisfies skip and 1... 4 satisfies p since 1 (p) = false. The fourth formula is true because the interval s three-state subintervals 0 1 2 and 2 3 4 both satisfy p  (skip  skip ). The interval  does not satisfy the formulas below: pskip  ptrue  (p  (true  p)).
Table 1 shows useful derived PITL operators, including empty for one-state intervals and the weak chop construct A; B which can ignore B in an infinite interval satisfying A. We derive here ITLs conventional weak chop-star A from the strong version, although the two are interderivable. In an infinite interval, strong chop-star requires an infinite number of iterations each of finite length, whereas weak chop-star also permits a finite number of iterations with the last having infinite length. The strong variants of chop and chop-star are taken as primitives here to simplify some of the reasoning about time symmetry. However, we extensively use the weak versions for reasoning about possibly nonterminating parts of programs.
We discuss in Sect. 15.4 the reason for our use of the term empty to describe one-state intervals even though in language theory it refers the unique empty word with no letters at all.
Let w and w denote state formulas without any temporal operators.
Table 2 contains several sample PITL formulas which are valid. For example, the formula (w  A)  (empty  w); A can be understood as stating that an interval satisfies state formula w and PITL formula A iff the first state of the interval satisfies w and the interval satisfies A. Here the first state is equally regarded as f f being a one-state interval in its own right. The valid equivalence (2f 2A
)  2A uses f f
2A to test the formula A in finite subintervals and uses 2f 2A to test A in these
8
A
3A
2A more empty finite inf fin A stable A f
3A f
2A
A;B i
3A i
2A
A
A+
A
AB
A < B
Ben Moszkowski
= b
= b
= b
= b
= b
= b
= b
= b
= b
= b
= b
= b
= b
= b
= b
= b
= b
= b
= bskip A true A
3A true more
3empty finite
2(empty  A)
2(more  (A   A))
A true f
3A(AB )  (inf  A)
A;true i
3A

A  A  (inf  A)
A;A inf  A finite  ((fin A)  B )
A  B  (stable A; skip )
Next
Eventually
Henceforth (Always)
More than one state
Only one state
Finite interval
Infinite interval
Weak test of final state
Stability
Some initial finite subinterval
All initial finite subintervals
Weak chop
Some initial subinterval (even infinite)
All initial subintervals (even infinite)
Conventional weak chop-star
One or more iterations
Chop-omega
Temporal assignment
Padded temporal assignment
Table 1 Some useful derived PITL operators(finite(w  A); B  w wskipf
2A
)A
A  (empty(A; B )
A  (empty ; A)w); Afinite  (A  A )f (A  B )  (2A f f
2
2B
) f f(2f 2A
)  2Ainf  2moref f(22A
)  (22A
)
A  (empty
A+ )f f f (3A f f
3A
3B
3
3B
)
Table 2 Sample valid PITL formulasfinite subintervals own finite subintervals. The equivalence is valid because the set of finite subintervals contained within an intervals finite subintervals is exactly the same as the set of the intervals own finite subintervals. This is related by time symmetry to the equivalence (22A)  2A which concerns suffix subintervals and is f f f found even in conventional temporal logic. The last formula (3A
3B
)  3f (3Af
3B ) states that two formulas A and B are each true in finite prefix subintervals f f of an interval exactly if the conjunction 3A
3B is true in some finite prefix subinterval (e.g., the larger of the two satisfying A and B, respectively).
Compositional reasoning using intervals and time reversal
9
3 Some important point-based subsets of PITL
We now present some point-based subsets of PITL which have been found useful in our previous work   and come in handy later.
3.1 Subset of PITL with only skip, next and diamond
Let PTL denote the subset of PITL formulas in conventional Propositional
Linear-Time Temporal Logic with just the (derived) temporal operators  and 3 in Table 1. We use X, X  and Y for PTL formulas. Various useful compositional safety and liveness properties can be expressed in PTL. For instance, we already presented the sample PTL formulas p  3q and 2(p  3q ) in the introduction in Sect. 1. Note that the PITL primitive construct skip can be derived in PTL astrue (the same as  empty ), so we can regard PTL as containing it as well.
We will use PTL here since it can express various compositional formulas. Furthermore, it has much lower computational complexity and better tool support than full PITL, which has nonelementary complexity (a theorem by Kozen described in our own joint work with Halpern   (reproduced in  )). Therefore, Sect. 14 describes some potential transformations using time symmetry from PITL to a slightly enhanced version of PTL with an until operator defined shortly in Sect. 3.3.
3.2 Subset of PTL with just unnested next operators
We extensively use an important subset of PTL involving the operator
:
Definition 3.1 (Next Logic) The set of PTL formulas in which the only primitive temporal operator is  is called Next Logic (NL). The subset of NL in which nois nested within anotheris denoted as NL1.
For example, the NL formula p   q is in NL1, but the NL formula p  (q   p) is not.
The variable T denotes formulas in NL1.
All state formulas (e.g., p  q ) are in NL1 because they contain no temporal operators. The important derived PITL constructs more and empty already defined in Table 1 are also in NL1. Unlike state formulas, more and empty can detect whether or not an interval has just one state. However, the primitive construct skip, which tests for exactly two states, cannot be expressed in NL1 because it requires one  within another:    true (the same as  empty ).
In order to further illustrate the nature of NL1 expressiveness, we list below some more properties which NL1 formulas cannot express, together with PTL formulas not in NL1 which do capture these properties:
Property
Corresponding formula not in NL1
The formula p  q is true in the third state  (p  q )true (same as  more )
The interval has more than two statestrue (same as  empty )
The interval has exactly two states
10
Ben Moszkowski
The NL1 formulas play a significant role in the theory of PITL. We therefore strongly encourage readers seriously interested getting a better understanding of ITL to study our presentation in, where we systematically describe some natural applications of NL1 to relating point-based and interval-based temporal logic.
Our new complete axiom system for PITL with infinite time   likewise makes extensive use of NL1 formulas and therefore shows how they can be profitably employed.
3.3 PTL with until operator
Our presentation also makes use of a PTL variant called here PTLu. It has a somewhat restricted strong version of the standard temporal operator until which is derivable in PITL:
T until A
= b(skip
T )  A.
Only NL1 formulas are permitted on our restricted until s left side, as the definition indicates by the use of T. This is because if the left operand is not in NL1, the restricted until will not work properly. For example, the formula (  p) until q actually reduces to false. Now PTLu is more expressive than PTL (e.g., see  ), but reducible to it using auxiliary variables to mimic until. For example, when considering the satisfiability of the formula p  (p until q )  (p until q ), we can transform it into the formula below with an extra auxiliary variable r : prr
2 r  q(p   r )

2(r  3q ).
We make extensive use of PTLu in our recent axiomatic completeness proof for
PITL with infinite time. Section 15.3 later shows an alternative way to derive until without chop-star.
Section 5 (particularly regarding formula (13)) and Sect. 14 include reductions from PITL to PTLu. We use PTLu because formulas in it can be more expressive than in PTL. Nevertheless, they can be readily transformed to PTL, although, as we noted already, this necessitates the introduction of some auxiliary variables.
When compared with PITL, the differences between PTL and PTLu are certainly quite small.
4 2-to-1 formulas
We now discuss in more detail the 2-to-1 formulas, which were already briefly considered in Sect. 1. These are the main class of formulas closed under conjunction and the temporal operator 2 in our presentation here. Such closure properties help to modularly construct formulas from simple building blocks in a way guaranteed to ensure that the results preserve some useful compositional properties. Many of the properties of 2-to-1 formulas which we consider concern sequential composition.
However, parallel composition of formulas is not neglected either.
In this section we focus on formally defining 2-to-1 formulas and studying some of their fundamental theoretical properties. The presentation mostly looks at the relatively abstract mathematics of compositional reasoning rather than any
Compositional reasoning using intervals and time reversal
11particular application of the formulas. We believe that the issues explored at such a level of abstraction are themselves an important contribution to work in the area.
Nevertheless, this material provides a solid and practical basis when the formulas are extensively used later on with time symmetry in Sects. 5 and 6 and in our experimental analysis of mutual exclusion in Sects. 1113.
Definition 4.1 (2-to-1 Formulas) Any PITL formula A for which the implication(A; A)  A is valid is called a 2-to-1 formula.
For example, the state formulas true and p are 2-to-1. In the first case, true is trivially true for any interval, so the implication (true ; true )  true is valid. Here is a proof for the case of p:
Proof (p is 2-to-1) Suppose that an interval  satisfies p; p. We can readily show from the PITL semantics of weak chop (see Table 1) that  has a prefix subinterval(perhaps  itself) which satisfies p. Hence, the first state of   also satisfies p.
Now the first states of  and   are identical, so  itself satisfies p and consequently also the implication (p; p)  p. Therefore, every interval satisfies this implication, so it is indeed valid. Consequently, p is 2-to-1.
In contrast to true and p, the formula skip is not 2-to-1 and perhaps even the simplest example of this. Observe that the chop formula skip ; skip is satisfied solely by intervals with precisely 3 states, whereas skip checks that an interval has exactly 2 states. Hence, the implication (skip ; skip )  skip is not satisfied by 3-state intervals and is consequently not valid.
As the next Lemma 4.2 shows, it does not actually matter whether we use weak or strong chop to define 2-to-1 formulas:
Lemma 4.2 The following is an alternative way to characterise 2-to-1 formulas using strong chop instead of weak chop:
|=(AA)
A.
Proof The chain of equivalences below demonstrates that the two implications(A;A)  A and (AA)  A are in fact semantically indistinguishable:(A;A)  A(AA)  (inf
(AA)  A(AA)  A(AA)  A.

A)  A
(inf  A)  A true
The first equivalence simply re-expresses A;A using the definition of weak chop in Table 1 in Sect. 2. The third equivalence holds since the implication (inf  A)  A is valid for any PITL formula A and can therefore be replaced by the formula true.
Therefore the two characterisations of 2-to-1 formulas are semantically equivalent.
We prefer to define 2-to-1 formulas using weak chop because it better copes with nontermination in applications (such as for mutual exclusion in Sects. 1113).
Hence, for consistency we will mostly stick with this convention in our presentation
12
Ben Moszkowskihere. Nevertheless, the variant with strong chop can sometimes help to slightly shorten proofs.
Local PITL is decidable (see our earlier work with Halpern   (reproduced in  )), but it has nonelementary complexity (a theorem by Kozen presented there). Therefore, the PITL subset consisting of 2-to-1 formulas is likewise decidable. Our recent axiomatic completeness proof for PITL with infinite time   ensures that a corresponding PITL theorem can be deduced for any 2-to-1 formula.
We can generalise the previous 2-to-1 example p to be any state formula w.
Any NL1 formula T (see Definition 3.1 in Sect. 3.2) is 2-to-1. Furthermore, any i i formulas 3C and 3C are 2-to-1, where 3C(defined in Table 1) tests that C is true in some prefix subinterval, possibly the interval itself even if it is infinite. The i cases for NL1 formulas and 3C can subsume the case for a state formula w because
1 i it is in NL and additionally semantically equivalent to the PITL formula 3w. Let us now consider one lemma dealing with all these cases and another concerning the conjunction of 2-to-1 formulas:
Lemma 4.3 All of the following are 2-to-1 formulas:
1.
2.
3.
4.
5.
Any state formula w.
Any NL1 formula T.
Any PITL formula of the form 3C. i
Any PITL formula of the form 3C. i
Any PITL formula of the form w  3B, for any state formula w and PITL formula
B.
Proof We examine each of these separately:
A state formula w: If an interval  satisfies the formula w; w then the semantics of PITL ensures that  s first state must satisfy w. Hence,  does as well. Aswe already noted, this case can alternatively be subsumed by either the next i one for NL1 formulas or the later one for 3C.
1
An NL formula T : Let  be an interval satisfying T ; T and let   be the subinterval satisfying the left instance of T. We use case analysis to show that the interval  indeed satisfies T as well.
If   has only one state, then  itself must satisfy the right-hand instance of T.
Otherwise, both  and   have two or more states. An NL1 formula cannot test beyond the second state and distinguish between the intervals  and. Consequently, if   satisfies T, so must.
A PITL formula of the form 3C : This follows from the next chain of valid implications involving the definition of weak chop in Table 1:(3C ); 3C(3C ) 3C
(inf
3C )(33C )  3C
3C.
For the purposes of comparison, here is a somewhat shorter valid chain of implications using Lemma 4.2s alternative characterisation of 2-to-1 formulas based on strong chop (i.e., |= (AA)  A):(3C ) 3C
33C
3C.
Compositional reasoning using intervals and time reversal
13i i i
A PITL formula of the form 3C
: Suppose an interval  satisfies (3C
); 3C. Thensome prefix subinterval  of  (perhaps  itself) satisfies the left instance of i i
3C and furthermore  satisfies 3i 3C. Moreover, some prefix subintervalof  (perhaps  itself) satisfies the subformula C. Now   is also a prefix i subinterval of, so consequently  satisfies 3C.
Here is a corresponding chain of valid implications: i i(3C
); 3Ci(3C
); truei 3C i
3i
3C.i
A PITL formula of the form w  3B
: The equivalence chain below invokes the i i case for 3C to also handle any formula w  3B
:
 i (w  B ) i (w )  B i (w )  3B i
3
3
3 i i(w)  3B  w  3B.
Lemma 4.4 For any 2-to-1 formulas A and B, the conjunction A  B is a 2-to-1 formula as well. That is, if |= (A; A)  A and |= (B ; B )  B, then also |= (A
B ); (A  B )  (A  B ).
Proof Here is a simple semantic proof with four steps:
1 |= A; A  A
2 |= B ; B  B
3 |= (A  B ); (A  B )  (A; A)  (B ; B )
4 |= (A  B ); (A  B )  A  B
Assumption
Assumption
PITL
1-3, Prop.
The mention of PITL in Step 3 refers to some routine semantic reasoning about intervals which we do not further justify here. However, we provide detailed deductions for valid properties of this kind in our recent axiomatic completeness proof for PITL with infinite time. We can summarise the proof as a chain of valid implications:(A  B ); (A  B )(A; A)  (B ; B )
A  B.
The next theorem about 2-to-1 formulas appears to us to be an important, yet previously unknown elementary mathematical property about compositionality:
Theorem 4.5 If A is 2-to-1, so is 2A. That is, from the valid implication
A follows the next one: |= ((2A); 2A)  2A.
|=(A; A)
Proof Our goal is to prove the validity of the implication below for any 2-to-1 formula A:
|=(2A); 2A  2A.(2)
The proof of validity is a little simpler if we use Lemma 4.2s alternative characterisation of 2-to-1 formulas involving strong chop (i.e., |= (AA)  A) to establish the validity of the next semantically equivalent implication:
|=(2A) 2A
2A.(3)
Let  be an interval satisfying (2A) 2A. We now show that  also satisfies 2A.
The semantics of strong chop ensures that there exists at least one pair of subintervals   and   of  which share a state, combine to make  and both satisfy the subformula 2A. Here is a diagrammatic representation of this:z
}|
{(2A)2A.
| {z }| {z }
14
Ben Moszkowski
From the semantics of 2 we have that every suffix subinterval of   and   (including   and   themselves) satisfies the subformula A. Let us now consider an arbitrary suffix subinterval   of the overall interval. We want to show that it satisfies A and hence  satisfies 2A. There are two subcases: consists of a suffix of   followed by all of   (perhaps even itself ): Now the suffix subinterval of   and the subinterval   both satisfy A.
Therefore,   satisfies the formula AA. The assumption that A is 2-to-1 and Lemma 4.2 then yield that   likewise satisfies A. is a suffix of   (perhaps even   itself ): Hence,   immediately satisfies the 2-to-1 formula A.
Therefore,  satisfies 2A. Consequently, implication (3) is valid, as is (2), so 2A is indeed 2-to-1.
Observe that we can alternatively express this reasoning about the interval and the formula (2A) 2A by means of a chain of valid implications starting with(2A) 2A and ending with 2A:(2A) 2A  2 A  (AA)

2 AA

2A.(4)
Lemma 4.6 For any NL1 formula T and PITL formulas B and C, the following are
2-to-1 formulas:
2T
23Ci
23Ci
2(w  3B
).
Proof This readily follows from Lemma 4.3 about some simple kinds of 2-to-1 formulas together with Theorem 4.5.
Recall that T subsumes w, so 2T likewise subsumes 2w. i
The 2-to-1 formulas of the form 2(w  3B
) can express some standard temporal liveness properties. For example, the PTL formula 3q is semantically equivalent i to 33q, so consequently the conventional PTL formula 2(p  3q ) is in fact 2-to-1.
Indeed, its subformula p  3q is also 2-to-1 because the semantic equivalence of i i
3q and 33q ensures that the implication can be expressed as p  33q.
Let us now discuss why the following three frequently occurring formulas (all defined in Table 1) are 2-to-1: finitefin winf,  where w is any state formula. The first one finite is 2-to-1 because it denotes
3empty, which is 2-to-1 by Lemma 4.3. The formula fin w denotes 2(empty  w).
The subformula empty  w is in NL1, so 2(empty  w) and fin w are 2-to-1 by
Lemma 4.6. It then follows from this that inf, which denotes finite, is also 2-to-1 since it is semantically equivalent to fin false. Alternatively, inf is 2-to-1 because it can be expressed as 2more. Now more is in NL1, so 2more is likewise 2-to-1 by
Lemma 4.6.
Compositional reasoning using intervals and time reversal
15
4.1 Introduction, combining and extension of 2-to-1 formulas
Our interest here is in compositionally proving the validity of implications of following form: w
Sys
Afin w,  where w is a state formula about the initial state, Sys expresses some abstract or concrete systems behaviour in PITL, A is a 2-to-1 formula and w is a state formula about the final state if the system terminates. Now we can build Sys by starting with various simple formulas corresponding to individual concrete or abstract program steps. These are then combined in different ways, such as sequentially (e.g., using chop) or in parallel (using logical-and). For example, Sys could be the sequential composition Sys  ; Sys  of two parts Sys  and Sys. Suppose we have already proved the validity of the following two implications for Sys  and Sys, respectively:
|=w
|=w
Sys
Sys
A
Afin wfin w.
The validity of the previous implication for Sys then follows from the validity of these, in part because the two instances of the 2-to-1 formula A can be combined into a single one.
Our mutual exclusion examples discussed later in Sects. 1113 involve two processes running in parallel, with each containing several sequential parts. We first employ a technique for showing that some of the systems individual steps imply 2-to-1 formulas. We regard this as a way to introduce 2-to-1 formulas. These can then be combined together (e.g., sequentially or in parallel) or extended using some of the other techniques to obtain 2-to-1 formulas about bigger portions of the overall system. Eventually we show that the entire system with its initial condition implies a 2-to-1 formula.
Let us now discuss four general kinds of techniques to help compositionally reason about 2-to-1 formulas. Each is associated with one or two valid generic implications concerning such formulas. We later present some specific suitable implications when we look at the four techniques individually in greater detail.
However, these implications are not meant to be exhaustive. Below is a list of the main categories we consider:
|= A  A
Introduction of a 2-to-1 formula A
Sequential combining of two copies of a 2-to-1 formula A |= (A; A)  A
|= (A ; A)  A
Extension of a 2-to-1 formula A leftward or rightward
|= (A; A )  A
|= (A  A )  A.
Parallel combining of two 2-to-1 formulas A and A
The shorthand ISEP can be used as an abbreviation for the four parts Introduction, Sequential combining, Extension leftward or rightward and Parallel combining. The later Sects. 69 cover in detail ISEP techniques for a class of 2-to-1 formulas for backward analysis. The basic theory of ISEP techniques can even be formalised in PITL with just chop and skip and so without chop-star. The theory therefore seems fairly elementary from a mathematical standpoint.
Section 10 adds a further technique for Iteration of 2-to-1 formulas for backward analysis. The abbreviation ISEPI enlarges ISEP to include this as well. The ISEPI techniques are later applied to mutual exclusion in Sects. 1113.
16
Ben Moszkowski
We now illustrate how the first three ISEP techniques can be used together to combine several sequential formulas in order to obtain from them a single 2to-1 formula. Let Sys be a hypothetical system with four sequential parts somehow or another expressed in PITL as the formulas Sys 1,..., Sys 4. We have Sys itself denote the sequential composition of Sys 1,..., Sys 4 :
= b
Sys
Sys 1 ; Sys 2 ; Sys 3 ; Sys 4.
Now further assume that Sys 1,..., Sys 4 have the associated valid implications below, which also include five state formulas w1,..., w5 to serve as pre- and postconditions:
|=w1 w2 w3 w4
|=
|=
|=
Sys 1
Sys 2
Sys 3
Sys 4
2p  fin w2(finite  fin p)
32q  fin w4(finite  fin q )fin w3fin w5.(5)
Our goal here is to compositionally prove that the four valid implications in (5) together ensure that Sys implies the 2-to-1 liveness formula 2(p  3q ) as expressed by the next valid implication:
|=w1
Sys
2(p  3q )fin w5.(6)
It happens that all the subformulas 2p, (finite  fin p), 32q and (finite  fin q ) in (5) are in fact themselves 2-to-1. However, this point is not essential here since our sole aim is to show the validity of implication (6) relating Sys with the 2-to-1 formula 2(p  3q ).
Below is a more detailed discussion which explains and motivates each ISEP technique and relates the first three of them to our example:
ISEP Introduction of a 2-to-1 formula: Here we show that some formula A concerning a system step implies the desired 2-to-1 formula A:
A
|=
A.
In our example (5), ISEP Introduction concerns three subformulas 2p, 32q and finite  fin q for which we can formalise some valid PTL implications:
|=
2p  2(p  3q )
|=
32q  2(p  3q )
|=(finitefin q )  2(p  3q ).
These ways for ISEP Introduction of the 2-to-1 formula 2(p  3q ) provide a means to obtain from three of the four valid implications in (5) the valid implications below for Sys 1, Sys 3 and Sys 4, respectively:
|=
|=
|=w1 w3 w4
Sys 1
Sys 3
Sys 4
2(p  3q )
2(p  3q )
2(p  3q )fin w2 fin w4 fin w5.(7)
Incidentally, the justification for obtaining 2(p  3q ) from finite  fin q can be subsumed by the case for 32q owing to the next chain of valid implications: finitefin q
32q
2(p  3q ).
The valid implications such as |= (2p)  2(p  3q ) for ISEP Introduction of a 2-to-1-formula are quite important since they can provide a way to start a compositional analysis involving this formula.
Compositional reasoning using intervals and time reversal
17
It is straightforward to check that if we have a valid implication |= A  A for
ISEP Introduction, then the ones below can also be used for ISEP Introduction :
2A  2A
|=
For example, fromf f
2A
2A.
|=p  (p  3q ) follows |= 2p  2(p  3q ).
ISEP Sequential combining of two instances of a 2-to-1 formula: Here we take two sequential instances of a 2-to-1 formula A and merge them together:
|=
|=
A; A
A.
This with the particular 2-to-1 formula 2(p  3q ) together provide a way to reduce the two valid implications in (7) for Sys 3 and Sys 4 to the next valid one concerning their sequential composition Sys 3 ; Sys 4 :
|=w3(Sys 3 ; Sys 4 )
2(p  3q )fin w5.(8)
Theorems and lemmas about closures provide ways to obtain an instance of an
ISEP technique for Sequential combining from a simpler variant of itself. For example, Theorem 4.5 ensures that |= (A; A)  A yields |= ((2A); 2A)  2A.
ISEP Extension of a 2-to-1 formula leftward or rightward : The previous
ISEP technique of Sequentially combining two instances of a 2-to-1 formula A such as 2(p  3q ) seems quite attractive. Unfortunately, it is not always the case that two adjacent subintervals both satisfy such a 2-to-1 formula A so that the overall interval automatically also does. However, if one of the subintervals satisfies A, then we can try to simplify the sequential compositions A ; A and A; A involving A and some other suitable formula A. The next two valid implications show the two possible ways to perform the ISEP technique of Extending leftward or rightward by merging A and A together into A:
|=
A ; A
A
|=
A; A
A.
Of course, the implications do not work for arbitrary A, but we shortly consider some actual practical instances.
Observe that the previous ISEP technique of Sequential combining of a 2-to-1 formula with itself (i.e., |= (A; A)  A) is in fact just a special case of ISEP
Extending leftward or rightward, where A is identical to the 2-to-1 formula A.
It seems that sequential extension can be highly dependent on the nature of A. The next valid implication illustrates the first case |= (A ; A)  A:
|=(finitefin p); 2(p  3q )
2(p  3q ).(9)
Here we take A to be the 2-to-1 formula 2(p  3q ) and extend it leftward by the formula finite  fin p which plays the role of A. Implication (9) is valid because the instance of p in the left operand of the chop ensures that p is also initially true in the right operands subinterval. Therefore, the right-hand subinterval moreover satisfies 3q, so the prefix subintervals of the overall interval which start before the right-hand subinterval and contain it likewise satisfy 3q, and hence also the 2-to-1 formula p  3q. We can then use valid implication (9) to obtain from the implication for Sys 2 in (5) and the later one for Sys 3 ; Sys 4 in (8) the next valid implication for Sys 2 ; Sys 3 ; Sys 4 :
|=w2(Sys 2 ; Sys 3 ; Sys 4 )
2(p  3q )fin w5.(10)
18
Ben Moszkowski
Once again using the fact that 2(p  3q ) is 2-to-1, we sequentially combine its two instances in the earlier implication for Sys 1 in (5) and the other implication (10) for Sys 2 ; Sys 3 ; Sys 4 to arrive at our overall goal, the validity of implication (6) for Sys.
Sect. 8 consider ways to obtain an instance of an ISEP technique for Extending leftward or rightward from a simpler variant of itself (e.g., see Theorems 8.1 and 8.7).
Here is a chain of valid implications summarising of all of the ISEP transformations which we have so far applied on the sequential composition of the original subformulas 2p, (finite  fin p), 32q and (finite  fin q ) in (5):(2p); (finite
| {z }
Sys 1fin p); (32q ); (finite  fin q )
| {z } |
{z
}
Sys 3
2(p  3q ); (finite
Sys 4fin p); 2(p  3q ); 2(p  3q )
|
{z
}
Sys 3 and Sys 4
2(p  3q ); (finite
|fin p); 2(p  3q )
{z
}
Sys 2 and Sys 3 ;Sys 4
Sequential combining
Extending leftward
2(p  3q ); 2(p  3q )
{z
}
|
Sys 1 and Sys 2 ;Sys 3 ;Sys 4
Introduction
Sequential combining
2(p  3q ).
Underbraces indicate the subformulas reduced to the 2-to-1 formula 2(p  3q ) in each step and also give the associated parts of Sys. Instead of the first steps reductions of each of the pair of 2-to-1 formulas 32q and finite  fin q to 2(p  3q ), we can alternatively use ISEP Introduction to reduce finite  fin q to 32q, and then invoke ISEP Sequential combining on (32q ); 32q to obtain 32q. We follow that by a second application of ISEP Introduction to arrive at our goal 2(p  3q ). Here is a chain of valid implications summarising this:(32q ); (finite
|
{zfin q )
}
Sys 4(32q ); 32q
|
{z
}
Sys 3 and Sys 4
32q
| {z }
Sys 3 ;Sys 4
2(p  3q )
Introduction
Sequential combining
Introduction
We now consider the last of the four ISEP techniques, namely ISEP Parallel combining of two suitable 2-to-1 formulas. Consider a hypothetical system
Sys  constructed as the conjunction Sys 1  Sys 2 of two parts Sys 1 and Sys 2, both somehow expressed in PITL. Suppose we have the following valid implications for
Sys 1 and Sys 2 :
|=
|=w1,1 w2,1
Sys 1
Sys 2
A  fin w1,2
A  fin w2,2, Compositional reasoning using intervals and time reversal
19
Description of ISEPI technique
Introduction (simple version): |= A  A
Introduction (with relaxed assumption): |= A  A
Sequential combining of 2-to-1 formula: |= (A; A)  A
Extend a 2-to-1 formula rightward : |= (A; A )  A
Parallel combining of 2-to-1 formulas: |= (A  A )  A
Iteration of +-to-1 formula: |= A+  A
Iteration of almost -to-1 formula: |= w  A  A
Basis(19)(20)
Def. 4.1(25)(30)(34)(40)
Use(62)(63)(64), (75)(65)(50), (66)(35)(54)
Table 3 Examples of ISEPI-based compositional reasoning about 2-to-1 formulaswhere the state formulas w1,1,..., w2,2 serve as pre- and post-conditions. ISEP
Parallel combining provides a way to obtain a similar implication concerning Sys from these two. Here is the most straightforward such implication which is valid:
|=(w1,1w2,1 )(Sys 1
Sys 2 )
A  Afin (w1,2w2,2 ).
However, we are particularly interested in cases where A and A are 2-to-1 formulas and moreover their conjunction A  A implies some formula A which is noticeably simpler than the conjunction:
A  A
|=
A.
Here is a valid PTL formula illustrating the ISEP technique of Parallel combining :
|=
2(p   p)
2(q   p)
2(p  q ).(11)
The following is another PTL example of ISEP Parallel combining :
|=
2(p  32p)
2(q  32p)
2(p  q ).
ISEP Parallel combining finds application in Sects. 1113 when we want to merge together the 2-to-1 formulas obtained for each of two parallel processes concerning mutual exclusion. Observe that from |= (A  A )  A readily follows |= ((2A)(2A ))  2A. This semantic inference rule can be used to prove the validity of the two implications just given concerning 2(p  q ) from simpler ones about(p  q ).
Later Sects. 69 will consider the ISEP techniques of Introduction, Sequential combining, Extension and Parallel combining on a class of formulas which are suitable for backward analysis. For the convenience of readers, Table 3 provides an index to various additional instances of the implications subsequently mentioned for the various ISEP techniques. This includes two extra entries for combining
Iterations of a +-to-1 formula and an almost -to-1 formula, which we describe later on in Sect. 10, so in fact all the ISEPI techniques are represented in Table 3.
Remark 4.7 It is interesting to note that in our applications of the ISEPI techniques considered above and later on, the concrete instances of all the formulas A, A and A found in the implications are always 2-to-1 formulas. For example, all three
2-subformulas in implication (11), which involves ISEPI Parallel combining (i.e., |= (A  A )  A ), are 2-to-1 by Lemma 4.6 because in each of them, the operand
20
Ben Moszkowskiof 2 is in NL1. In fact, the sole exception to formulas being 2-to-1 is just the statement of Theorem 8.7 in Sect. 8.2 for extending a 2-to-1 formula A to the right: |= (A; A )  A. However, even there the generic formula for A is in a class called 1-to-2f formulas (see Definition 8.2 in Sect. 8.1) which, like the class of 2-to1-formulas, is closed under conjunction and the temporal operator 2 (as stated in Sect. 8.1 in Lemma 8.4 and Theorem 8.5). In our application of Theorem 8.7 in Sect. 12, the concrete instance of A is in fact both 1-to-2f and 2-to-1.
4.2 2-to-1 formulas involving finite prefix subintervals
The earlier Theorem 4.5 shows that the class of 2-to-1 formulas is closed under the operator 2, which concerns suffix subintervals. It is natural to ask whether time symmetry can help extend the result to prefix subintervals and the associated operator 2f. In this section we demonstrate that this is indeed the case. The result is needed when we later consider in Sect. 6 a class of 2-to-1 formulas suitable for backward analysis. These 2-to-1 formulas play a central role in practically all of the subsequent sections, including Sects. 1113 on mutual exclusion. f
Theorem 4.8 If A itself is 2-to-1 for finite time, so is 2A for all intervals, including
|
= f f f infinite ones. More precisely, if finite  (A; A)  A, then |= (2A
); 2A
2A.
Proof The proof is largely based on applying time symmetry to the earlier proof for Theorem 4.5, which concerns 2 and suffix subintervals instead of 2f and prefix subintervals. The earlier chain of valid implications (4) in Theorem 4.5 can be f adapted for use with 2A in place of 2A:f f f A  (A A)(2A
) 2A
2
f A  A
2
f
2A.(12)
The following is a simple corollary of Theorem 4.8: f
Corollary 4.9 If a formula 2A is 2-to-1 for finite time, it is itself likewise 2-to-1 for

|= finite  ((2A f f f all intervals, including infinite ones.
More precisely, if );
2A
)
2A,  f f f then |= (2A
); 2A
2A. f f f f
Proof We start with (2A
); 2A. Now the PITL formulas 2A and 2f 2A are semantically equivalent since they both inspect exactly the finite prefix subintervals. The f assumption that 2A is 2-to-1 for finite time together with Theorem 4.8 ensures f f f that 22A is 2-to-1 for all intervals. Hence, so is the equivalent formula 2A.i
Remark 4.10 It is not hard to adapt the results in this section to deal with 2A, f which is the weak version of 2A defined in Table 1. We omit the details here. f
A formula 2A can in principle be 2-to-1 even if A itself is not 2-to-1. The f f formula 2skip is a (not especially useful) example. This is because 2skip is semantically equivalent to the 2-to-1 formula false, but the operand skip is not 2-to-1by our earlier discussion near the beginning of this Sect. 4. At present we are not aware of any such formulas with some practical benefits.
Compositional reasoning using intervals and time reversal
21
5 Time reversal and reflection
In this section we consider two complementary ways to exploit time symmetry.
The first is syntactic and the second is semantic.
One way to extend known facts and techniques is by interpreting them in reverse. For example, as we discussed in Sect. 1, the 2-to-1 PTL formula p  3q can be viewed as a forward analysis from a state in which p is true to one in which q is true. For backward analysis, we in essence reverse our perspective by means of the formula (fin p)  3q (if p is true in the final state, then q is true in some state ).
This implication considers the behaviour of p in a finite intervals last state rather than the first one. In the two sample implications, the subformula 3q has the same semantic meaning in both the forward or reversed perspectives. The reversed way of reasoning can with care provide a basis for performing backward analysis from a situation in a state to some activities which lead up to it. For instance, an analysis of a system fault could investigate various plausible anomalies which must precede it. The next statement is also an example: If I am wearing shoes, then they must have been previously placed on my feet.
We will look at some simple and natural syntactic transformations on formulas which involve time symmetry and are referred to here as time reversal. These transformations are in general limited to finite intervals, so we employ a twostage approach to also obtain results for infinite time. For example, we can prove validity of suitable formulas for infinite time after using time reversal to establish their validity for finite time. The current section includes some compositional uses of the two-stage process on the class of 2-to-1 formulas already introduced in Sect. 4. Various 2-to-1 formulas are then later applied to doing backward analysis of mutual exclusion in Sects. 1113.
For any PITL formula A, define the temporal reversal Ar by induction on As syntax to act like A in reverse: true r = b truepr = b fin pskip r = b skip(A)r = b (Ar )(A B )r = b B r  Ar(AB )r = b A r B r(A )r = b (Ar ).
For instance, more r (the same as (skip  true )r ) reduces to true  skip, which is semantically equivalent to more in finite intervals (although not in infinite ones). f
Similarly, (2A
)r reduces to 2(Ar ).
For a finite interval, let  r denote the interval ||... 0 which temporally reverses. Observe that any such  equals the twice reversed interval  rr. Here are some simple lemmas concerning time reversed intervals and formulas:
Lemma 5.1 For any finite interval  and PITL formula A, the following are equivalent statements:(a)  |= A(b)  r |= Ar.
Proof We do induction on formula As syntax.
Lemma 5.2 Any PITL formula A is semantically equivalent to Arr in all finite intervals. This can be expressed by the valid implication below:
|=finite  (A  Arr ).
22
Ben Moszkowski
Proof We use Lemma 5.1 together with the equivalence of  and  rr to show that
A and Arr have the same truth values for every finite interval  :
|=
Aiffr
|=
Ariffrr
|=
Arriff
|=
Arr.
Lemma 5.3 For any PITL formula A, the following statements are equivalent:(a)(b)
|=
|=finite  A finite  Ar.
Proof The formula finite  A is valid iff all finite intervals satisfy A. Let ( + )r denote the set of reversed finite intervals. This in fact equals  +. Time reversal of the intervals creates a 1-to-1 mapping between  + and itself. Furthermore, Lemma 5.1 ensures that each finite interval  satisfies A iff the finite interval  r satisfies Ar. Hence, (a) and (b) are indeed equivalent statements.
Note that PITL with just finite time, like some other temporal logics such as quantified PTL, expresses the regular languages with words having one or more letters (as we discuss in  ). The set of regular languages for any (finite) alphabet is closed under word reversal. This explains semantically why reversal cannot increase PITLs expressiveness.
The next semantic concept provides a further application of time symmetry:
Definition 5.4 (Reflections) A PITL formula A reflects another PITL formula
B if |= finite  (A  B r ). We call A a reflection of B.
For example, the state formula w  w reflects fin (w  w ). The 2-to-1 PTL formula
3w reflects itself and so can be said to be self-reflecting.
It is important to keep in mind that time reversal and reflection both involve time symmetry, but time reversal is a syntactic concept, whereas reflection is a semantic one. In practice, we often employ both techniques together.
We now consider some other examples of reflection in order for readers to gain fluency with the concept in the context of PITL. This will help when we later look in Sect. 6 at some properties of reflections of 2-to-1 formulas. The formula (fin p)
3q reflects the formula p  3q. They indeed exhibit symmetrical behaviour in finite intervals. The first formula (fin p)  3q ensures that if p is true in the final state, then some state has q true. The second formula p  3q ensures that if p is true in the initial state, then some state has q true. It follows that the next formula reflects the 2-to-1 PTL formula 2(p  3q ):
 f (fin p)  3q.
2(13)
It is not hard to see how p is reflected to be fin p. Similarly, 2 becomes 2f. We later show in Sect. 6 that formula (13) is likewise 2-to-1. This formula ensures that whenever p is true in an interval state, then q is either true in that same state or some earlier one. Recall from Sect. 3.3 the version of PTL called PTLu and having a strong until operator. The PTLu formula below has the same semantics as the PITL formula (13), although we do not claim that this is obvious:
2p
(p) until q.
The left conjunct 2p deals with intervals where p is never true. In such intervals, q does not need to be true either, so we can ignore its behaviour. The right disjunct
Compositional reasoning using intervals and time reversal
23(p) until q rather opaquely ensures that if, on the other hand, q is somewhere true, then p will stay false until the first time q is true. This suffices to guarantee that the first instance of p cannot precede the first instance of q in the interval.
Let us now look at some trickier examples of reflection involving 2-to-1 formulas and the operators skip and. The formula 3(skip  q ) reflects the 2-to-1 formula
NL1 formula  q. Let us consider why this is so. For any finite interval, the formula q ensures that the interval has at least two states with q true in the second state. The formula 3(skip  q ) likewise ensures that the interval has at least two states with q true in the penultimate state (i.e., the one which is next to last).
Consequently, any finite interval  indeed satisfies one of the formulas 3(skip  q ) and  q iff the intervals reversal  r satisfies the other. The next formula reflects the 2-to-1 formula 2(p   q ) and by the presentation in Sect. 6 is likewise 2-to-1: f (fin p)  3(skip
2
 q).(14)
The only tricky part of the reflection here is when we time-wise reverse the effect of  q by reflecting it using 3(skip  q ) as discussed above.
Consider what kind of finite intervals are satisfied by formula (14). First of all, a finite interval satisfies the subformula (fin p)  3(skip  q ) in (14) iff the propositional variable p is false in the intervals last state or the interval has at least two states and the propositional variable q is true in the intervals penultimate state. So if p ends up in the last state being true, then the interval has two or more states and the last one is immediately preceded by another with q true. The effect of the subformula (fin p)  3(skip  q ) is therefore to make the overall formula (14) test that within each finite prefix subinterval of an interval, if p is true in the final state, then the subinterval has at least two states and q is true in the one just before the final state. This is identical to testing that any state in the overall interval with p true is immediately preceded by another state with q true. The PTL formula below has the same semantics as PITL formula (14): p
2 (more
 q )   p.
We now demonstrate that every formula has a reflection:
Lemma 5.5 For any PITL formula A, the formula Ar is a reflection of A. In fact, the formulas A and Ar reflect each other.
Proof Lemma 5.2 ensures for any PITL formula A the valid implication |= finite
A  Arr ). Therefore, by Definition 5.4 about reflections, the formula A is a reflection of Ar. In addition, we have the trivially valid implication |= finite
Ar  Ar ). From this and Definition 5.4 about reflections, the formula Ar is a reflection of A. Consequently, the formulas A and Ar indeed reflect each other.
It also follows from our discussion that A reflects B iff B reflects A. Reflecting can sometimes aid in avoiding redundant finite-time proofs in two directions.
Instead, we try to do a proof in one time direction and then with care reflect the result to apply the other way around. For example, later on in Sect. 6 we reflect some syntactic classes of 2-to-1 formulas to obtain further classes of 2-to-1 formulas. Sect. 14 discusses how reflection can help reduce reasoning involving 2f to simpler PTL-based reasoning.
24
Ben Moszkowski
Here is another example of reflecting based on the previously mentioned chains of implications (4) and (12), which concern the closure of 2-to-1 formulas under 2 and 2f, respectively:

2 A  A  2A r r r  r r r f A  (A f A  A f
2
A )  2
2A.(2A) 2A  2 A  (AA) r f r f(2A
) 2A

Remark 5.6 We can alternatively define Ar to be a primitive operator in a variantof PITL called PITLr. However, it seems at present simpler to work in conventional
PITL.
5.1 PTL with past time
In our later application of time symmetry to compositional reasoning with 2-to-1 formulas, we sometimes compare PITL formulas to others in a version of PTL with past time, denoted here as PTL. It is not a subset of conventional PITL because that does not have past time. Our experience is that even readers with previous experience with ITL will find the unfamiliar processes of viewing formulas in reverse and interval-based backward analysis somewhat challenging. Consequently, it seems beneficial to compare PITL formulas obtained using time symmetry with semantically quite similar formulas in a more widely known formalism such as
PTL.
Time is modelled in PTL as being linear and discrete (like for PITL and PTL) but having a bounded past. The syntax of PTL is modified to include the X (read previous X ) and 3X two additional primitive operators(read once X ).
|
=
The semantics of a PTL formula X is now expressed as (, k)
X, where k is any natural number not exceeding ||. The purpose of k is to indicate the present are as follows: and 3 state. For example, the semantics of X iff k > 0 and (, k  1) |= X(, k) |=(, k) |= 3X iff for some j : 0  j  k, (, j ) |= X.
Consider the sample formula below: pp
3q
3r.
This is satisfied by any pair (, k) with k  1 where p is true in the state k, false in the previous one k1, q is true in the state k or after it, and r is true in the state k or before it.
The derived PTL operator first is defined as follows to test for the first state of an interval: true. first
= b
We later use the operator first to help us relate formulas in PITL with others in PTL. For example, the following two examples in PTL and PTL, respectively, are satisfied by the same intervals: first(pq)more
( p)  q.
More precisely, for any interval, the pair (, 0) satisfies the left-hand PTL formula iff  satisfies the right-hand PTL formula. The PTL formula expresses
Compositional reasoning using intervals and time reversal
25that there are at least two states and the first one, which is the present state, has no past. Furthermore, if p is true in the second state, q is true in its predecessor, the first state. The second formula is in PTL and expresses that the interval has at least two states (with no past), and if p is true in the second one, then q is true in the first. So both formulas concern the same kind of behaviour.
A PTL formula X is defined to be satisfiable iff (, k) |= X holds for some pair (, k) with k  ||. The formula X is valid iff (, k) |= X holds for every pair(, k) with k  ||.
Duan   and Bowman et al.   present versions of ITL with past-time constructs (see also Gomez and Bowman  ). So in principle, PTL can be regarded as a subset of PITL with past time.
6 2-to-1 formulas for backward analysis
Recall Theorem 4.8 in Sect. 4.2 which establishes that if a PITL formula A is 2-to-1 f for finite intervals, then the PITL formula 2A is 2-to-1 for all intervals, including even infinite ones. Let us now consider a significant class of such 2f -formulas which are shown to be 2-to-1 with the help of time symmetry. They offer a natural compositional framework
 for backward analysis. The previously mentioned PITL formula 2f (fin p)  3q is an example.

The PITL formula 2f (fin w)  3B is a generalisation of 2f (fin p)  3q and tests that in any finite prefix interval where w ends true, it is preceded by B. The subformula B therefore represents some activity observable (non-strictly) prior to any state where w is true. Such formulas provide a way to do backward analysis when we want to reason about what must have preceded a state with w true. They will be extensively investigated and applied in our presentation.
Below is an informal graphical representation of a 10-state interval containing some finite 8-state prefix subinterval which satisfies (fin w)  3B and ends with w true: w
States:
B
3B

The role which the 2-to-1 formula 2f (fin w)  3B plays here is similar to the one for formulas in the past-time variant PTL of PTL (see Sect. 5.1) having the form 2(w  X ), where the only temporal operators in the PTL formula X are past-time ones.
Perhaps the most important result we need
 is the following one about a key f property of the PITL formula 2 (fin w)  3B :
Theorem 6.1 For any state formula w and PITL formula B, the following formula is 2-to-1:
 f (fin w )  3B.
2(15) r i
Proof The operand (fin w)  3B can be reflected to obtain the formula w  3B, which is 2-to-1 by our previous Lemma 4.3. Hence, the formula (fin w)  3B is itself
26
Ben Moszkowskif
2-to-1
 for finite intervals. It follows from this and Theorem 4.8 that 2 (fin w)
3B is 2-to-1 for all intervals.
There is alsoan alternative proofinvolving the reflection of 2. We can reflect r i f
2 (fin w)  3B to be 2 w  3B
. By Lemma 4.6, this 2-formula is 2-to-1.
Hence, the formula 2f (fin w)  3B is 2-to-1 for finite intervals. By Corollary 4.9, this formula is 2-to-1 for all intervals, including infinite ones.

Let us now consider the next instance of 2f (fin w)  3B : f (fin p)  3(skip
2
 q).(16)
We already mentioned formula (16) as (14) when previously defining and explaining the concept of reflecting formulas. It is true for intervals when each state with p true is immediately preceded by one with q true. This is because the formula ensures that any finite prefix subinterval ending with p true in the subintervals last state has q equal true in the subintervals penultimate state. So any state with p true must be immediately preceded by one with q true.
We explained when previously discussing the earlier instance of (16) as formula (14) that it is a reflection of the 2-to-1 PTL formula 2(p   q ).
Let us now relate formula (16) to one in PTL, the version of PTL with past time previously discussed in Sect. 5.1. We believe that this will help readers better familiarise themselves with our approach. Formula (16) is comparable to the nextfor examining the previous
PTL formula with the standard past-time operator state: firstq ).
2(p(17)
By comparable, we mean here that an interval  satisfies the first formula (16) iff the pair (, 0) satisfies the second formula (17). Our use of the PTL derived q ) only construct first in formula (17) ensures that the second subformula 2(p considers intervals with no past. This is in order to conform to the time model for
PITL which, unlike PTL, lacks past time.
It can be useful to consider the simple case where the interval  has just one state. Observe that  satisfies the first formula (16) iff p is false in that state.
Similarly, the pair (, 0) satisfies the PTL formula (17) iff p is false in  s single state. If  has exactly two states, then either p is false in both of them or else the initial state has p false and q true and the second one has p true.
Pnueli   and Lichtenstein, Pnueli and Zuck   give early accounts about how to formalise safety properties for mutual exclusion using past-time formulas of the form 2(w  X ), where the temporal formula X only concerns past states and perhaps the current state, but not future ones. We later look at such approaches in more detail in Sect. 16.2.
Here is another example of a 2f -formula which is an instance of (15) and hence
2-to-1 by Theorem 6.1:
 f (fin p)  3p.
2(18)of 3:
This is analogous to the next PTL formula with the past-time variant 3first
2(p  3p
).
Compositional reasoning using intervals and time reversal
Introduction
Sequential combining
Extension rightward
Parallel combining
Iteration
A  A
|= (A; A)  A
|= (A; A)  A
|= (A1  A2 )  A
|= A+  A, |= (w  A )  A
|=
27
Sect.
Sect.
Sect.
Sect.
Sect.
7
6
8
9
10
Table 4 ISEPI compositional techniques for a 2-to-1 formula for backward analysis
7 ISEPI introduction of 2-to-1 formulas for backward analysis
Recall the ISEPI techniques previously described in Sect. 4.1. A large part of this
Sect. 7 and the subsequent Sects. 810 concerns the ISEPI techniques for 2-to-1 formulas for backward analysis, including iteration of such formulas. The 2-to-1 formulas and their ISEPI techniques will also be extensively used for backward analysis when we formally study mutual exclusion in Sects. 1113.
Table 4 gives a summary of our presentation of ISEPI techniques in the previous, current and next sections concerning 2-to-1 formulas for backward analysis. In this section we consider the ISEPI technique of Introduction for use with backward analysis. It can provide a way for a 2-to-1 formula A to be implied from another one A (i.e., |= A  A).
We now discuss two simple valid implications to
 do the ISEPI technique of f
Introduction with the 2-to-1 formula 2 (fin w)  3B. As we already mentioned in Sect. 4.1, such implications can be quite important since they provide a way to start a compositional analysis involving the 2-to-1 formula. Therefore, readers should make sure that they understand the material here. Instances of the implications are later used in our analysis of mutual exclusion in Sects. 1113.
The first valid implication for ISEPI Introduction considered here concerns situations where the state formula w is everywhere false. The implication provides a way to introduce from a quite simple 2-to-1 formula
2w in PTL the much more
 complicated 2-to-1 PITL formula 2f (fin w)  3B :
|=
2w
 f (fin w )  3B.
2(19)
Proof (Validity of (19)) This follows from the fact that if in an interval the state formula w is always false, then the PTL formula fin w is false in every finite subinterval. Hence, for such an interval the implication (fin w)  3B is trivially true in all finite subintervals. It also follows that the details of B are irrelevant.
We can alternatively show the validity of implication (19) by observing that the formula 2w is equivalent to 2f fin w (i.e., |= 2w  2f fin w). Now 2f fin w is f semantically equivalent to 2 fin w and in addition, simple propositional reasoning ensures that  fin w implies (fin w)  3B in each finite prefix subinterval.
The next valid implication is an example of (19) and its simple form of ISEPI
Introduction :
|=
2p
 f (fin p)  3q.
2
This can be interpreted as stating that if p is always false, then every state with p true is (non-strictly) preceded by a state with q true.
28
Ben Moszkowski
Below is a variant of (19) for ISEPI Introduction which relaxes the requirement in finite intervals that w is everywhere false. Instead, w only has to be false in all states except for perhaps the last one:
|=
2(more  w)(inf
3B )
 f (fin w )  3B.
2(20)
Observe that if the subformula B is in PTL, so is the antecedent of (20).
Proof (Validity of (20)) We consider the two cases for finite and infinite intervalsseparately. The case for infinite ones is easier, so we look at it first.
For any infinite interval, the formula more is true for each of  s suffix subintervals (including  itself). As a result, the formula 2(more  w) is semantically equivalent to 2w. Therefore, the previous valid implication (19) ensures that  also satisfies 2f (fin w)  3B.
On the other hand, suppose  is a finite interval which satisfies the antecedent of (20). Hence,  satisfies 2(more  w), so in each proper prefix subinterval of, the PTL formula fin w is false. This in turn ensures that (fin w)  3B is true in all such. In addition,  itself satisfies 3B, so it likewise satisfies the implication (fin w)  3B. Hence, each prefix subinterval of, including
 f itself, satisfies (fin w)  3B. Therefore,  also satisfies 2 (fin w)  3B.
Below is a simple valid instance of (20) and the relaxed form of ISEPI Introduction :
|=
2(more  p)(inf
3q )
 f (fin p)  3q.
2
In the later Sects. 1113 on mutual exclusion, the first simpler variant (19) of ISEPI Introduction will be used when a process is not in its critical section.
The second relaxed version (20) finds application for the process step in which a request is made to enter the critical section.
8 ISEPI extension of 2-to-1 formulas rightward for backward analysis
We have so far presented the 2-to-1 formulas for backward analysis and looked at associated ISEPI techniques for Introduction and Sequential combining. Here is an example of the ISEPI technique for Extending rightward already discussed in Sect. 4.1:
|=(p  2q ); 2q  p  2q.(21)
Below is a proof using a chain of valid implications showing that the 2-to-1 formula p  2q is extended rightward by the 2-to-1 formula 2q :(p  2q ); 2qp  (2q ; 2q )p  2q.
We later use implication (21) in Sect. 8.2 when we illustrate how to incrementally obtain another variant of the ISEPI technique for Extending rightward a 2-to-1 formula.
The earlier Theorem 4.8 in Sect. 4.2 concerns 2-to-1 formulas being closed under 2f. The next Theorem 8.1, which naturally generalises Theorem 4.8, provides an incremental way to adapt the ISEPI technique of Extending rightward a formulaf f
A using another one A to Extending rightward the formula 2A using 2A.
Compositional reasoning using intervals and time reversal
29
Theorem 8.1 For any PITL formulas A and A, we have the semantic inference rule below:


|= f f f finite  (A; A)  A  |=(2A
); 2A
2A.(22)
Proof The reasoning in Theorem 4.8s proof can be readily adapted for application to (22) by simply using two formulas A and A instead of just one. For example,  here is a chain of valid implications which generalises the earlier one (12):f f f A  (A A )(2A
) 2A
2
f A  A
2
f
2A.
Theorem 8.1 is later used in Sect. 8.2 in Theorem 8.7s proof. Incidentally, a symmetric variant of Theorem 8.1 to generalise Theorem 4.5 using 2 instead off is possible (i.e., |= (A ; A)  A
2
|= ((2A ); 2A)  2A). This can facilitate adapting the ISEPI technique of Extending leftward a formula A using another one
A to Extending leftward the formula 2A using 2A.
8.1 A class of formulas for use with ISEPI extending rightward
There are various classes of formulas which, like the 2-to-1 formulas, are closed under conjunction and 2. Our presentation now considers one for use in the next
Sect. 8.2 with the  ISEPI technique for Extending rightward the 2-to-1 formula f
2 (fin w)  3B for backward analysis. This material finds later application in our analysis of mutual exclusion in Sects. 1113 when we merge some sequential steps of a process together. f formulas) Any PITL formula A for which the implication
Definition 8.2 (1-to-2 f f formula.
A  2A is valid is called a 1-to-2 f formula therefore has the property that if it is true in an interval, then
A 1-to-2 it is also true in all the intervals finite prefix subintervals. The 1-to-2f formulas include all state formulas and 2f -formulas as well as the formula finite because the next three implications are all valid:
|=f w  2w
|=f f(2B
)  2f 2B
|=f finite  2finite.f since any one-state interval falsifies the imThe NL1 formula more is not 1-to-2 f plication more  2more. However, we have the next lemma for a general syntactic class of NL1 formulas involving more :
Lemma 8.3 For any NL1 formula T, the NL1 implication more  T is a 1-to-2f formula.
Proof We consider two cases for intervals with just one state and with more thanone state. In each case, we show that the intervals indeed satisfy the following implication:(more  T )  2f (more  T ).(23)
If an interval  has just one state, then the PTL formula more is false, so the interval satisfies more  T. Furthermore, in a one-state interval, any PITL formula f
A is semantically equivalent to 2A. Therefore, the interval  satisfies the PITL formula 2f (more  T ) and hence also implication (23).
30
Ben Moszkowski
Now consider an interval  which has more than one state and satisfies the NL1 implication more  T. It follows that the interval also satisfies more and therefore the NL1 formula T as well. The formula T, like any NL1 formula, can only test at most the first two states of an interval, so all of  s finite prefix subintervals with two or more states also satisfy T. It follows that every finite prefix subinterval of, including the initial one-state one, satisfies the implication more  T. Therefore, f -formula 2 f (more  T ) and hence also implication (23).itself satisfies the 2
Lemma 8.4 The 1-to-2f formulas are closed under conjunction. That is, if f f (A  B ). and |= B  2B, then also |= (A  B )  2
Proof Here is a simple semantic proof with four steps: f
1 |= A  2A f
2 |= B  2B
|
= f f f (A  B )
3
2A  2B  2
4 |= A  B  2f (A  B )
|=f
A  2A
Assumption
Assumption
PITL
1-3, Prop.f formulas is somewhat analogous to the earlier
Theorem 8.5 below for 1-to-2
Theorem 4.5 concerning closure under 2 for 2-to-1 formulas: f
Theorem 8.5 If A is 1-to-2, so is 2A. That is, from the valid implication follows the next one:
|= f
2A  22A.
Proof Here is a short semantic proof: f
1 |= A  2A f
2 |= 2A  22A
|
= f f
3
22A  22A f
4 |= 2A  22A
|=f
A  2A
Assumption
1, PTL
PITL
2, 3, Prop.
Now for any NL1 formula T, the implication more  T is also in NL1. So we already have by Lemma 4.6 that the PTL formula 2(more  T ) is 2-to-1. It follows f. This includes from Lemma 8.3 and Theorem 8.5 that 2(more  T ) is also 1-to-2 the PTL formula stable p defined in Table 1. The operator stable frequently occurs in applications of ITL, so it is convenient that a formula such as stable p is both f. The PTL formulas w, 2w and finite are likewise 2-to-1 and 2-to-1 and 1-to-2
1-to-2f. The formula 2q already mentioned in the sample valid implication (21) is an example. We shortly make use of the formula 2q being 1-to-2f.
Remark 8.6 Another simple example of formulas which are closed under conjunction and 2 is the set of 1-to-2 formulas for any A for which A  2A is valid. f ones. We do not
These are to a degree time-wise symmetric versions of the 1-to-2 further discuss here the theory of the 1-to-2 formulas but briefly encounter themlater in Sect. 13.3 (when we analyse formula (92)).
8.2 Incremental version of ISEPI technique to extend a 2-to-1 formula rightward f formulas just presented in Sect. 8.1.
We now provide an application of the 1-to-2
The main result here is Theorem 8.7, which provides a way to do the ISEPI
Compositional reasoning using intervals and time reversal
31
technique of Extending rightward the 2-to-1 formula 2f (fin w)  3B for backward analysis. Theorem 8.7 concerns a semantic inference rule for ensuring that if B is Extended rightward by a suitable PITL formula C, then the 2-to-1 formula f (fin w )  3B, which contains B as a subformula, is itself Extended rightward by
2 the conjunction w  C.
Theorem 8.7 Let B be a PITL formula, C be a 1-to-2f formula and w be a state formula. Then the following semantic inference rule is sound:
|=(B ; C )  B
|=
f f(2B
); (w  C )  2B, (24)
f f (fin w )  3B. where 2B is simply the 2-to-1 formula 2
The second implication in the semantic inference identical to the following
 rule isf f one which does not abbreviate 2 (fin w)  3B as 2B :fff (fin w )  3B
2


; (w  C )  2f (fin w)  3B.(25)
Here is now the proof of Theorem 8.7:
Proof (Theorem 8.7) If we have the valid implication |= (B ; C )  B, then the following instance of the same ISEPI technique for Extending rightward is alsovalid:
(fin w)  3B ; (w  C )
|=
(fin w)  3B.(26)
Here is a chain of valid implications to justify this from its sole required assumption
|= (B ; C )  B :
(fin w)  3B ; (w  C )(3B ); Cff(fin w)  3B
3(B ; C )
3B

 fin w ; C
(fin w)  3B.(27)
From implication (26) and Theorem 8.1 then follows the validity of the next implication that is a variation of (26):
|=ff
2 (fin w)  3B f

; 2f (w  C )
 f (fin w )  3B.
2(28)f
The formula 2f (w  C ) can be re-expressed as w  2C. This and our assumption that C is 1-to-2f permit us to obtain the next chain of valid implications:w
Cwf
2Cf (w
2
C ).
Consequently, the next implication is valid:
|=ff
 f (fin w )  3B
2
; (w  C )fff (fin w )  3B
2

; 2f (w  C ).
This together with the earlier one (28) ensures the validity of implication (25) and therefore the desired soundness of semantic inference rule (24).
32
Ben Moszkowski
Like the semantic inference rule in the previous Theorem 8.1, semantic inference rule (24) provides an incremental way to obtain an instance of an ISEPI technique from a simpler variant of it.
We illustrate the use of Theorem 8.7 by taking as examples of w, B and C the propositional variable p, and the two PTL formulas p  2q and 2q, respectively.
Here is the associate instance of |= (B ; C )  B :
|=(p  2q ); 2qp  2q.
This was already presented as implication (21) at the beginning of this section to provide a simple example of the ISEPI technique of Extending rightward. It was furthermore shown there to be valid. The formula 2q is 1-to-2f (and 2-to-1).
Implication (21) can therefore serve as the first implication required by Theorem 8.7s semantic inference rule (24) to obtain the sample instance below of implication (25) for the ISEPI technique of Extending rightward the 2-to-1 formula f (fin p)  3(p  2q ) :
2
|=fff (fin p)  3(p  2q )
2


; (p  2q )  2f (fin p)  3(p  2q ).
The particular instance of C we later use in our analysis in Sect. 13 of mutual exclusion for Petersons algorithm is the conjunction (70) of two formulas each of form 2(more  T ), where T is in NL1. Such formulas are conveniently both 2-to-1 and 1-to-2f, as we already noted above in Sect. 8.1. The PTL formulas w, 2w and f (and additionally 2-to-1), so they can likewise be included in finite are also 1-to-2 such conjunctions which serve as instances of C.
9 ISEPI parallel combining of 2-to-1 formulas for backward analysis
The next Lemma 9.1 involves an instance of the ISEPI technique already discussed in Sect. 4.1 for the Parallel combining of two suitable 2-to-1 formulas. It will be needed later on to obtain Corollary 11.1 in Sect. 11.2.3. That lemma concerns mutual exclusion and gives a way to establish that two processes operating in parallel are not simultaneously in their critical sections. We consider
 here the f f conjunction of two 2-to-1 2-formulas each of the form 2 (fin w)  3B :
Lemma 9.1 For any state formulas w and w and PITL formulas B and B, suppose the following implication is valid:
|=
3B
3B(29)inf.
Then the next implication for use with ISEPI Parallel combining and backward analysis is also valid:
|=f (fin w )  3B
2
f (fin w )  3B
2

2(ww  ).(30)
The assumption (29) states that the formulas B and B  cannot both occur in suffix subintervals of any finite interval.
Compositional reasoning using intervals and time reversal
33
Before proving Lemma 9.1, we discuss some illustrative examples of implications (29) and (30), respectively:
|=
|=
3(skipq)
3(skipf (fin p)  3(skip
2q)
q )inff (fin p )  3(skip
2q )
(31)
2(p  p ). (32)
The first implication (31) expresses that a finite interval with two or more states cannot have the propositional variable q being both true and false in the penultimate state (i.e., the one next to last). Observe that the antecedent of implication (31) is actually unsatisfiable, so the implication is vacuously true. The second implication (32) involves backward analysis to specify that any state with p true is immediately preceded by one with q true, and similarly each state with p true is immediately preceded one with q false. This implication is comparable to the valid PTL formula below: q)
2(p
|=q )
2(p
2(p  p ).
By comparable, we mean here that an interval  satisfies the PITL implication (32) iff the pair (, 0) satisfies the PTL formula.
Proof (Lemma 9.1) Here is a proof in steps which assumes the validity of (29):
The next implication is valid by the assumed validity of (29) together withpropositional reasoning:
|=inf(fin w)  3B
(fin w )  3B
( fin w)  ( fin w ).
This contains the subformula inf in the antecedent and so concerns behaviour in finite intervals.
We then have the following chain of valid implications involving PTL-based reasoning about the operator fin :( fin w)( fin w )  (fin w)  (fin w ) fin (w  w )  fin (w  w ).
The valid implication below, which is suitable for ISEPI Parallel combining, subsequently results from combining the previous one and this chain:
|=inf(fin w)  3B
(fin w )  3B
fin (ww  ).
The following implication for ISEPI Parallel combining, which is about finiteprefix subintervals, is consequently valid:
|=f
2inff (fin w )  3B
2
f (fin w )  3B
2
f fin (w
2w  ).
This is because for any PITL formulas A1,..., An and A, if the implicationf f f(A1      An )  A is valid, so is (2A(and indeed n )  2A
1 )      (2A
 also (2A1 )      (2An )  2A ). f
The subformula 2inf is trivially true because inf is semantically equivalent to finite and therefore true in all finite intervals. Furthermore, the subformulaf fin (w  w ) and the PTL formula 2(w  w ) are semantically equivalent.
2
This is because for any interval, the set of the final states of  s finite prefix subintervals (which 2f fin (w  w ) examines) and the set of  s states (which
2(w  w ) examines) are identical. Hence, the previous valid implication is semantically equivalent to our goal (30), which is therefore also valid.
34
Ben Moszkowski
10 ISEPI iteration of 2-to-1 formulas for backward analysis
We now define some natural variants of 2-to-1 formulas which involve the iterative constructs chop-star and  chop-plus instead of chop. It turns out that the 2-to-1 formula 2f (fin w)  3B for backward analysis has special connections with such variants. The associated ISEPI technique for Iteration finds application in our analysis of mutual exclusion in Sects. 1113 when we consider multiple requests by a process to a shared resource.
Definition 10.1 (-to-1 formulas) Any PITL formula A for which the implication A  A is valid is called a -to-1 formula.
Definition 10.2 (+-to-1 formulas) Any PITL formula A for which the implication A+  A is valid is called a +-to-1 formula.
Here is a brief summary of the three classes of formulas we have defined for sequential composition:
2-to-1 formulas
-to-1 formulas
+-to-1 formulas(A; A)  A
|=
A  A
|= A+  A.
|=
The three categories are all closed under conjunction and 2 (e.g., see Lemmas 10.4 and 10.5 below for +-to-1 formulas). It is not hard to see that any formula A which is +-to-1 is 2-to-1:
Lemma 10.3 Every +-to-1 formula is also 2-to-1.
Proof Observe that for any PITL formula A, we have that A; A implies A+ : |=(A; A)  A+. Now if A is +-to-1, then A+ in turn implies A. Hence, by transitivity, the formula A; A implies A as well, so the formula A is indeed 2-to-1.
Here is a corresponding chain of two valid implications:
A; A
A+
A.
Likewise, any formula which is -to-1 is also 2-to-1 and +-to-1 as well because of the valid PITL implications |= (A; A)  A and |= A+  A, which respectively yield the following two chains of valid implications:
A; A
A+
A
A
A
A.
However, the three categories are by no means identical. Below are sample formulas which illustrate this point: finite p empty
2-to-1
X
X
X
-to-1
+-to-1
X
X
X
Compositional reasoning using intervals and time reversal
35
The reason not every 2-to-1 formula is also +-to-1 is because of the situation in infinite time. Consider the 2-to-1 formula finite. Any infinite interval satisfies finite + but not finite. The same reasoning holds if we replace finite + by finite, so the formula finite is therefore also not -to-1.
All 2-to-1 2f -formulas are also +-to-1 as is later shown in Theorem 10.7. Fur f f thermore, the 2-formulas of the form 2 (fin w)  3B, which we already considered for backward analysis, are subsequently shown in a meaningful formal sense to be nearly members of the class of -to-1 formulas. Certain instances of such formulas can then be profitably used in our analysis of mutual exclusion when we want to compositionally analyse the behaviour of a process making multiple requests to a shared resource.
Let us now discuss further properties of 2-to-1 and +-to-1 formulas. We make some use of -to-1 formulas as well and later mention in Sect. 15.5 their connection with our earlier work on compositionality in ITL.
Lemma 10.4 For any +-to-1 formulas A and B, their conjunction A  B is +-to-1 as well. That is, if |= A+  A and |= B +  B, then also |= (A  B )+  (A  B ).
Proof The formula (A  B )+ implies both A+ and B + and consequently also their conjunction A+  B +. Our assumption that A and B are both +-to-1 then guarantees that this implies A  B. Here is a corresponding chain of valid implications:(A  B )+
A+
B+
Lemma 10.5 If A is +-to-1, so is 2A. That is, if 2A.
|=
A  B.
A+  A, then also
|=(2A)+
Proof Let  be an interval which satisfies (2A)+. Our proof will check that each suffix subinterval of, including  itself, satisfies A+ and hence also A. Therefore,  satisfies 2A. There are two cases to consider which depend on whether thenumber of iterations is finite or infinite:
The chop-plus involves a finite number of sequential iterations of 2A: It follows that  satisfies the PITL formula (2A) 2A containing strong versions of chop and chop-star. Each of  s suffix subintervals can then be shown to satisfy A+ and so also A, since A is +-to-1. Hence,  satisfies 2A.
The chop-plus involves  sequential iterations of 2A (so the interval is infinite): We can readily check that each suffix subinterval   of  satisfies
A and hence also A+. Therefore,   satisfies A itself because A is +-to-1.
Consequently,  satisfies 2A.
The next theorem is the converse of Lemma 10.3, but necessarily restricted to finite intervals for reasons given shortly:
Lemma 10.6 If A is 2-to-1, then it is +-to-1 for finite time, that is, the implication below is valid: finite  (A+  A).(33)
Proof Let  be a finite interval satisfying A+. We want to show that  satisfies
A as well. Now for some natural number k  1,  satisfies k instances of A sequentially combined with k  1 chops between then. For example, if k is 3, then satisfies A; A; A. Note that in finite intervals, strong and weak chop have the same
36
Ben Moszkowskisemantics. We do induction on the number of chops in the formula A;... ; A and employ the assumption that A is 2-to-1 to demonstrate that  satisfies A itself.
Therefore, A is indeed +-to-1 for finite-time intervals and hence implication (33) is valid.
We already pointed out above that the formula finite is an example of a 2to-1 formula which is not +-to-1 in infinite time. This explains Lemma 10.6s requirement about finite time. However, the next Theorem 10.7 demonstrates that all 2f -formulas which are 2-to-1 formulas are also +-to-1 even for infinite time. Such formulas are moreover later used in our analysis of mutual exclusion in Sects. 1113 for multiple requests by a process to a shared resource. f
Theorem 10.7 Any 2-to-1 formula 2B is also +-to-1 for all intervals, including infinite ones:
|= f f(2B
)+  2B.(34)
The proof of Theorem 10.7 is given shortly.
Note that in contrast to a 2-to-1 2f -formula, a 2-to-1 2-formula, which looks at suffix subintervals rather than the prefix ones examined by 2f, is not necessarily
+-to-1. We can take the formula 2finite to serve as an example of this. It is semantically equivalent to finite, which we already pointed out is not +-to-1 in infinite intervals.
We use Theorem 10.7 to provide an ISEPI technique for Iteration with chopplus. This has the form |= A+  A. The theorem ensures that the implication is indeed valid if we take A to be the 2-to-1 formula 2f (fin w)  3B for backward analysis:
|=ff
 + f (fin w )  3B
2
 f (fin w )  3B.
2(35)
Before proving Theorem 10.7, we present a lemma which concerns a semantic inference rule used in the proof:
Lemma 10.8 For any PITL formulas C and C, the next semantic inference rule is sound:
|= (finite  C + )  2C f f(36)
|= C  C   2C.f
Proof We start by assuming the validity of the implication (finite  C + )  2C.
Our goal is to show from this that any interval  which satisfies C  C  also satisfiesf
2C. Let   be any finite prefix subinterval of  (including  itself if it is finite). Ourf proof will show that any such   satisfies C  and hence  itself satisfies 2C. Nowsatisfies C C, so  is contained in a finite prefix subinterval  which likewise satisfies C  C  and so also both C + and finite  C +. Hence by the assumption,  falso satisfies 2C, so its prefix subinterval   satisfies C. It follows that all of the finite prefix subintervals of  indeed satisfy C, and therefore  itself satisfiesf
2C.
We now supply Theorem 10.7s proof:
Proof (Theorem 10.7) Case for finite time: Lemma 10.6 ensures that (33) is validfor finite time for any 2-to-1 formula, so the next instance of (33), which is moreover a variant of (34), is valid as well: finitef(2B
)+
f
2B.
Compositional reasoning using intervals and time reversal
37
Case for infinite time: Our goal here is to show the validity of the next implication: inff(2B
)+f
Let A denote 2B. We re-express inf
|=inf
A+
f
2B.
A+ :(inf
A )
A  (inf
The subformula A  (inf  A) is re-expressible as inf proof can be divided into two parts:(A A)
|=inf
|=inf  A

A).(A A), so our semantic
A
A.(37)(38)
Subcase for (37): We already have A+  A valid for finite time. Therefore, the chain of implications below is valid since A is 2-to-1 and A occurs in the finiteleft of :
A A(empty  A+ )A  (empty A)  (A+ A)
A  (AA)  A  (A; A)  A  A  A.
Hence, formula (37) is valid. f -formula 2B f
Subcase for (38): Recall that A denotes here the 2. Furthermore, f f f the PITL equivalence 2B  22B is valid (much like the valid PTL equivalence
|= 2p  22p). Hence, we have |= A  2A f. Lemma 10.8 permits us to take an instance of the sound semantic inference rule (36) with C and C  both A:
|=(finitef
A+ )  2Af
We then replace each 2A by A using
|=(finite
|=
A+ )  A
|=f
AA  2A.f
A  2A
:
|=
AA  A.
f f
We already have the validity of finite  (2B
)+  2B from the case for finite f time. This is re-expressed using A instead of 2B to obtain |= (finite  A+ )  A.
The semantic inference rule then yields that the implication AA  A is also valid. In infinite time, A and A A are semantically equivalent, so our goal (38) is valid.
The combination of (37) and (38) ensures (34) is valid for infinite intervals.
Our proofs two cases for finite and infinite intervals then yield (34)s validity for all intervals.
Remark 10.9 Let us briefly note without proof some interesting facts not needed i here. Recall from Lemma 4.3 that any formula w, T or 3C is 2-to-1. They are in fact also +-to-1 even for infinite time. Also, if B is 2-to-1, so are the two formulas w  (B  fin
 w) and 2 w  (B  fin w). Reflection helps ensure that f f -formula is +-to-1 even for infinite time.
2 (fin w)  (B  w) is as well. This 2
Furthermore, if the formula B   B is valid (i.e., B is -to-1), then so is C   C, where C is any of these three formulas.
38
Ben Moszkowski
10.1 Zero or more sequential iterations of a 2-to-1 formula
When we later compositionally analyse how a process can make multiple accesses to a shared resource, it is natural to include the case where no accesses are performed. So it would be convenient in such circumstances to use for backward analysis some -to-1 formulas introduced in Definition
10.1 at the beginning of this

Sect. 10. Now every 2f -formula 2f (fin w)  3B has already been shown to be 2to-1 (Theorem 6.1) and therefore also +-to-1 (Theorem
10.7 and implication (35)).

However, we now show that 2f (fin w)  3B is unfortunately not necessarily to-1. Nevertheless, we offer a workaround which is nearly -to-1 and quite suitable for using as an ISEPI technique for Iteration when we look at mutual exclusion in Sects. 1113.
Let us now present two lemmas
 concerning the relationship between instances of the 2f -formula 2f (fin w)  3B for backward analysis and the class of -to-1 formulas:
 f (fin w )  3B
Lemma 10.10 Not every formula 2 is -to-1. f -formula and an interval which satisfies the weak chopProof We exhibit such a 2 star of the formula but not the formula itself. Consider the previous 2f -formula (16),  which is reproduced below: f (fin p)  3(skip
2
 q).
Let  be a one-state interval with the propositional variable p true. We show thatfalsifies the next implication:fff (fin p)  3(skip
2q)
f (fin p)  3(skip
2
 q).(39)
Now, like every one-state interval, trivially satisfies any weak chop-star formula
A. Therefore,  satisfies (39)s antecedent. In a one-state interval, the consequent of implication (39) reduces to the PTL formula p  (skip  q ). However, the interval, which sets p to true, cannot satisfy the subformula skip since that requires at least two states to be present.
The earlier sample 2f -formula(18) is also not -to-1. This is because in a one-state
 interval, 2f (fin p)  3p simplifies to p  p, which is falsified if the interval sets p to true.

The next lemma shows how instances of the 2f -formula 2f (fin w)  3B can always be regarded as almost -to-1 if we require w to initially equal false :
 f (fin w )  3B, the next implication is valid:
Lemma 10.11 For any formula 2
|=wfff (fin w )  3B
2

 f (fin w )  3B.
2(40)
 f (fin w )  3B. We already used Theorem 10.7 to show that
Proof Let C denote 2
C is +-to-1 (i.e., see the earlier valid implication (35)). Therefore, we have thefollowing:
|=
C+
C.(41)
Compositional reasoning using intervals and time reversal
39
This is the ISEPI technique of Iteration for chop-plus, as we previously mentioned with regard to (35). We can also show the following:
|=emptyw(42)
C.f
This is because in a one-state interval any formula 2A is semantically identical to its operand A. In particular, C is identical to (fin w)  3B, which in a one-state interval further simplifies to w  B. So a one-state interval which satisfies w also satisfies C.
Let us now look at merging the two implications (41) and (42) into a single one from which we can later on obtain that C is almost -to-1:
|=
C+(emptyw)(43)
C.
Simple propositional reasoning ensures that the conjunction w implies the antecedent C +  (empty  w) in (43):
|=w(empty
C+)
C+(empty(empty
C+)w).
We can then combine this and (43) using further straightforward propositional reasoning:
|= w  (empty  C + )  C.
The PITL equivalence A  (empty  A+ ) is valid for any formula A. We use it to simplify empty  C + to obtain the next valid implication:
|=w
C
C.
This is in fact identical to our goal (40).
For the convenience of readers, Table 5 lists the ISEPI techniques presented in Sects. 610 specifically for use with the 2-to-1 formulas for backward analysis. The table can be used for reference when we apply the techniques to mutual exclusion in the next three Sects. 1113.
11 Analysis of an abstract mutual exclusion algorithm
In this section and the next two, we consider how to apply compositional backward analysis and the previously introduced 2-to-1 formulas of the form 2f ((fin w)  3B ) to mutual exclusion and Petersons algorithm. These have provided us with a rich and stimulating initial testing ground for developing and experimenting with our ideas about backward analysis in ITL. They together also serve as a proofof-concept of the approach and at least at present are a rather inseparable part of our exploration of time symmetry. We certainly do not claim that our research has reached a stage where it is ready to be deployed in practical problems.
Figure 1 shows a version of Petersons algorithm. One reason for looking at it is because it is a quite elegant and popular example of mutual exclusion and seems to serve as a kind of benchmark for formal techniques. We will have much more to say about Petersons algorithm in Sect. 13 where we formalise in PITL a version of it with two concrete processes P0 and P1. However, our analysis of mutual exclusion initially mostly focuses on a more abstract and higher-level
40
Ben Moszkowski
Introduction (first variant): Formula (19) in Sect. 7:
|=
 f (fin w )  3B.
2
2w
Introduction (second variant): Formula (20) in Sect. 7:
2(more  w)
|=(inf
3B )
 f (fin w )  3B.
2
Sequential combining: (See Theorem 6.1)fff (fin w )  3B
2

; 2f (fin w)  3B

 f (fin w )  3B.
2
Extending rightward: Formula (25) in Sect. 8.2:ff
|=f (fin w )  3B
2


; (w  C )  2f (fin w)  3B,  where C is a 1-to-2f formula and extends B rightward (i.e., |= (B ; C )  B ).
Parallel combining: Formula (30) in Sect. 9: f (fin w )  3B
2
|=where
|=(3B
f (fin w )  3B
2

2(ww  ), 3B  )  inf.
Iteration (version for +-to-1 formula): Formula (35) in Sect. 10:
|=ff
 + f (fin w )  3B
2
 f (fin w )  3B.
2
Iteration (version for almost -to-1 formula): Formula (40) in Sect. 10.1:
|=wfff (fin w )  3B
2

 f (fin w )  3B.
2
Table 5 Summary of ISEPI techniques for 2-to-1 formulas for backward analysisalgorithm with two abstract processes Q0 and Q1. It contains shared aspects of several algorithms and proofs. This is in part because our study of compositionality in Petersons algorithm has helped us see benefits of applying time symmetry to formalising in PITL some abstract issues arising in mutual exclusion. In the future we would of course like to gain more experience by considering other applications and also a range of modelling assumptions, but our research has not yet progressed to this stage.
Let us now review the notion of mutual exclusion. It is one way to ensure that multiple processes safely access a shared resource. Examples of it include cash machines accessing a single bank account and processes utilising a shared printer.
Compositional reasoning using intervals and time reversal
Process P0 noop 0 ; flag 0 := 1; turn := 1; await (flag 1 = 0  turn = 0); noop 0 ; (critical section) flag 0 := 0;
41
Process P1 noop 1 ; flag 1 := 1; turn := 0; await (flag 0 = 0  turn = 1); noop 1 ; (critical section) flag 1 := 0;
1.
1.
2.
2.
3.
3.
4.
4.
5.
5.
6.
6.
7. noop 0
7. noop 1
Initially flag 0 = flag 1 = 0. The starting value of turn is unimportant.
Each statement noop i denotes a no-operation which does no assignments.
Fig. 1 A version of Petersons algorithm with two concrete processes P0 and P1
Here is the general structure of a single access by one abstract process:(a)(b)(c)(d)(e)
Noncritical section;
Request exclusive right to resource;
Critical section with exclusive access;
Release exclusive right to resource;
Noncritical section.(44)
Taubenfelds textbook   gives English-language proofs of mutual exclusion for various algorithms, starting with Petersons (as is indeed often the case in textbooks). Unlike mutual exclusion proofs in conventional point-based temporal logic such as those by Pnueli   and Kroger and Merz, ours does not use a comprehensive set of labels for all relevant program steps. This reflects the quite different nature of point- and interval-based approaches, which can be respectively referred to as endogenous and exogenous. We have more to say about this later on in Sect. 15.2.
The abstract processes Q0 and Q1 and the associated analysis capture some general features of mutual exclusion which apply to many concrete algorithms, not just Petersons. A major benefit of the abstract framework is that it involves a fairly direct application of the ISEPI techniques for 2-to-1 formulas for backward analysis presented earlier in Sects. 610.
At first glance, it might seem easier to formalise something specific and tangible such as the processes P0 and P1 in Petersons algorithm than to formalise the more abstract processes Q0 and Q1. However, before we can reason about the concrete Peterson processes P0 and P1 in PITL, their individual statements need to be expressed as PITL formulas. This requires some further explanation and justification about the modelling assumptions used for concurrency and so is deferred until later in Sect. 13. Furthermore, any analysis dealing just with the concrete processes P0 and P1 in Petersons algorithm is of course much more limited than an analogous one about a higher-level framework for abstract processes Q0 and Q1 which can be adapted to many algorithms, including Petersons. In distinct contrast to the situation with modelling and reasoning about Petersons algorithm in PITL, our ISEPI techniques for 2-to-1 formulas presented in Sects. 610 can be almost immediately used to provide a fairly concise and high-level analysis of the abstract processes Q0 and Q1.
42
Ben Moszkowski
Nevertheless, it can be confusing to work just with the abstract algorithm without having any motivation provided by a concrete one. Therefore, Fig. 1 shows our processes P0 and P1 for Petersons algorithm. We will only discuss certain aspects of them here which help with understanding the abstract processes Q0 and Q1 and the associated correctness formulas.
The concrete processes P0 and P1 in Fig. 1 together have three program variables flag 0, flag 1 and turn with values in {0, 1}. To stay propositional, let 0, 1 and = stand for false, true and, respectively. Both flag 0 and flag 1 are initialised to
0, but turn s starting value is unimportant. The statements noop 0 and noop 1 are simply no-operations or no-ops during which time the processes do not assign their respective variables values. Real processes would likely examine and modify other variables besides flag i and turn, but we ignore them here. The PITL semantics of noop i and other statements in each concrete process Pi are given in Sect. 13.
We do not need to know their details in our analysis of the abstract processes Q0 and Q1.
11.1 Model with the abstract processes Q0 and Q1
The abstract processes Q0 and Q1 are modelled as executing together with iniV tialisation, and expressed as i{0,1} (init i  Qi ). Here init i is some state formula for initialising Qi s variables. The analysis assumes that each process Qi has an auxiliary boolean variable cs i true exactly when Qi is in its critical section and that init i sets cs i to false:
|=init i(45)cs i.
Section 13 gives a concrete instance Pi in (71) for each abstract process Qi. We use
Pi to serve as a variant of Petersons algorithm with additional formulas describing the behaviour of cs i. In Sect. 13 we likewise define in (76) the concrete version pinit i of init i to be the state formula flag i = 0  cs i. As is already noted in Fig. 1, the initial value of the shared writable variable turn is not important. For our analysis of the abstract algorithm, we need for each init i that the implication (45) is valid. This is certainly the case with the concrete formula flag i = 0  cs i, as the next valid implication demonstrates: flag i = 0
|=cs ics i.
Our goal here is to have two general Abstract Assumptions which together with the valid implication (45) (i.e., |= init i  cs i ) suffice to ensure that the abstract processes Q0 and Q1 are never simultaneously in their critical sections(line (c) in (44)). The Abstract Assumptions will be shortly introduced in Table 6 in the next Sect. 11.2.
We now briefly summarise our goal concerning mutual exclusion. Our aim is to prove (cs 0  cs 1 ) is always true, as stated in the next implication:
|=
^(init i
Qi )
2(cs 0cs 1 ).i{0,1}
The Abstract Assumptions will indeed be shown in Sect. 11.2 to be sufficient to guarantee the validity of this.
Compositional reasoning using intervals and time reversal
43
First Abstract Assumption for each i  {0, 1}
|=init i
Qi
AbsSafe ifin init i, (46)where AbsSafe i is defined as 2f ((fin cs i )  3Di ) for some Di.
Second Abstract Assumption
|=
3D0
3D1inf(47)
Table 6 The first and second abstract assumptions
Our abstract analysis can also be generalised to multiple accesses to the shared resource by processes as is discussed later in Sect. 11.3. Properties besides mutual exclusion such as freedom from deadlock are not considered here, but they could be shown with our compositional techniques for liveness   using 2-to-1 formulas for forward analysis such as 2(p  3q ).
11.2 Basic mutual exclusion for the abstract processes
We now introduce the two Abstract Assumptions (46) and (47). They concern mutual exclusion for the abstract processes Q0 and Q1 and describe some temporal behaviour. Table 6 shows these Abstract Assumptions, which are individually referred to as the First Assumption (46) and the Second Assumption (47). The following 2-to-1 formula AbsSafe i is used in the First Assumption (46) to describe a safety property for Qi :
AbsSafe i
= bf ((fin cs )  3D ).
2 i i(48)
This formula AbsSafe i is an instance of the 2-to-1 formula 2f ((fin w)  3B ) introduced in Sect. 6 for compositional backward analysis. Our experience is that many readers have trouble grasping the intuition behind the Abstract Assumptions (46) and (47) and in particular the role of the abstract formulas Di and AbsSafe i. We therefore first discuss concrete instances of Di and AbsSafe i and only then give a general explanation of the Abstract Assumptions. One aim here is to preview some aspects of our analysis of Petersons algorithm in Sect. 13.
11.2.1 Justification of the first abstract assumption
As already noted above in Sect. 11.1, we later on define a variant process Pi of each process Pi in (71) in Sect. 13 (more precisely, in Sect. 13.2). The purpose of Pi is to ensure that the auxiliary variable cs i is indeed true exactly when the process
Pi is in its critical section. The later definition of process Pi in (71) is reproduced below for the convenience of readers in order to assist in our explanation of Di and AbsSafe i :

Pi = b
Pi s lines 13  stable csi ;
Pi s line 4  cs i < true ;
Pi s line 5  cs i < false ;
Pi s lines 67  stable cs i.
44
Ben Moszkowski
Recall the derived constructs stable and padded temporal assignment (<) given in Table 1. The actual concrete instance of Di defined and used in Sect. 13.3 for our analysis of Petersons algorithm is the formula Ei given below (see (73)):
Ei
= bflag i = 1turn = 1  i
3(flag 1i = 0turn = i)nochange i.
Here nochange i is defined later in Sect. 13.1 as part of the PITL semantics of the statements in Petersons algorithm. The formula nochange i specifies that the process Pi is not assigning any values to flag i and turn. Further details about nochange i are not needed for the moment.
Let us consider a concrete formula PeteSafe i which summarises some key behaviour observable when process Pi is its critical section. We later formally define PeteSafe i as (74) in Sect. 13.3 to be a concrete version of AbsSafe i with the concrete instance Ei of the abstract formula Di. The definition is reproduced below for the convenience of readers:
PeteSafe i
= bf ((fin cs )  3E ).
2 i i
We now informally show that if the first state of an interval  satisfies the initialisation formula flag i = 0  cs i for process Pi and the interval  itself satisfies the formula Pi, then each finite prefix subinterval   of  satisfies the next concrete formula, and hence  satisfies PeteSafe i :(fin cs i )
3Ei.
Here is the main goal expressed as an implication which the overall interval satisfies:
 f (fin cs )  3E flag i = 0  cs i  Pi  2 i i.
Suppose the finite prefix subinterval   of  satisfies fin cs i. It follows that cs i is true in the last state of   and hence process Pi is in its critical section during this state. Inspection of our definitions of Pi and Pi reveal that whenever the variable cs i is true, this is preceded by the execution of the following sequence of statements in Pi : flag i := 1; turn := 1  i; await (flag 1i = 0turn = i).
In the state immediately after the first two of these statements, the formula flag i =
1  turn = 1 i is true. That state in fact marks the start of some suffix subinterval in   which satisfies Ei. This is because when the process manages to enter its critical section following the execution of the await statement, the test flag 11 =
0  turn = i must have succeeded. So the state with cs i = 1 will be preceded by a state with flag 11 = 0  turn = i. That state is itself preceded by a state with flag i = 1  turn = 1 i. Furthermore, from the moment that flag i = 1  turn = 1 i is true in that state until when the process leaves its critical section, the process does not assign either flag i or turn, so the formula nochange i holds. Therefore, the suffix subinterval   of   (itself a finite prefix of  ) satisfies the following formulas: flag i = 1  turn = 1  i
3(flag 11 = 0  turn = i)nochange i.
Compositional reasoning using intervals and time reversal
45
Consequently,   satisfies Ei, which is simply the conjunction of these, and itself satisfies 3Ei and hence also (fin cs i )  3E
 i. It follows that the overall inf terval  satisfies the formula 2 (fin cs i )  3Ei, which is the same as PeteSafe i.
Therefore, the following concrete instance of the First Assumption (46) for the concrete instance Pi of the abstract process Qi is valid:
|=flag i = 0cs i
Pif (fin cs )  3E
2 i i
fin (flag i = 0cs i ).(49)
The formula 2f (fin cs i )  3Ei is identical to the concrete version PeteSafe i of AbsSafe i. In (49) we also mention the concrete formula fin (flag i = 0  cs i ) about the last state if the process Pi terminates. This formula, which is a concrete version of the formula fin init i in the First Assumption (46), is easy to check from the behaviour of Pi. In our analysis of Petersons algorithm in Sect. 13, we let the concrete instance pinit i of the abstract initialisation formula init i denote this conjunction flag i = 0  cs i (as already noted in Sect. 11.1).
The First Assumption (46) is an abstracted version of implication (49), where we leave the fine points of Qi, Di and the 2-to-1 formula AbsSafe i largely unspecified. The formula fin init i in the First Assumption later helps to iterate Qi using
Q i in Sect. 11.3 when we compositionally reason about multiple requests to access a shared resource. This concludes our motivation for the First Assumption (46).

11.2.2 Justification of the second abstract assumption
We now turn to motivating the Second Assumption (47) in Table 6. Let us consider the undesirable situation where both processes P0 and P1 in Petersons algorithm somehow end up simultaneously in their critical sections. Suppose the processes are running in an interval. Therefore, the concrete instance (49) of the First
Assumption (46) ensures that  satisfies PeteSafe 0 and PeteSafe 1. Furthermore, the failure of mutual exclusion means that  has a state satisfying cs 0  cs 1. Let denote the finite prefix subinterval of  ending with that state. It follows that satisfies fin (cs 0  cs 1 ). The combination of the fact that  satisfies PeteSafe 0 and PeteSafe 1 together with the definition of PeteSafe i moreover ensures that must satisfy the concrete implications (fin cs 0 )  3E0 and (fin cs 1 )  3E1. Here is a summary of this:
|=fin (cs 0cs 1 )
|=(fin cs 0 )  3E0
|=(fin cs 1 )  3E1.
Hence,   also satisfies the two formula 3E0 and 3E1. Consequently, if we can somehow prove that in fact the conjunction (3E0 )  (3E1 ) is not satisfied by any finite interval (such as   ), it follows from a proof by contradiction that   does not exist. Instead, all finite prefix subintervals of  satisfy fin (cs 0  cs 1 ), so itself satisfies 2f fin (cs 0  cs 1 ), which is semantically equivalent to 2(cs 0  cs 1 ).
This demonstrates that mutual exclusion is achieved. Indeed, we later show in Sect. 13.3 (Lemma 13.9) the validity of following implication about 3E0 and 3E1 not being simultaneously satisfiable in a finite interval:
|=
3E0
3E1inf.
The Second Assumption (47) in Table 6 is simply a much more abstract version of this implication which can capture behaviour in many mutual exclusion algorithms.
This concludes our motivation for the Second Assumption.
46
Ben Moszkowski
11.2.3 Proof of mutual exclusion from the two abstract assumptions
Lemma 11.2 shortly establishes that the First and Second Assumptions together suffice to ensure mutual exclusion for the abstract processes Q0 and Q1 as stated in the following implication:
^
|=(init i
Qi )
2(cs 0cs 1 ).i{0,1}
Let us also point out that we already encountered in Lemma 9.1 the implication (29) which serves as an assumption and is moreover exactly like the Second
Assumption (47). Now Lemma 9.1 concerns the ISEPI technique for Parallel combining (i.e., |= (A1  A2 )  A ) of two suitable 2-to-1 formulas such as AbsSafe 0 and AbsSafe 1 which are intended for backward analysis. Recall that Lemma 9.1 states that if the implication (3B  3B  )  inf is valid, then so is the implication below (which reproduces formula (30) in Lemma 9.1s statement):
|=f (fin w )  3B
2
f (fin w )  3B
2

2(ww  ).
The Second Assumption (47) |= (3D0  3D1 )  inf for abstract processes Q0 and Q1 is indeed just a straightforward instance of the assumption |= (3B  3B  ) inf. Therefore, a version of Lemma 9.1 can be specialised to deal with AbsSafe 0, AbsSafe 1, cs 0 and cs 1 :
Corollary 11.1 Suppose the Second Assumption (47) in Table 6 holds. Then it ensures that the abstract safety formulas imply mutual exclusion as expressed by the valid implication below which combines two instances of the 2-to-1 formula AbsSafe i in parallel:
|=
AbsSafe 0
AbsSafe 1
2(cs 0cs 1 ).(50)
Corollary 11.1 helps in a simple proof of the next Lemma 11.2 concerning mutual exclusion for the abstract processes Q0 and Q1 :
Lemma 11.2 The First Assumption (46) and Second Assumption (47) together ensure that two abstract processes can achieve mutual exclusion as formalised in the valid implication below:
^
|=(init i
Qi )
2(cs 0cs 1 ).(51)i{0,1}
Proof The Second Assumption (47) and Corollary 11.1 together ensure the validimplication (50). We then use simple propositional reasoning to combine this implication with the First Assumption (46) to obtain the desired valid implication (51), thus ensuring mutual exclusion for the abstract processes Q0 and Q1.
Below is a chain of valid implications which capture the main reasoning:
Vi{0,1} (init i
Qi )
AbsSafe 0
AbsSafe 1
2(cs 0cs 1 ).
Compositional reasoning using intervals and time reversal
47
11.3 Multiple accesses by a process to a shared resource
Let us now consider a lemma showing that the two Abstract Assumptions (46) and (47) ensure validity of an implication which describes mutual exclusion for multiple accesses to the critical sections expressed with weak chop-star:
Lemma 11.3 If Assumptions (46) and (47) in Table 6 hold, then the next formula concerning multiple requests for a shared resource is valid:
^
|=(init i  Q
2(cs 0  cs 1 ).(52) i ) i{0,1}
Proof Recall the First Assumption (46):
|=init i
Qi
AbsSafe ifin init i.
This has the form |= (w  A)  (B  fin w). Our earlier work on compositional reasoning (e.g.,  ) discusses semantic inference rules for various combinations of such formulas. Here is a version of one from   which is quite suitable for our purposes here:
|=(w  A)  (Bfin w)
|=(w  A )  (Bfin w).
For example, we can prove this for finite time by doing induction on interval length.
The rule yields from the First Assumption (46) a valid generalisation to multiple exclusive accesses by one process:
|=init i
Q i(AbsSafe i )fin init i.(53)
The formula AbsSafe i, which has the form 2f ((fin w)  3B ), is almost -to-1 by Lemma 10.11 in Sect. 10.1. This is formalised by a valid implication for the ISEPI technique of Iteration (see also the valid implication (40) and Table 5 in Sect. 10.1):
|= cs i  (AbsSafe i )  AbsSafe i.(54)
As noted earlier, we assume that init i implies cs i (see implication (45)), so we can replace cs i in (54) by init i :
|=init i(AbsSafe i )
AbsSafe i.(55)
Propositional reasoning then permits us to combine implications (53) and (55) into the following one:
|=init i
Q i
AbsSafe ifin init i.(56)
The Second Assumption (47) together with Corollary 11.1 about the conjunction
AbsSafe 0  AbsSafe 1 and some further propositional reasoning then yields our goal (52).
Below is a chain of valid implications to capture the main reasoning:
Vi{0,1} (init i
Qi )
AbsSafe 0
V
i{0,1} cs i  (AbsSafe i )
AbsSafe 1
2(cs 0  cs 1 ).
48
Ben Moszkowski
|=init i
|=
Di
|=
Di ; Di(2cs i ); Ri ; (cs i
Qi
Di ); 2cs if 2D i
fin init i(58)(59)(60)
Diwhere Ri is defined as follows:
= b
Ri
2(more  cs i )(inf
3Di ).(61)
Table 7 The third abstract assumption
12 Correctness of an individual abstract process
Recall that the First Assumption (46) in Table 6 in Sect. 11.2 states that a single abstract process Qi ensures that the 2-to-1 formula AbsSafe i is true:
|=init i
Qi
AbsSafe ifin init i.
The rather abstract First Assumption gives no details about how Qi achieves this.
We shortly define what we call the Third Abstract Assumption or more briefly the Third Assumption. This contains some sufficient conditions concerning the overall structure of the sequential behaviour of Qi. Later in this sections Lemma 12.1, these conditions are shown to indeed ensure the validity of the First Assumption for a single abstract process. Subsequently in Sect. 13.3 we prove that an individual process in Petersons algorithm fulfils the Third Assumption (see Theorem 13.4).
Therefore, Lemma 12.1 guarantees that it fulfils the First Assumption as well.
For the convenience of readers, we reproduce below our earlier informal outline of an abstract process previously given as (44) at the start of Sect. 11:(a)(b)(c)(d)(e)
Noncritical section;
Request exclusive right to resource;
Critical section with exclusive access;
Release exclusive right to resource;
Noncritical section.(57)
Table 7 shows some formulas (58)(61) which collectively make up the Third
Abstract Assumption (also referred to as the Third Assumption) about the behaviour of abstract process Qi s steps. As we already noted, the Third Assumption is meant to precisely model the informal description in (57).
It is important to observe that we have fashioned the individual formulas in the Third Assumption in Table 7 so that they are readily suitable for use with the compositional ISEPI techniques already presented in Sects. 610 for backward analysis with 2-to-1 formulas. Table 8 lists several ISEPI techniques for the 2-to-1 formula AbsSafe i which are all instances of the ones in the previous Table 5 in Sect. 10.1. The various formulas found in the Third Assumption in Table 7 find application with most of the entries for ISEPI techniques in Table 8.
Let us now consider each of the Third Assumptions parts individually:
Third Assumptions implication (58):
|=init i
Qi(2cs i ); Ri ; (cs i
Di ); 2cs i
fin init i.
Compositional reasoning using intervals and time reversal
49
Introduction (first variant): Instance of formula (19) in Sect. 7:
|=
2cs i(62)
AbsSafe i.
Introduction (second variant): Instance of formula (20) in Sect. 7:
2(more  cs i )
|=(inf
3Di )
AbsSafe i.(63)
Sequential combining: (See Theorem 6.1)
|=
AbsSafe i ; AbsSafe i
AbsSafe i.(64)
Extending rightward: Instance of formula (25) in Sect. 8.2:
|=
AbsSafe i ; (cs i
Di )
AbsSafe i, (65)f formula and extends D rightward (i.e., |= (D ; D ) where Di is a 1-to-2 i i i
Di ).
Parallel combining: Instance of formula (30) in Sect. 9:
|=where
|=(3D0
AbsSafe 0
AbsSafe 1
2(cs 0cs 1 ), (66)
3D1 )  inf.
Iteration (version for +-to-1 formula): Instance of formula (35) in Sect. 10:
|=(AbsSafe i )+
AbsSafe i.
Iteration (version for almost -to-1 formula): Instance (54) in Sect. 13.3 of formula (40) in Sect. 10.1:
|=cs i(AbsSafe i )
AbsSafe i.
Table 8 Summary of ISEPI techniques with the 2-to-1 formula AbsSafe i
This primarily ensures that process Qi achieves four sequential phases corresponding to lines (a), (b), (c) and the pair of lines (d)-(e) of the abstract process in (57). A feature of the Third Assumptions first implication (58) is that it is abstract and compositional enough to not need a detailed labelling of individual program steps in Qi. We instead sequentially compose them using the chop operator in PITL. Implication (58) asserts that when Qi operates with the state formula init i initially true, then the steps are sequentially performed and also init i is true in the last state if there is one. Here are the lines in the abstract process in (57) and the corresponding individual steps:(a)
2cs i(b)(c)
Rics i  Di(d)-(e)
2cs i.
The first and fourth of the abstract steps are both the formula 2cs i. This concerns a period of time when Qi is not in its critical section and does not even try to enter it. The second formula Ri is for when Qi has succeeded or 50
Ben Moszkowskifailed to enter the critical section in line (b) in the abstract process in (57).
The formula Ri s definition (61) is discussed shortly.
Third Assumptions implications (59) and (60):
|=
Dif
2D i
Di ; Di
|=
Di.
These together restrict the formula Di to being a 1-to-2f formula (Definition 8.2 in Sect. 8.1) and also ensure that it extends Di rightward. We require the two assumptions so that we can invoke Theorem 8.7 (found in Sect. 8.2) for the ISEPI technique of Extending rightward a 2-to-1 formula for backward analysis using a 1-to-2f formula. Table 8 includes an instance (65) of the ISEPI technique for Extending rightward the 2-to-1 formula AbsSafe i. This is obtained using
Theorem 8.7.
We illustrate Di and Di with a simple contrived example. If Di is the formula pi  3pi  stable pi, then Di could be the formula stable pi, which is in fact both f and 2-to-1 (as discussed in Sect. 8.1 after Theorem 8.5). The chain of 1-to-2 valid implications below shows the ISEPI technique of Extending rightward the formula pi  3pi  stable pi (which serves as Di ) using the formula stable pi :(pi
3pi  stable pi ); stable pi pi  3pi  stable pi.pi
3pi(stable pi ; stable pi )
These sample Di and Di are only for illustrative purposes since they are unlikely to properly ensure mutual exclusion.
Third Assumptions definition of Ri in (61):
Ri
= b
2(more  cs i )(inf
3Di ).
This concerns the step in line (b) of (57) when the process awaits entry into its critical section. The definition captures the idea that the process waits infinitely long in vain to enter the critical section or succeeds with the formula
Di true in some suffix of the interval associated with Ri. We can immediately use this formula as an instance of the earlier valid implication (20) in Sect. 7 for the ISEPI technique of Introduction of AbsSafe i. Implication (63) in Table 8 corresponds to this.
The next Lemma 12.1 formally states that the conditions in the Third Assumption suffice to imply the First Assumption:
Lemma 12.1 For any formulas init i, Qi, Di, Di, if all three implications (58)(60) in the Third Assumption are valid, then so is the First Assumption (46).
Proof We first prove the validity of the next formula (67) and make use of the valid implications (62)(65) in Table 8 concerning ISEPI techniques for AbsSafe i :
|=
1
2
3
4
5
6
7
8
9
|=(2cs i ); Ri ; (cs i
Di ); 2cs i
AbsSafe i.
2cs i  AbsSafe i
2(more  cs i )  (inf  3Di )  AbsSafe i
|= Ri
AbsSafe i
|= AbsSafe ; (cs i  D )
AbsSafe i i i
|= Ri ; (cs i  D )
AbsSafe i i
|= (2cs i ); Ri ; (cs i  D ); 2cs i
AbsSafe i ; AbsSafe i ; AbsSafe i i
|= AbsSafe ; AbsSafe
AbsSafe i i i
|= AbsSafe ; AbsSafe ; AbsSafe
AbsSafe i i i i
|= (2cs i ); Ri ; (cs i  D ); 2cs i
AbsSafe i i
|=(67)(62) [ISEPI](63) [ISEPI]
2, Def. of R(65) [ISEPI]
3, 4, PITL
1, 5, PITL(64) [ISEPI]
7, PITL
6, 8, Prop.
Compositional reasoning using intervals and time reversal
51
This can be summarised as a chain of valid implications clearly showing our application to AbsSafe i of the ISEPI techniques discussed in Sects. 68 for Introducing, Sequential combining and Extending rightward such 2-to-1 formulas for backward analysis. We underline the parts of formulas which get reduced to AbsSafe i :
Di ); 2cs i  AbsSafe i ; Ri ; (cs i  Di ); AbsSafe i
AbsSafe i ; AbsSafe i ; (cs i  Di ); AbsSafe i
AbsSafe i ; AbsSafe i ; AbsSafe i  AbsSafe i.(2cs i ); Ri ; (cs i
It then follows from implication (58) in the Third Assumption together with implication (67) that the Third Assumption indeed suffices to ensure the First Assumption (46)s validity.
Suppose we instead let the abstract process Qi itself be defined to be the following:(2cs i ); Ri ; (cs i  Di ); 2cs i.
Then the Third Assumptions first formula (58) can be simplified as shown below:
|=init i
Qifin init i.
13 Analysis of Petersons algorithm
Before showing mutual exclusion for Petersons algorithm (given earlier in Fig. 1 in Sect. 11), we capture the processes behaviour in PITL. Varying concurrency assumptions can be made. We discuss one possible way which illustrates some compositional techniques and time symmetry, and furthermore serves as an initial proof-of-concept. This follows the practice of Pnueli, Barringer, Kuiper and Pnueli   and many other researchers over the years who have used Petersons algorithm as a sort of canonical benchmark for studying mutual exclusion. Petersons algorithm also serves this purpose in the recent textbooks by Aceto et al., Taubenfeld, Herlihy and Shavit   and Kroger and Merz. As we already noted at the beginning of Sect. 11, Taubenfelds discussion about mutual exclusion using Petersons algorithm   has a special significance for our approach because it helped inspire us to see the potential of time symmetry.
13.1 Expressing Petersons algorithm in PITL
One of the main issues with modelling Petersons algorithm in temporal logic involves the semantics of assignment statements. In imperative programming languages, when one variable is assigned, the values of others normally do not change.
On the other hand, in temporal logic, a formula which only mentions the dynamic behaviour of some variables gives absolutely no indication about what happens with other variables
 not occurring in the formula. For example, the PTL formula skip  ( p)  p can be regarded as setting the next value of the propositional variable p to the negation of its current value. This tells us nothing about the behaviour of q and other propositional variables. Such a phenomenon is an instance of the frame problem given prominence by McCarthy and Hayes   (see also
52
Ben Moszkowski
Shanahan  ). If we want variables to remain unchanged during an interval, some explicit formula or semantic mechanism for this must be in place. The simplest solution is to add a formula such as stable q (defined in Table 1 in Sect. 2) for each relevant variable. Hale   initiated the study of framing variables in ITL. Duan has also investigated this issue. f can
The presentation here shows one way formulas which are 2-to-1 and 1-to-2 be used to handle framing issues.
Our illustrative formulation in temporal logic of each process Pi in Petersons algorithm needs to ensure that the variable flag i is always being framed or assigned using :=. We handle framing for flag i by modelling process Pi as having exclusive write access to this variable. Therefore, the definitions of statements for the process
Pi which do not change flag i (i.e., all statements except the ones of the form flag i := j ) can simply include the formula stable flag i.
On the other hand, in Petersons algorithm the two processes must have shared write access to the variable turn. This significantly complicates framing turn. A process cannot simply frame turn by asserting stable turn because this would prevent the other process from changing the variables value. However, observe that process P0 only uses := to assign the variable turn the value 1, and similarly P1 only uses := to assign turn the value 0. So if for example turn = 0, then only process P0 is interested in possibly changing it to 1. We can therefore adopt the convention that if a process Pi wants to frame turn, the process only needs to do so between the pairs of adjacent states with turn = i in the first one. When turn = 1  i, the other process has the responsibility for framing. The temporal formula frameturn i defined below formalises this approach in our modelling of process Pi : frameturn i
= b
2 (more
 turn = i)   turn = i.(68)
Process Pi just has to include frameturn i instead of stable turn in the statements which do not change turn (i.e., all of the statements except turn := 1  i). This is an acceptable solution to framing in Petersons algorithm. For example, no logical inconsistency occurs if say process P0 is assigning turn the value 1 while at the same time process P1 is partially framing turn to prevent it from changing whenever it already equals 1. Also, if both processes simultaneously frame turn, then the combination of activities is logically equivalent to stable turn as expressed by the following valid PTL formula:
|=stable turnframeturn 0frameturn 1.(69)
We now define another PITL formula nochange i. It is used as a part of statements in Petersons algorithm which frame both flag i and turn. The formula nochange i describes any finite or infinite period when P0 changes neither the variable flag i nor the variable turn : nochange i
= bstable flag iframeturn i.(70)
We later need in Sect. 13.3 (in Lemma 13.5) the next Lemma 13.1 concerning nochange 0 : f
Lemma 13.1 The formulas frameturn i and nochange i are 2-to-1 and 1-to-2.
Compositional reasoning using intervals and time reversalnoop 0 flag 0 := c
53
= b
= bnochange 0  finite(stable flag 0  skip )  fin (flag 0 = c) frameturn 0 turn := 1 = b(frameturn 0  skip )  fin (turn = 1) stable flag 0 await (flag 1 = 0  turn = 0) = b  finite  3(flag 1 = 0  turn = 0)  nochange 0.
Table 9 Semantics of individual statements in process P0 in Petersons algorithm
Proof We consider each of the formulas individually:frameturn i : Observe that frameturn i (defined in (68)) has the form 2T, where T is in NL1. Therefore, Lemma 4.6 ensures that frameturn i is 2-to-1. Furthermore, frameturn i can be re-expressed to have the form 2(more  T  ), where Tis also in NL1 :
|=frameturn i

2 more  (turn = i   turn = i).
Recall from Sect. 8.1 that all such 2-formulas (e.g., stable flag i ) are 1-to-2f (see the earlier Lemma 8.3 and Theorem 8.5). nochange i : This is defined in (70) to be the conjunction of stable flag i and f. In addition, the 1-to-2 f forframeturn i. Each of these is both 2-to-1 and 1-to-2 mulas, like the 2-to-1 formulas, are closed under conjunction (see Lemmas 4.4 f. and 8.4). Hence, nochange i is 2-to-1 and 1-to-2
An alternative and perhaps more general and intuitive approach to framing turn in each Pi can employ interleaving controlled by an additional auxiliary variable. This variable determines which process has write access to turn. Therefore, a process has write access and is responsible for framing exactly at such times. That process can then either choose to assign a value to turn or frame it. We would like in future work to look at such an approach and formally compare it with the one used here.
13.2 Semantics of one process in Petersons algorithm
Table 9 shows the semantics of the individual statements of the concrete process
P0 in Petersons algorithm. Note that flag 0 := c is also definable as (flag 0 < c) frameturn 0  finite using the padded temporal assignment operator < (defined in Table 1 in Sect. 2). We define await to terminate iff the wait condition is eventually true. Termination might not be immediate. Process P1 has analogous definitions.
Remark 13.2 Some readers will wonder why the definition of flag 0 := c requires a skip subformula. This is needed so that the variable flag 0 remains stable except perhaps in the very last state when it might change. If we omit the skip, then the variable flag 0 will always be stable and unable to change value. This is because the definition of stable flag 0 in Table 1 in Sect. 2 specifies that the variables value remains unchanged between all adjacent pairs of states. Hence, for any propositional variable p, the formula stable p is semantically equivalent to the conjunction
54
Ben Moszkowski(2p)  (2p). For example, the following formula concerning a change from 0 to
1 is unsatisfiable in finite intervals: pstable pfin p.
One can however dispense with the skip in flag 0 := c by replacing stable flag 0  skip with the formula finite  padded flag 0 containing the derived PITL construct padded. The formula padded A is defined to keep the formula A stable except for perhaps in the last state:
= bpadded A
2(more  A)
2(more  A).
However, the formulas stable A and padded A are semantically equivalent in infinite intervals.
Our analysis uses a version of Pi called Pi (previewed in Sect. 11.2.1) with the auxiliary boolean variable cs i to track Pi s critical section:
Pi
= b
Pi s
Pi s
Pi s
Pi s
lines 13  stable csi ; line 4  cs i < true ; line 5  cs i < false ; lines 67  stable cs i.(71)
We ultimately prove the validity of the next implication which formalises mutual exclusion for Petersons algorithm:
|=
^(pinit i
Pi )
2(cs 0cs 1 ).(72)i{0,1}
This is a concrete instance of the earlier formula (51) for abstract mutual exclusion.
The state formula pinit i for initialisation denotes the conjunction flag i = 0  cs i and is later formally defined as formula (76), but it was already previewed in Sect. 11.1.
13.3 Mutual exclusion for Petersons algorithm based on the abstract one
We now consider how the properties we showed for an abstract model of a single process can be employed to reason about Petersons algorithm. This will save us from having to do a detailed analysis specifically for Petersons algorithm. Such an analysis would require us to first use ISEPI techniques to prove that various parts of process Pi with suitable pre-conditions each imply some 2-to-1 formula or a related one and then to combine them to get a 2-to-1 formula for Pi. Instead, we only need to show something weaker about Petersons algorithm. This then ensures that a concrete instance of the 2-to-1 formula AbsSafe i for backward analysis holds as well. Furthermore, various other properties of the abstract algorithm automatically apply to Petersons algorithm (e.g., formula (52) in Lemma 11.3 for multiple accesses).
Our main goal here is the validity of concrete instances for Petersons algorithm of the Second Assumption (47) and the Third Assumption (implications (58)(60) in Table 7 in Sect. 12). As we previously noted, the Third Assumption is meant to precisely model the informal description in (57) of an abstract process.
Compositional reasoning using intervals and time reversal
55
Let PeteSafe i denote a concrete instance of AbsSafe i. We already discussed
PeteSafe i in a preliminary manner in Sects. 11.2.1 and 11.2.2 in order to motivate our use of the abstract processes Qi, the associated 2-to-1 formula AbsSafe i and the two associated Abstract Assumptions (46) and (47) in Table 6. The concrete instance of Di used in PeteSafe i is the following conjunction, which we denote as
Ei :
Ei
= bflag i = 1turn = 1  i
3(flag 1i = 0turn = i)nochange i.(73)
Recall that the formula nochange i previously defined in (70) specifies that Pi does not alter either of the variables flag i and turn. The formula Ei is based on the values of flag i and turn after process Pi s lines 23 together with the behaviour of lines 45. This was already overviewed in Sect. 11.2.1 but is now summarised again. The relevant phase of process operation concerns requesting entry into the critical section, at which time flag i = 1 and turn = 1  i, and then either succeeding with flag 1i = 0 or turn = i or alternatively forever waiting in vain. The formula
Ei contains the subformula 3(flag 1i = 0  turn = i) and so deals with the case when the request is successful.
Lemma 13.3 The formula Ei is 2-to-1.
Proof This follows from Ei being the conjunction of formulas which are themselves
2-to-1 (using Lemmas 4.3 and 13.1 and then Lemma 4.4).
Lemma 13.3 is invoked later on in Lemma 13.6s proof.
We can in principle use noop i (defined in Table 9) instead of nochange i in Ei s definition. However, the analysis with nochange i is slightly simpler because it omits the subformula finite in noop i.
The use of the formula Ei as a concrete instance of Di results in the concrete instance of AbsSafe i which we denote as PeteSafe i :
PeteSafe i
= bf ((fin cs )  3E ).
2 i i(74)
Another possibility for Ei in PeteSafe i is the weak chop of Pi s lines 25 in Sect. 11s
Fig. 1. We can denote this portion of Pi as Pi,25.
The formula PeteSafe i is 2-to-1 because it is a concrete instance of AbsSafe i, and we therefore have the next instance of the valid implication (64) in Table 8 in Sect. 12:
|=
PeteSafe i ; PeteSafe i  PeteSafe i(75)
In addition to formulas PeteSafe i and Ei, we also define pinit i, ptest i and ptest i to each be a state formula as described below: pinit i ptest i ptest i
= bflag i = 0cs iflag i = 1turn = 1  i(See line 3 of Pi in Fig. 1)(77)
= bflag 1i = 0turn = i(See line 4 of Pi in Fig. 1).(78)
= b(76)
Therefore, the following equivalence relating the formula Ei (defined in (73)) with ptest i, ptest i, and nochange i is valid:
|=
Eiptest i
3ptest inochange i.(79)
56
Ben Moszkowski
Part P0, P0,13
P0,4
P0,5
P0,67
Pre-condition pre 0, Post-condition post 0,  flag 0 = 0  cs 0 flag 0 = 1  turn = 1  cs 0 flag 0 = 1  cs 0 flag 0 = 1  cs 0flag 0 = 1  turn = 1  cs 0 flag 0 = 1  cs 0 flag 0 = 1  cs 0 flag 0 = 0  cs 0.
Table 10 Pre- and post-conditions for parts of P0
We need concrete instances of the formulas init i (found in the First Assumption (46) in Table 6 and Third Assumption in Table 7) and Di (found in the Third
Assumption in Table 7) which are suitable for Petersons algorithm. Let us take init i to be pinit i and Di to be nochange i. Here is a summary of the various abstract formulas and corresponding concrete instances:
Abstract formula:
Concrete formula:init i pinit i
Di
Ei
Di nochange i
AbsSafe i
PeteSafe i.
Alternatively, Di can be Pi,25 (the weak chop of Pi s lines 25) or even Pi,24 and Di can be noop i.
In addition, we use a concrete version Si of the formula Ri defined in the Third
Assumption in Table 7. The two formulas are given below to facilitate comparison:
Abstract formula Ri : 2(more  cs i )(inf
3Di )
Concrete formula Si : 2(more  cs i )(inf
3Ei )
We now turn to showing that Petersons algorithm indeed obeys the requirements imposed on the abstract algorithm to guarantee mutual exclusion. Our presentation first considers the Third Assumption in Table 7, which by Lemma 12.1 implies the First Assumption (46), and then deals with the Second Assumption (47). These suffice to show that all of the mutual exclusion properties we established for the abstract algorithm also apply to Petersons concrete one.
Owing to symmetry, our analysis only needs to consider process P0 in Petersons algorithm. For clarity, we typeset in boldface references to the version
P0, which was defined in (71) in Sect. 13.2 and includes the behaviour of cs 0.
Let us first re-express the formula P0 as the semantically equivalent formula
P0,13
; P0,4
; P0,5
; P0,67 and look at the behaviour of the four primary sequential parts P0,13, P0,4, P0,5 and P0,67. Our analysis shows that each of these combined with a suitable pre-condition implies a corresponding part in the formula given below:(2cs i ); Si ; (cs i  nochange i ); 2cs i.
This is a concrete instance of a subformula of the Third Assumptions first formula (58). Every primary sequential part with its pre-condition furthermore also implies the associated post-condition in the final state when there is one.
State formulas for the pre- and post-conditions for the parts of P0 are fairly straightforward. Table 10 shows one possible approach. For example, pre 0,4 refersto the pre-condition flag 0 = 1  turn = 1  cs 0 for part P0,4. Observe that normally the post-condition for each part is actually the pre-condition of the next
Compositional reasoning using intervals and time reversal
57one. In the case of P0,67, which is the last part, the post-condition can be takento be the pre-condition pre 0,13 for P0,13. We therefore only need to refer to the formulas for pre-conditions and do not actually need separate names for the post-conditions.
Note that pre 0,13 is identical to pinit 0 (i.e., both denote flag 0 = 0  cs 0 ; see (76)).
Theorem 13.4 The concrete instances of all of the Third Assumptions three implications (58)(60) for our version of Petersons algorithm are valid.
The proof is deferred until after we first state and prove Lemmas 13.513.7 for the concrete instances of the Third Assumptions three implications (58)(60) for
Petersons algorithm. Since the proof of Lemma 13.7 for the first one (58) is the most complicated, we save it for last.
Lemma 13.5 (Validity of instance of Third Assumptions implication (59))f
The next concrete instance of the abstract algorithms implication Di  2D i is valid:
|=f nochange i  2nochange i.
Proof This follows immediately from the earlier Lemma 13.1 in Sect. 13.1, thus ensuring that nochange i is 1-to-2f.
Lemma 13.6 (Validity of instance of Third Assumptions implication (60))
The next concrete instance of the abstract algorithms implication (Di ; Di )  Di is valid:
|=
Ei ; nochange i(80)
Ei.
Proof Recall from Lemma 13.3 that Ei is 2-to-1. The proof of the validity of (80) involves a routine use of the ISEPI technique of Extending rightward such a 2to-1 formula. We employ the equivalence (79) to express Ei as the conjunction ptest i  3ptest i  nochange i. Here is chain of valid implications which make use of the fact that nochange i is 2-to-1 as well (Lemma 13.1):
Ei ; nochange iptest i  3ptest i  nochange i ); nochange iptest i  3ptest i  (nochange i ; nochange i )ptest i  3ptest i  nochange i
Ei.
Hence, Ei can indeed be Extended rightward with nochange i, and so implication (80) is in fact valid.
Lemma 13.7 (Validity of instance of Third Assumptions implication (58))
For each process Pi, the following concrete instance of the Third Assumptions implication (58) is valid:
|=pinit i
Pi(2cs i ); Si ; (cs inochange i ); 2cs i
fin pinit i.(81)
58
Ben Moszkowski
Proof We will only deal with P0, but the proof easily generalises to P1. Stateformulas used for the lines pre- and post-conditions are found in the previouslypresented Table 10. Each of the four main parts of P0 in (71), that is P0,13, P0,4, P0,5 and P0,67, contributes one of the chop operands in implication (81)s subformula (2cs 0 ); S0 ; nochange i ; 2cs 0. Here are the associated implications, which are shortly proven to be valid:
P0,13
|=pre 0,13
|=pre 0,4
P0,4
S0fin pre 0,5
|=pre 0,5
P0,5cs 0nochange i
|=pre 0,67
P0,67
2cs 0
2cs 0(82)fin pre 0,4(83)(84)fin pre 0,67(85)fin pre 0,13.
We structure the rest of Lemma 13.7s proof as four steps. Let us first look at a summary of them:
Step 1, case for P0,13 and P0,67
: We show the validity of the associatedimplications (82) and (85).
Step 2, case for P0,4
: We show the validity of the associated implication (83).
Step 3, case for P0,5
: We show the validity of the associated implication (84).
Step 4, case for P0 : We show the validity of the associated implication (81).
Step 1, case for P0,13 and P0,67 to show the validity of implications (82) and (85): Validity readily follows from the associated pre-conditions which set cs 0 to equal false together with the temporal formulas in the followingparts of our definition (71) of P0 corresponding to P0,13 and P0,67
:
P0,13
: Pi s lines 13stable cs i

P0,67
: Pi s lines 67
 stable cs i.
Below are versions of the two implications (82) and (85) with the various formulas replaced by their definitions for easier checking:
|=flag 0 = 0  cs 0  (noop 0 ; flag 0 := 1; turn := 1)  stable cs i
2cs 0  fin (flag 0 = 1  turn = 1  cs 0 )
|=flag 0 = 1  cs 0  (flag 0 := 0; noop 0 )  stable cs i
2cs 0  fin (flag 0 = 0  cs 0 ).
Step 2, case for P0,4 to show the validity of implication (83): Recall that the Third Assumptions definition of Ri in Table 7 is the conjunction 2(more cs i )  (inf  3Di ), so Si is the concrete instance 2(more  cs i )  (inf  3Ei ).
Here is an expanded version of implication (83):
|=flag 0 = 1  turn = 1  cs 0  await (flag 1 = 0  turn = 0)  cs 0 < true
2(more  cs 0 )  (inf  3E0 )  fin (flag 0 = 1  cs 0 ).(86)
From cs 0 and cs 0 < true readily follows 2(more  cs 0 ). The main remaining portion of the proof of implication (86)s validity involves showing that (86)s antecedent implies the consequents subformula inf  3E0. Recall from (73) that
Ei has the following definition:
Ei
= bflag i = 1turn = 1  i
3(flag 1i = 0turn = i)nochange i.
Compositional reasoning using intervals and time reversal
59
Below is a proof first showing that the pre-condition pre 0,4 and P0,4 together imply inf  E0, from which readily follows that they imply inf  3E0. For conciseness in the proof, we use ptest 0 and ptest 0 to denote the state formulas flag 0 = 1  turn = 1 and flag 1 = 0  turn = 0, as previously defined in (77) and (78), respectively.
1
|=
2
3
|=
4
|=
5
|=
6
7
8
|=
|=
|=
|=await (ptest 0 )(finite  3ptest 0 )  nochange 0(finite  3ptest 0 )  inf  3ptest 0 ptest 0  await (ptest 0 ) ptest 0  (inf  3ptest 0 )  nochange 0 ptest 0  (inf  3ptest 0 )  nochange 0
 inf  ptest 0  3ptest 0  nochange 0 ptest 0  await (ptest 0 ) inf  (ptest 0  3ptest 0  nochange 0 ) ptest 0  await (ptest 0 )  inf  E0 inf  E0  inf  3E0 ptest 0  await (ptest 0 )  inf  3E0
Def. of await
PTL
1, 2, Prop.
Prop.
3, 4, Prop.
5, Def. of E0
PTL
6, 7, Prop.
Step 3, case for P0,5 to show the validity of implication (84): This is fairly straightforward from the definitions of noop 0 and cs 0 < false. Here is a version ofimplication (84) with pre 0,5, P0,5 and pre 0,67 replaced by their definitions:
|=flag 0 = 1  cs 0  noop 0  cs 0 < falsecs 0  nochange 0  fin (flag 0 = 1cs 0 ).
Step 4, case for P0 to show the validity of implication (81): The formulas pinit 0 and pre 0,13 are identical (i.e., both denote flag 0 = 0  cs 0 ; see (76)).
Consequently, the initial process state ensures that pre 0,13 is true. The four validimplications (82)(85) for P0,13, P0,4, P0,5 and P0,67 can then be sequentially combined to obtain the validity of the implication (81) for P0.
Recall that Theorem 13.4 states that concrete instances of the Third Assumptions three implications (58)(60) (shown in Table 7 in Sect. 12) for our version of Petersons algorithm are valid. The proof of Theorem 13.4 now readily follows:
Proof (Theorem 13.4) The previous Lemmas 13.513.7 together establish that the concrete instances of all three implications (58)(60) are indeed valid.
We now use Theorem 13.4 to show that Petersons algorithm has suitable instances of the First Assumption:
Lemma 13.8 The next concrete instance of the First Assumption (46) for each process Pi in our version of Petersons algorithm is valid:
|=pinit i
Pi
PeteSafe ifin pinit i.(87)
Proof Lemma 12.1 yields from the Third Assumption the First Assumption (46).
In addition, Theorem 13.4 demonstrates that each process Pi in Petersons algorithm fulfils an associated concrete instance of the Third Assumption. The combination of these then guarantees that each Pi also fulfils the associated concrete instance (87) of the First Assumption.
60
Ben Moszkowski
We also need the next Lemma 13.9 concerning the Second Assumption (47):
Lemma 13.9 The following concrete instance of the Second Assumption (47) for Petersons algorithm is valid:
|=
3E0
3E1(88)inf.
Recall that the Second Assumption (47) was needed in Sect. 11.2.3 to show mutual exclusion exclusion for the abstract algorithm. Consequently, implication (88), as an instance of the Second Assumption, encapsulates in a concise way a key aspect of Petersons algorithm, and it focuses on a central mechanism used to ensure mutual exclusion. Therefore, the proof of the validity of implication (88) has a special significance in the understanding of how Petersons algorithm works.
Proof (Lemma 13.9) Our proof of the validity of implication (88) actually shows the stronger result that 3E0  3E1 is unsatisfiable. Simple temporal reasoningallows us to establish this by a case analysis which demonstrates that each of the following two formulas is unsatisfiable:
E0
3E1
E1(89)
3E0.
This is because if 3E0  3E1 were to be satisfiable, then there would be some suffix subinterval satisfying one of the two formulas E0  3E1 or E1  3E0 in (89).
Owing to the symmetry involved, we only need to consider the first of these here.
Let us use the valid equivalence (79) to re-express E0  3E1 in terms of ptest i, ptest i, and nochange i : ptest 0
3ptest 0nochange 0
3 ptest 1
3ptest 1
 nochange 1.(90)
Our analysis can ignore the conjunct 3ptest 0. When we replace the remaining state formulas ptest 0, ptest 1 and ptest i by their respective definitions given in (77) and (78), the slightly shortened version of formula (90) without 3ptest 0 becomes the following: flag 0 = 1  turn = 1  nochange 0
3 flag 1 = 1  turn = 0  3(flag 0 = 0
 turn = 1)  nochange 1.(91)
The variable flag 0 always equals 1 because of the effect of stable flag 0 in the definition of nochange 0 (see (70)). Therefore, the subformula flag 0 = 0  turn = 1 in (91) can be reduced to turn = 1, which we underline below: flag 0 = 1  turn = 1  nochange 0

3 flag 1 = 1  turn = 0  3(turn = 1)  nochange 1.(92)
Observe that the formulas nochange 0 and nochange 1, as defined in (70), are both conjunctions of 2-formulas. It follows that if nochange 0 and nochange 1 are true for an interval, then they are also true for all suffix subintervals (i.e., they are 1-to-2 formulas):
|=nochange i
2nochange i.
Now consider the suffix subinterval starting with the state where the subformula flag 1 = 1  turn = 0 in (92) is true. In that subinterval, the formulas nochange 0 and nochange 1 are both true, so the two formulas frameturn 0 and frameturn 1 in Compositional reasoning using intervals and time reversal
61their definitions are as well. Therefore, the variable turn must remain stable from then on (as we previously noted with valid equivalence (69) in Sect. 13.1). This behaviour concerning nochange 0, nochange 1 and turn is expressed by the following valid PTL formula:
|=nochange 0nochange 1stable turn.
However, the eventual stability of turn in formula (92) is contradicted by the conjunction turn = 0  3(turn = 1) found within the outer 3-formula. Consequently, the formula (92) itself is in fact unsatisfiable. It then follows from this that formula (91) is likewise unsatisfiable and so is the previous formula E0  3E1 in (89).
Symmetry ensures that the formula E1  3E0 is unsatisfiable as well. This all demonstrates that the conjunction 3E0  3E1 is unsatisfiable and so implies anything, including the formula inf. Consequently, implication (88) is indeed valid.
At this stage, we have obtained for Petersons algorithm concrete instances of the Third Assumption (Theorem 13.4), then the First Assumption (Lemma 13.8), and finally the Second Assumption (Lemma 13.9). Consequently, from the concrete instances (87) and (88) of the First Assumption (46) and Second Assumption (47), respectively, all of the mutual exclusion properties discussed for abstract processes in Sect. 11 can be carried over to Petersons algorithm.
14 Use of time symmetry to reduce some PITL formulas to PTL
We now briefly discuss at an exploratory level how our new techniques of time symmetry and reflections introduced in Sect. 5 can provide a theoretical basis for transforming some PITL formulas to the computationally more tractable formalism PTL. The main contribution of this section is to show how to combine some ideas from our earlier work in   with the new concept of reflection and reasoning about prefix subintervals. In particular, we will first reduce a PITL safety property concerning backward analysis to a PTL formula involving suffix subintervals together with the temporal operators 2 and until. This kind of reduction can then also be done on a formula about a system and an associated safety property. One potential benefit is that we can extend the application of some existing decision procedures and tool-support for PTL to handle suitable PITL formulas as well.
Some computational aspects of PTL are surveyed by Kroger and Merz   and Fisher, who also provide further references to the significant literature on the subject. In   we discuss an implemented decision procedure for PTL with both finite and infinite time which has connections with the theory of PITL. We only mention this because some of the techniques presented in   are later on adapted when we reduce PITL formulas to PTL.
A key observation here is that a reflection of a formula with 2f -subformulas contains 2-subformulas. The later can be easier to reduce to PTL because 2 is itself a PTL construct, whereas 2f is not. Recall that PTLu is the version of PTL with strong until defined earlier in Sect. 3.3. Let us use the formula PeteSafe 0 defined in (74) to illustrate obtaining from a 2f -formula a reflection in PTLu. In order to derive a PTLu formula which reflects PeteSafe 0, our reduction to PTLu
62
Ben Moszkowskifirst obtains the next interval-oriented way to re-express PeteSafe 0 :ff f (fin cs )  3 (empty  ptest ); nochange ;
2
0
0
0 
(empty  ptest 0 ); nochange 0.(93)
Here the PTL formula E0 (defined in (73)) has been replaced by a PITL formula with weak chops which is semantically equivalent to E0 in finite intervals. We now reflect (93):ff rf nochange ; (empty  ptest );
2 cs 0  3
0
0
(94) nochange r0 ; (empty  ptest 0 )
We then re-express the 3f -subformula in PTLu :
Y until ptest 0
(Y until ptest 0 ), (95)where Y acts like nochange r0 on pairs of adjacent states:( flag 0 ) = flag 0
( turn = 0)  turn = 0.
Finally, we can take the PTLu reflection of PeteSafe 0 to be (94) with the 3f subformula replaced by (95). Note the reduction to PTLu of the reflection of a f -formula containing chop-star might require auxiliary variables. This is because
2
PITL with chop-star (which can express regular and omega-regular languages  ) is much more expressive than PTLu. However, this is not always an issue as our example demonstrates. See Kroger and Merz   for a discussion of the operator until and the expressiveness of temporal logics containing it. It would appear that reductions from PITL to PTLu could be automated for a range of syntactic classes of formulas.
To further illustrate the potential of reflection, let us now consider how to checkf the validity of a formula (w  Sys )  (2A fin w ), for some system Sys expressed in PITL. For finite-time analysis, this has the reflection ((fin w)  Sys r )  (2Ar w ). We can reduce Sys r to some PTL formula X with auxiliary variables and test f finite-time satisfiability of (fin w)  X  (X   w ), where X  is a reflection of 2A u expressed in PTL as described above for the example PeteSafe 0.
For infinite time, we can first reduce Sys to a PTL formula with auxiliary variables or an omega automaton. As we show in, these can be represented in PTL by a low-level transition configuration of the form below:
2Tinit
2 3+ L, (96)where T is an NL1 formula, init is a state formula, 3+ L abbreviates  3L (strict
3), and L is a finite conjunction of implications each of the form w  3w. As shown in, the transition configuration has ultimately periodic models and is equivalent to the next formula in infinite time:(Xinit ) X
L  (V  V )
, (97)where X  denotes 2(more  T ) and V  V is the conjunction of temporal assignments v  v for each variable v in the transition configuration. Note that in, the chop-omega operator (A ) is used instead of strong chop-star (A ). However, the two operators have identical semantics in infinite intervals. Testing for
Compositional reasoning using intervals and time reversal
63f infinite-time validity of (w  Sys )  (2A fin w ) is reducible to checking infinitef time unsatisfiability of Sys  w  2A. Here fin w is trivially true for infinite time and ignored. We then replace Sys by (97) to obtain the formula below:(Xinit ) X
L  (V  V )
wf
2A.
This is equivalent to a variant with w in the chops left side:(Xinitw) X
L  ( V  V)
f
2A.(98)
The next semantic inference rule (related to (36)) reduces testing unsatisfiability for (98) to finite-time unsatisfiability:
|= finitef(B1  B2 )  2B
3
|=f(B1  B2 )  2B
3,  where the Bi s can be any formulas. More precisely, it follows from this that if f the conjunction (B1  B2 )  2B
3 is unsatisfiable, then it is unsatisfiable in finite time. Observe that (98) has this form. In order to do the testing for finite time, we can first reflect (98) and reduce it to a PTL formula with more auxiliary variables. f
For example, if 2A is the formula PeteSafe 0 we reflected above and reduced to u
PTL, then this PTLu reflection can be used.
The transition configuration (96) is only meant for analysing infinite-time behaviour. However, a simplified transition configuration of the form shown below canf analogously be used for checking finite-time validity of (w  Sys )  (2Afin w ):
2Tinitfinite.
We would like to see these rather experimental ideas implemented and also to have this approach compared with others, such as one based on a reduction of thef f implication (w  Sys )  (2Afin w ) to a suitable formula with A instead of 2A.
Various formulas in our analysis of Petersons algorithm could be used as an initial test.
15 Discussion
We now touch upon a number of topics with relevance to our framework based on
ITL, 2-to-1 formulas and time symmetry.
15.1 Summary of formulas closed under conjunction and box
For the convenience of readers, Table 11 lists the classes of formulas closed under conjunction and 2 which we have looked at. It also mentions where they are described and some of their uses with suitable formulas. However, note that the almost -to-1 formulas are not a proper class.
We plan in future work to discuss some other classes of formulas which are closed under conjunction and 2 and have potential applications. One example is i the 1-to-2i formulas, that is, any formula A for which the implication |= A  2A is valid. Recall that the operator 2i (defined in Table 1 in Sect. 2) examines all prefix subintervals. In contrast, the operator 2f only examines prefix subintervals having
64
Ben Moszkowski
Class of formulas
2-to-1 Formulas
-to-1 Formulas
+-to-1 Formulas(Almost -to-1 Formulas f Formulas
1-to-2
1-to-2 Formulas
Where defined
Def. 4.1
Def. 10.1
Def. 10.2
Lemma 10.11
Def. 8.2
Remark 8.6
Some uses
ISEPI Sequential combining
ISEPI Iteration
ISEPI Iteration
ISEPI Iteration )
ISEPI Extend rightward
Import formula into 3
Table 11 Various classes of formulas closed under conjunction and boxfinite length. We are studying whether the operator 2i and its associated class of f formulas in practice. For
1-to-2i formulas can be used instead of 2f and 1-to-2 example, 2f ((fin w)  3B ) is semantically equivalent to the 2i -formula 2i ((sfin w)
3B ). Here sfin w is a strong version of fin derivable as 3(empty  w) and also expressible as finite  fin w. Our general experience is that weak interval operators can sometimes be more convenient in applications involving compositionally. More evidence one way or the other still needs to be collected.
We presented in previous sections various results which relate some of the classes. For example, Theorem 10.7 gives a sufficient condition for a 2-to-1 formula to also be +-to-1. Similarly, Lemma 10.11 concerns 2-to-1 formulas which are almost -to-1. It seems worthwhile to further investigate interrelationships between various classes. We report some new results in.
15.2 Exogenous and endogenous frameworks
Our compositional way of reasoning about concurrency in ITL using 2-to-1 formulas contrasts with the better known and much more widely used one based on point-based temporal logic that Pnueli   and others have quite successfully advocated. In particular, the point-based approach does not represent or reason about a program directly in the logic but requires it to be first translated into a state-transition system with many labels (as was also done earlier by Floyd  ).
Temporal logic is used to reason about these. Pnueli already in his first publication about temporal logic over thirty five years ago describes this as being endogenous  :
Another point that is worth mentioning is that the [Endogenous] approach taken here can be classified together with Floyds,.... By that
[the term Endogenous] we mean that we immerse ourselves in a single program which we regard as the universe, and concentrate on possible developments within that universe. Characteristic of this approach is the first phase which translates the programming features into general rules of behavior which we later logically analyze.
An ITL-based analysis, on the other hand, is much closer to what Pnueli   refers to as being exogenous when he compares the two categories:
These [proponents of Exogenous systems such as Hoare  ] suggest a uniform formalism which deals in formulas whose constituents are both logical assertions and program segments, and can express very rich relations
Compositional reasoning using intervals and time reversal
65between programs and assertions. We will be the first to admit the many advantages of Exogenous systems over Endogenous systems. These include among others: a. The uniform formalism is more elegant and universal, richer in expressibility, no need for the two-phase process of Endogenous systems. b. Endogenous systems live within a single program. There is no way to compare two programs such as proving equivalence or inclusion. c. Endogenous systems assume the program to be rigidly given, Exogenous systems provide tools and guidance for constructing a correct system rather than just analyse an existent one.
Against these advantages Endogenous system can offer the following single line of defense: When the going is tough, and we are interested in proving a single intricate and difficult program, we do not care about generality, uniformity or equivalence. It is then advantageous to work with a fixed context rather than carry a varying context with each statement. Under these conditions, Endogenous systems attempt to equip the prover with the strongest possible tools to formalize his intuitive thinking and ease his way to a rigorous proof.
We do not believe that this is the place for a detailed, meaningful assessment of the merits of the (endogenous) point-based and (exogenous) interval-based temporal frameworks, particularly since ours is certainly much more experimental and less applied.
It seems appropriate to quote below the related discussion by Harel et al. in their comparison of Dynamic Logic (DL)   with point-based temporal logic since the succinctly expressed points concerning compositionality equally apply here:
There are two main approaches to modal logics of programs: the exogenous approach, exemplified by Dynamic Logic and its precursor Hoare
Logic, and the endogenous approach, exemplified by Temporal Logic and its precursor, the invariant assertions method of Floyd. A logic is exogenous if its programs are explicit in the language. Syntactically, a Dynamic Logic program is a well-formed expression built inductively from primitive programs using a small set of program operators. Semantically, a program is interpreted as its input/output relation. The relation denoted by a compound program is determined by the relations denoted by its parts.
This aspect of compositionality allows analysis by structural induction. The importance of compositionality is discussed by van Emde Boas. In Temporal Logic, the program is fixed and is considered part of the structure over which the logic is interpreted. The current location in the program during execution is stored in a special variable for that purpose, called the program counter, and is part of the state along with the values of the program variables. Instead of program operators, there are temporal operators that describe how the program variables, including the program counter, change with time. Thus Temporal Logic sacrifices compositionality for a less restricted formalism.
Readers should be able to readily discern that the explanation of Harel et al. gives the impression that temporal logic as a whole is somehow intrinsically limited to being endogenous. The authors do not mention research exploring exogenous uses
66
Ben Moszkowskiof temporal logics to reason about imperative program behaviour. However several earlier publications on this subject by us and others were already available at the time (e.g.,  ). Most of these appeared significantly before the summary appeared. Unlike Dynamic Logic, this ITL-based work does not have separate notations for programs and formulas. Our range of new and fundamental mathematical results about 2-to-1 formulas and time symmetry are a direct continuation of the research on the exogenous use of ITL to express imperative programming constructs. This is a topic we have been pursuing since the 80s.
More recent work by Duan et al.   and the KIV theorem prover group   concerns exogenous uses of variants of ITL for concurrent algorithms.
15.3 2-to-1 formulas and the assumption of discrete time
Our central Theorem 4.5 states that 2-to-1 formulas are closed under the temporal operator 2. Observe that the proof there requires that time is linear but does not at all depend on it being discrete. The theorem is even applicable to a restricted version of PITL consisting of conventional propositional logic with the sole addition of the temporal operator weak chop. Now 2 is the only other temporal operator needed to formalise basic 2-closure of 2-to-1 formulas. It is not hard to derive 2 from weak chop (as described in our earlier publications  ): inf = b true ; falsefinite = b inf
3A = b finite ; A
So Theorem 4.5 seems quite basic in the theory of temporal logic.
2A = b 3A.
We can alternatively take strong chop as a primitive to obtain 2-to-1 formulas using Lemma 4.2s second characterisation of them (i.e., |= (AA)  A). The PTL temporal operator 2 is then derivable as shown in Table 1 in Sect. 2 in order to formalise 2-closure of 2-to-1 formulas.
Our comments here about Theorem 4.5 not requiring discrete time also apply to the analogous Lemma 10.5 concerning the closure of +-to-1 formulas under 2.
If we take skip and either weak or strong chop as the two temporal primitives, then the derived operator until defined in Sect. 3.3 (and used to express 2-to1 formulas in Sects. 5 and 14) is expressible without chop-star by means of the following semantic equivalence:
|=
T until Afinite

2(more  T ) ; A
This uses the PTL subformula 2(more  T ) instead of the PITL subformula (skip
T ) in the original definition of T until A in Sect. 3.3. The two subformulas are semantically equivalent because of the valid PITL equivalence below (we formally state and prove this in [55, Theorem 5.4]):
|=
2(more  T )(skip
T ).
Note that our technique for defining until as a derived operator using skip assumes discrete time. However, the second definition of until can be made to work without discrete time if the left operand is limited to being a state formula (e.g., p until 2q ).
We can simply take either more or empty to be a primitive operator. Alternatively, if chop-star is taken to be a primitive, then we first derive empty from chop-star as false  and then derive more (which is normally defined using skip ) using empty.
Compositional reasoning using intervals and time reversal
67
15.4 Empty intervals
We have for about thirty years used the adjective empty to describe one-state intervals in ITL. Some readers will surely find this convention a bit puzzling because, in contrast, the empty word in regular languages has no letters at all. Let us now examine the choice of terminology. This also helps explain the behaviour of chop-star with one-state intervals, which is a further source of confusion.
In language theory, the empty word is the unique word with no letters at all.
However, since the time of our early work on ITL, we have alway let the derived construct empty (defined in Table 1 in Sect. 2) denote the test for one-state intervals, which are also known in ITL as empty intervals. In fact, intervals in ITL and PTL with finite time always have at least one state, so there is normally no ambiguity about the meaning of the word empty in these logics.
Another reason why the term empty seems reasonable is because one-state intervals in fact play a role in ITL quite similar to empty words in regular languages and the standard finite-state automata associated with them. For example, some of our proofs of axiomatic completeness for versions of ITL   use such automata to encode ITL formulas, but the operation of the automata is modified so that they always examine at least one letter. Such a letter represents both an individual state and a one-state interval. The appropriateness of using empty for one-state intervals can also be clearly seen by means of a comparison of Kleene star with chop-stars semantics on finite intervals:
Standard definition of Kleene star on a regular language L: Define L0 to be the singleton set {} containing just the empty word. For each k  0, inductively define Lk+1 to be the set of finite words { :   L,   Lk }, where  is the usual string concatenation of wordsand. The language L
S is defined to be the infinitary union of these sets: k0 Lk.
Semantics of PITLs chop-star for finite intervals: For any PITL formula
A, we can analogously define A0 to be the formula empty and for each k  0, the formula Ak+1 to be AAk. For each k  0, let Sk denote the set of finite intervals which satisfy the formula Ak and let S  denote the set of finite intervals which satisfy the chop-star formula A (as defined in Sect. 2). Then the two
S sets k0 S k and S  can be shown to be equal.
Observe that the set obtained from the application of Kleene star to a regular language, even the empty one {} with no words in it, always contains the empty word. This is because the language L0 equals {} for every L, so L also includesas an element. Similarly, if one applies chop-star to a PITL formula A, the result
A is satisfied by all one-state (empty) intervals, even if A itself is unsatisfiable.
The formula false  therefore provides a natural alternative way to express empty using just the boolean formula false combined with the temporal operator chopstar.
Duan   and Bowman and Thompson   follow our convention of using empty, although Duan recently abbreviates it as. We should point out that some other naming conventions for the formula empty nevertheless also exist. For example, Paech uses the construct L0. This follows a convention found in some earlier work by others on process logics. The formula  = 0 is favoured in the Duration Calculus, where the special construct
68
Ben Moszkowskiequals interval length. The formula  = 0 can be abbreviated as. The KIV group use the construct last to specify one-state intervals.
15.5 Star-to-1 formulas and chop-star fixpoints
The -to-1 formulas defined in the beginning of Sect. 10 (i.e., |= A  A in Definition 10.1) are identical to the ones called chop-star fixpoints in our earlier work on compositional reasoning in ITL. A chop-star fixpoint is any formula
A for which the equivalence A  A is valid. Now for any PITL formula A, the implication A  A is valid. Hence, A is -to-1 iff the equivalence A  A is valid.
We present an analysis of -to-1 formulas which relates them to other classes of formulas in recent work   that further explores the theory of 2-to-1 formulas.
16 Related work
We now consider relevant research by others and limit our coverage to the categories below:
Mirror images
Early proposals for using temporal logic with past time to reason about concurrency
Interval-based approaches for analysing mutual exclusion
More information about other formal ways to analyse mutual exclusion, including extensive bibliographies, can be found in the various recent textbooks we already cited at the beginning of Sect. 13 when justifying our choice of Petersons algorithm to illustrate time symmetry.
16.1 Mirror images
Time reversal and reflections are related to mirror images (see Prior  ) used with temporal logics to obtain a rule for past-time operators from an analogous one for future-time operators by means of time symmetry. Analyses of conventional temporal logics for computer science typically cannot directly exploit mirror images because the time models are intentionally asymmetric with an infinite future and either no past or a bounded one. That has severely limited the application of mirror images. Nevertheless, Furia and Spoletini   and Reynolds   have recently applied mirror images to symmetric time models (e.g., bounded past and future).
This demonstrates ongoing interest in mirror images and associated techniques.
16.2 Early applications of temporal logic with past time to concurrency
Our presentation already mentioned in Sect. 6 the work by Pnueli   and Lichtenstein, Pnueli and Zuck   in the mid 80s which formalises safety properties using temporal formulas of the form 2(w  X ), where the only temporal operators in X are past-time ones such as those described in Sect. 5.1. Therefore, X can just
Compositional reasoning using intervals and time reversal
69concern past states and the current state, but not future ones. Only Pnueli   specifically discusses mutual exclusion and Petersons algorithm. One motivation for using past time is to assist in doing backward analysis about what must have preceded certain events. We pointed in Sect. 6 out that the formula 2(w  X ) bears a certain resemblance to our class of 2-to-1 PITL formulas having the form f (fin w )  3B
2 and showed how some instances can be formally related in a semantic sense. One example of this given in Sect. 6 concerns the PITL formula (16) and PTL formula (17) which we reproduce below for the convenience of readers: f (fin p)  3(skip
2q)
firstq ).
2(p
Pnuelis main justification given for past time is that point-based temporal logic without past-time constructs imposes a more global view of the system behaviour.
In contrast, past-time constructs help to modularly specify and analyse the behaviour of an individual process.
Interestingly, around the same time as Pnueli, both Barringer and Kuiper   and Koymans, Vytopil and de Roever   similarly suggest the use of pasttime constructs for reasoning about concurrency. They do not discuss ones of the form 2(w  X ). However, Barringer, Kuiper and Pnueli in the slightly later joint paper   mention a couple of formulas of this kind and also examine mutual exclusion and Petersons algorithm.
The straightforward definitions of satisfiability and validity we use for PTL in Sect. 5.1 correspond to the so-called floating framework of PTL with past time.
However, Manna and Pnueli propose another approach called the anchored framework   (also discussed by Lichtenstein and Pnueli in  ) which they argue is superior. In this framework, satisfiability and validity only examine pairs of the form (, 0). There exist ways to go between the two conventions, but we will not delve into this here and instead simply assume the more traditional floating interpretation.
16.3 Other interval-based analyses of mutual exclusion
We now mention some interval-based work involving algorithms for mutual exclusion and the related topic of lock-free data structures. The only previously published analysis of Petersons algorithm in some ITL variant seems to be the one by Pei and Xu   which uses the Discrete Time Duration Calculus. Verification is performed using model checking with the popular SPIN tool   and is global rather than modular in the sense of Pnueli   (as we briefly discussed in Sect. 16.2).
Projection Temporal Logic is an ITL extension with operators for temporal granularities and framing. Duan   expresses Dekkers mutual exclusion algorithm (first published by Dijkstra in  ) in Projection Temporal Logic but without any formal analysis. Yang, Duan and Ma   have applied Projection
Temporal Logic to the analysis of an mutual exclusion example involving a counter and described earlier by Biere et al.. The interactive theorem prover PVS   provides tool support for a global proof in Pnuelis sense involving the combined behaviour of two concurrent processes. Consequently, no compositional properties involving the correctness of the individual processes are given. Duan, Zhang and 70
Ben Moszkowski
Koutny   investigate axiomatic completeness for propositional Projection Temporal Logic and illustrate their framework by summarising the global analysis of another mutual exclusion example. In principle, Projection Temporal Logic supports past-time constructs, so a modular analysis, at least in Pnuelis sense, seems feasible. However, the case studies of mutual exclusion in   are formalised in(previa version of the logic where the only past-time construct, the operator ous), seems intended solely for framing variables. Our techniques involving time symmetry and compositional formulas which are closed under conjunction and the temporal operator 2 might also be applicable to analysis involving Projection
Temporal Logic because it supports basic ITL operators.
The KIV interactive theorem prover group   has combined a variant of ITL with the rely-guarantee paradigm   of Jones to verify lock-free algorithms.
However, they have not yet looked at mutual exclusion. Moreover, the lack of much published literature on applying the quite established rely-guarantee approach to mutual exclusion (e.g., Stark   and see also the related work of Stlen   and Collette  ) suggests that the framework is not particularly well suited for it. The textbook by de Roever et al.   presents a rely-guarantee example involving mutual exclusion and is a comprehensive source of information about compositional reasoning based on rely-guarantee conditions as well as other similar work.
We take this opportunity to also mention a class of ITL formulas which Siewe et al.   and Janicke et al.   use for describing access control policies. Such formulas have the form given below:
 f (3B )  fin w.
2(99)

Their syntax makes them similar to the 2-to-1 formula 2f (fin w)  3B we first discussed in Sect. 6. However, the variant (99) is not necessarily 2-to-1. For example, consider any three-state interval. It has exactly two two-state subintervals.
Each of these subintervals trivially satisfies the next 2f -formula:ff

 f
2
3(skip  skip )  fin false.(100)
This is because a one- or two-state interval does not satisfy the implications left operand 3(skip  skip ), which is only true for intervals with three or more states.
Hence, the implications right operand fin false is ignored. Now let A denote the f -formula (100). Our reasoning so far about the subintervals ensures that the 2 three-state interval  satisfies the chop formula A; A. Nevertheless,  fails to satisfy
A because the left subformula 3(skip  skip ) of the implication in A is true in, but the right subformula fin false is not. Hence,  does not satisfy the implication(A; A)  A, so the formula (100) is not 2-to-1.
Conclusions and Further Work
We believe that our results about interval-based compositional reasoning using 2to-1 formulas and time symmetry are promising. The various compositional classes of formulas described here which are closed under conjunction and the temporal operator 2 seem quite intriguing owing to their simple mathematical features and natural connections with PTL. The approach therefore appears worthy of further study. Moreover, perhaps the application of the compositional classes and time
Compositional reasoning using intervals and time reversal
71symmetry can even somewhat narrow the currently perceived wide practical gap between PITL and PTL and help increase combined use of the two formalisms.
Possible connections could also be explored involving temporal logics with the same expressiveness as PITL but lower computational complexity such as Regular Linear
Temporal Logic proposed by Leucker and Sanchez. Incidentally, PITL itself contains a natural, equally expressive sublogic of this sort called Fusion Logic, which has some tool support.
Ideally, we would also like to see a comparative analysis encompassing a number of suitable benchmark applications, range of formalisms and models of concurrency such as interleaving and true concurrency. It furthermore seems appropriate to evaluate the tradeoffs between analyses involving concrete algorithms and more abstract ones. The compositional details required in our analysis of Petersons algorithm certainly suggest to us that abstraction can be quite beneficial. We have clearly focused our attention on modular techniques here, but the nature of both global and modular ones deserves further investigation.
Our future research plans include using 2-to-1 formulas and time symmetry in a calculus of sequential and parallel composition based on Hoare triples having assertions expressed in ITL. Implementations of decision procedures for PITL using time symmetry and reductions to point-based temporal logic are also envisioned.
We end our discussion here by noting that we believe that the basic mathematical concepts described here enrich the body of knowledge about intervals and temporal logics, no matter what the ultimate practical implications might be.
They include some elementary and exciting properties about compositionality and time symmetry which turned out with the hindsight of several decades to be quite elusive and so until now were completely overlooked and unexplored. It also seems remarkable that most of them only involve the subset of PITL with just the temporal operators chop and skip, but not chop-star. Perhaps similar treasures still remain hidden, waiting to be discovered. We believe that the further systematic and scientific study and application of the compositional techniques we already presented in our earlier work, together with our interval-oriented analysis of conventional point-based linear time temporal   and new completeness proof for PITL with infinite time, could help in the exploration. This view is supported by the fact that the material in these publications played a crucial part in leading us to uncovering the results we have described here.
Acknowledgements We would like to thank Antonio Cau, Amin El-kustaban, Helge Janicke, Maciej Koutny, Sven Schewe, Xiaoxiao Yang and anonymous referees for comments. Shirley
Craigs outstanding library services deserve special mention.
References
1. Aceto, L., Ingolfsdottir, A., Larsen, K.G., Srba, J.: Reactive Systems: Modelling, Specification and Verification. Cambridge University Press (2007)
2. Balser, M., Baumler, S., Knapp, A., Reif, W., Thums, A.: Interactive verification of UML state machines. In: J. Davies, W. Schulte, M. Barnett (eds.) Proc. 6th International
Conference on Formal Engineering Methods (ICFEM 2004), LNCS, vol. 3308, pp. 434
448. Springer-Verlag (2004)
3. Barringer, H., Kuiper, R.: Hierarchical development of concurrent systems in a temporal logic framework. In: S.D. Brookes, A.W. Roscoe, G. Winskel (eds.) Seminar on Concurrency, LNCS, vol. 197, pp. 3561. Springer-Verlag (1985)
72
Ben Moszkowski
4. Barringer, H., Kuiper, R.: Towards the hierarchical, temporal logic, specification of concurrent systems. In: B. Denvir, W. Harwood, M. Jackson, M. Wray (eds.) The Analysis of Concurrent Systems, LNCS, vol. 207, pp. 157183. Springer-Verlag (1985)
5. Barringer, H., Kuiper, R., Pnueli, A.: A really abstract concurrent model and its temporal logic. In: Proc. 13th ACM SIGACT-SIGPLAN Symposium on Principles of Programming
Languages (POPL86), pp. 173183. ACM (1986)
6. Baumler, S., Balser, M., Nafz, F., Reif, W., Schellhorn, G.: Interactive verification of concurrent systems using symbolic execution. AI Communications 23(23), 285307 (2010)
7. Baumler, S., Schellhorn, G., Tofan, B., Reif, W.: Proving linearizability with temporal logic. Formal Aspects of Computing 23(1), 91112 (2011)
8. Biere, A., Cimatti, A., Clarke, E.M., Strichman, O., Zhu, Y.: Bounded model checking.
Advances in Computers 58, 117148 (2003)
9. Bowman, H., Cameron, H., King, P., Thompson, S.: Mexitl: Multimedia in Executable
Interval Temporal Logic. Formal Methods in Systems Design 22(1), 538 (2003)
10. Bowman, H., Thompson, S.J.: A decision procedure and complete axiomatization of finite
Interval Temporal Logic with projection. Journal of Logic and Computation 13(2), 195
239 (2003)
11. Collette, P.: Composition of assumption-commitment specifications in a UNITY style.
Science of Computer Programming 23(2-3), 107125 (1994)
12. Dijkstra, E.W.: Cooperating sequential processes. In: F. Genuys (ed.) Programming Languages: NATO Advanced Study Institute, pp. 43112. Academic Press (1968)
13. Duan, Z.: An extended interval temporal logic and a framing technique for temporal logic programming. Ph.D. thesis, Dept. of Computing Science, University of Newcastle Upon
Tyne (1996). Technical report 556, later published as  
14. Duan, Z.: Temporal Logic and Temporal Logic Programming. Science Press, Beijing, China (2005). Published version of 15. Duan, Z., Koutny, M.: A framed temporal logic programming language. Journal of Computer Science and Technology 19(3), 341351 (2004)
16. Duan, Z., Koutny, M., Holt, C.: Projection in temporal logic programming. In: F. Pfenning(ed.) Proc. of Logic Programming and Automated Reasoning (LPAR 94), LNCS, vol. 822, pp. 333344. Springer-Verlag, Berlin (1994)
17. Duan, Z., Yang, X., Koutny, M.: Framed temporal logic programming. Science of Computer
Programming 70(1), 3161 (2008)
18. Duan, Z., Zhang, N., Koutny, M.: A complete axiomatization of propositional projection temporal logic. Theor. Comp. Sci. (2012). DOI 10.1016/j.tcs.2012.01.026
19. Fisher, M.: An Introduction to Practical Formal Methods Using Temporal Logic. John
Wiley & Sons (2011)
20. Floyd, R.W.: Assigning meanings to programs. In: J.T. Schwartz (ed.) Proc. AMS Symp. on Applied Mathematics 19, pp. 1932. American Mathematical Society, Providence, Rhode Island, USA (1967)
21. Furia, C.A., Spoletini, P.: Tomorrow and all our yesterdays: MTL satisfiability over the integers. In: J.S. Fitzgerald, A.E. Haxthausen, H. Yenigun (eds.) 5th International Colloquium on Theoretical Aspects of Computing (ICTAC 2008), LNCS, vol. 5160, pp. 126140.
Springer-Verlag (2008)
22. Gomez, R., Bowman, H.: PITL2MONA: Implementing a decision procedure for propositional Interval Temporal Logic. Journal of Applied Non-Classical Logics 14(12), 105148(2004). Special issue on Interval Temporal Logics and Duration Calculi. V. Goranko and A. Montanari, guest editors
23. Hale, R.: Temporal logic programming. In: A. Galton (ed.) Temporal Logics and Their
Applications, pp. 91119. Academic Press, London (1987)
24. Hale, R.W.S.: Programming in temporal logic. Ph.D. thesis, Computer Laboratory, Cambridge University, Cambridge, England (1988). Appeared in 1989 as Technical report
173
25. Hansen, M.R., Zhou Chaochen: Duration calculus: Logical foundations. Formal Aspects of Computing 9(3), 283330 (1997)
26. Harel, D., Kozen, D., Parikh, R.: Process Logic: Expressiveness, decidability, completeness.
Journal of Computer and System Sciences 25(2), 144170 (1982)
27. Harel, D., Kozen, D., Tiuryn, J.: Dynamic Logic. MIT Press, Cambridge, Mass. (2000)
28. Harel, D., Kozen, D., Tiuryn, J.: Dynamic Logic. In: D. Gabbay, F. Guenthner (eds.)
Handbook of Philosophical Logic, vol. 4, 2nd edn., pp. 99217. Kluwer Academic Publishers, Dordrecht (2002)
Compositional reasoning using intervals and time reversal
73
29. Herlihy, M., Shavit, N.: The Art of Multiprocessor Programming. Morgan Kaufmann
Publishers Inc., San Francisco, CA, USA (2008)
30. Hoare, C.A.R.: An axiomatic basis for computer programming. Communications of the ACM 12(10), 576580,583 (1969)
31. Holzmann, G.: The SPIN Model Checker: Primer and Reference Manual. Addison-Wesley
Professional (2003)
32. Interval Temporal Logic web pages. http://www.tech.dmu.ac.uk/STRL/ITL/
33. Janicke, H., Cau, A., Siewe, F., Zedan, H., Jones, K.: A compositional event & time-based policy model. In: Proceedings of POLICY2006, London, Ontario, Canada, pp. 173182.
IEEE Computer Society Press (2006)
34. Jones, C.B.: Specification and design of (parallel) programs. In: R.E.A. Mason (ed.) Proc.
IFIP Congress 83, pp. 321332. North Holland Publishing Co., Amsterdam (1983)
35. Jones, C.B.: Tentative steps toward a development method for interfering programs. ACM
Transactions on Programming Languages and Systems 5(4), 596619 (1983)
36. Koymans, R., Vytopil, J., de Roever, W.P.: Real-time programming and asynchronous message passing. In: Proceedings of the Second Annual ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing (PODC83), pp. 187197 (1983)
37. Kroger, F., Merz, S.: Temporal Logic and State Systems. Texts in Theoretical Computer
Science (An EATCS Series). Springer-Verlag (2008)
38. Lamport, L.: Specifying Systems: The TLA+ Language and Tools for Hardware and Software Engineers. Addison-Wesley Professional (2002)
39. Leucker, M., Sanchez, C.: Regular Linear Temporal Logic. In: C.B. Jones, Z. Liu, J. Woodcock (eds.) Proc. 4th International Colloquium on Theoretical Aspects of Computing (ICTAC07), Macau, China, LNCS, vol. 4711, pp. 291305. Springer-Verlag (2007)
40. Lichtenstein, O., Pnueli, A.: Propositional temporal logics: Decidability and completeness.
Logic Journal of the IGPL 8(1), 5585 (2000)
41. Lichtenstein, O., Pnueli, A., Zuck, L.: The glory of the past. In: R. Parikh, et al. (eds.)
Logics of Programs, LNCS, vol. 193, pp. 196218. Springer-Verlag, Berlin (1985)
42. Manna, Z., Pnueli, A.: The anchored version of the temporal framework. In: J.W.D.
Bakker, W.P. de Roever, G. Rozenberg (eds.) Linear Time, Branching Time, and Partial
Order in Logics and Models for Concurrency (REX Workshop 1988), LNCS, vol. 354, pp.
201284. Springer-Verlag (1989)
43. McCarthy, J., Hayes, P.J.: Some philosophical problems from the standpoint of artificial intelligence. In: D. Michie, B. Meltzer (eds.) Machine Intelligence 4, pp. 463502. Edinburgh University Press, Edinburgh (1969). Reprinted in 44. Mo, D., Wang, X., Duan, Z.: Asynchronous communication in MSVL. In: S. Qin, Z. Qiu(eds.) 13th Intl Conf. on Formal Engineering Methods (ICFEM 2011), LNCS, vol. 6991, pp. 8297. Springer-Verlag (2011)
45. Moszkowski, B.: Reasoning about digital circuits. Ph.D. thesis, Department of Computer
Science, Stanford University (1983). Technical report STANCS83970
46. Moszkowski, B.: A temporal logic for multilevel reasoning about hardware. Computer 18, 1019 (1985)
47. Moszkowski, B.: Executing Temporal Logic Programs. Cambridge University Press, Cambridge, England (1986)
48. Moszkowski, B.: Some very compositional temporal properties. In: E.R. Olderog (ed.)
Programming Concepts, Methods and Calculi (PROCOMET94), IFIP Transactions, vol.
A-56, pp. 307326. IFIP, Elsevier Science B.V. (NorthHolland) (1994)
49. Moszkowski, B.: Compositional reasoning about projected and infinite time. In: Proc.
1st IEEE Intl Conf. on Engineering of Complex Computer Systems (ICECCS95), pp.
238245. IEEE Computer Society Press (1995)
50. Moszkowski, B.: Using temporal fixpoints to compositionally reason about liveness. In:
He Jifeng, J. Cooke, P. Wallis (eds.) BCS-FACS 7th Refinement Workshop, electronic
Workshops in Computing. BCS-FACS, Springer-Verlag and British Computer Society, London (1996)
51. Moszkowski, B.: Compositional reasoning using Interval Temporal Logic and Tempura.
In: W.P. de Roever, H. Langmaack, A. Pnueli (eds.) Compositionality: The Significant
Difference, LNCS, vol. 1536, pp. 439464. Springer-Verlag, Berlin (1998)
52. Moszkowski, B.: An automata-theoretic completeness proof for Interval Temporal Logic(extended abstract). In: U. Montanari, J. Rolim, E. Welzl (eds.) Proc. 27th Intl. Colloquium on Automata, Languages and Programming (ICALP 2000), LNCS, vol. 1853, pp.
223234. Springer-Verlag, Geneva, Switzerland (2000)
74
Ben Moszkowski
53. Moszkowski, B.: A complete axiomatization of Interval Temporal Logic with infinite time(extended abstract). In: Proc. 15th Ann. IEEE Symp. on Logic in Computer Science(LICS 2000), pp. 242251. IEEE Computer Society Press (2000)
54. Moszkowski, B.: A hierarchical completeness proof for Propositional Interval Temporal
Logic with finite time. Journal of Applied Non-Classical Logics 14(12), 55104 (2004).
Special issue on Interval Temporal Logics and Duration Calculi. V. Goranko and A. Montanari, guest editors.
55. Moszkowski, B.: Using temporal logic to analyse temporal logic: A hierarchical approach based on intervals. Journal of Logic and Computation 17(2), 333409 (2007)
56. Moszkowski, B.: Compositional reasoning using intervals and time reversal. In: 18th Intl
Symp. on Temporal Representation and Reasoning (TIME 2011), pp. 107114. IEEE Computer Society (2011)
57. Moszkowski, B.: A complete axiom system for propositional Interval Temporal Logic with infinite time. Logical Methods in Computer Science 8(3:10), 156 (2012)
58. Moszkowski, B.: Interconnections between classes of sequentially compositional temporal formulas. Inf. Process. Lett. 113(9), 350353 (2013)
59. Olderog, E.R., Dierks, H.: Real-Time Systems: Formal Specification and Automatic Verification. Cambridge University Press, Cambridge, England (2008)
60. Owre, S., Shankar, N.: A brief overview of PVS. In: O.A. Mohamed, C. Munoz, S. Tahar(eds.) 21st International Conference on Theorem Proving in Higher Order Logics (TPHOLs
2008), LNCS, vol. 5170, pp. 2227. Springer-Verlag (2008)
61. Paech, B.: Gentzen-systems for propositional temporal logics. In: E. Borger, H.K.
Buning, M.M. Richter (eds.) Proceedings of the 2nd Workshop on Computer Science Logic(CSL88), LNCS, vol. 385, pp. 240253. Springer-Verlag (1989)
62. Parikh, R., Chandra, A.K., Halpern, J.Y., Meyer, A.R.: Equations between regular terms and an application to process logic. SIAM Journal on Computing 14(4), 935942 (1985)
63. Pei Yu, Xu Qiwen: Checking interval based properties for reactive systems. In: B. Steffen, G. Levi (eds.) Verification, Model Checking, and Abstract Interpretation, LNCS, vol. 2937, pp. 5175. Springer-Verlag (2004)
64. Peterson, G.L.: Myths about the mutual exclusion problem. Inf. Process. Lett. 12(3), 115116 (1981)
65. Pnueli, A.: The temporal logic of programs. In: Proc. 18th Ann. IEEE Symp. on the Foundation of Computer Science (FOCS), pp. 4657. IEEE Computer Society Press (1977)
66. Pnueli, A.: In transition from global to modular temporal reasoning about programs. In:
K.R. Apt (ed.) Logics and Models of Concurrent Systems, NATO ASI Series F, vol. 13, pp. 123144. Springer-Verlag (1985)
67. Prior, A.: Past, Present and Future. Oxford Univ. Press, London (1967)
68. Reif, W., Schellhorn, G., Stenzel, K., Balser, M.: Structured specifications and interactive proofs with KIV. In: W. Bibel, P.H. Schmitt (eds.) Automated Deduction  A Basis for Applications, Volume II: Systems and Implementation Techniques, pp. 1339. Kluwer
Academic Publishers, Dordrecht (1998)
69. Reynolds, M.: A tableau for Until and Since over linear time. In: 18th Intl Symp. on
Temporal Representation and Reasoning (TIME 2011), pp. 4148. IEEE Computer Society(2011)
70. de Roever, W.P., de Boer, F., Hanneman, U., Hooman, J., Lakhnech, Y., Poel, M., Zwiers, J.: Concurrency Verification: Introduction to Compositional and Noncompositional Methods. No. 54 in Cambridge Tracts in Theoretical Computer Science. Cambridge University
Press (2001)
71. Sanchez, C., Leucker, M.: Regular Linear Temporal Logic with past. In: 11th Intl Conf. on Verification, Model Checking, and Abstract Interpretation (VMCAI 2010), LNCS, vol.
5944, pp. 295311. Springer-Verlag (2010)
72. Shanahan, M.: Solving the Frame Problem: A Mathematical Investigation of the Common
Sense Law of Inertia. MIT Press (1997)
73. Siewe, F., Cau, A., Zedan, H.: A compositional framework for access control policies enforcement. In: M. Backes, D. Basin, M. Waidner (eds.) ACM Workshop on Formal Methods in Security Engineering (FMSE03), pp. 3242. ACM Press, Washington, DC (2003)
74. Stark, E.W.: A proof technique for rely/guarantee properties. In: Proceedings of the 5th
Conference on Foundations of Software Technology and Theoretical Computer Science(FSTTCS 1985), LNCS, vol. 206, pp. 369391. Springer-Verlag (1985)
75. Stlen, K.: A method for the development of totally correct shared-state parallel programs.
In: CONCUR 1991, LNCS, vol. 527, pp. 510525. Springer-Verlag (1991)
Compositional reasoning using intervals and time reversal
75
76. Taubenfeld, G.: Synchronization Algorithms and Concurrent Programming.
Pearson/Prentice Hall (2006)
77. Thomas, W.: Automata on infinite objects. In: J. van Leeuwen (ed.) Handbook of Theoretical Computer Science, vol. B: Formal Models and Semantics, chap. 4, pp. 133191.
Elsevier/MIT Press, Amsterdam (1990)
78. Thums, A., Schellhorn, G., Ortmeier, F., Reif, W.: Interactive verification of Statecharts.
In: H. Ehrig, W. Damm, J. Desel, M. Groe-Rhode, W. Reif, E. Schnieder, E. Westkamper(eds.) SoftSpez Final Report, LNCS, vol. 3147, pp. 355373. Springer-Verlag (2004)
79. Tofan, B., Baumler, S., Schellhorn, G., Reif, W.: Temporal logic verification of lockfreedom. In: Proc. MPC 2010, Springer LNCS 6120, pp. 377396 (2010)
80. van Emde Boas, P.: The connection between Modal Logic and Algorithmic Logic. In:
7th Symposium on Mathematical Foundations of Computer Science (MFCS 1978), lncs, vol. 64, pp. 115. springer (1978)
81. Webber, L., Nilsson, N.J. (eds.): Readings in Artificial Intelligence. Tioga Publishing Co., Palo Alto, California (1981)
82. Yang, X., Duan, Z., Ma, Q.: Axiomatic semantics of projection temporal logic programs.
Mathematical Structures in Computer Science 20(5), 865914 (2010)
83. Zhang, N., Duan, Z., Tian, C.: A cylinder computation model for many-core parallel computing. Theor. Comp. Sci. (2012). DOI 10.1016/j.tcs.2012.02.011
84. Zhou Chaochen, Hansen, M.R.: Duration Calculus: A Formal Approach to Real-Time
Systems. Monographs in Theoretical Computer Science (An EATCS series). SpringerVerlag (2004)
85. Zhou Chaochen, Hoare, C.A.R., Ravn, A.P.: A calculus of durations. Inf. Process. Lett.
40(5), 269276 (1991)
This author-produced version was formatted on 26 July 2013.Reasoning about Plan Revision in Agent Programs
Natasha Alechina
University of Nottingham, UK
TIME 2012, Leicester 14 September 2012
Natasha Alechina
Reasoning about plan revision
TIME 2012
1 / 46
What this talk is aboutverification (of agent programs with changing plans) transition systems correspond to agent program execution model-checking agent programs joint work with Brian Logan, Mehdi Dastani and John-Jules Meyer on a theorem-proving approach (using dynamic logic) main extension: explicit operator for having a plan
Natasha Alechina
Reasoning about plan revision
TIME 2012
2 / 46
Transition systemsacbdp
Natasha Alechina
Reasoning about plan revision
TIME 2012
3 / 46
Dynamic logic ha; bip, hc; dipacbdp
Natasha Alechina
Reasoning about plan revision
TIME 2012
4 / 46
Having and executing a plan
Plan(a;b) abp
Natasha Alechina
Reasoning about plan revision
TIME 2012
5 / 46
What is an agent?many definitions of agent in the literature  key ideas include: autonomy: an agent operates without the direct intervention of humans or other agents situatedness: an agent interacts with its environment (which may contain other agents) reactivity: an agent responds in a timely fashion to changes in its environment proactivity: an agent exhibits goal-directed behaviour
Natasha Alechina
Reasoning about plan revision
TIME 2012
6 / 46
What I will mean by an agenta computational system whose behaviour can be usefully characterised in terms of propositional attitudes such as beliefs and goals and which is programmed in an agent programming language which makes explicit use of propositional attitudes
Natasha Alechina
Reasoning about plan revision
TIME 2012
7 / 46
What is an agent programming language?
Belief, Desire and Intentions (BDI) framework, (Bratman 1987)
BDI agent programming languages are designed to facilitate the implementation of BDI agents: programming constructs corresponding to beliefs, desires and intentions agent architecture or interpreter enforces relationships between beliefs, desires and intentions and which causes the agent to choose actions to achieve its goals based on its beliefs
Natasha Alechina
Reasoning about plan revision
TIME 2012
8 / 46
3APLone of the first agent programming languages PRS (Georgeff and Ingrand 1988), very rich. I will talk about a more modern and less rich langauge, 3APL
3APL is a BDI agent programming language proposed in (Dastani et al. 2003)
I present a cut-down version of 3APL (mostly regarding the language for beliefs, but also distinction between external and internal actions, not considering messages etc.)
Natasha Alechina
Reasoning about plan revision
TIME 2012
9 / 46
3APL beliefsthe beliefs of a 3APL agent represent its information about its environment and itself beliefs are represented by a set of positive literals the initial beliefs of an agent are specified by its program e.g., the agent may initially believe that its in room1 and its battery is charged:
Beliefs: room1, battery
Natasha Alechina
Reasoning about plan revision
TIME 2012
10 / 46
3APL goalsthe agents goals represent situations the agent wants to realise(not necessarily all at once) goals are represented by a set of arbitrary literals the initial goals of an agent are specified by its program e.g., the agent may initially want to achieve a situation in which both room1 and room2 are clean
Goals: clean1, clean2
Natasha Alechina
Reasoning about plan revision
TIME 2012
11 / 46
Declarative goalsthe beliefs and goals of an agent are related to each other if an agent believes p, then it will not pursue p as a goal if an agent does not believe that p, it will not have  p as a goalthese relationships are enforced by the agent architecture
Natasha Alechina
Reasoning about plan revision
TIME 2012
12 / 46
3APL basic actionsbasic actions specify the capabilities of the agent (what it can do independent of any particular agent program)
2 types of basic actions: belief test actions: test whether the agent has a given belief belief update actions: external actions which change the agents beliefs
Natasha Alechina
Reasoning about plan revision
TIME 2012
13 / 46
Belief test actionsa belief test action ? tests whether a boolean belief expression is entailed by the agents beliefs, e.g.:(room2 and -battery)? tests whether the agent believes it is in room2 and its battery is not charged
Natasha Alechina
Reasoning about plan revision
TIME 2012
14 / 46
Belief update actionsbelief update actions change the beliefs (and goals) of the agent a belief update action is specified in terms of its pre- and postconditions (sets of literals), e.g.:
{room1} moveR {
}, {-room1, room2}an action can be executed if one of its pre-conditions is entailed by the agents current beliefs executing the action updates the agents beliefs to make one of the postconditions entailed by the agents beliefs (actions non-deterministic)
Natasha Alechina
Reasoning about plan revision
TIME 2012
15 / 46
Belief entailmenta belief query (a belief test action or an action precondition) is entailed by the agents belief base if all positive literals in the query are contained in the agents belief base, and for every negative literal  p in the query, p is not in the belief base i.e., we use entailment under the closed world assumptiongoal entailment corresponds to a formula being classically entailed by one of the goals in the goal base
Natasha Alechina
Reasoning about plan revision
TIME 2012
16 / 46
Belief updateexecuting a belief update action adds all positive literals in the corresponding postcondition to the belief base, and for every negative literal  p in the postcondition, p is removed from the agents belief basegoals which are achieved by the postcondition of an action are dropped for simplicity, we assume that the agents beliefs about its environment are always correct and its actions in the environment are always successful
Natasha Alechina
Reasoning about plan revision
TIME 2012
17 / 46
Abstract plansunlike basic actions, abstract plans cannot be directly executed by the agent. abstract plans provide an abstraction mechanism (similar to procedures in imperative programming) which are expanded into basic actions using plan revision rules if the first step of a plan  is an abstract plan, execution of blocks.
Natasha Alechina
Reasoning about plan revision
TIME 2012
18 / 46
3APL plansplans are sequences of basic actions and atomic plans composed by plan composition operators: sequence: 1 ;2  (do 1 then 2 ) conditional choice: if  then {1 } else {2 } conditional iteration: while  do {}e.g., the plan: if room1 then {suck} else {moveL; suck} causes the agent to clean room1 if its currently in room1, otherwise it first moves (left) to room1 and then cleans it
Natasha Alechina
Reasoning about plan revision
TIME 2012
19 / 46
3APL PG rules planning goal rules are used for plan selection based on the agents current goals and beliefs a planning goal rule    |  consists of three parts:
: an (optional) goal query which specifies which goal(s) the plan achieves
: a belief query which characterises the situation(s) in which it could be a good idea to execute the plan
: a plana PG rule can be applied if  is entailed by the agents goals and is entailed by the agents beliefs applying the rule adds  to the agents plans
Natasha Alechina
Reasoning about plan revision
TIME 2012
20 / 46
Example 3APL PG rules clean2 <- battery | if room2 then {suck} else {moveR; suck} states that if the agents goal is to clean room2 and its battery is charged, then the specified plan may be used to clean the room an agent can generate a plan based only on its current beliefs(reactive invocation), e.g., the rule:
<- -battery | if room2 then {charge} else {moveR; charge} states if the battery is low, the specified plan may be used to charge it
Natasha Alechina
Reasoning about plan revision
TIME 2012
21 / 46
Example 3APL PR rules a plan revision rule pj = j  j |  0 j can be applied if j is in the plan base, j is entailed by the agents beliefs and j is not executable, in other words the first action of j is either a belief update or belief test action which is not executable in the current belief state, or an abstract plan for example, if moveR fails, the agent may execute a slow but reliable version of the action, slowR: charge <- room1 |
{slowR; charge}
Natasha Alechina
Reasoning about plan revision
TIME 2012
22 / 46
Operational semantics we define the operational semantics of 3APL in terms of a transition system states are agent configurations h,, i where,  are sets of literals representing the agents beliefs and goals, and  is a set of plan entries representing the agents current active plans(annotated by the goals which they were adopted to achieve) each transition corresponds to a single step in the execution of the agent different execution strategies give rise to different semantics for simplicity we focus on non-interleaved executioni.e., the agent executes a single plan to completion before choosing another plan
Natasha Alechina
Reasoning about plan revision
TIME 2012
23 / 46
Formal entailment definitions
|=cwa (belief entailment for closed world assumption):
|=cwa p iff p
|=cwa p iff p 6
|=cwa  and  iff  |=cwa  and  |=cwa
|=cwa  or  iff  |=cwa  or  |=cwa
|=cwa {1,..., n } iff 1  i  n  |=cwa i
|=g (goal entailment):
|=g p iff p
|=g p iff p
|=g  or  iff  |=g  or  |=g
Natasha Alechina
Reasoning about plan revision
TIME 2012
24 / 46
Belief update function let a be a belief update action and  a belief base such that
|=cwa precj (a) intuitively,  |=cwa precj (a) if it contains all positive literals in precj (a) and does not contain the negative ones the result of executing belief update action a with respect to(assuming precj (a) holds and the action results in the postj,i becoming true) is defined as:
Tj,i (a, ) = (  {p : p  postj,i (a)}) \ {p :  p  postj,i (a)} intuitively, the result of the update satisfies (entails under |=cwa ) the corresponding postcondition postj,i (a)
Natasha Alechina
Reasoning about plan revision
TIME 2012
25 / 46
Transitions: belief test actionsbelief test actions
|=cwa h,, {?;. }i  h,, {. }i
Natasha Alechina
Reasoning about plan revision
TIME 2012
26 / 46
Transitions: belief update actionsbelief update actions when the corresponding goal not achieved yet:
|=cwa preci () Ti,j (, ) =  0  0 =  \ { |  0 |=cwa }  0 6|=cwa h,, {;. }i  h 0,  0, {. }i belief update actions when the corresponding goal is achieved:
|=cwa preci () Ti,j (, ) =  0  0 =  \ { |  0 |=cwa }  0 |=cwa h,, {;. }i  h 0,  0, { }i
Natasha Alechina
Reasoning about plan revision
TIME 2012
27 / 46
Transitions: plans conditional choice
|=cwa h,, {(if  then 1 else 2 );. }i  h,, {1 ;. }i
6|=cwa h,, {(if  then 1 else 2 );. }i  h,, {2 ;. }i conditional iteration
|=cwa h,, {(while  do 1 );. }i  h,, {1 ; (while  do 1 );.
6|=cwa h,, {(while  do 1. ); }i  h,, {. }i
Natasha Alechina
Reasoning about plan revision
TIME 2012
28 / 46
Transitions: PG rulesplanning goal rules    |
|=g  cwa |= h,, {}i  h,, {. }i
Natasha Alechina
Reasoning about plan revision
TIME 2012
29 / 46
Transitions: PR rulesplan revision rules pj = j  j |  0 j i  6|=cwa preci ()  |=cwa j h,, {j = ;. }i  h,, { 0 j. }i
6|=cwa
|=cwa j h,, {j = ?;. }i  h,, { 0 j. }i
|=cwa j h,, {j = ;. }i  h,, { 0 j ;. }i where  is the name of an abstract plan.
Natasha Alechina
Reasoning about plan revision
TIME 2012
30 / 46
State of the art
State of the art in model-checking agent programs
Model-checking AgentSpeak (Promela, Spin)
Rafael H. Bordini, Michael Fisher, Carmen Pardavila, Michael
Wooldridge: Model checking AgentSpeak. AAMAS 2003:409-416
General platform for model-checking BDI agents (AIL and AJPF)
Louise A. Dennis, Michael Fisher, Matthew P. Webster, Rafael H.
Bordini: Model checking agent programming languages. Autom.
Softw. Eng. 19(1): 5-63 (2012)
Work with Goal, 3/2APL,...
Natasha Alechina
Reasoning about plan revision
TIME 2012
31 / 46
State of the art
Challenges
In common with general model-checking: scalability issues
In common with general (software) model-checking: hard to deal with an infinite number of possible inputs/events, first-order properties
I think there is still no system specification language at the right level of abstraction
Beliefs, goals, plans, etc. are treated as just ordinary data structures: same as lists of strings or some other dumb values
However, they do have some logical structure (e.g. closure under the agents reasoning rules) and connections to each other, which should be used, in a transparent fashion (use something more like
Maude?)
The most interesting logical challenge here I think is the logic of having committed to a set of intentions
Natasha Alechina
Reasoning about plan revision
TIME 2012
32 / 46
State of the art
What does having a set of intentions mean
If an agents set of intentions is {a; b; c, d; e; f } then it is easy to figure out what the possible actions by the agent are (a and d); for more general plans it is more complicated, but also well defined no logic with explicit adopted plans (in the logical language), apart from TCS11 (for single agent/single plan) and a paper in informal proceedings of DALT 2009. there are logics with explicit strategies (Simon and Ramanujam
2008,2009), but strategies and plans are not exactly the same and logics have no he has adopted this strategy operator
Natasha Alechina
Reasoning about plan revision
TIME 2012
33 / 46
State of the art
Verification by theorem proving
State properties of the system as axioms (completely axiomatise the operational semantics)
Prove that the desired property logically follows from them
This is a more complex problem than model-checking, but it is easier to deal with first-order, infinite domains, etc.
Natasha Alechina
Reasoning about plan revision
TIME 2012
34 / 46
Logic
Signature of an agent program
The signature of an agent program R is defined as R = hP, PG,  Act, Plani
PR, Ac, Ac, P is a set of belief and goal atoms
PG is a set of planning goal rules, ri = i  i | i
PR is a set of plan revision rules, pj = j  j | j0
Ac is a set of belief update actions occurring in the plans of PG and PR rulesis a set of abstract plans occurring in the plans of PG and PR
Ac rules
Act is the set of specifications for belief update actions Ac
Plan is the set of all possible.  pairs where  is one of the agents goals and  is a plan occurring in PG and PR rules or a suffix of such a plan
Natasha Alechina
Reasoning about plan revision
TIME 2012
35 / 46
Logic
Language of PDL-3APLprogram expressions:
| r i | p | 1 ; 2 | 1  2 |
::=   Ac | t() | a  Ac j formula:
::= Bp | Gp | G  p | x | P   | P | | 1  2 | hi
Natasha Alechina
Reasoning about plan revision
TIME 2012
36 / 46
Logic
Models of PDL-3APL
Act, Plani be the signature of an agent
Let R = hP, PG, PR, Ac, Ac, program. A PDL-3APL model M relative to R is defined as
M = (W, V, R, Rt(), R, Rr i, Rp j ) where W is a non-empty set of states.
V = (Vb, Vg, Vc, Vp ) such that for every s  W :
Vb (s) = {p1,..., pm : pi  P} is the set of the agents beliefs in s;
Vg (s) = {(  )u1,..., (  )un : ui  P} is the set of the agents goals in s (note that Vg assigns literals rather than propositional variables);
Vc (s) is either an empty set or {x};
Vp (s) is either the empty set or a singleton set {. }, where  is the agents plan in s and  is the goal(s) achieved by this plan
R, Rt(), R, Rr i, Rp i are binary relations on W
Natasha Alechina
Reasoning about plan revision
TIME 2012
37 / 46
Logic
Conditions on models
C1 Vg (s)  Vb (s) =  and {p :  p  Vg (s)}  Vb (s)
C2 If Vp (s) = {;. }, Vb (s) |=cwa preci () and x 6 Vc (s), then there is an R transition to a state s0 where Vb (s0 ) = Ti,j (, Vb (s)), Vg (s0 ) = Vg (s) \ ({p : p  Vb (s0 )}  {  p : p 6 Vb (s0 )}) and if Vb (s0 ) 6|=cwa, Vp (s0 ) = {. }.
If Vb (s0 ) |=cwa, x  Vc (s0 ) and Vp (s0 ) = {}.
C3C10 similarly correspond to operational semantics in non-x states
Natasha Alechina
Reasoning about plan revision
TIME 2012
38 / 46
Logic
Conditions for exceptional states
Condition for non-executable actions: if Vp (s) = {;. }, Vb (s) 6|=cwa preci (), and x 6 Vc (s), then there is an R transition to a state s0 where x  Vc (s0 ).
Condition for executing in exceptional states: if x  Vc (s) then there are R, R and Rt() transitions from state s to itself
Condition for PR rules: if x  Vc (s), Vp (s) = {j. }, Vb (s) |=cwa j, then there is a Rp j transition to a state s0 where Vp (s0 ) = {j0. } and x 6 Vc (s0 ) (where pj = j  j | j0 ).
Natasha Alechina
Reasoning about plan revision
TIME 2012
39 / 46
Logic
Satisfaction
M, s |= Bp iff p  Vb (s)
M, s |= Gp iff p  Vg (s)
M, s |= G  p iff  p  Vg (s)
M, s |= x iff x  Vc (s)
M, s |= P   iff Vp (s) = {. }
M, s |= P iff Vp (s) = {}
M, s |=  iff M, s 6|=
M, s |= 1  2 iff M, s |= 1 and M, s |= 2
M, s |= hi iff there exists s0 such that R (s, s0 ) and M, s0 |=.
Natasha Alechina
Reasoning about plan revision
TIME 2012
40 / 46
Logic
Translation into PDLfb : fb (p) = Bp; fb ( and ) = fb ()  fb (); fb ( or ) = fb ()  fb () fg (p) = Gp; fg (  p) = G  p fp : fp () = fp (?) = t() fp () = fp (1 ; 2 ) = fp (1 ); fp (2 ) fp (if  then 1 else 2 ) = t(); fp (1 ))  (t(); fp (2 )) fp (while  do ) = (t(); fp ()) ; t().
Natasha Alechina
Reasoning about plan revision
TIME 2012
41 / 46
Logic
Axioms
A1 Bp  Gp
A2 G  p  Bp
0
A3a P    P   0 where  0 6=  or 0 6=
W
A3b P.Plan P
BA1 x  P  (; )  fb (preci ())     0  hi((fb (postij ())fb ()P  )(fb (postij ())fb ()x P 0 )) where,  0 are any formulas not containing plan expressions or literals in fb (postij ()), and in addition  0 does not contain x
BA2a x  P    [u] where  6= u;  0 and u  Ac  Ac
BA2b x  P    [t()] if  does not start with a belief test action ? or a conditional plan test on  where  =  or  =
Natasha Alechina
Reasoning about plan revision
TIME 2012
42 / 46
Logic
Axioms continued
V
V 0(; )  f (prec ())
BA3 x
Pb j i j j j  [](
W
Wj ( fb (postij ())  fb ()  P   j )0 j ( fb (postij ())  fb ()  x  P  j )) where j and j0 are any formulas not containing plan expressions or literals in fb (postij ()), and in addition j0 does not contain x
BA4 x  P  (?; )  fb ()  np  h[t()]i(P    np )
V
BA5 x  P  (; )  i fb (preci ())  nx  h[]i(x  nx )
BA6 x  P  (?; )  fb ()  nx  h[t()]i(x  nx )
BA7 x  P  (; )  nx  h[]i(x  nx )
BA8 x    h[u]i where u is, t() or Natasha Alechina
Reasoning about plan revision
TIME 2012
43 / 46
Logic
Axioms continued
CP1 x  P  (if ; )  fb ()  np  h[t()]i(P  1 ;   np ), where if is of the form if  then 1 else 2
CP2 x  P  (if ; )  fb ()  np  h[t()]i(P  2 ;   np ), where if is as in CP1
CP3 x  P  (wh ; )  fb ()  np  h[t()]i(P  1 ; wh ;   np ), where wh is of the form while  do 1
CP4 x  P  (wh ; )  fb ()  np  h[t()]i(P    np ), where wh is as in CP3
CP5 x  (P  if  P  wh )  fb ()  [t()] where if and wh are as above
PG1 P  fg (i )  fb (i )  npx  h[r i ]i(x  P i i  npx )
PG2 P  fg (i )  fb (i )  [r i ]
PR1 x  P  j  fb (j )  npx  h[p j ]i(x  P  j0  npx )
PR2 x  P  j  fb (j )  [p j ]
Natasha Alechina
Reasoning about plan revision
TIME 2012
44 / 46
Logic
Translation of the programtr (R) = (i (r i ; fp (i ))
Sj (p j ; fp (j0 )))+
Theorem: tr (R) picks out exactly those paths in a model which correspond to an execution of the program
Can verify liveness and safety properties by checking whether htr (R)i and [tr (R)] are entailed by the formulas describing initial conditions complications: encoding plan expressions; encoding properties which hold along a path (Fahad Khan 2012, Regular Path
Temporal Logic)
Natasha Alechina
Reasoning about plan revision
TIME 2012
45 / 46
Logic
Conclusionsagent programs can be verified just as ordinary programs however they have additional properties which it may be possible to expoit one of the properties is having an explicit set of plans, which seems to be an interesting logical property may be also of interest for game logics (being able to say this player is going to play this strategy rather than if this player plays this strategy)
Natasha Alechina
Reasoning about plan revision
TIME 2012
46 / 46Checking Linear Temporal Formulas on Sequential Recursive Petri Nets
Serge Haddad
LAMSADE - UPRESA 7024, Universite Paris IX, Dauphine
Place du Marechal De Lattre de Tassigny, 75775 Paris cedex 16
Denis Poitrenaud
LIP6 - UMR 7606, Universite Paris VI, Jussieu
4, Place Jussieu, 75252 Paris cedex 05
Abstract
Recursive Petri nets (RPNs) have been introduced to model systems with dynamic structure. Whereas this model is a strict extension of Petri nets and contextfree grammars (w.r.t. the language criterion), reachability in RPNs remains decidable. However the kind of model checking which is decidable for Petri nets becomes undecidable for RPNs. In this work, we introduce a submodel of RPNs called sequential recursive
Petri nets (SRPNs) and we study the model checking of the action-based linear time logic on SRPNs. We prove that it is decidable for all its variants : finite sequences, finite maximal sequences, infinite sequences and divergent sequences. At the end, we analyze language aspects proving that the SRPN languages still strictly include the union of Petri nets and context-free languages and that the family of languages of SRPNs is closed under intersection with regular languages(unlike the one of RPNs).
1. Introduction
In the area of verification theory, a great attention has been recently paid on infinite state systems. In contrast to finite state systems where theoretical and practical developments mainly focus on complexity reduction, an essential topic in infinite state systems is to find a trade-off between expressivity of the models and decidability of verification. As the model checking of temporal logic formula is one of the most general approach for verification, it has been intensively studiedin the framework of infinite-state systems.
Context-free grammars and stack automata have led to several works. In, it is shown that the model checking of branching time -calculus formula for pushdown processes is decidable. When restricting the logic to the linear time logic LTL, one obtains polynomial time algorithms.
In, model checking for Petri nets has been studied. The branching temporal logic as well as the statebased linear temporal logic are undecidable even for restricted logics. Fortunately, the model checking for action-based linear temporal logic is decidable. The case of infinite sequences may be straightforwardly reduced to the search of repetitive sequences studied in   and the case of finite sequences may be similarly reduced to the reachability problem. It seems interesting to combine context-free grammars and Petri nets and to look for decidable properties. Indeed, for two such models - the process rewrite systems   and the recursive Petri nets (RPNs)   - the reachability problem is decidable. However, for both these two models, the model checking of action-based temporal logic becomes undecidable. It remains undecidable even for restricted models such as those presented in. So for any previously existing model strictly including Petri nets and context-free grammars, the action-based linear time model checking was undecidable.
In this work, we present a submodel of RPNs called sequential recursive Petri nets (SRPNs) and we give some decision procedures including the model checking. Roughly speaking, in RPNs some transitions emulate concurrent procedure calls by initiating a new token game in the net. The return mechanism is ensured by reachability conditions. A state of a RPN is then a tree of token games. In a SRPN, a procedure call freezes the current token game and the activity goes on, in the last initiated token game. A state of a SRPN is then a stack of token games. At first, we illustrate the increase of modelling power of SRPNs w.r.t. the Petri nets one. Indeed, a SRPN can model an infinite in-degree transition system whereas it is not the case with Petri nets (or with process algebras). Moreover, from a practical point of view the use of SRPNs often leads to a great simplification in the design process.
We then focus on the model checking problem for an action-based linear time logic. We handle the case of finite (and maximal) sequences relying on a product
SRPN construction which emulates the synchronised product of a SRPN and an automaton and then reducing the problem to a reachability problem (which is decidable from  ). The case of infinite (and divergent) sequences is more tricky and requires to distinguish such sequences w.r.t. the asymptotic behavior of the depth of token games. As the decision procedure is partly based on a reachability decision algorithm for
Petri nets, it is not primitive recursive. Nevertheless in a modeling, the places of a SRPN are very often k-bounded with the bound k given a priori (e.g. computed by linear algebraic techniques). In such situations, taking as inputs the SRPN and the bound, we can show that our procedure is in PSPACE. We emphasize that even in this case we deal with infinite-state systems.
At last, we study the language family of SRPNs and we show that this family strictly includes the union of Petri nets and context-free languages. Moreover, unlike RPNs, this family is closed under intersection with regular languages. Finally we will discuss about complexity features and give some perspectives to this work. The complete proofs can be found in a research report.
2. Sequential Recursive Petri Nets
2.1. Presentation
A sequential recursive Petri net has the same structure as an ordinary one except that the transitions are partitioned into two categories: elementary transitionsand abstract transitions. Moreover a starting marking is associated to each abstract transition and an effectively semilinear set of final markings is defined. The semantics of such a net may be informally explained as follows. In an ordinary net, a thread plays the token game by firing a transition and updating the current marking (its internal state). In a SRPN there is a stack of threads (denoting the fatherhood relation) where all the threads, except the one on the top of the stack, are suspended. We call this thread, the current thread. The step of a SRPN is thus a step of the current thread. If the thread fires an elementary transition, then it updates its current marking using the ordinary firing rule. If the thread fires an abstract transition, it consumes the input tokens of the transition and creates a new thread on the top of the stack (the new current thread) which begins its token game with the starting marking of the transition. If the thread reaches a final marking, it may terminate its token game producing(in the token game of its father) the output tokens of the abstract transition which gave birth to him. In case of a single thread in the stack, one obtains an empty stack.
Definition 2.1 (Sequential Recursive Petri nets)
A sequential recursive Petri net is defined by a tuple
N = hP, T, W, W +,, i where P is a finite set of places, T is a finite set of transitions.
A transition of T can be either elementary or abstract. The sets of elementary and abstract transitions are respectively denoted by Tel and Tab(with T = Tel ] Tab where ] denotes the disjoint union).
W  and W + are the pre and post flow functions defined from P  T to IN. is a labeling function which associates to each abstract transition an ordinary marking (i.e. an element of INP ) called the starting marking of t. is an effective representation of semilinear set of final markings.
A semilinear set of markings is a finite union of linear sets of markings. A linear set L is definedby a marking m0 and a finite family of markings
{m1,..., mk } such that L = {m | 1,..., k
P
INk, m = m0 + i=1,...,k i.mi }. An effective representation is any representation which can be reduced(by an algorithm) to this standard representation. For instance, any system of linear (in)equations on the places marking is an effective representation.
Definition 2.4 The firing of an enabled elementary step t from an extended marking tr = hV, M, E, Ai leads to the extended marking tr0 = hV 0, M 0, E 0, A0 i t(denoted by tr tr0 ) depending on the type of t.t  Tel
V 0 = V, E 0 = E, e  E, A0 (e) = A(e), v 0  V \ {vT }, M 0 (v 0 ) = M (v 0 )extended
Definition 2.2 (Extended marking) An marking tr of a sequential recursive Petri net
N = hP, T, W, W +,, i is a labeled list tr = hV, M, E, Ai wherep  P, M 0 (vT )(p) =
M (vT )(p)  W  (p, t) + W + (p, t)t  Tab
V 0 = V  {v 0 }, E 0 = E  {(vT, v 0 )}, e
E, A0 (e) = A(e), A0 ((vT, v 0 )) = t
V is the set of nodes. If V is not empty then V contains a bottom node vB and a top node vT.
These nodes are identical iff |V | = 1.
M is a mapping V  INP, E  (V \ {vT })  (V \ {vB }) is the set of edges with: v  V \ {vB } there is only one node called pred(v) such that (pred(v), v)  E v  V \ {vT } there is only one node called succ(v) such that (v, succ(v))  E
A is a mapping E  Tab.
A marked sequential recursive Petri net hN, tr0 i is a sequential recursive Petri net N associated to an initial extended marking tr0. For sake of simplicity(w.l.o.g.), we will require that there is only one node in any initial extending marking.
When we will deal with different extended markings, we will denote the items of an extending marking tr as a function of the extending marking (e.g. vB (tr)). The empty list is denoted by. Any ordinary marking m can be seen as an extended marking, denoted by dme, consisting of a single node. An elementary step of a SRPN may be either a firing of a transition or an ending of a token game (called a cut step and denoted by  ).
Definition 2.3 A transition t is enabled in an ext tended marking tr 6= (denoted by tr
) if p
P, M (vT )(p)  W (p, t) and a cut step is enabled(denoted by tr
) if M (vT )v 00  V \ {vT }, M 0 (v 00 ) = M (v 00 ), p  P, M 0 (vT )(p) = M (vT )(p)  W  (p, t)
M 0 (v 0 ) = (t) where v 0 is a fresh identifier absent in V ; v 0 = vT (tr0 ).t=
V 0 = V \ {vT }, E 0 = E  (V 0  V 0 ), e  E 0, A0 (e) = A(e) v 0  V 0 \ {pred(vT )}, M 0 (v 0 ) = M (v 0 ) p  P, M 0 (pred(vT ))(p) = M (pred(vT ))(p) +
W + (p, A(pred(vT ), v))
Let us notice that if |V | = 1 then the firing of leads to to empty list.
The depth of an extended marking is defined as
|V |. For an extended marking tr, its depth is denoted by depth(tr). A firing sequence is defined as usual: a sequence  = tr0.t0.tr1.t1.....tn1.trn is a firtiing sequence (denoted by tr0 trn ) iff tri tri+1 for i  [0, n  1]. We define the depth of  as the maximal depth of tr1, tr2,..., trn. In the sequel, for sake of simplicity,  will be often denoted by  = t0.t1.....tn1
2.2. An illustrating example
In order to analyze fault-tolerant systems, the engineer starts from a nominal system and then introduces the faulting behavior as well as the repairing mechanisms. We limit ourselves to an elementary system.
The nominal system periodically records some measure of the environment (elementary transition tcount ).
The number of measures is stored in place pcount. The complete system is obtained by adding the bordered part of the figure 1. The behavior of the SRPN can be described as follows. Initially and in the crash state, the extended marking consists in a single node. A token in the place prepair indicates that one is repairing the system while a token in pstart indicates that the system is ready. When the abstract transition tstart is fired the correct behavior is played by the new thread. If this thread dies by a cut step, a crash state is reached. As the place pf ault is always marked in the correct system and from the very definition of, the occurrence of a fault is always possible. With additional places and modifying, we could model more complex fault occurrences (e.g. conditioned by software execution). pstart t startpfault t repairp init + pfaultprepair pinit t count
= {m | m(p fault) > 0}pcount
Figure 1. a basic fault-tolerant system
In, the model of recursive Petri nets is illustrated by additional examples and compared to other similar models.
3. Model Checking
The model checking that we investigate applies on action based linear-time formulas represented by
Buchi automaton. The usual verification method consists to check the existence of a sequence of the system fulfilling the negation of the formula. Depending on the kind of the sequence, different semantics have been defined. We will study the main ones: finite sequences, maximal finite sequences (leading to a deadlock), infinite sequences, divergent sequences (infinite sequences ended by a non observable subsequence).
Definition 3.1 (Buchi automaton) A Buchi automaton is a tuple A = h, Q,, q0, F i where  is an alphabet, Q a finite set of states,   Q    Q a transition relation, q0  Q an initial state and F  Q a set of accepting states. a 0
As usual, we denote by q q that (q, a, q 0 ).
Moreover, the extension of  to words over  is denoted by = and is defined as follows:q q  Q, q = a 0
00 a 0 q, q 0  Q, q = q  q 00, q = q  q 00 q
The SRPN switches between states with a single node and states with a bottom and a top node. However, the number of reachable markings in the top node is infinite (the place pcount is unbounded). In other words, the crash state can be reached from an infinite number of states which means that the transition system associated to a SRPN may have some nodes with an infinite in-degree. This capability is neither shared by Petri nets nor by process algebras. Consequently, such models cannot represent this kind of systems. More generally, any transition system where some node has an infinite in-degree can neither be modelled by Petri nets nor by process algebras. We emphasize that even in the case of finite state transition systems such modelisations are rather difficult and lead to very intricate Petri nets (or process algebras) whereas the same design is quite easy with SRPNs.
A run r of A on a finite word  = a1... an over is a finite sequence q0,..., qn on Q such that j aj
[1, n], qj1 qj. A run r of A on a infinite word  = a1... ai... is an infinite sequence q0,..., qi,... on Q aj such that j > 0, qj1 qj. We now define how such an automaton recognizes and accepts finite and infinite words.
Definition 3.2 (Recognition and acceptance) Let
A = h, Q,, q0, F i be a Buchi automaton.
Let  be a finite word over. Then  is recognized by A if there is a run on. Moreover, if one of these runs is ended by a state of F then is accepted by A. L(A) denotes the set of finite words accepted by A.
Let  = a1... ai... be an infinite word over.
Then  is recognized by A if there is a run r = q1,... qi,... on. Moreover, if one of these runs fulfills |{k | qk  F }| =  then  is accepted by A. L (A) denotes the set of infinite words accepted by A.
The observable behaviors of the SRPN we will consider are defined via a labeling function. A labeled marked sequential recursive Petri net is a marked
SRPN and a labeling function h defined from the transition set T  { } to an alphabet  plus  (the empty word). As usual, h is extended to sequences.
Before the study of the model checking problem, we introduce A SRPN representing the synchronised product of a given SRPN and an automaton both labeled on a same alphabet. The product SRPN is constructed from the places of the original one by adding a place set Q which corresponds to the states of the automaton. As usual, the elementary transitions are synchronized with the ones of the automaton using a 0 these new places. For each extended arc q = q (with a    {}) of the automaton and for each elementary transition t such that h(t) = a, an elementary transition t.q.q 0, having W  (t) + q as pre-condition and W + (t) + q 0 as post-condition, is added. When an abstract transition is fired a new node appears and, due to the SRPN definition, the token game is limited to this node. Then, we have to predict the state reached by the automaton when the new token game will be ended. The abstract transitions constructed in the product SRPN are denoted t.q.q 0.q 00 where the prefix t.q.q 0 expresses the same conditions as for the elementary transitions (excepted that t is an abstract transition of the original net). For each state q 00  Q such an abstract transition is added (the prediction is non deterministic). To ensure that the predicted state is effectively reached when the cut step closing the token game is fired, a set of places Q (complementary to Q) is used. The firing of an abstract transition t.q.q 0.q 00 leads to the creation of a new node for which its starting marking has the place q 00 marked. Using these places, the effectively semilinear set of final markings is built in order to ensure that the predicted state is effectively reached. Let us notice that this composition corresponds to a weak synchronization as some transitions of the SRPN can be labeled by.
Definition 3.3 (Product SRPN) Let
A
= h, Q,, q0 i be an automaton and S
= hhN, dm0 ei,, hi a labeled SRPN. The product
SRPN of A and S is a labeled marked SRPN hhN 0, dm00 ei,, h0 i defined by
P 0 = P  Q  Q, m00 = m0 + q0 h(t)
Tel0 = {t.q.q 0 | (t  Tel )(q, q 0  Q)(q =q 0 )} t.q.q 0  Tel0, h0 (t.q.q 0 ) = h(t), W 0 (t.q.q 0 ) = W  (t) + q, +
W 0 (t.q.q 0 ) = W + (t) + q 0
0 = {t.q.q 0.q 00 | (t  T )  (q, q 0, q 00  Q)
Tab ab h(t)(q =q 0 )}
0,  t.q.q 0.q 00  Tabh0 (t.q.q 0.q 00 ) = h(t)
W 0 (t.q.q 0.q 00 ) = W  (t) + q, +
W 0 (t.q.q 0.q 00 ) = W + (t) + q 00
0 (t.q.q 0.q 00 ) = (t) + q 0 + q 00
0 = {m + q + q 0 | (m  )  (q, q 0  Q) h( )(q =q 0 )}
0h ( ) = h( )
The next proposition shows the soundness of the product SRPN construction. This SRPN simulates the synchronized product of the orginal net with the Buchi automaton w.r.t. the language criterion.
We denote by L(N, tr0, T rf ) (where T rf is a finite set of extended markings) the set of firing sequences (mapped on (T   ) ) of N from tr0 to an extended marking of T rf. This set is called the language of N. The language of a labeled marked SRPN hhN, tr0 i,, hi for a finite extended marking set T rf is defined by h(L(N, tr0, T rf )) where h is extended to languages.
For sake of simplicity, we impose that the sets of terminal states are composed by extended marking limited to a single node. One can remark that this condition is not a theoretical restriction.
Proposition 3.4 (SRPN product property) Let A = h, Q,, q0, F i be a Buchi automaton, S = hhN, dm0 ei,, hi a labeled SRPN and Mf a set of terminal markings. Let hhN 0, dm00 ei,, h0 i be the product SRPN of h, Q,, q0 i and S and Mf0 = {dm + qe | dme  Mf  q  F }. The following equality holds h0 (L(N 0, dm00 e, Mf0 )) = h(L(N, dm0 e, Mf ))  L(A)
Sketch of proof:
The main part of the proof follows from the construction presented below. The critical point is that although the product SRPN allows bad sequences (i.e. not recognized by the automaton), such ones cannot lead to a terminal extended marking of the product
SRPN.
We now adapt the product construction to reduce the model-checking problem of finite sequences to a reachability problem for the product SRPN which is known to be decidable.
Theorem 3.5 (Acceptance of finite sequences) Let
A = h, Q,, q0, F i be a Buchi automaton and S = hhN, dm0 ei,, hi a labeled SRPN. The existence of a finite firing sequence  of S such that h() is accepted by A is decidable.
Sketch of proof:
Let hhN 0, dm00 ei,, h0 i be the product SRPN of A and S. We construct a new SRPN hN 00, dm000 ei in the following way:
N 00 = N 0 except for 00 = 0  {m | q
F, m  q}m00 = m000
It can be shown that the existence of a finite firing sequence  of S such that h() is accepted by A is equivalent to the reachability of  by hN 00, dm000 ei.
The critical point is that considering sequences of N 00 reaching, then the shortest ones correspond to sequences  of the original net such that h() is accepted by A.
Maximal finite sequences are handled similarly with a more complex construction. In this new product, a pair of places is added to allow the prediction of deadlocks when creating a new node in the stack and the semi-linear set of terminal markings is adapted to detect deadlocks.
Theorem 3.6 (Acceptance of maximal sequences)
Let A = h, Q,, q0, F i be a Buchi automaton and S = hhN, dm0 ei,, hi a labeled SRPN. The existence of a finite firing sequence  of S such that  leads to a deadlock of N and h() is accepted by A is decidable.
For the infinite case, the technique based on the SRPN product is not sufficient to obtain a decision procedure. We have developed an original proof technique based on the analysis of the sequences depending on the asymptotic behavior of the depth of the visited extended markings.
We are looking for an infinite firing sequence of the SRPN accepted by a Buchi automaton. We will perform two independent searches depending on a characteristic of the sequence: the asymptotic behavior of the depth of the sequence. ti t1 t2 tri...
Let  = dm0 e tr1... tri1 be an infinite sequence, we define dinf () = lim inf i depth(tri ) (defined by limi inf ji {depth(trj )}). dinf () always exists but it can be either finite or infinite.
In case of a finite value, there exists a strictly increasing sequence of indexes i1,..., ik,... such that: beyond i1 the set of indexes {i1, i2,..., ik,...} is exactly the indexes for which the depth of the visited extended markings is equal to dinf ()(i  i1, depth(tri ) = dinf () i  {i1, i2,..., ik,...})beyond i1 the depth of the visited extended markings will be greater or equal than dinf ()(i  i1, depth(tri )  dinf ()) i1 is the first index from which the depth of the visited extended markings will be no more less than dinf ()(i < i1, j  i, depth(trj ) < dinf ())
Sowill be decomposed as k
0
1 dm0 e tri1... trik trik+1... where 0 ends with the firing of an abstract transition leading to an extended marking of depth dinf () (with the creation of a new node) and k is either a firing of an elementary transition in this node or a sequence beginning by the firing of an abstract transition in this node and ended by a corresponding cut step.
In case of an infinite value, there exists a strictly increasing sequence of indexes i1,..., ik,... such that:k is the depth of the extended marking trik(k, depth(trik ) = k)beyond ik the depth of the visited extended markings will be greater or equal than k(i  ik, depth(tri )  k) ik is the first index from which the depth of visited extended markings will be no more less than k(i < ik, j  i, depth(trj ) < k)
So  will be decomposed as: k
1
2 dm0 e = tri1 tri2... trik trik+1... where k begins by a firing in an extended marking of depth k, ends with the firing of an abstract transition leading to an extended marking of depth k + 1 and such that all the extended markings visited by k have a depth greater or equal than k.
So the first step of the proof consists in developping a procedure to check the existence of some finite firing subsequences beginning and ending in the same node of two extended markings and corresponding to paths of the Buchi automaton. Indeed, we need another procedure which restricts the sequences to those which visit an accepting state of the automaton. In either case, these procedures are very similar to the model checking for finite sequences.
We are now in position to explain the two main procedures. Looking for a sequence  with dinf () finite, we first compute the couples of starting markings and automaton states reachable by a firing sequence.
We build an ordinary Petri net representing an abstract view of sequences of the SRPN (recognized by the automaton) where the successive extended markings visited by the sequence are infinitely often reduced to a single node. Then, for each couple as initial marking of this Petri net, we look for an infinite sequence visiting a subset of transitions infinitely often (this can be done by the algorithm of  ).
Looking for a sequence  with dinf () infinite, we build a graph where the nodes are the computed couples of the first procedure and an edge denotes that one node has been reached from the other one by a sequence increasing by one the depth of the visited extended markings and such that the intermediate subsequences never decrease the depth below its initial value. The edges are partitioned depending on the visit by the sequence of an accepting state of the Buchi automaton. Then the existence of an accepting infinite sequence is equivalent to the existence of some kindof strongly connected component.
Theorem 3.7 (Acceptance of infinite sequences)
Let A = h, Q,, q0, F i be a Buchi automaton and S = hhN, dm0 ei,, hi a labeled SRPN. The existence of an infinite sequence  of hN, dm0 ei such that h() is an infinite word accepted by A is decidable.
Divergent sequences are handled similarly.
Theorem 3.8 (Acceptance of divergent sequences)
Let A = h, Q,, q0, F i be a Buchi automaton and S = hhN, dm0 ei,, hi a labeled SRPN. The existence of an infinite sequence  of hN, dm0 ei such that h() is a finite word accepted by A is decidable.
All our decision procedures use the decidability of reachability in RPNs (based on reachability in Petri nets). Thus none of them are primitive recursive.
However it must be emphasized that very often unbounded Petri nets correspond to systems with dynamic structure. Modelling such systems with SRPNs leads to infinite states SRPNs with bounded places.
Moreover the bound may be computed by structural analysis. In such cases, complexity of our decision procedure is reduced as stated by the next theorem.
Theorem 3.9 (Complexity of model-checking) Let
A = h, Q,, q0, F i be a Buchi automaton and S = hhN, dm0 ei,, hi a labeled k-bounded SRPN.
The problem of existence of a finite (maximal finite, infinite, divergent) sequence  of hN, dm0 ei such that h() is a word accepted by A is PSPACE-complete w.r.t. the size of A and S.
4. Language Properties
In order to discuss about expressivity of models, different criteria may be applied such like generated languages, behavioural equivalences,... In this section, we focus on the properties of the languages generated by SRPNs and we compare it with the standard hierarchy of languages.
Theorem 4.1 (SRPN closure) The family of SRPN languages is closed under intersection with regular languages.
Sketch of proof:
Follows straightforwardly from proposition 3.4
Theorem 4.2 (Strict inclusion) SRPN languages strictly include the union of context-free and Petri net languages
Proof:
It is obvious that any PN is a SRPN. Moreover, in, it is demonstrated that any context-free language can be simulated by a RPN. We can remark that the proposed construction of the RPN corresponding to a context-free language leads to a SRPN (i.e. the initial extended marking is limited to a single node and all the reachable states are stacks and only the top node is active). In the same paper, it is shown that RPN languages strictly include the union of context-free and Petri net languages. The proof of this result exhibits a RPN for which its language is neither PN nor context-free language. We can remark that this RPN behaves as a SRPN. Then, we can conclude that the language family of SRPN strictly includes the union of the context-free and PN languages.
Moreover, in, it is demonstrated that the RPN languages are not closed under intersection with regular ones. Then the theorem 4.1 leads to the next one.
Corollary 4.3 (SRPN versus RPN) The family of SRPN languages is strictly included in the family of RPN languages.
5. Conclusion
In this work, we have introduced sequential recursive Petri nets and studied their theoretical features.
From a modeling point of view, an important characteristic of SRPNs is their capability to generate infinite in-degree transition systems. Such a feature makes possible to model dynamic systems which can be handled neither by process algebra nor by Petri nets.
In the second part of the paper, we have focused on the model checking for an action-based linear time logic and obtained different decision procedures depending on the semantics of the logic. These procedures are not primitive recursive in the general case but restricting the SRPNs to bounded ones (with an a priori known bound), the model checking problem is shown to be PSPACE-complete.
At last, we have studied the language family of SRPNs and proved that this family strictly includes the union of Petri nets and context-free languages. Moreover, unlike RPNs, this family is closed under intersection with regular languages.
We now plan to study how we can extend SRPNs preserving the model checking decidability.
References
  A. Bouajjani and P. Habermehl. Constraint properties, semi-linear systems, and Petri nets. In Proc. of CONCUR96, volume 1119 of Lecture Notes in Computer
Science. Springer Verlag, 1996.
  J. Esparza. Decidability of model checking for infinite-state concurrent systems. Acta Informatica, 34:85107, 1997.
  A. Finkel, B. Willems, and P. Wolper. A direct symbolic approach to model checking pushdown systems.
In Proc. of INFINITY97, 1997.
  S. Haddad and D. Poitrenaud. Decidability and undecidability results for recursive Petri nets. Technical
Report 019, LIP6, Paris VI University, Paris, France, Sept. 1999.
  S. Haddad and D. Poitrenaud. Theoretical aspects of recursive Petri nets. In Proc. 20th Int. Conf. on Applications and Theory of Petri nets, volume 1639 of Lecture Notes in Computer Science, pages 228247, Williamsburg, VA, USA, June 1999. Springer Verlag.
  S. Haddad and D. Poitrenaud. A model checking decision procedure for sequential recursive petri nets.
Technical Report 024, LIP6, Paris VI University, Paris, France, Sept. 2000. http://www.lip6.fr/reports/lip6.2000.024.html.
  S. Haddad and D. Poitrenaud. Modelling and analyzing systems with recursive Petri nets. In Proc. of the Workshop on Discrete Event Systems - Analysis and Control, pages 449458, Gand, Belgique, Aug. 2000.
Kluwer Academics Publishers.
  E. Mayr. An algorithm for the general Petri net reachability problem. In Proc. 13th Annual Symposium on
Theory of Computing, pages 238246, 1981.
  R. Mayr. Decidability and Complexity of Model
Checking Problems for Infinite-State Systems. PhD thesis, TU-Munchen, 1997.
  I. Walukiewicz. Pushdown processes: Games and model checking. In Int. Conf. on Computer Aided Verification, volume 1102 of Lecture Notes in Computer
Science, pages 6274. Springer Verlag, 1996.
  H.-C. Yen. A unified approach for deciding the existence of certain Petri net paths. Information and Computation, 96:119137, 1992.Temporal XML? SQL Strikes Back!
Fusheng Wang
Carlo Zaniolo and Xin Zhou
Siemens Corporate Research
755 College Road East, Princeton, NJ 08540 fusheng.wang@siemens.com
Computer Science Department
University of California, Los Angeles
{zaniolo, xinzhou}@cs.ucla.edu
Abstract
While the introduction of temporal extensions into database standards has proven difficult to achieve, the newly introduced SQL:2003 and XML/XQuery standards have actually enhanced our ability to support temporal applications in commercial database systems. We illustrate this point by discussing three approaches that use temporally grouped representations. We first compare the approaches at the logical level using a common set of queries; then we turn to the physical level and discuss our ArchIS system that supports the three different approaches efficiently in one unified physical implementation. We conclude that the approaches of managing transaction-time information using XML and SQL can be integrated and supported efficiently within the current standards, and claim that the proposed approach can be extended to valid-time and bitemporal databases.
1. Introduction
In this paper, we seek to support historical information management and temporal queries without extending current standards. Our insistence on using only current standards is inspired by the lessons learned from the very history of temporal databases, where past proposals failed to gain much acceptance in the commercial arena, in spite of great depth, breadth   and technical elegance. An in-depth review of the technical (and often non-technical) reasons that doomed temporal extensions proposed in the past would provide an opportunity for a very interesting and possibly emotional discussion; but such a discussion is outside the scope of this paper. Here, we simply accept the fact that temporal extensions to existing standards are very difficult to sell, in spite of the growing pull by temporal applications; then, we move on from there by exploring solutions that do not require extending current standards. This low-road approach is hardly as glamorous as the new temporal standards approach pursued in the past, but it is not without interesting research challenges and opportunities, as we will show in this paper. In particular, new opportunities are offered by two recent developments that have taken information systems well beyond SQL:1992 which, in the past, supplied the frame of reference for temporal database research. The first development is the introduction of XML/XQuery standards, that have gained wide acceptance by all DBMS vendors, and the second is the introduction of SQL:2003, which contains new advanced features such as nested relations and OLAP functions.
The benefits of XML in temporal information management include: i) XML can be used to represent data in a temporally grouped data model, ii) XQuery provides an extensible and Turing-complete language, where new temporal functions can be defined in the language itself.
These features make it possible to use XML to represent the history of relational databases by timestamping the grouped attribute histories of each table, and XQuery to express complex temporal queries. This approach requires no extension to current standards, and it is very general, insofar as it can be used to represent and query the transaction-time, valid-time and bitemporal history of databases, and arbitrary XML documents.
Therefore, contrasting this experience with the past one focusing on SQL, we might simply conclude that XML and its query languages are more supportive to historical information management and temporal queries than SQL.
However, there are many reasons for which we are not prepared to give up on SQL. Indeed, relations represent a simple and intuitive data model which comes with (i) a built-in graphical representation in form of tables, (ii)
WYSIWYG query languages such as QBE, and (iii) unique areas of commercial strength, such as OLAP applications and data warehousing. By contrast, (i) there is no built-in graphical rendering for an XML document, and this must be provided by the user via stylesheets, (ii) WYSIWYG XML query languages require further research and development, and (iii) XQuery is more complex than SQL, and its commercial application areas are still emerging.
There is also the critical issue of performance. In particular, in supporting transaction-time history of relational databases in XML, we compared the two approaches of(i) implementing temporal queries directly in a native XML system, and (ii) recasting these views into historical tables, whereby the original XQuery statements are then mapped into equivalent SQL (or SQL/XML  ) queries. Our experiments show that the second approach tends to be significantly more efficient.
Therefore, both logical and physical considerations point to the conclusion that SQL is to remain the database language of choice, for a long time to come particularly in data warehousing and business-intelligence applications and every effort should be made to assure efficient management for historical information and temporal queries in SQL:2003. Toward this goal, we will take full advantage of the lessons learned in supporting temporal queries in XML and seek an efficient support for temporal queries independent of whether they are expressed in SQL or XQuery.
The paper is organized as follows. After the discussion of related work, in Section 3, we study the problem of representing relational database history in XML, along the lines proposed in. In the core of the paper, we seek to apply the lessons learned on XML to SQL:2003. Thus, in Section 4, we try to use the nested relations constructs provided by SQL:2003 to represent temporally grouped representations of database table histories. We use the same basic temporal queries to compare this approach to the XMLbased approach and the SQL:2003-based approach of Section 5, where we support a temporally grouped representation using an OLAP-inspired view based on null values and flat tables. The representation used in Section 5 dovetails with data warehousing and business intelligence applications, and it is also capable of reconciling the event-based and state-based views of temporal databases. Finally, we consider efficient implementation issues and, in Section 6, we describe the architecture of our ArchIS system that unifies the support for both SQL-based and XML-based temporal views and queries at the physical level.
2. Related Work
Time in XML. Interesting research work has recently focused on the problem of representing historical information in XML. Approaches to support temporal XML documents by extending XML or its query languages have been proposed in.
For instance in, valid time on the Web is supported by introducing a new <valid> tag. The  XQuery language proposed in, extends XQuery with new constructs for temporal support.
An archiving technique for scientific data was presented in, but XML query language support is not provided.
Temporal Databases and Grouped Representations.
There is a large number of temporal data models and query languages, including those discussed in  ; thus the design space for the relational data model has been exhaustively explored. A useful taxonomy was introduced by
Clifford et al.   who classified them into two main categories: temporally ungrouped and temporally grouped data models. Clifford had also suggested that the latter representation has more expressive power and is more natural sinceempno salary title deptno
1001 60000 Engineer d01
1001 70000 Engineer d01
1001 70000 Sr Engineer d02
1001 70000 Tech Leader d02start
1995-01-01
1995-06-01
1995-10-01
1996-02-01end
1995-05-31
1995-09-30
1996-01-31
1996-12-31
Table 1. The table employee history it is history-oriented.
The basic representation used in ungrouped data models is tuple timestamping. As shown in Table 1, a new timestamped tuple is generated whenever there is a change in any of the attribute values. The well-know problem with this approach is that coalescing is needed when some of the attributes are projected out. Much research has focused on this problem, and the solutions proposed include the TSQL2   approach, and the point-based temporal model.
Versioning of DBMS was discussed in, and techniques for accurate time-stamping of transactions were discussed in   and Immortal DB. Recently Oracle implemented Flashback, which supports the rollback to old versions of tables in case of errors. However, these systems do not provide much support for temporal queries.
SQL:2003. SQL:2003, the latest release of SQL standards, is similar to SQL:1999, but provides significant extensions from SQL:1992. In particular, SQ:2003 O-R features include multiset, nested collection types (supported by both Oracle   and Informix  ), and user-defined types.
Another major feature is SQL/XML, which defines how SQL can be used together with XML in a database, and is supported by major database vendors. Publishing functions provided by SQL/XML can directly construct query results as XML documents or fragments.
3. Viewing Database History in XML
The use of XML to publish the history of database relations has been discussed in, using a temporally grouped representation such as that of Figure 1 (which we call H-document) for the employee table as shown in Table 1. Powerful temporal queries on such representations can be expressed using XQuery. (In the remainder of this paper, our granularity for time is a day; however, all the techniques we present are equally valid for any granularity used by the application. For finer granularity, techniques in   can be used. Furthermore, throughout this paper, we assume that relation keys remain invariant.)
3.1. Temporal Queries with XQuery
A full spectrum of queries was presented in   to illustrate the effectiveness of the approachincluding temporal projection, temporal snapshot, temporal slicing, temporal join, and temporal aggregate. Because of space limitations, we restrict ourselves to the following three examples that will be used throughout the paper.
<employees tstart="1995-01-01" tend="1996-12-31">element empno {$e/empno/text()}, element salary{$s/text()}, $ol
<employee tstart="1995-01-01" tend="1996-12-31">
<empno tstart="1995-01-01" tend="1996-12-31">1001</empno>
<salary tstart="1995-01-01" tend="1995-05-31">60000</salary>
<salary tstart="1995-06-01" tend="1996-12-31">70000</salary>
<title tstart="1995-01-01" tend="1995-09-30">Engineer</title>
<title tstart="1995-10-01" tend="1996-01-31">Sr Engineer</title>
<title tstart="1996-02-01" tend="1996-12-31">Tech Leader</title>
<deptno tstart="1995-01-01" tend="1995-09-30">d01</deptno>
<deptno tstart="1995-10-01" tend="1996-12-31">d02</deptno>
</employee>
</employees>
}
Here overlapperiod($a, $b) is a user-defined function that returns an element PERIOD with overlapped period as attributes(tstart, tend); if there is no overlap, then no element is returned which satisfies the XQuery built-in function empty().
3.2. Discussion
Figure 1. H-document: XML-based Representation of Employees History
Q UERY Q1. Temporal Projection. Retrieve the title history of employee 1001: element title_history{ for $t in doc("employees.xml")/employees/ employee[empno="1001"]/title return $t }
Observe that no coalescing is needed after this projection, since the history of titles is temporally grouped.
Q UERY Q2. Temporal Snapshot. Retrieve titles and salaries of all employees on 1994-05-06: for $e in doc("employees.xml")/employees/ employee let $t:=$e/title[ tstart(.) <= date("1994-05-06") and tend(.) >= date("1994-05-06") ] let $s:=$e/salary[ tstart(.) <= date("1994-05-06") and tend(.) >= date("1994-05-06") ] return <employee>{$e/empno,$t,$s}</employee>
In this query, we need to check only the timestamps of the leaf nodes, since the H-document has a temporal covering constraint, i.e., the interval of a parent node always covers that of its child nodes.
Here, date() is a built-in function of XQuery (for simplicity, we omit the namespace fn). Instead, tstart() and tend() are user-defined functions to shield the user from the complexity of the underlying representation, since, e.g., now   requires special representation and special handling (in ArchIS   we use the end-of-time to represent now). date() is a built-in function of XQuery ( for simplicity, the namespace fn is omitted here).
Q UERY Q3. Retrieve the salary history of employees in dept. d01, while they were in that department. for $e in doc("employees.xml")/employees/ employee[deptno="d01"] for $s in $e/salary for $d in $e/deptno[.="d01"] let $ol:=overlapperiod($s, $d) where not (empty($ol)) return element salhistory{
The previous examples illustrate that XQuery is capable of expressing complex temporal queries, but the expression of these queries can be greatly simplified by a suitable library of temporal functions. The ArchIS system, discussed in Section 6, supports a rich set of functions, including the simple scalar functions described above, and also complex functions, including temporal aggregates and coalesce functions.
A significant benefit offered by the XML/XQuery-based approach to temporal information management is that it is very general and can handle the history of arbitrary XML documents that have evolved through successive versions. The approach can also be extended to valid-time databases and bitemporal databases.
On the other hand, the ease of use of XQuery is questionable, and the problem of displaying the results of temporal queries in user-friendly ways can be a real challenge, since the tagged representations, such as that of Figure 1, are not suitable for casual users. To produce visually appealing representations, the query designer might have to code a stylesheet, using XSL  possibly a different one for each query. This problem is far from trivial, and the visual rendering of temporal information poses interesting research challenges.
Finally, the growing popularity of XML in web-oriented applications does not change the fact that SQL remains the cornerstone of database applications, and its importance in areas such as business intelligence and data warehouses is growing every day. For these reasons, efficient support for temporal information and queries in SQL remains critical
[?]. Therefore, we explore two approaches: one based on nested relations, which is discussed next, and another based on OLAP tables, which is discussed in Section 5.
4. DB History and Nested Relations
Nested relations are part of the latest SQL:2003 standards, and also supported by some commercial database vendors. Therefore a temporally grouped representation, similar to that used with XML, can also be achieved within SQL standard. For instance, for our employee history example, we can use the following schema containing the nested table (n-table for short, or n-view if it is a nested view) n employee:
CREATE TYPE salary_typ AS OBJECT( salary
NUMBER(7), timep
PERIOD
);...
CREATE TYPE salary_tbl AS TABLE OF salary_typ;...
CREATE TABLE n_employee( empno
VARCHAR2(8), timep
PERIOD, n_name name_tbl, n_salary salary_tbl, n_title title_tbl, n_deptno deptno_tbl)
NESTED TABLE n_salary STORE AS n_salary, NESTED TABLE n_title STORE AS n_title, NESTED TABLE n_deptno STORE AS n_deptno;
This definition uses the user-defined type PERIOD, which can be defined in SQL:2003 as follows:
CREATE TYPE PERIOD AS OBJECT( tstart
DATE, tend
DATE
);
The same temporal queries that we have expressed on
XML using XQuery can now be expressed on nested tables using SQL:2003, as follows:
Q UERY Q1n. History projection. Retrieve the title history of employee 1001:
SELECT
FROM
WHEREt.* n_employee e, TABLE(e.n_title) AS t e.empno=1001
Q UERY Q2n. Temporal Snapshot. Retrieve titles and salaries of all employees on 1994-05-06:
SELECT t.title, s.salary
FROM n_employee e, TABLE(e.n_title) AS t, TABLE(e.n_salary) AS s
WHERE tstart(t.timep) <= 1994-05-06
AND tend(t.timep)
>= 1994-05-06
AND tstart(s.timep) <= 1994-05-06
AND tend(s.timep)
>= 1994-05-06
Here too we use the functions tstart() and tend() to isolate the user for the internal representation of time, including now. (Support for user-defined scalar functions is now available in all commercial OR-DBMSs.)
Q UERY Q3n. Retrieve the salary history of employees in dept.d01, while they were in that department.
SELECT e.empno, overlapperiod(d.timep, s.timep), s.salary
FROM n_employee AS e, TABLE(e.n_dept) AS d, TABLE (e.n_salary) AS s
WHERE d.deptno = d01 AND overlaps(d.timep, s.timep)
Here overlaps() is defined to return true if two periods overlap, and false otherwise; overlapperiod() is defined to return the overlapped PERIOD.
In addition to scalar functions, such as overlapperiod(), temporal aggregates (e.g., the temporal version of min and sum   ) will be required by temporal queries.
These new functions could be easily built into commercial systems by the vendors, or by the users, since commercial
OR-DBMSs now support the introduction of new scalar and aggregate functions coded in a procedural language. (In the ATLaS system, user-defined aggregates can also be introduced natively in SQL, with no recourse to external
PLs.) The new temporal aggregates that must be introduced include, the rising function of TSQL2, and also the tcoalesce aggregate for temporal coalescing since the temporally grouped representation made possible by nested tables has greatly reduced the need for coalescing, but not eliminated it all together (and the same is true for XML).
Assuming that a library containing the basic temporal functions is available, the complexity of writing temporal queries in SQL:2003 and nested tables is about the same as writing them in XQuery and XML. Both approaches present users with more alternatives in presenting data than flat relations. For instance, the join of nested employees and departments tables can be represented by a one-level hierarchy where the department and employee attributes are at the same level, or as a hierarchy where employees are grouped inside departments, or vice-versa. We next return to the Spartan simplicity of flat relations, in which the alternatives are fewer and the problem is simplified.
5. An OLAP-Inspired Representation
A temporally grouped representations can also be obtained by using null values in flat tables such as those returned by OLAP aggregates. Thus, the transaction-time history of employees, that was described by tuple timestamping in Table 1, and as an XML document in Figure 1, is now described as a flat table with null values as shown in Figure 2, where the null value is represented by the question mark, ?. This representation can be defined by a ROLLUP operation on Table 1, defined by the following SQL statement (again here we use timep to represent the period of tstart and tend). As in the case of OLAPs, we might also want to represent the null values generated by the rullup operation differently from those representing null values in the original table.
CREATE VIEW e_employee AS
SELECT empno, tcoalesce(timep,salary,title,deptno)
FROM employee_history
GROUP BY GROUPING SETS(empno,(empno,salary), (empno,title),(empno,deptno) )
We refer to the representation shown in Figure 2 as an etable (or e-view if it is a view) because this captures the event-history for employees, as it will be discussed in Section 5.1. Moreover, temporal queries on e-tables preserveempnotstarttendsalarytitledeptno
1001
1995-01-01
1995-05-31
60000
?
?
1001
1995-06-01
1996-12-31
70000
?
?
1001
1995-01-01
1995-09-30
?
Engineer
?
1001
1995-10-01
1996-01-31
?
Sr Engineer
?
1001
1996-02-01
1996-12-31
?
Tech Leader
?
1001
1995-01-01
1995-09-30
?
?d01
1001
1995-10-01
1996-12-31
?
?d02
1001
1995-01-01
1996-12-31
?
?
?
Figure 2. The history view e employees the traditional style of SQL queries:
Q UERY Q1e. History projection. Retrieve the title history of employee 1001:
SELECT title, tstart, tend
FROM e_employee
WHERE empno= 1001
AND title IS NOT NULL
Q UERY Q2e. Temporal Snapshot. Retrieve titles and salaries of all employees on 1994-05-06:
SELECT
FROM
WHERE
AND
AND
ORe.empno, e.title, e.salary e_employee AS e tstart(e.timep) <= 1994-05-06 tend(e.timep)
>= 1994-05-06 e.title IS NOT NULL e.salary IS NOT NULL
This query assumes that we only want to retrieve the information, without reformatting it. However, if we want to reformat the information derived into a join table, then we also want to join the titles and salaries of all employees at that date into a flat relation as follows:
SELECT
FROM
WHERE
AND
AND
AND
AND
AND
ANDs.empno, t.title, s.salary e_employee AS s, e_employee AS t tstart(t.timep) <= 1994-05-06 tend(t.timep)
>= 1994-05-06 tstart(s.timep) <= 1994-05-06 tend(s.timep)
>= 1994-05-06 s.empno=t.empno t.title IS NOT NULL s.salary IS NOT NULL
Q UERY Q3e. Retrieve the salary history of employees in dept. d01, while they were in that department:
SELECT n1.empno, n1.salary, overlapperiod(n1.timep,n2.timep)
FROM e_employee n1, e_employee n2
WHERE n1.empno = n2.empno
AND n1.salary IS NOT NULL
AND n2.deptno IS NOT NULL
AND n2.deptno = "d01"
AND overlaps(n1.timep, n2.timep)
This query illustrates the use of temporal joins, with intersection of overlapping periods; these are required for query Q3 in all three representations. While the complexity of queries is similar for our three temporally-groupedapproaches, e-tables offer unique advantages that are discussed next.
5.1. Event-Oriented Histories
An advantage of this last representation is that grouping can be easily controlled by the ORDER BY clause in SQL.
For instance, the representation of Figure 2, where the history of each employee attribute is grouped together, is produced by the following clause:
SELECT empno, timep, salary, title, deptno
FROM e_employee
ORDER BY empno, salary, title, deptno, tstart(timep)
Since the null value is assumed to be the last value in each domain, this ORDER BY clause indeed produces the table of Figure 2.
Assume now that we want to view the history of events, pertaining to employees salaries and departments, that have occurred in the company; then we can just list them in ascending chronological order as follows:
SELECT timep, empno, salary, deptno
FROM e_employee
WHERE title IS NULL
ORDER BY tstart(timep),empno,salary,deptno
However, in order to visualize the salary history of employees in a given department, we need first to write a query similar to that of Example Q3e to derive a table (or a view) depthist(deptno, empno, salary, timep), on which we can write following query:
SELECT deptno, timep, empno, salary
FROM depthist
ORDER BY deptno,tstart(timep),empno,salary
This last statement returns all the events grouped by department and arranged in chronological order.
The visual presentation of historical data and query results is much simpler using e-tables than using n-tables or H-tables (which is discussed later in Section 6.1). This is because flat tables come with their built-in graphical representation, while, e.g., XML requires the user to write a style sheet to visualize data. Moreover, as demonstrated by the previous examples, restructuring on e-tables can be realized by simply reordering the tuple using an ORDER BY clause, whereas it might require complex nesting and unnesting in the other representations.
In most temporal database approaches, including TSQL2, a temporal relation can be either declared as a state table or as an event table but the two views are not easily combined. A simple mapping between the two views is highly desirable since, in everyday life, states and events are two facets of the same evolving reality. Moreover, many advanced applications, such as time-series analysis, sequence queries, and data stream queries, view the database as a sequence of events, rather than a sequence of states.
The e-tables just described, make it possible the unification of state-based and event-based representations by simply using SQL ORDER BY construct. For instance, say that we want to find employees who have been transferred from a department to another, and from this, back to the old one.
To answer this query by perusing the history of employees, we would probably start by carefully viewing the results of the following query:
Q UERY Q4. Reordering to detect round-trip transitions between departments:
SELECT empno, timep, depno, salary, title
FROM e_employee
ORDER BY empno, tstart(timep)
Then, the immediate sequence of any three tuples with non-null deptno column, would satisfy the query provided that the first department is equal to the third (and that there was no interruption in the employees employment).
Although this query is conceptually simple, it requires the detection of three successive tuplesan operation that is rather complex and inefficient to express in standard SQL.
A first solution to this problem is to write a user-defined aggregate (UDA); in fact UDAs can easily express statebased computations. Moreover, several event-patterns and sequence languages for time-series analysis have been proposed in the literature   and would work very nicely with the representation discussed here. For instance, using SQL-TS   our query could be expressed as follows:
Q UERY Q5. From department A to B and back, with no other change in between:
SELECT A.empno, A.title
FROM e_employee [ORDER BY empno, tstart(timep)] AS (A,B,C)
WHERE A.deptno = C.deptno
AND B.deptno IS NOT NULLinternal level should be provided for these multiple external views. At UCLA, we have been developing the ArchIS system that unifies the support for multiple external temporal models into one architecture.
The basic architecture of ArchIS   is shown in Figure 3. ArchIS is designed to preserve and archive the history of the database by preserving the evolution of its content, either by using active rules attached to the database or by periodically visiting their update logs. ArchIS then supports alternative logical views of the database history described in the previous sections, by mapping queries against these views into equivalent queries against the history database. In our previous work on the implementation of storing H-documents, we have compared the use of a native XML DBMS such as the Tamino XML Server, against the approach of shredding these documents and storing them into RDBMSs. The second approach was found to offer substantial performance advantages and will be used here. (In our implementation, the current database and the archived one are managed by the same system. But the results are easily generalized to the situations where these two are separate and even remote.)
In the next sections we first discuss the structure of the Key & Attribute History Tables, used at the internal level and then we describe the problem of mapping external queries into internal ones. We finally describe the temporal clustering and indexing techniques used in improving the performance of such queries.
The problem of supporting XML views through stored
RDBMS tables is hardly new since it has recently provided a major focus for database research. However, here we do not need to support all XML documents and queries, but only historical views of database tables and temporal queries on such tables; thus, specialized techniques can be used for more efficient storage, and optimized query mapping.
6.1. History Tables
Here, the FROM clause specifies that, given the ordering described above, A, B and C are three successive tuples that are also related by the conditions specified in the WHERE clause. Space limitation prevents us from delving into languages as SQL-TS, although they represent a very interesting and pertinent topic in temporal database research.
Here, it suffices to observe that these languages rely on tuples being arranged in a suitable orderwhich is easier to achieve with e-tables than with H-tables or n-tables.with key empno. The history of employee is preserved by following tables in ArchIS:
6. Efficient Implementation
The Key Table:
In the previous sections, we have discussed the pros and cons of alternative representations for temporal history. In reality, these are likely to be supported together, rather than as alternatives, since database vendors are gung ho on supporting both SQL and XML in their systems. Practical considerations also suggest that a unified implementation at the Since empno will not change along the history, the period(tstart,tend) in the key table also represents the valid period of the employee. The use of keys is for easy joining of all attribute histories of an object such as an employee.
The history of each relation is preserved by a set of tables: one table for each attribute, and an additional table for the primary key of the original relation. Each tuple in the tables is timestamped with the two attributes tstart and tend. For example, consider our evolving DB relation employee(empno, salary, title, deptno)employee empno(empno, tstart, tend)
Attribute History Tables:
Current Database
However, this is only the first step of the translation performed by ArchIS which also adds conditions to exploit the temporal clustering and indexing discussed later.
Relational data
SQL queries
Active rules/ update logs
Temporal data
A
R
XML view
Cn-view
He-view
I
H-tables
Temporal queries
S
Figure 3. ArchIS: Archival Information System employee_salary(empno, salary, tstart,tend) employee_title (empno, title, tstart,tend) employee_deptno(empno, deptno, tstart,tend)
The values of empno in the above tables are the corresponding key values, thus indexes on such empno can efficiently join these relations.
When a new tuple is inserted, the tstart for the new tuple is set to the current timestamp, and tend is set to now.
When there is a delete on a current tuple, we simply change the tend value in that tuple as current timestamp. An update can be viewed as a delete followed by an insert. We will later refer to these as key & attribute history tables (Htables for short). H-tables could also be viewed as yet another candidate representation at the logical level; we have not considered them here because they do not provide real query advantages with respect to e-tables, and they make tasks such as reordering and visualization harder.
In addition to these, we also store information about the schema in a global relation: relations(relationname, tstart, tend)
Our design builds on the assumption that keys (e.g., Otherwise, a system-generated surrogate key can be used. empno) remain invariant in the history.
6.2. Query Mapping
Mapping from e-views to H-tables. Mapping from Htables to the e-views (or e-tables) of Figure 2 is simple, since the latter can be obtained taking the union of the Htables after padding them with null values. This simple correspondence simplifies the translation and optimization of queries expressed on e-tables into equivalent queries on Htables. The pattern of null values associated with the query plays an important role in the translation. Take for instance
QUERY Q1e. There, the condition that title IS NOT
NULL implicitly determines that salary and department must be null, and attribute table employee title will appear in the WHERE condition of mapped query. Thus our original query is translated into:
SELECT T.title, T.tstart, T.tend
FROM employee_title as T
WHERE T.empno = 1001
Mapping from n-views to H-tables. In DBMS that support nested relations, n-views (or n-tables) can be supported directly at the physical level. But even so, we might prefer to shred and store them into flat H-tables, to simplify support for alternative external views (in particular, e-views), of for performance reasons, e.g., to take advantage of the clustering techniques available for H-tables, that will be discussed later. A simple approach to achieve this is to define a nested object-view (as defined in SQL:2003) on H-tables, as follows:
CREATE VIEW n_employee OF employee_t
WITH OBJECT IDENTIFIER (empno) AS
SELECT e.empno, PERIOD(e.tstart, e.tend) AS timep, CAST(MULTISET(
SELECT s.salary, s.tstart, s.tend
FROM employee_salary s
WHERE s.empno = e.empno)
AS salary_tbl)
) AS n_salary,...
FROM employee_empno e;
With such a mapping, temporal queries on n-views are automatically translated by the DBMS into queries on Htables through view definitions.
Mapping from XML-views to H-tables. The mapping from XML-views (or H-documents) to H-tables is significantly more complex. The problem of supporting XQuery on H-tables is similar in the sense that we have to generate efficient SQL queries, but more complex insofar as XML documents must be structured as output. Therefore, we use
SQL/XML, whereby the results of SQL queries can be efficiently assembled into XML documents for output.
Many database vendors now support efficient SQL/XML implementations, in which tag-binding and structure construction are done inside the relational engine for best performance. In ArchIS, we compile XQuery statements on temporal XML-views, and optimize their translation into SQL/XML on the H-tables in five main steps, as follows:
1. Identification of variable range. For each distinct tuple variable in the original query, a distinct tuple variable is created in the FROM clause of the SQL/XML query, which refers to a certain key table or attribute table.
2. Generation of join conditions. There is a join condition T.empno and N.empno for any pair of distinct tuple variables.
3. Generation of the WHERE conditions. These are the conditions in WHERE clause of XQuery or specified in the XPath expressions.
4. Translation of built-in functions. The built-in functions(such as overlaps($a,$b)) are simply mapped intothe corresponding SQL built-ins we have implemented for ArchIS.
5. Output generation. This is achieved through the use of the XMLElement and XMLAgg constructs defined in SQL/XML.
Scheme
Feature
External
Schema
Temporal
Ungrouped
XML
Flat Tables
XML View
Ungrouped
SQL
Nested
OLAP
Relations
Tables
Nested
Null-filled
Tables
Flat Tables
Flat
Grouped
Grouped
Grouped
XQuery
SQL:2003
SQL
Model
For instance, the SQL/XML translation of Query Q1 is:
SELECT XMLElement (Name "title_history", XMLAgg (XMLElement (Name "title", XMLAttributes (T.tstart as "tstart", T.tend as "tend"), T.title)))
FROM employee_title as T
WHERE T.empno = 1001
Query
Language
Temporal
Coalescing
Event
Offten ten
Very O
Needed
Needed
Very
No
No
Needed
Seldom
Seldom
Needed
No
No
Needed
Seldom
Seldom
Needed
No
No
Needed
Seldom
Seldom
Needed
Yes
Yes
ALL
Many
Many
Some
Some
ALL
Support
DBMS
ALL
ALL
Support
6.3. Clustering and Indexing
Efficient support for historical queries requires support for temporal clustering and indexing; in ArchIS, this is achieved by a simple usefulness-based scheme whereby the H-tables are partitioned into segments. For each table, the usefulness of its current segment is defined as the percentage of the segment tuples that have not expired yet (i.e., whose tend timestamp is still now). The usefulness of the current segment is monotonically decreasing with time, and as soon as it falls below a user-specified percentage, the whole segment is archived, and a new segment is started containing only those tuples whose timestamps are now.
The segment number then can become part of the search keys supported by the indexes used in the database.
Thus, a request to find the salary of a given employee at certain time, could involve finding the corresponding segment in a small memory-resident index, and then using the(segment no, empno) pair in the index search.
This usefulness-based scheme achieves temporal clustering through redundancy. Since there is no update in the archived tuples of a transaction-time database (unlike validtime databases), redundancy does not generate additional execution costs. For reasonable usefulness values the extra storage costs are modest (e.g., 30% storage overhead for
33% usefulness  ); this cost represents a minor drawback, because of the fast decreasing cost of storage, and the applicability of compression techniques which has been proven in. (The cost of re-compressing after updates is not present for archived data, since these are not updated.) On the other hand, the usefulness-based approach expedites archival search in a predictable and controllable fashion. For instance, for usefulness of 33% (1/3) we are assured that, when searching in the corresponding segments for records with a given timestamp, at least one of the three records visited has the right timestamp. Therefore, the time required to regenerate the past snapshot of a relation can be expected to be less than three times of that needed to generate the current snapshot from the current database.
Also, observe that the joining of H-tables require little extra time since they are already sorted on empno. The architecture and performance of ArchIS is covered in.
Figure 4. Temporal Scheme Comparison
6.4. Summary
Only the skeleton of ArchIS is currently operational, and many improvements are planned for the future; even so, its realization confirms the practicality of supporting both
SQL-based and XML-based temporal views and queries with a unified and efficient internal representation. ArchIS can now run on top of IBM DB2 and the ATLaS system. We are currently working on extending it to run on commercial DBMS that support nested relations, and explore any performance improvement that can be gained with this approach. We also plan to experiment with additional storage structures, such as R-trees, to better support valid-time and bitemporal databases.
7. Conclusion and Future Work
An important conclusion emerges from the research presented in this paper: a unified multi-model support for transaction-time databases can be achieved effectively using a temporally grouped data model. This requires the introduction of new temporal functions and aggregates, but no extension to the current standards. A unified efficient implementation for the three external models relies on well-understood query mapping/optimization techniques, and temporal clustering/indexing techniques at the internal level. In practice, the ArchIS approach is desirable since it provides a low-cost approach to address a wide range of applications. In particular, XML-based views dovetail with web applications, while nested-relations are more natural for object-oriented applications, and the null-filled flat tables are best for traditional database applications, decisionsupport applications, and event-oriented queries. This last approach provides a simple framework for the presentation of the data, which can require significantly more effort when XML is used. Figure 4 summarizes the features of the temporally-grouped schemes proposed, comparing them to the basic ungrouped scheme.
While we have concentrated here on transaction-time databases, it was recently shown that, for XML, this approach can be extended to bitemporal representations and queries as well. Support for valid-time and bitemporal views and queries using nested relations and nullfilled tables represents an important topic of forthcoming research. Many research issues also remain open at the physical level, including the use of nested relations and of clustering schemes that support updates on historical data (such updates are not present in transaction-time databases).
Acknowledgments
This work was partially supported by a gift of NCR Teradata. The authors would also like yo thank the referees for many useful suggestions.
References
  G. Ozsoyoglu and R.T. Snodgrass. Temporal and Real-Time
Databases: A Survey. TKDE, 7(4):513532, 1995.
  F. Grandi. An Annotated Bibliography on Temporal and Evolution Aspects in the World Wide Web. In TimeCenter
Technique Report, 2003.
  R. T. Snodgrass. The TSQL2 Temporal Query Language.
Kluwer, 1995.
  R. T. Snodgrass, M. H. Bohlen, C. S. Jensen, and A. Steiner.
Transitioning Temporal Support in TSQL2 to SQL3. Lecture
Notes in Computer Science, 1399:150194, 1998.
  Database Languages SQL, ISO/IEC 9075-*:2003.
  A. Eisenberg, J. Melton, K. Kulkarni, J. Michels, and F. Zemke. SQL:2003 has been published. SIGMOD Rec., 33(1):119126, 2004.
  SQL 2003 Standard Support in Oracle Database
10g, otn.oracle.com/products/database/ application development/pdf/SQL 2003 TWP.pdf.
  S. Kepser. A Proof of the Turing-Completeness of XSLT and XQuery. In Technical report SFB 441, Eberhard Karls
Universitat Tubingen, 2002.
  F. Wang and C. Zaniolo. An XML-Based Approach to Publishing and Querying the History of Databases. To Appear in World Wide Web: Internet and Web Information Systems.
  F. Wang, X. Zhou, and C. Zaniolo. Using XML to Build Efficient Transaction-Time Temporal Database Systems on Relational Databases. Technical Report 81, TimeCenter, Mar.
2005.
  F. Wang and C. Zaniolo. XBiT: An XML-based Bitemporal
Data Model. In ER, 2004.
  F. Wang and C. Zaniolo. Publishing and Querying the Histories of Archived Relational Databases in XML. In WISE, 2003.
  F. Wang and C. Zaniolo. Temporal Queries in XML Document Archives and Web Warehouses. In TIME, 2003.
  ISO. Information technology - Database languages - SQL
Part 14: XML-Related Specifications. 2003.
  F. Grandi and F. Mandreoli. The Valid Web: An XML/XSL
Infrastructure for Temporal Management of Web Documents. In ADVIS, 2000.
  T. Amagasa, M. Yoshikawa, and S. Uemura. A Data Model for Temporal XML Documents. In DEXA, 2000.
  C.E. Dyreson. Observing Transaction-Time Semantics with
TTXPath. In WISE, 2001.
  S. Zhang and C. Dyreson. Adding Valid Time to XPath. In
DNIS, 2002.
  D. Gao and R. T. Snodgrass. Temporal Slicing in the Evaluation of XML Queries. In VLDB, 2003.
  P. Buneman, S. Khanna, K. Tajima, and W. Tan. Archiving scientific data. TODS, 29(1):242, 2004.
  J. Chomicki, D. Toman, and M.H. Bohlen. Querying ATSQL Databases with Temporal Logic. TODS, 26(2):145
178, June 2001.
  J. Clifford, A. Croker, F. Grandi, and A. Tuzhilin. On Temporal Grouping. In Recent Advances in Temporal Databases, pages 194213. Springer Verlag, 1995.
  J. Clifford, A. Croker, and A. Tuzhilin. On Completeness of Historical Relational Query Languages. ACM Trans. Database Syst., 19(1):64116, 1994.
  C. Zaniolo, S. Ceri, C.Faloutsos, R.T. Snodgrass, V.S. Subrahmanian, and R. Zicari. Advanced Database Systems. Morgan Kaufmann Publishers, 1997.
  D. Toman. Point-based Temporal Extensions of SQL. In
DOOD, pages 103121, 1997.
  M. Stonebraker. The Design of the POSTGRES Storage System. In VLDB, 1987.
  C. S. Jensen and D. B. Lomet. Transaction Timestamping in Temporal Databases. In VLDB, 2001.
  D. Lomet, R. Barga, M. F. Mokbel, G. Shegalov, R. Wang, and Y. Zhu. Immortal DB: Transaction Time Support for
SQL Server. In SIGMOD, 2005.
  Oracle
Flashback
Technology. http://otn.oracle.com/deploy/availability
/htdocs/flashback overview.htm.
  Informix Universal Server. http://www.ibm.com/informix.
  F. Wang, X. Zhou, and C. Zaniolo. Temporal Information
Management using XML. In ER, 2004.
  J. Clifford, C.E. Dyreson, T. Isakowitz, C.S. Jensen, and R.T.
Snodgrass. On the Semantics of Now in Databases. TODS, 22(2):171214, 1997.
  The Extensible
Stylesheet
Language(XSL). http://www.w3.org/Style/XSL/.
  ATLaS. http://wis.cs.ucla.edu/atlas.
  Chang-Shing Perng and D. S. Parker. SQL/LPP: A Time
Series Extension of SQL Based on Limited Patience Patterns.
In DEXA, 1999.
  R. Sadri, C. Zaniolo, A. Zarkesh, and J. Adibi. Expressing and Optimizing Sequence Queries in Database Systems.
TODS, 29(2):282318, 2004.
  C. Zaniolo Y.-N. Law, H. Wang. Query Languages and Data
Models for Database Sequences and Data Streams. In VLDB, pages 492503, 2004.
  H. Wang and C. Zaniolo. Using SQL to Build New Aggregates and Extenders for Object-Relational Systems. In
VLDB, 2000.
  P. Seshadri, M. Livny, and R. Ramakrishnan. SEQ: A Model for Sequence Databases. In ICDE, pages 232239, 1995.
  H. Schoning. Tamino - a DBMS Designed for XML. In
ICDE, 2001.
  M. Carey, J. Kiernan, J. Shanmugasundaram, and et al. XPERANTO: A Middleware for Publishing ObjectRelational Data as XML Documents. In VLDB, 2000.
  D. DeHaan, D. Toman, M. P. Consens, and M. T. Ozsu. A
Comprehensive XQuery to SQL Translation Using Dynamic
Interval Encoding. In SIGMOD, 2003.
  M. F. Fernandez, A. Morishima, D. Suciu, and W. C.
Tan. Publishing Relational Data in XML: the SilkRoute
Approach. IEEE Data Engineering Bulletin, 24(2):1219, 2001.
  J. Shanmugasundaram and et al. Efficiently Publishing Relational Data as XML Documents. In VLDB, 2000.Networks of qualitative interval relations: combining circuit consistency and path consistency in the search for a solution
A. Isli and H. Bennaceur
Laboratoire dInformatique de Paris-Nord
CNRS URA 1507, Inst. Galilke, Universit6 Paris-Nord
Villetaneuse, F-93430, France is known that in such problems the relations {<, >} and {<, m, mi,>} are crucial; and none of the three subclasses contains them. For instance, in scheduling expressing that two tasks I and J are disjunctive is extremely solicited (this is expressed by I{<, >} J or I{<, m,m i, > } J ).
Another solution is to design a general backtracking algorithm that deals with any problem, and eventually behaves well for all or part of real-life problems.
In this paper, we propose to combine circuit consistency and path consistency in such algorithms. Instead of applying path consistency at every node of the search space, as does, for instance, Ladkin and Reinefelds algorithm [Ladkin et al. 92, van Beek 921, our method applies path consistency only at nodes of level ( n- 1) x n/2 (where n is the number of variables of the input network), and circuit consistency in the remaining nodes of the search space. Circuit consistency is less filtering than path consistency; however, it is one factor less expensive. We provide experimental results comparing Ladkin and Reinefelds algorithm (1) as provided by its authors, and (2) as we propose in the paper.
The paper is organized as follows. Section 2 provides some background on qualitative interval networks. Section 3 defines the concept of circuit consistency, while Section 4 presents an algorithm making a network circuit consistent. The complexity analysis of circuit consistency is studied in Section 5. Section 6 gives some background on existing backtracking search algorithms, while Section 7 explains how to combine circuit consistency and path consistency during the search in those algorithms. Section 8 is devoted to experimental results. Finally, Section 9 summarizes the paper.
Abstract
W e first define the concept of circuit consistency for interval networks. W e then provide an example showing that even for atomic networks circuit consistency is not complete. Then we describe how to combine circuit consistency and path consistency in existing search algorithms. Instead of applying pathconsistency at each node of the search tree, as do existing algorithms, the idea of our method is to apply path consistency only a t nodes of level ( n - l ) n / 2, and circuit consistency in the remaining nodes of the search tree (n is the number of variables of the input network). Circuit consistency filtering is potentially less effective than path consistency filtering; however circuit consistency is computationally one factor less expensive. W e provide experiments showing the performances of the search in the two cases (a) when circuit consistency and path consistency are combined and (b) when only path consistency is used.
Area: Time and constraints.
Keywords: Interval algebra, Temporal constraint satisfaction, circuit consistency, path consistency, backtracking search.
1
Introduction
Reasoning in the interval algebra defined by Allen
[Allen 831 is known to be NP-hard [Vilain et al. 861.
One solution is to restrict the expressiveness in such a way to obtain a subclass behaving well while still representing a large class of interesting problems; this solution makes a tradeoff between tractability and expressiveness. Three such subclasses are known, which are the convex subclass (C), the pointizable subclass( P ) and the ORD-Horn subclass (31);they are related by C c P c 3c. All of them are subalgebras of the whole interval algebra (they are closed under composition, intersection and transposition), making networks expressed in either of them closed under path consistency, which solves the consistency problem in these cases.
Many existing systems based on Allens algebra restricts the expressiveness to either of the above three subclasses; even to either of C and P. There are however real-life problems for which neither of the subclasses gets use: diagnosis problems, scheduling problems and planning problems. For instance, it
2
57
0-8186-7528/96 $5.00 0 1996 IEEE
Qualitative interval networks
Some background on qualitative interval networks is needed.
In [Allen 831, Allen defined what is known in the literature as the interval algebra (IA). Temporal information is expressed in IA as relations on pairs of intervals; these relations will be referred to in the sequel as interval relations. An atomic interval relation stands for one of the thirteen alternative, exclusive configurations a pair of intervals can stand in:before (<), meets (m), overlaps ( o ), starts (s), during (d), finishes (f); their respective converses after(>), met-by (mi), overlapped-by (oi), started-by (si), contains (di), finished-by (fi); equals (=), which is its proper converse. For instance, interval I is during interval J is expressed as (I d J ). In turn, an interval relation is a disjunction of atomic interval relations; this is used to allow a pair of intervals to stand in one of many configurations. The set representation of an interval relation ( I r l J ) V
V ( I r, J ) ( n 5 13) is I { q,..., r n } J. For instance, erval I is before, overlaps or contains interval J is expressed by the disjunction ( I < J ) V ( I o J ) V ( I d i J ),the set representation of which is I { <, 0, d i } J.
A qualitative interval network, P, consists of:.."
RI
/
Iine in RI
1. a finite number of variables, say 11,..., I,, ranging over the set { ( a, b ) E IR2 : a < b } of intervals, andee n
1
Figure 1: Illustration of the concept of circuit consisR1 @ R2) tency: in each case, the condition ( R g holds.
2. interval relations on pairs of the variables, the constraints o f the network.
Given an n-variable interval network P, its graphical representation is defined as usual: the vertices are the variables of the network, and if a constraint Ii Rij Ij is specified on the pair ( I i,I j ) of variables then the arc( I i,I. ) is created and labeled by R q. On the other hand, the matrix representation consists of an n x nmatrix M p defined as follows:
Example 1 Consider the 6-variable interval network defined as follows:
R23 = R.56 = O i l
R15 = R35 = m, Rij = 0, for all otherpair (i, j),i < j.
The variables are X I,X 2,..., x6,' Rij stands for the > label on edge ( X i, X j ) ; the label on edge (Xi,Xj),i j, is not given explacately: at is equal to the converse(or transpose) of Rji:
The network is carcuit consistent. Indeed, it respects the definition of circuit consistency with respect to the ordering X I,X z,..., X6 of its variables. However, the triangle ( X I,X 3, Xs),and hence the whole network, is not path inconsistent.
As a side remark, verifying whether an atomic interval network' as circuit consistent with respect to the ordering X I,..., X, of variables is equivalent to veriXi),containfying whether all triangles, ( X i,Xsucc(i), ing two consecutive edges are path consastent.
Vi,j = 1... n, if a constraint IiRijIj is specified on the pair (Ii, I j ) of variables then M p [ i,j ] = Rij, otherwise M p [ i,j] = Allen13 (where Allen13 is the universal interval relation: the set of all thirteen atomic interval relations).
A solution, or consistent instantiation, to P consists of an assignment (I1 = ( a l,b l ),..., I, = (an,6,)) of values to the variables satisfying all the constraints in the network; i.e. such that for all i, j = 1... n, if a constraint Ii R;jIj is specified on the pair (Ii, I j ) of variables then the interval relation ( a i, b i ) R ; j ( a j,b j ) holds.
P is consistent if it contains a solution; it is minimal if any solution of any two-variable subnetwork extends to a global solution [Montanari 74, Mackworth 771; it is globally consistent if any solution of any subnetwork extends to a global solution [Freuder 821. Global consistency is also called strong n-consistency.
3e
Example 1clearly shows that circuit consistency is not complete for the consistency problem of interval networks: an interval network may be inconsistent even if it is circuit consistent.
The concept of circuit consistency
4
Bennaceur, in [Bennaceur 941, defined the concept of circuit consistency for discrete networks. We define the concept for interval networks.
Achieving circuit consistency
Figure 2 presents an algorithm achieving circuit consistency for an n-variable interval network. The algorithm makes use of the following notations, for i E { 1, * *., n } :
Definition 1 Let P be an n-variable interval network. P is circuit consistent if there exists an ordering, say 11,..., I n, of the variables such that for allpred(i) =i - 1 if i > 1, n if i = 1.
'As it will be defined later, an interval network is atomic if for all i, j = 1...n, the label R13 on edge ( X i,X, ) is an atomic interval relation.where ( j mod n ) stands for ( j modulo n ), and 8 f o r composition of interval relations.
58
5
1. Input : An n-variable interval network P.
2. Output : The network P made circuit consistent with respect to the ordering I I,..., I, of its variables.
Method : The algorithm makes use of a data structure Queue. Initially, Queue contains those pairs (i, succ(i)) such that the constraint
Rqsucc(q) is not the universal relation. Then the algorithm proceeds by removing pairs ( i,succ(i)) from Queue until Queue becomes empty. For each pair ( i,succ(i)) that it removes, the following points are performed:
6
Temp := R i ( s u c c ( j ) ) ;
Ri ( s u c c ( j := Ri ( s u c c ( j) )nRij 8R j ( s u c c ( j) ) ;
Ri(succ(j))c Temp{
R ( s u c c ( j ) ) i := t r a n s p o s e ( R i ( s u c c ( j ) ) ) ;add the pair ( s u c c ( j ) succ(succ(j))), to
Queue;
1 j := succ(j);
1
3. The whole algorithm :
While (Queue is not empty){ remove a pair ( i,succ(i)) from Queue;
1. C contains all thirteen atomic relations, and is closed under path-consistency (i.e. pathconsistency applied to a network expressed in C leads to a network expressed in C);j := succ(i);
While ( j # pred[i]){
2. path-consistency detects inconsistency for networks expressed in C.
Temp := & ( s u c c ( j ) ) ;n Rij 8 R j ( s u c c ( j ) ) ;
R i ( s u c c ( j ) ) := R i ( s u c c ( j ) )
If
&(succ(j))
R(,,,,(j
)i
Backtraking search: existing algorit hms
Given an interval network P, we define a refinement of P to be any network on the same set of variables in which every constraint is included in or equal to the corresponding constraint in P ; i.e. for all constraint IR'J of the refinement, the corresponding constraint I R J of P is such that R' E R. A refinement is atomic (resp. convex, pointizable, ORD-Horn) when all its constraints are atomic (resp. convex, pointizable, ORD-Horn); i.e. they are of the form I R J where R is an atomic (resp. convex, pointizable, ORD-Horn) relation.
It is known that when a network contains only atomic labels on its edges the path-consistency method [Montanari 74, Mackworth 771 answers the consistency problem. Vald6s-PCrez [ValdCs-PQez 871 used this result to design a backtracking search algorithm in the style of backjumping [Gaschnig 781 for the consistency problem of interval networks.
Another backtracking search algorithm for the consistency problem of general interval networks is the one of Ladkin and Reinefeld [Ladkin et al. 92, van Beek 921 which is based on a subclass C of the interval algebra verifying the following points:j := succ(i);
While ( j # pred[i]){
If
Complexity analysis
The data structure Queue used in the algorithm of Figure 2 contains at most n pairs ( i,succ(i)) at a time.
A pair can be put into Queue at most thirteen times.
Moreover, for each removing of a pair (i, suec(i)) from
Queue O(n) operations (compositions, intersections and transpositions) are performed (see the inner loop of the algorithm in Figure 2). It follows that the computational complexity of the algorithm is O ( n 2 ).
C may be the set of atomic relations or any of the convex, the pontizable or the ORD-Horn subclasses:c Temp{
1. each of these three subclasses is a subalgebra of the whole interval algebra: it is closed under transposition, intersection and composition;
:= transpose (Ri(,uc,(j ) ) ) ;add the pair ( s u c c ( j ) succ(succ(j))), to
2. the consistency problem of a network expressed
Queue;in either of the subclasses is solved by the pathconsistency algorithm;
3. the ORD-Horn subclass is the unique greatestj := succ(j);subclass among the tractable subclasses that contain all thirteen atomic relations [Nebel et al. 941.
1
21f Rt(succ(J))C Temp then R*(succ(J)) has been success) ) t constrain refully modified, Implying that R ( s u C C ( 3may lations R ( s u c c ( j ) )tok modification; for this reason, the pair( s u c c ( j ),s u c c ( s u c c ( j ) ) ) is added to Queue.
1
Figure 2: The circuit consistency algorithm.
59
Let n be the number of variables and 11,..., In the variables of an interval network. The algorithm of Ladkin and Reinefeld defines an instantiation ordering, say(11 1 2 ), ( 1 1, 1 3 ),..., (11,I n ),... 1
J(1~,~~+l),...,(~~,In),...,(I~-l,~n)of the edges and constructs in a depth-first manner the labeled tree described in Figure 3 until a consistent refinement is found or all the tree is constructed without finding such a refinement.
We then check whether the current node in the search tree is of level ( n - 1) x n / 2. If this is the case then the corresponding edge is the last in the instantiation ordering, and the algorithm calls the path-consistency procedure. Otherwise, there are more than one edge yet not instantiated, and the algorithm calls the circuit consistency procedure. Hence, all we need, in addition to the modification above, is to modify step
2d in Figure 3 in the following manner.
1. if P is not the empty network:
1.
1. create the root of the tree, and label it by PC(P),where
P is the original network;ii. let l a b e l ( I,J ) be the label on edge ( I, J ) in the network P;... decompose label(1,J) into
/*
111.
* the root is of level 1;
*if a nodenl
J ) be the 1th edge in the instantiation orderlet (1, ing;is of level 1 then all node
* an immedite successor of n1
*/
712is of level 1
Uctwhich is + 1;of elements of C;r=liv. if 2. while there are nodes yet not marked:(t < ( n - 1) x n / 2 ) then for all c,, i = 1... m{(a) consider a node s yet not marked;create an immediate successor for n, and(b) let 1 be the level of s and P its label;label it by CC(P[ZabeZ(I, J )
1(c) mark s;(d) i j t
#(n- 1)x n/2 ande= 1
+ct]);...m{create an immediate successor for n, and label it by PC(P[label(I, J) t cl]);
}
8m
Uelse for all c,, i = 1
P is not the empty n e t ~ o r k : ~i. let ( I, J ) be the t t h edge in the instantiation ordering; ii. let label(1, J ) be the label on edge ( 1, J ) in the network P; iii. decomposelabel(1, J ) into a union label(1, J ) =
Experiments
In this section, we provide experimental tests on the performances of Ladkin and Reinefelds search algorithm in the following two cases: (1) the algorithm in which only path consistency is used during the search, and (2) the algorithm in which circuit consistency and path consistency are combined.
We compared the two algorithms on randomly generated problems. We took into account the following three parameters:c, of elements of C ;.iv. for all c,, i = 1.. m create an immediate successor for n, and label it by P C ( P  [ Z a b e l ( l, J ) t ~ $ 1 ) ; ~
Figure 3: Ladkin and Reinefelds algorithm
7a union label(I,J) =m
Combining circuit consistency and path consistency in search algorithms
1. the size of the problems, i.e. the number of variables;
2. the density, i.e. the fraction of the number of non universal constraints to n x ( n - 1)/2, where n is the number of variables;
Ladkin and Reinefelds algorithm is modified in the following manner. We first apply circuit consistency to the whole network; i.e. we replace step 1 in Figure
3 by the following:
3. the tightness, i.e. the fraction of forbidden atomic relations in the non universal constraints to 13.
1. create the root of the tree, and label it by
CC(P ),5 where P is the original network;
We randomly generated a first list of problems according to the following values of the parameters:
3 P C ( P ) is the network obtained by applying path consistency to P.
41f 1 = ( n - 1) x n/2 and the label P of node s is not the empty network then P is a consistent refinement of the original network.
5 P  [ l a b e l ( l, J ) e c, ] is the network obtained by substituting c2 to the label on edge (I,J ) of P.
5 C C ( P )is the network obtained by applying circuit consistency to network P.
1. 8 5 size
5 15;
2. 0.7 5 density 5 0.9; and 3. 9/13 5 tightness 5 12/13.
Then a second list according to the following values of the parameters:
60
1. 8
< size 5 15;not reported here, the algorithm with P C alone answers in a reasonable amount of time while the algorithm with CC and PC combined takes much more time, in some cases giving no answer. This explains that, at least for the generated problems, the filtering power of PC is more important than the one of CC.
We believe however that the study of combining
CC and PC during the search, not necessarily in the way presented in the paper, should be pursued. An alternative may be the following:
2. density = 0.05; and 3. tightness = 1/13.
The comparison is based on the number of calls to the composition of two relations. Composition is the main time consuming during the search. We also computed the number of nodes of the search space effectively spanned. The respective results are reported in the two tables below, where CC and PC stand for circuit consistency and path consistency, respectively. nb of variables
PC alone nb of nodes I nb of calfs
I
I
1. consider two integer values a and,O such that
1 5 a <,f3 5 n, where n is the number of variables of the input network;
CC and PC combined nb of nodes I nb of calls
2. then during the search if the level 1 of the current edge is such that ([ mod @) a apply CC otherwise apply PC;
<
3. finally, to make the algorithm complete, apply PC when instantiating the last edge.
9 nb of variables
9
PC alonenb of nodes
I
-.
I
Inb of calls
I
C C and PC combined nb of nodes I nb of calls
I
555
I
36
I
578
12
37
I 46
56
67
13
79
I 817
1083
1447
1885
14
92
2386
91
1873
2373
15
1 n5xn.5
1 n.5
2947
10
11
I 45
55
66
78
Summary and future work
We extended the definition of circuit Consistency to qualitative interval networks. We then showed how to modify Ladkin and Reinefelds search algorithm in such a way to combine circuit consistency (CC) and path consistency (PC) during the search, instead of using only PC. CC is less filtering than PC; however, it is one factor less expensive. We presented experimental results comparing the performances of (1) Ladkin and Reinefelds algorithm [Ladkin et al. 921 in which only
PC is used during the search, and (2) the algorithm in which CC and PC are combined.
The experiments presented show that, at least for the problems randomly generated, combining CC and PC gets more use only in some cases. However, as we discussed it in last section, other ways of combining
CC and PC exist, that may beat, eventually for classes of real-life problems, the algorithm with PC alone.
Finally the work presented in this paper extends in a natural way to search algorithms in quantitative temporal networks [Dechter et al. 911.
I 815
1103
1459
The first case corresponds to dense and tight problems, which are difficult to satisfy (that is to say, the probability for such a problem to be inconsistent is almost 1 ). The results clearly show that for these problems, combining circuit consistency and path consistency gets more use than path consistency alone.
For this first case the number of nodes of the search space effectively spanned is equal to 0. This is due to the fact that the problems are trivially inconsistent, and that inconsistency is detected by the first path consistency or the first circuit consistency, depending on whether the search uses PC alone or combines CC and PC (before calling the procedure backtrack).
The second case corresponds to problems of very weak tightness and very weak density; that is to say to underconstrained problems. These problems are trivially consistent. The first path consistency or the first circuit consistency, depending on whether the search uses PC alone or combines CC and PC, succeeds; then a solution is found with backtrack free (the table shows clearly that the number ofvisited nodes is n x (n-1)/2, where n is the number of variables). As the second table shows, the two methods present similar performances for this second class of problems.
Discussion : Except for the two cases reported above, using PC alone, as suggested by Ladkin and Reinefeld [Ladkin et al. 921, gets more use than combining the two filtering methods. Indeed, for the other problems we generated in our experiments, which are
References
[Allen 831 Allen, J.F., Maintaintng Knowledge
About Temporal Intervals, Communications of the ACM 26 (1 1) (1983) 832 - 843.
[Bennaceur 941 Bennaceur, H., Partial Consistency for Constraint Satisfaction Problems, in: Proceedings ECAI-94, Amsterdam, (1994) 120 - 124.
[Dechter et al. 911 Dechter, R., Meiri, I. and Pearl, J., Temporal Constraint Networks, Artificial Intelligence 49 (1991) 61 - 95.
[Freuder 821 Freuder, E.C., A Suficient Condition for Backtrack-free Search, Journal of the ACM 29(1982) 24 - 32.
[Gaschnig 781 Gaschnig, J., Experimental case studies of backtrack us. Waltz-type us. new algorithms for satasficing asszgnment problems, in: Proceedings of the Second Biennial Conference of the 61
Canadian Society for Computational Studies of Intelligence, Toronto, Ont., (1978) 268 - 277.
[Isli et al. 951 Isli, A. and Bennaceur, H., Networks of qualitative interval relations: combining circuit consistency and path consistency in the search for a solution, PrC-publication, L.I.P.N., UniversitC
Paris 13, France (to appear).
I
[Ladkin et al. 92 Ladkin, P. and Reinefeld, A., EfjCective so vtion of qualitative constraint problems, Artificial Intelligence 57 (1992) 105 - 124.
[Mackworth 771 Mackworth, A.K., Consistency in Networks of Relations, Artificial Intelligence 8(1977) 99 - 118.
[Montanari 741 Montanari, U., Networks of Constraints: Fundamental Properties and Applications to Picture Processing, Information Sciences
7 (1974) 95 - 132.
[Nebel et al. 941 Nebel, B. and Burckert, Reasoning about Temporal Relations: A Maximal Tractuble Subclass of Allens Interval Algebra, in: Proceedings AAAI-94, Seattle, WA, (1994)
356 - 361.
[ValdCs-PCrez 871 ValdBs-PBrez, R.E., The satisfiability of temporal constraint networks, in: Proceedings AAAI-87, Seattle, Washington, (1987)
256 - 260.
[van Beek 921 van Beek, P., Reasoning about Qualitative Temporal Information, Artificial Intelligence 58 (1992) 297 - 326.
[Vilain et al. 861 Vilain, M. and Kauts, H., Constraint Propagation Algorithms for Temporal Reasoning, in: Proceedings AAAI-82, Philadelphia, PA, (1986) 377 - 382.
62Resolution for Branching Time Temporal Logics: Applying the Temporal
Resolution Rule
Alexander Bolotov and Clare Dixon
Department of Computing and Mathematics
Manchester Metropolitan University
Manchester M1 5GD, UK.
A.Bolotov,C.Dixonfi@doc.mmu.ac.uk
Abstract
In this paper we propose algorithms to implement a branching time temporal resolution theorem prover. The branching time temporal logic considered is Computation
Tree Logic (CTL), often regarded as the simplest useful logic of this class. Unlike the majority of the research into temporal logic, we adopt a resolution-based approach. The method applies step and temporal resolution rules to the set of formulae in a normal form. Whilst step resolution is similar to the classical resolution rule, the temporal resolution rule resolves a formula,, that must eventually occur with a set of formulae that together imply that can never occur. Thus the method is dependent on the efficient detection of such sets of formulae. We present algorithms to search for these sets of formulae, give a correctness argument, and examples of their operation.
1 Introduction
Since it was first proposed in   temporal logics have been used extensively in the specification and verification of properties of concurrent and distributed systems. If in this application the ability to refer to a range of possible execution paths is important then the power of the language of branching-time logics is essential. It has been observed that most correctness properties of concurrent programs (that do not deal with fairness) can be expressed in the family of branching time logics called Computation
Tree Logics. The core logic we concentrate on is a Computation Tree Logic (CTL)   often regarded as the simplest useful logic of this family. There are several extensions of CTL of which CTL is the most powerful.
Much of the research on the verification of concurrent and distributed systems has centered around the modelchecking technique utilising CTL. Here the satisfiabilityof a CTL formula is checked with respect to a model derived from a finite-state program. The underlying research on decision procedures for branching time temporal logics has mostly involved tableau or automata methods   with an obvious lack of research into deductive proof methods.
For propositional linear-time temporal logics (PLTL) a clausal resolution method   has been developed. This resolution approach has been extended to CTL in. Its key elements consist of translation to a normal form and a variety of resolution rules. The normal form is a set of formulae which utilize only next, always and sometime temporal operators (all other operators are subsumed within this representation). Two types of resolution rules are distinguished, namely, resolution within states known as step resolution, and resolution over states known as temporal resolution. The latter applies when a proposition fi occurs at all future moments (known as a loop in fi), and if fi is also constrained to be false at some point in the future. The efficient search for such loops is crucial to the temporal resolution method. In the linear-time case, several algorithms for detecting loops have been developed. In this paper we select one of these loop detection algorithms and extend it to apply to the branching time logic CTL.
The remaining of the paper is organized as follows. In
2 we overview the logic CTL. In 3 a clausal resolution method is outlined. Algorithms to apply the temporal resolution rule and examples of their operation are given in 4.
A correctness argument is outlined in 5. Finally, in 6 we consider related work and in 7 provide concluding remarks.
2 The logic CTL
Here we summarize the syntax and semantics of the core logic, CTL.
2.1. Syntax and semantics of CTL
In the language of CTL we utilize only future-time(always), ff (sometime), (next time), fi operators(until) and ff (unless). Additionally, we use path quantifiers A (on all future paths) and E (on some future path).
The syntax of CTL distinguishes state (ff ) and path ( ) formulae. These are defined inductively as follows, whereff is any well-formed formula of propositional logic, including classically defined constants fiff and fffi.ff
fififf  ff ff ff  ff fi ff  ff  ff   ff  A  E ff  ffff  ff  ff fi ff  ff ff ff
Well formed formulae of CTL are state formulae. Thus, each CTL formula has a structure where any temporal operator can only be followed by a path operator or a classical operator, while any path operator can only be followed by a temporal operator. An example of a CTL formula is Efffi ff E fi meaning there is a path on which fi eventually holds and there is a path on which fi always holds. It follows that CTL is weaker than linear-time temporal logic in its expressive capabilities within a path, but is more expressive in that it can quantify over paths themselves. As an example of its restricted nature, note that no formula de are satisfied on scribing the property both ff and the same specific path can be constructed using CTL syntax. For the detailed description of CTLs theoretical properties, subsystems and extensions see.
Before continuing with the semantics of CTL we introduce some notation. We interpret a well-formed formula of CTL in a tree-like model structure 	 fiff, where ff is a set of states, ff  ff is a binary relation over ff and ff is an interpretation function mapping atomic propositional symbols to truth values at each state.
A path, fifi, over, is a sequence of statesff 	 fffi 	 fffiff 	    such that for all   ff	 ff 	 fi  .
A path fifi is called a fullpath.
Given a path fifi and a state   fifi 	 ff   we term a finite subsequence  ff 	 fffi 	    	  a prefix of a path fi fi and an infinite sub-sequence of states   	  fi 	  fiff 	    a suffix of a path fi fi abbreviating these respectively with
  fffifi 	 ffff 	  fi (or simply as ffff 	  fi when it is clear which path this prefix belongs to) and ff fffi fi 	  .
We assume that a CTL model 	 satisfies the following conditions:
1. there is a designated state,    ff, a root of a structure(i.e. for all 
 	  ff ff
), 2. every state belongs to some fullpath, i.e. a path starting at , It is known that if linear-time temporal logic is interpreted over discrete linear models with finite past and infinite future then adding past-time operators does not give more expressiveness.
3. tree structures are of at most countable branching, 4. every state should have a successor state, and, 5. every path is isomorphic to .
Below we define the satisfaction relation fi which evaluates well-formed CTL formulae at a state  ff in a model. Postulates s1-s7 define satisfaction relation for the CTL formulae at states while p1-p6 determine evaluation of their subformulae along paths. s1ff ff fi fi s2 s3 s4 s5 s6 s7 p1 p2fi  ffffff fi.ff ff fi ff ff fffi .ff ff fi  ff ff ff fi  andff ff fi .ff ff fi  fi ff ff fi  orff ff fi .ff ff fi   ff ff fffi  orff ff fi .ff ff fi Afifi ff fi .ff ff fi Efi  fi ff fi .fi ff fi ff ff fi 
.fi ff fi

  fifi ff  ff fffifi 	  ff fi .fi ff fi ff
  fifi  ffff fffifi 	  ff fi .fi ff fi ff fffifi 	 fffi ff fi .fi ff fi  fi 
  fifi  ffff fffifi 	  ff fi ff  fifi ff    ff fffifi 	 ff ff fi .fi ff fi  ff fi ff fi
fi ff fi  fi .fiffff fififififififfff fifi fffifffi fi fi
 ffff fifi fffffififfff fiff
fffiffp3fi fffifffi fi 
 fiffp4 p5fifi
fffifffi fi fiffffp6
 fiff ffff fi
fffifffi
ff
A well-formed formula, , is satisfiable if, and only if, there exists a model 	 such that
 ff fi . A wellformed formula, , is valid if, and only if,  is satisfied in every possible model, i.e.for each, 		   ff fi .
Recall that well-formed CTL formulae are state formulae and due to the syntactic requirement (see above) when we evaluate a CTL formula, for example, A ff, we reduce the problemff ff fi A ff, following s6 above, to the evaluation of ff along each path fi fi. This, acording to p4, meansff fffi fi 	 fffi ff fi ff. Since ff must be a state formula, applying p1, we obtain from the latterfffi ff fi ff. Now, if ff contains another temporal operator, then this operator will again be preceded by a path operator indicating a specific path context. For example, ifff fi E  then the problemfffi ff fi E  will be reduced, according to s7, to evaluating  along some path flfi, etc.
2.2. Closure properties of CTL models
When trees are considered as models for distributed systems, paths through a tree are viewed as computations. The natural requirements for such models would be suffix and fusion closures. The former means that every suffix of a path is itself a path. The latter requires that a system, following the prefix of a computation , at any point    , is able to follow any computation fl fifi originating from  . Finally, we might require that if a system follows a computation for an arbitrarily long time, then it can follow a computation forever. This corresponds to limit closure property, meaning that for any fullpath fi fi and any paths fl fifi 	 fiff   (      fi) such that fifi has the prefix ff 	  fi, flfifi has the prefix ff 	 ff fi, fiff has the prefix ffff 	 fi fi etc, the following holds (see Figure 1):
The language for indices is based on the set of terms
fi
ff

ffff ff ff fi  fififi

ffff
  ifffffi
Definition 1 (Separated Normal Form for CTL)
Given a CTL formula , the separated normal form for F, SNFfffi (F), is a set of clauses of the formfffffifffi
ff
Thus, E fi means that  holds on some path labelled asff ff. Indices of the type
ff ffff aim to capture limit closure property. Once the translation to SNF fffi has been carried out, all SNFfffi clauses containing a E quantifier are labelled with some index (for more details see  ).
Further, an additional operator,  fifi, which effectively identifies the initial state, is introduced:
A
ff
ff  ff where each of the ff  ff  is further restricted as in Figure 2, where each  ff,  or  is a literal, fiff or fffi, andff  ff is some index.ffffffff
 fifithere exists an infinite path  that is a limit of the prefixes
 	  fi	 ff 	 ff fi	 ffff 	 fi fi   .
In the following we assume that tree-like models of CTL are suffix, fusion and limit closed ff.fiff
3. The temporal resolution method for CTL
Here we review the temporal resolution method for CTL
  whose main components are translation into the clausal normal form and application of resolution rules.
3.1. A normal form for CTL
The basic idea behind the normal form for CTL called
Separated Normal Form (SNF fffi ) is to identify the core operators and generate formulae relevant to either the first state in a model, or to all subsequent states in a model. The transformation procedure uses fixpoint unwinding and subformula renaming in order to reduce an arbitrary formula to SNFfffi. To preserve a specific path context indices are used.
A variety of difficult problems concerning branching-time logics are due to the limit closure property, resulting, for example, in the case of CTLff, in the absence of a complete axiomatization.fifffi ff
A 
fifffi ff
E 
fiff
Figure 1. Limit closurefffifffifffiff


ff

ff
an initial clause
ff

an A step clause
a E step clauseff

ff

Aff
ff

Eff fifffian A sometime clausefffi fifffia E sometime clause
Figure 2. Form of SNFfffi Clauses
The natural intuition here is that the initial clauses provide starting conditions while step and sometime clauses constrain the future behaviour. For example, a step clause
A ff  A fi means for any fullpath fi and any state  ff  fi ff  ff, if  is satisfied at a state ff then fi must be satisfied at the moment, next to ff, along each path which starts from  ff.
Similarly, interpreting A ff  E fi fifffi , we use the information that E is associated with the indexffff: for any fullpath fi and any state  ff  fi ff  ff, if  is satisfied at a state ff then fi must be satisfied at the moment, next to  ff, along some path associated withff which departs from  ff.
Finally, A ff  Efffi fffi	fifffi  means for any fullpath fi and any state  ff  fi ff  ff if  is satisfied at a state ff then fi must be satisfied at some state, say  ffff  ff, along some path  fi associated with the limit closure offfff which departs from  ff.
All the other operators are subsumed within this representation. For example, the A  operator is represented by a (possibly infinite) sequence of A  operations (see
 ). For convenience we will omit the outer A  connective that surrounds the conjunction of clauses and drop the conjunction considering the set of clauses.a constant fffi to indicate this situation and, for example, the conclusion of SRES 2 rule, when resolving   A and   A , will be   A fffi.
Once a contradiction within a state(s) is found, as for example,   A fffi, then we simplify it applying the following rule:
3.2. Resolution rules for CTL
The step resolution process terminates when either no new resolvents are derived, or  fifi  fffi is derived.
Once step resolution has been applied, the temporal resolution rule can be invoked. The basic idea here is to resolve a set of formulae containing a loop in fi, i.e.a situation whenfi occurs at all future moments along some (E-loop in fi) or every path (an A-loop in fi) from a particular point in a CTL model, with the formula containing a fffi, provided that both refer to the same path. Thus, identification of loops within given set of SNF fffi clauses, similar to PLTL, is the crucial part of the temporal resolution method in CTL.
As in PLTL, some loops might be given directly as a set of SNFfffi clauses; in other cases loops might be more difficult to detect. One of the benefits of the normal form is that it allows us to identify hidden loops within some set of clauses.
Once a set of SNFfffi clauses,, has been obtained, a resolution method is applied to. Here we repeatedly apply step and temporal resolution rules, together with various simplification steps.
3.2.1 Step resolution. Step (classical) resolution can be used between formulae that refer to the initial moment of time or same next moment on some or all paths. The corresponding step resolution rules are given below
SRES 1
 fifi
 fifi
 fififf fifi
 fi fiff fi



SRES 2

ff ff 


ff fi fi
 fi fi ffff fi  
A
A
Affff
SRES 3

ff ff 



A
E
Eff fi fi
 fi fi ffff fi  fffffifffififffi
SRES 4

ff ff 



E
E
Eff fi fi
 fi fi ffff fi  fffffifffififffififffiwhere fi is a literal andffff is an index.
When an empty clause is generated on the right hand side of the conclusion of the resolution rule, we introduce




P fffifffiwhere P is either of path quantifiers. The conculsion,  fffi, in turn, requires that  must never be satisfied in any moment in time. This is reflected in generating extra constraints by applying the following rule:




 fifififffffi

A 
3.2.2. Loops in CTL. Loops in CTL are defined on sets of merged clauses, which are, in turn, generated from step clauses.
Merging

ff ff 



A
A
Aff
ffff ff  

ff ff 



A
E
Eff
 fiffff ff  fifffi

ff ff 



E
E
Eff fi
 fiffff ff  fifffififffifffiff
Note that, similar to SRES 4, we allow merging of two
E step clauses if both existential path quantifiers refer to the same path.
Definition 2 (Loop in CTL)
A loop in fi is a set of merged clauses (possibly labelled) of the form



 Pff
 Pff
then Pfi, fiff
fifffi
 

fffi


fiff  !.
 
the following formulae are satisfiedff ff  ff  !, Pff only involves one E quantifier labelled byff fi ff or every P ff which involves the E quantifier has the same labelff fi ff thenffff fi
ff fffi ff and we have a E-loop in fi on the path
ff fffi ff, otherwise
 if for all
 we have indicated a E-loop in fi on the path
ff ffff, whereffff is a new index.
For this set of merged clauses, each right hand side implies one or more left hand sides from the side condition on loops. Each right hand side implies fi. Hence, once one of the left hand sides is satisfied, a literal fi holds at all future moments on some or all paths (dependent on the type of the path quantifier).
As a simple example consider the following set of clauses (where the first clause on its own gives us a loop in ).fiff  A 	  ff   E  fifffi(1)
By merging both clauses, we obtain
 ff fi
In each of the states fi fi fi fi  fi    along the path fi fffffifi  ff 	fi
Efifffi
ff
A,  ffff is empty, and we have an A-loop inff
fi
ff  !, Pff is the A path quantifier
ff Efifffffffifi

We will abbreviate such loop by
P P fi fifffi, wherefffi fffffififififf  , for allwhere fi ffff  fi and fi ff
 if for allfiff

Figure 3. Effects of limit closure in CTL: Eloopff 	  	     is a path, and each state along this path satisfies  ff , which gives us the desired E-loop in .
3.2.3. Temporal resolution rules. Now, using the expressions   A A fi and   E E fi as abbreviations for sets of SNFfffi clauses which together represent these formulae, temporal resolution rules for CTL are defined as follows.
TRES 1






A A fi
Afffi
Aff ff fi
TRES 2fifffi


(2)which gives us additionally a E-loop, in , which is linked to the limit closure property of CTL. Consider a model given in Figure 3, where we arbitrarily chose a fullpath and let ff  fi be the first moment along fi which satisfies  ff . Therefore, there is a path fl fi associated withffff such that , the successor of  ff on this path, satisfies
 ff . Formula (2) means for any fullpath and any stateff  ff  , if ff is satisfied at ff then E ffff fifffi is satisfied at ff. Due to the fusion closure property, there is a fullpath ff 	 ff fi  flfi (a concatenation of ff  	 ff fi andflfi ). Thus, setting fi ff 	 ff fi  flfi and  fi , we conclude that
 ff fi E ff ff  fifffi. Therefore, there is a path fifi associated withffff such that there is a state, next to , say , on this path which satisfies  ff , etc.
Hence, according to the limit closure property, the sequence



A A fi
Efffi fffi	fifffi
Eff ff fi fffi	fifffi
TRES 3






E E fi fffi	fifffi
Afffi
Aff ff fi
TRES 4






E E fi fffi	fifffi
Efffi fffi	fifffi
Eff ff fi fffi	fifffi
In each case the resolvent ensures that once  has been satisfied, the conditions, , for triggering a -formula arenot allowed to occur, i.e.,  must be false, until the eventuality (fi) has been satisfied. Although it might be surprising that resolving an Afffi with a E-loop in fi results in an Aformula, if the premises of temporal resolution in this case are satisfiable, the satisfiability of the conclusion of TRES 3 is guaranteed by the limit closure property (the corresponding proof is given in  ).
This system of resolution rules is a complete deductive method for the logic CTL (  ).
4. Applying CTL Temporal Resolution
The clausal resolution approach to linear-time logic has been shown to be particularly amenable to efficient implementation. Here we concentrate on one of these algorithms, the Breadth-First Search approach, and modify it for use in our branching time setting.
4.1. Overview of the Loop Detection Method in CTL
While in PLTL we have only one temporal resolution rule, in the branching-time framework, a variety of such rules are defined. Depending on the type of a path quantifier in the sometime SNF fffi clause, we look for different types of loops. In particular, given Afffi, we search for a set of clauses that together imply either A A fi or E E fi (labelled by anyffff), which can be used to apply TRES 1 and TRES 3. When we are resolving with a sometime formula containing Efffi labelled by
ff ffff, then we search for a set of clauses that together imply either A A fi or E E fi fifffi to apply TRES 2 or TRES 4. In the latter case use of indices is crucial.
The Breadth-First Search Algorithm constructs a sequence of nodes that are labelled with formulae in Disjunctive Normal Form. This represents the left hand sides of clauses used to expand the previous node which have been disjointed and simplified. Clauses are selected for use in the algorithm if they generate the required literal at the next moment in time and their right hand side implies the previous node. The former ensures the required literal holds and the latter gives the looping required so that the literal always holds. If we build a new node that is equivalent to the previous one, using this approach, then we have detected a loop.
However, if we cannot create a new node then we terminate without having found a loop.
4.2. Breadth-first A-loop search algorithm
Given a set,, of SNFfffi clauses we develop an algorithm to detect an A-loop in fi by constructing a set of nodes
" 	 " 	    	 " labelled by formulae ff  	    	 ff, where each ffff ff  ff  ! is in DNF and the label, ff , of the terminating node "  satisfies the following condition:
  A A fi.
Thus, to detect an A-loop in fi follow the steps below.(1) Search for all SNF fffi clauses of the form # ff  A fi, for  fi  to $, disjoin the left hand sides and make the label
, of the top node "  equivalent to this, i.e.
" fifi# ffff
Simplify ". If  "  fiff we have found a loop.(2) Given a node " ff, build node " fffi for ff fi 	 	    by looking for clauses or combinations of clauses of the form
  A ff ff fi, for  fi  to % where    "ff.
Disjoin the left hand sides so that
"fffifi
fi
 
and simplify as previously.(3) Repeat (2) until one of the conditions (a)-(c) holds:(a)  "ff  fiff. We have found a A-loop and return the label of the terminating node, fiff.(b)  "ff  "fffi. We have found a A-loop and return the label of the terminating node, DNF formula " ff.(c)
"fffiis empty. Terminate - no loop has been found.
4.3. Breadth-first E-loop search algorithm
To detect a E-loop in fi do the following.(1) Search for all the clauses of the form # ff  A fi, or #ff  E fi fiff fi, for  fi  to $, disjoin the left hand sides, make the top node "  equivalent to this and label "  with
Ind, i.e.fi
" fi
fi ff
#ff
ffwhere Ind is a set of all indicesffff ff occurring within
#ff  E fi fiff fi. Simplify ". If  "  fiff we terminate having found a loop.fi
Not surprisingly, the detection of a A-loop is almost identical to that of Breadth-First Search in linear-time temporal logic. However, with the detection of an E-loop we must take care when combining clauses (see below).
To simplify the presentation below, since a labelof a nodefifi uniquely identifies this node, instead of saying a labelfi ff fi     
 fi of a node fffi  we will use the expression fffi ff fi      fi fi.(2) Given a node " ff
ffff ff, build a node " fffi
ffffff ff forff fi 	 	    by looking for combinations of clauses of the form   A ff ff fi or   E ff ff fi fiff fi for
 fi  to % where    "ff. Disjoin the left hand sides so thatfffffi ff
 fi

"fffifi
 
step (2) of the E-loop search algorithm (i.e. all the pairs of clauses can be merged and the right hand side contains fi as a conjunct and also implies "  ). So we disjoin the literals on the left hand sides of the merged clauses 6+1, 7+2 and 8+3 to obtain node
"ffff
ffwhere Ind is a set of all indicesff ff occurring within
  E ff ff fi fiff fi. Simplify "fffi as previously.ff(3) Repeat (2) until one of the conditions (a)-(c) holds:(a)  "ff  fiff. We terminate having found a E-loop on pathffff and return the label of the terminating node, fiff, provided that the following condition () is satisfied
 ifffff is the only element of ff then we have found a E-loop in fi on the path
ff ffff, else(c)
" fffi
& ff   Efffffifffi fififf fiff

& ff fiff fiwe cannot now combine it with clause 1 as it has a different path index. We can, however, merge it with either clause 2, 3 or 4 to give
& ff  ff $
& ff  ff 'ff& ff  ff (


ffff
& ff  ff fi
& ff  ff fiff& ff  ff fi 
E
E
Efffiff fifffiff fififf fi
The first two left hand sides will be removed via simplification to leave node " ff as
"ff fi ff& ff  ff ( fi $ fi 'is empty. Terminate - no loop has been found.
In a particular case of the E-loop detection algorithm, given a sometime clause labelled by
ff ffff we search for a loop on the path
ff ffff. Thus, we only apply merging to those step clauses containing E quantifier which are labelled byffff. This will guarantee that if the algorithm terminates by finding a E-loop in fi, this loop will occur on the desired path
ff ffff.
& ff  fi $ fi '
Note that merged clause 7+1 would be removed via simplification.
3. Clauses 7+2 and 8+3 still satisfy the expansion criteria so we can add $ fi ' to our new node. However if we merge clauses 5 and 6 to give
 we have found a E-loop in fi on the path
ff ffff ff, whereffff ff is a new index.(b)  "ff  "fffi. We terminate having found a E-loop and return the label of the terminating node, DNF formula "ff provided that condition  above is satisfied;fi fffiff fififf fiff

4. Now only clauses 7+2 and 8+3 satisfy the expansion criteria so the new node is "ff fi $ fi 'fiff fiff

5. The same thing happens when we construct the next node so we obtain
"fi fi $ fi ' fiff  and terminate with the loop ff$ fi '  Efiff
4.4. Examples
Example 1. Consider the following set of SNF fffi clauses in which we are looking for a loop:





&
$
'(




E
A
A
Afifififififffi fi




ff& ff 
$
'




E
A
A
E

&
$
$fiff fififf fi
Noting that here A-loop searching algorithm detects a loop
$  A A fi, we will construct a E-loop.
1. The clauses 14 have either A fi or E fi on their right hand side. We disjoin their left hand sides and simplify to give the top node
" fi & fi $ fi ' fi (fifffi fiff

2. To build the next node, ", we see that the merged clauses 6+1, 7+2 and 8+3 satisfy the expansion criteria in Efififf fiff.
Example 2. Consider the following set of SNF fffi clauses
 fi




E
Afifi
 fi


fifffi fi
A
Efififf fi
It is not immediately obvious that this set of SNF fffi clauses contains a E-loop in fi, namely, fi fi  E E fi.
1. The clauses 1 and 2 have either A fi or E fi on their right hand side, hence, we disjoin their left hand sides and simplify to give the top node
" fi fi fi
2. To build the next node, 1+3 and 2+4, to obtainfi


E
E
"ffff
fifffi fiff
, we derive merged clausesff fifi ff fififffi fififf fi

These satisfy the expansion criteria, so we add fi fi to the new node. Note that while we can not merge clauses
1 and 4 as they are labelled by different indices, we can, additionally to the merging 1+3 and 2+4, obtain a merged clause 2+3. However, its left hand side will be removed via simplification to leave node " as
"fififi ff
 fifffi fififf fiff
5. Correctness of the loop searching for CTL
Here we outline the soundness and completeness of the loop detection algorithms. The following lemma is useful.
Lemma 1 Given a series of nodes " ff, for ff  , output by a Breadth-First A-Search for a loop in fi then

fi A
3. Now, as " fi " we terminate the searching with the loop fffi fi   E E fi fffi	fifffi, whereff ff is a new index.

The model,, (Figure 4), which satisfies the set of clauses given in Example 2, in particular, represents this loop. Pick a fullpath fi and a state  ff  fi that is the first state satisfying fi fi.
"fffiff
Aff
"ff ff fi
PROOF :
For ff *  in step (2) of the algorithm, given node " ff, we select clauses   A ff ff fi, for  fi  to %, where fi   "ff and the new node " fffi is the disjunction of the  s. Therefore, for each  , fi   A "ff and fi   A fi. Hence, we obtain
fi A
"fffiff
A
"ff ff fiffas required. (END)ff fi satisfies  fi fi and E fi	 fi fififffififisatisfies  fi fi and E fi	 fi fisatisfies  and E fi	 fi fififffififf
fifffifi

fi A
PROOF :fifffifffi
fifffi
fi
fffiff satisfies  fi fi and E 	 fi fifiE
Lemma 2 Given a series of nodes " ff, for ff  , output by a Breadth-First E-Search for a loop in fi thenfifififififi
Figure 4. E-loop in a combination of step clauses with different labels
Suppose thatff ff fi fi. Thus, according to merged clause 1+3, ff ff fi E ff ff fi fiff fi, i.e.there must be a path flfi associated withff	 ff, such that   flfi, the successor of ff along flfi, satisfies ff fi. Hence,  ff fi and therefore, according to merged clause 2+4, 		   ff fi
E fffi ff fi fiff fi. Therefore, we must have in the model a path fifi (possibly different from ff fffl fi 	  ), associated withff such that there is a state ff  fifi, the successor of , which satisfies fi ff fi. Now, considering ff, we apply the same reasoning as in the case offf, etc. Thus, there is a path ) fi, the limit closure of the prefixes ffff 	  fi	 ff 	 ff fi	 ffff 	  fi	    such that
)fi ff fi
E fi. Hence, 		 ff ff fi E E fi as desired.fi

"fffiff
Eff
"ff ff fi
Similar to the A-loop (END)
Theorem 1 [(Soundness)] Let be a set of step clauses and fi be the literal we are searching for a loop in. For any
DNF formula # output by a Breadth-First A-Search (respectively a Breadth-First E-search), on, fi #  A
Afirespectively #  Eff
Efi
PROOF : We prove this for the A-Search and the E-Search is similar. From the termination conditions of the algorithm given in 4.2 and 4.3 we know that either #  fiff from step (1) or step (3a), or " fffi fi "ff from step (3b). For the former either the clause fiff  A fi is in the clauseset or there are clauses in the clause-set that together imply this. Again, due to the implicit A -operators surrounding SNFfffi clauses, the clause fiff  A fi holds in all states on all paths. Therefore, fi fiff  A A fi holds as required. Otherwise " fffi fi "ff and from Lemma 1 we have fi A ff"fffi  A ff"ff ff fi. Thus, if we terminate with # then fi A ff#  A ff# ff fi and fi #  A A fi as required. (END)
Theorem 2 [(Completeness)] Let be a set of step clauses and fi be the literal we are searching for a loop in. For any set of clausesff that together imply an Aloop, i.e. fi #  A A fi, (respectively a E-loop, i.e.
fi #  E E fi) the Breadth-First A-Search (respectively E-Search) applied to outputs a DNF formula # ff and #  # ff.
PROOF :
As we only use A step clauses for the Aloop, completeness for the A-loop can be shown as in the linear-time case. Extract all A step clauses from, delete the path quantifier and let the set of(linear-time) clauses beff. Note also that the BreadthFirst A-Search algorithm is identical to that of BreadthFirst Search algorithm for linear-time temporal logic if the path quantifiers are deleted. To show completeness in the linear-time case a graph is constructed from the clauses inff, whose nodes are valuations of all the propositions inff. Paths through the graph represent all possible models offf. It is shown that if a loop exists inff, #, then this is represented in the graph offf by a terminal subgraph where the required literal fi holds at each node.
More specifically # is satisfied by each node (a valuation) in the subgraph. The completeness proof shows that each step in the Breadth-First Search algorithm corresponds to an operation on the graph. If the Breadth-First Search algorithm detects a loop returning the DNF formula # ff then this corresponds to the terminal subgraph representing the largest most comprehensive loop inff. For more details see.
The proof for E-loops is similar but we must construct a graph as described above for each path through the branching tree structure. (END)
6. Related work
Automata-theoretic methods for CTL extend those developed for PLTL. To test formulae of PLTL finite automata on infinite strings are used, the appropriate type of automata in the branching-time setting are finite automata on infinite trees, i.e. when automaton visits a state it reads an input tree rather then an input word. Given a CTL formula, a run of the automaton constructed for is considered successful if it meets certain requirements known as acceptance conditions. This is also known as checking automaton for (non)emptiness. If the acceptance condition is satisfied then a state structure of a successful run is not empty and it gives a model for. Alternatively, a run is unsuccessful. If the automaton does not have a successful run then is not satisfiable. Note that although the structure of the normal form described in this work is close to alternating tree automata used in, there is no direct method of testing these automata for (non)emptiness. On the contrary, clausal resolution method is effectively applied to a set of clauses of normal form.
Tableau-based method for CTL are outlined in. Using tableau methods, to show that a formula is valid, we negate and apply tableau algorithm. The algorithm systematically constructs a structure from which a model can be generated. If the structure is empty then no model can be constructed, the negated formula is unsatisfiable and theoriginal formula is valid. The incremental method of the construction of the tableau   has been essentially used in showing completeness of the resolution method for CTL.
Proof methods for particular modal logics are given in several papers, for example. Ohlbach takes a resolution based approach removing modal operators and replacing them with world path arguments to predicate and function symbols, i.e. a modal diamond (possibility) is replaced by & meaning there is an accessible world & from here. Similarly here we annotate E rules with an index to denote which path we are referring to. Ohlbach requires sophisticated unification algorithms dependant upon the properties of the paths concerned. In the CTL resolution system matching indices is trivial.
Temporal logics are hard to reason about due to the interand operators encoding, in case action between the of linear-time temporal logic, a simple form of induction i.e.ffffff




The formulation of induction extended to branching-time temporal logic, which can be found in the axiomatization of CTL, is given by a set of formulae of a complex structure, for example, A
  ffffffE
  ff  Aff 
The complex resolution rule, and search method described in this paper is required to deal with the above induction principle. Note that induction in branching-time logic is additionally complicated by the limit closure property of the underlying tree models and in case of the full branchingtime logic, CTL, represents a main difficulty in axiomatizing the latter.
One of the benefits of the clausal resolution technique is the possibility of invoking a variety of well-developed methods and refinements used in the framework of classical logic. For example an initial investigation into the development of the set of support for classical logics   to that for linear-time temporal logics has been made in. The refinement of this strategy is ongoing work and could potentially be adapted to the branching framework.
7 Conclusions
As we have already mentioned, most of the research on the proof methods for branching-time logics has been concentrated around the tableau or automata methods. In this paper we have investigated the application of the clausal resolution method for CTL. The authors know of no other clausal resolution methods developed for branchingtime logics. Searching for a loop is the crucial part of theresolution technique. We have described breadth-first algorithms of identifying A-loops and E-loops and sketched the correctness argument. This, together with the algorithm for the clausal resolution for CTL, makes the resolution method developed practically suitable for implementation.
However, ways to improve the application of the temporal resolution rule must be further investigated. Here, although we have formulated one method of searching for a loop, this is only the starting point. The work to be done in this direction concerns, in particular, development of the strategies of the preferred loops to find first, reduction of the search graphs and loop subsumption algorithms. Again, we expect here to incorporate the related results obtained for
PLTL. Also, taking into account that in branchingtime logics we deal with path quantifiers, it might be useful to investigate parallels between loop searching techniques and (rather simple in this case) unification algorithms used in the resolution technique for predicate logic.
Acknowledgements This work has been partially supported by funding from HEFCE, under a PhD studentship and EPSRC, under research grant GR/L87491. Both authors would like to thank Michael Fisher for his advice and comments on this work. We are also grateful to anonymous referees for their useful suggestions on improving the presentation.
References
  O. Bernholtz, M. Vardi, and P. Wolper. An automatatheoretic approach to branching-time model checking. In
Computer Aided Verification. Proceedings of 6th International Workshop, volume 818 of Lecture Notes in Computer
Science. Springer-Verlag, 1994.
  A. Bolotov. Clausal Resolution for Branching-Time Temporal Logic. PhD thesis, The Manchester Metropolitan University, 1999, (submitted).
  A. Bolotov and M. Fisher. A clausal resolution method for ctl branching time temporal logic. Journal of experimental and theoretical artificial intelligence, (11):7793, 1999.
  E. M. Clarke and E. A. Emerson. Using Branching Time
Temporal Logic to Synthesise Synchronisation Skeletons.
Science of Computer Programming, pages 241266, 1982.
  C. Dixon. Search Strategies for Resolution in Temporal Logics. In M. A. McRobbie and J. K. Slaney, editors, Proceedings of the Thirteenth International Conference on Automated Deduction (CADE), volume 1104 of Lecture Notes in Artificial Intelligence, pages 672687, New Brunswick, New Jersey, July/August 1996. Springer-Verlag.
  C. Dixon. Temporal resolution using a breadth-first search algorithm. Annals of Mathematics and Artificial Intelligence, 22, 1998.
  C. Dixon and M. Fisher. The Set of Support Strategy in Temporal Resolution. In Proceedings of TIME-98 the Fifth International Workshop on Temporal Representation and Reasoning, Sanibel Island, Florida, May 1998. IEEE Computer
Society Press.
  E. A. Emerson. Temporal and Modal Logic. In J. van
Leeuwen, editor, Handbook of Theoretical Computer Science: Volume B, Formal Models and Semantics., pages 996
1072. Elsevier, 1990.
  E. A. Emerson.
Automated reasoning about reactive systems.. In Logics for Concurrency: Structures Versus Automata, Proc. of International Workshop, volume 1043 of Lecture Notes in Computer Science. Springer-Verlag, 1996.
  M. Fisher. A Resolution Method for Temporal Logic. In
Proc. of the XII International Joint Conference on Artificial
Intelligence (IJCAI), 1991.
  D. Gabbay, A. Phueli, S. Shelah, and J. Stavi. On the temporal analysis of fairness. In Proceedings of 7th ACM Symposium on Principles of Programming Languages, 1980.
  H.-J. Ohlbach. A Resolution Calculus for Modal Logics.
Lecture Notes in Computer Science, 310:500516, May
1988.
  A. Pnueli. The Temporal Logic of Programs. In Proc. of the Eighteenth Symposium on the Foundations of Computer
Science, 1977.
  L. A. Wallen. Matrix Proof Methods for Modal Logics. In
Proc. IJCAI-87, pages 917923, Milan, Aug. 1987.
  L. Wos, G. Robinson, and D. Carson. Efficiency and Completeness of the Set of Support Strategy in Theorem Proving.
J. ACM, 12:536541, Oct. 1965.Counterexample-Guided Abstraction Renement
Edmund Clarke
School of Computer Science
Carnegie Mellon University
Pittsburgh, USA edmund.clarke@cs.cmu.edu
Abstract
The main practical problem in model checking is the combinatorial explosion of system states commonly known as the state explosion problem. Abstraction methods attempt to reduce the size of the state space by employing knowledge about the system and the specication in order to model only relevant features in the Kripke structure.
Counterexample-guided abstraction renement is an automatic abstraction method where, starting with a relatively small skeletal representation of the system to be veried, increasingly precise abstract representations of the system are computed. The key step is to extract information from false negatives (spurious counterexamples) due to overapproximation.
The methods for alleviating the state explosion problem in model checking can be classied coarsely into symbolic methods and abstraction methods. By symbolic methods we understand the use of succinct data structures and symbolic algorithms which help keep state explosion under control by compressing information, using, e.g., binary decision diagrams or efcient SAT procedures.
Abstraction methods in contrast attempt to reduce the size of the state space by employing knowledge about the system and the specication in order to model only relevant features in the Kripke structure. An abstraction function associates a Kripke structure  with an abstract Kripke structure  such that two properties hold:ff This research was sponsored by the Semiconductor Research Corporation (SRC) under contract no. 99-TJ-684, the National Science Foundation (NSF) under grant no. CCR-9803774, the Ofce of Naval Research(ONR), the Naval Research Laboratory (NRL) under contract no. N0001401-1-0796, and by the Defense Advanced Research Projects Agency, and the Army Research Ofce (ARO) under contract no. DAAD19-01-1-0485, and the General Motors Collaborative Research Lab at CMU. The views and conclusions contained in this document are those of the author and should not be interpreted as representing the ofcial policies, either expressed or implied, of SRC, NSF, ONR, NRL, DOD, ARO, or the U.S. government.
Feasibility.  is signicantly smaller than .
Preservation.  preserves all behaviors of .
Preservation ensures that every universal specication which is true in  is also true in . The converse implication, however, will not hold in general: a universal property which is false in  may still be true in . In this case, the counterexample obtained over  cannot be reconstructed for the concrete Kripke structure , and is called a spurious counterexample, or a false negative.
An important example of abstraction is existential abstraction   where the abstract states are essentially taken to be equivalence classes of concrete states; a transition between two abstract states holds if there was a transition between any two concrete member states in the corresponding equivalence classes.
In certain cases, the user knowledge about the system will be sufcient to allow manual determination of a good abstraction function. In general, however, nding abstraction functions gives rise to the following dichotomy:
If  is too small, then spurious counterexamples are likely to occur.
If  is too large, then verication remains infeasible.
Counterexample-Guided Abstraction Renement (CEGAR) is a natural approach to resolve this situation by using an adaptive algorithm which gradually improves an abstraction function by analysing spurious counterexamples.(i) Initialization. Generate an initial abstraction function.(ii) Model Checking. Verify the abstract model. If verication is successful, the specication is correct, and the algorithm terminates successfully. Otherwise, generate a counterexample fi on the abstract model.(iii) Sanity Check. Determine, if the abstract counterexample fi is spurious. If a concrete counterexample
Proceedings of the 10th International Symposium on Temporal Representation and Reasoning and Fourth International Conference on Temporal Logic (TIME-ICTL03) 1530-1311/03 $17.00  2003 IEEEcan be generated, the algorithm outputs this counterexample and terminates.
 (iv) Renement. Rene the abstraction function in such a way that the spurious counterexample  is avoided, and return to step (ii).
 
Using counterexamples to rene abstract models has been investigated by several researchers beginning with the localization reduction of Kurshan   where the model is abstracted/rened by removing/adding variables from the system description. A similar approach has been described by Balarin and Sangiovanni-Vincentelli in.
A systematic account of counterexample guided abstraction renement for CTL model checking was given in. Here, the initial abstraction is obtained using predicate abstraction   in combination with a simple static analysis of the system description; all other steps use
BDD-based techniques. The use of tree-like counterexamples guarantees that the method is complete for ACTL.
During the last few years, the CEGAR paradigm has been adapted to different projects and verication frameworks, both for hardware and software verication. The major improvements to the method include, most notably, the integration of SAT solvers for both verication and renement, and the use of multiple spurious counterexamples.
It is well-known that most abstraction methodologies can be paraphrased in the framework of abstract interpretation by Cousot and Cousot. Giacobazzi and Quintarelli   have shown that, not surprisingly, this holds true for counterexample-guided abstraction renement as well. The practical and computational signicance of such embeddings for verifying real-life systems however remains controversial.
 
 
 
 
 
 
 
 
 
 
References
  F. Balarin and A. L. Sangiovanni-Vincentelli. An iterative approach to language containment. In Computer-Aided Verication, 1993.
  T. Ball and S. K. Rajamani. Getting abstract explanations of spurious counterexamples in C programs, 2002. Microsoft
Technical Report MSR-TR-2002-09.
  S. Barner, D. Geist,, and A. Gringauze. Symbolic localization reducation with reconstruction layering and backtracking. In CAV 2002, volume 2404 of LNCS, pages 6577, 2002.
  S. Chaki, J. Ouaknine, K. Yorav, and E. M. Clarke. Multilevel abstraction renement for concurrent C programs.
2002. Submitted for Publication.
  E. Clarke, S. Chaki, S. Jha, and H. Veith. Strategy guided abstraction renement, 2003. Manuscript.
  E. Clarke, O. Grumberg, S. Jha, Y. Lu, and H. Veith.
Progress on the state explosion problem in model checking.
 
 
In Informatics, 10 Years Back, 10 Years Ahead, volume 2000 of LNCS, pages 176194, 2001.
E. Clarke, A. Gupta, J. Kukula, and O. Strichman. SAT based abstraction - renement using ILP and machine learning techniques. volume 2404 of LNCS, pages 265279, Copenhagen, Denmark, July 2002.
E. Clarke, S. Jha, Y. Lu, and H. Veith. Tree-like counterexamples in model checking. In Proc. Logic in Computer Science (LICS), 2002.
E. M. Clarke, A. Fehnker, Z. Han, B. H. Krogh, O. Stursberg, and M. Theobald. Verication of hybrid systems based on counterexample-guided abstraction renement. In
TACAS03, pages 192207, 2003.
E. M. Clarke, O. Grumberg, S. Jha, Y. Lu, and H. Veith.
Counterexample-guided abstraction renement. In Computer Aided Verication, pages 154169, 2000.
E. M. Clarke, O. Grumberg, and D. E. Long. Model checking and abstraction. ACM Transactions on Programming Languages and Systems, 16(5):15121542, September
1994.
P. Cousot and R. Cousot. Abstract interpretation : A unied lattice model for static analysis of programs by construction or approximation of xpoints. ACM Symposium of Programming Language, pages 238252, 1977.
S. Das and D. Dill. Successive approximation of abstract transition relations. In LICS, pages 5160, 2001.
S. Das and D. Dill. Counter-example based predicate discovery in predicate abstraction. In Formal Methods in Computer-Aided Design, pages 1932, 2002.
R. Giacobazzi and E. Quintarelli. Incompleteness, counterexamples and renements in abstract model checking. In
SAS01, pages 356373, 2001.
M. Glusman, G. Kamhi, S. Mador-Haim, R. Fraer, and M. Vardi. Multiple-counterexample guided iterative abstraction renement: An industrial evaluation. In TACAS03, pages 176191, 2003.
S. Graf and H. Saidi. Construction of abstract state graphs with PVS. In Computer-Aided Verication, June 1997.
T. A. Henzinger, R. Jhala, and R. Majumdar. Counterexample guided control. In ICALP, 2003. To appear.
R. P. Kurshan. Computer-Aided Verication of Coordinating
Processes. Princeton University Press, 1994.
Y. Lakhnech, S. Bensalem, S. Berezin, and S. Owre. Incremental verication by abstraction. pages 98112, 2001.
Proceedings of the 10th International Symposium on Temporal Representation and Reasoning and Fourth International Conference on Temporal Logic (TIME-ICTL03) 1530-1311/03 $17.00  2003 IEEEThe Role of Labelled Partitionings for Modelling Periodic Temporal Notions
Hans Jurgen Ohlbach
Institut fur Informatik, Universitat Munchen email: ohlbach@lmu.de
Abstract
The key notion for modelling calendar systems as well as many periodic events, for example the seasons, is the notion of a partitioning of the real numbers. A partitioning of R splits the time axis into a nite or innite sequence of intervals. Basic time units like seconds, minutes, hours, days, weeks, months, years etc. can all be represented by nite partitionings of R. There are a lot of other temporal notions which can be modelled as partitions either: the seasons, the ecclesiastical calendars, nancial years, semesters at universities, the sequence of sunrises and sunsets, the sequence of the tides, the sequence of school holidays etc. In this paper a formalization of periodic temporal notions by means of partitionings of R is presented.
The paper is limited to 4 pages. Therefore it contains only basic ideas and informal descriptions. The technical details can be found in.
1. Motivation and Introduction
The basic time units of calendar systems, years, months, weeks, days etc. are the prototypes of periodic temporal notions. They can be modelled with algorithms mapping the begin and end times of a given year, month etc. to dates on a reference time axis. This is sufcient for translating dates between different calendar systems. Another approach is to introduce an intermediate level between the reference time axis and the time units. Different formalizations of this intermediate level have been proposed. In this paper the intermediate level consists of the mathematical concept of partitionings of the time axis. A partitioning splits the time axis into disjoint parts, and these parts can represent years, months etc. They can also represent other periodic temporal notions, for example seasons, nancial years, ecclesiastical calendars, semesters, Olympic years etc. By introducing partitionings as an explicit datatype one can then write algorithms which work for basic time units in the same way as for other periodic temporal notions. The algorithm for computing the n th week of a month can also compute for example the n th week in the summer. Or the query when is the next Wednesday? is answered in the same way as when is the next summer holiday?.
Many periodic temporal notions not only correspond to sequences of partitions, but the partitions are named. For example, the days are named Monday, Tuesday, etc. The seasons are named winter, spring etc. There is usually a nite sequence of names, and the sequence of partitions is named by starting at a particular partition, and repeating the sequence of names as often as necessary. To account for this, the concept of labelled partitionings is introduced. With labelled partitionings temporal notions like next Wednesday, last summer etc. can be modelled in a uniform way. A built-in label is gap. It can be used to denote a partition which logically does not belong to a given partitioning.
The work on partitionings for modelling periodic temporal notions is part of the W EB C AL-project. W EB C AL   is a system for understanding, representing and manipulating complex temporal notions from everyday life. It can represent and manipulate fuzzy time intervals   to deal with fuzzy notions like early today or in the late 20s. It can deal with different calendar systems, even with historical sequences of calendar systems. Other components are a specication language for specifying application specic temporal notions like my weekend. A prototype of the W EB C AL system is currently being tested.
2. Relation to Other Work
Periodic temporal notions have been modelled in various ways. For example, in their book, Time Granularities, Bettini, Jajodia and Wang   introduce time granularities as a generalization of partitionings. The granules in time granularities are like the partitions in partitionings, but there can be gaps between two subsequent granules, and the granules can be non-convex intervals. There is an algebra of time granularities, which allows one to dene new time granularities from existing ones in various ways. Other approaches are the formalisms of collections   and slices. A collection is a structured set of intervals where the order of the collection gives a measure of the structure depth. The Proceedings of the 11th International Symposium on Temporal Representation and Reasoning (TIME04)
1530-1311/04 $20.00  2004 IEEEslice formalism was introduced in   as an alternative to the collection formalism in order to have an underlying evaluation procedure for the symbolic formalism.
There are certain fundamental differences between these approaches and the approach in this paper. The basic mathematical structure used in this paper are just ordinary partitionings, which makes things simpler and easier to understand than granules, collections and slices. We get, however, additional expressivity by labelling the partitions with symbolic labels. One of the labels is gap, which corresponds to the gaps between granules. The labels have certain advantages. First of all, they are nite data structures for innite partitions, which is exploited by certain algorithms. Labellings can be put into a hierarchy of labellings, which permits different views on the same partitioning.
The algebraic operations for constructing new granularities or collections from given ones only approximate reality in most cases. For example, the construction of minutes from seconds usually ignores the leap seconds introduced almost every year. A precise denition of minutes,however, must take into account information from a database of leap seconds. A similar problem occurs when days are constructed from hours. The day in spring when daylight savings time is enabled has only 23 hours, and the day in autumn when it is disabled has 25 hours. This information must also be taken from a database. More extreme is the denition of the ecclesiastical calendar, which is anchored at the date for easter. This date depends on the moon cycle, and must therefore be computed algorithmically. Therefore, the proposal in this paper is to dene partitionings not algebraically, but algorithmically. This allows one to take all the irregularities of the real calendar systems into account.
Many periodic temporal notions, for example, school holidays depend on concrete dates in concrete calendar systems. Therefore a two-level approach is necessary. At the rst level, the basic temporal notions are dened, which are needed for modelling dates in concrete calendar systems, and then new partitionings can be dened which use the dates for their specication.
There is a further difference to the time granularities of Bettini et al. Granules may have holes, and this can be used, for example to dene the notion of working days within a month. This is not directly possible in the partitioning approach. Instead, one can dene such a notion as a function which maps intervals (one month, for example) to intervals(the working days in the month). These functions may use the partitionings, but their specication and use is a completely different issue and not discussed here.
3. Partitionings
A partitioning of the real numbers R may be for example(..., [100, 0[, [0, 100[, [100, 101[, [101, 500[,...). The intervals in the partitionings considered in this paper need not be of the same length (because time units like years are not of the same length either). The intervals can, however, be enumerated by natural numbers (their coordinates). For example, we could have the following enumeration... [100 0[ [0 100[ [100 101[ [101 500[......
1
0
1
2...
The formal denition for partitionings of R which is used in this paper is:
Denition 3.1 (Labelled Partitionings) A partitioning P of the real numbers R is a sequence... [t1, t0 [, [t0, t1 [, [t1, t2 [,... of half open intervals in R with integer boundaries, such that either the sequence is innite at one or both ends, or it is preceded by an innite interval ], t[ (the start partition) or/and it is ended by an innite interval [t, +[ (the end partition).
A coordinate mapping of a partitioning P is a bijective mapping between the intervals in P and a subset of the integers. Since we always use one single coordinate mapping for a partitioning P, we can just use P itself to indicate the mapping.
Therefore let pP be the coordinate of the partition p in P.
For a coordinate i let i P be the partition which corresponds to i.
A Labelling L is a nite sequence of strings l 0,..., ln1.
A labelling L = l0,..., ln1 is turned into a labelling function L P (p) for a partitioning P as follows:if p is nite lpP mod n startPartition if p = [, t[
=
LP (p) defendPartition if p = [t, +[ where p is a partition in P.
In contrast to coordinate mappings, where only one coordinate mapping per partitioning is considered, it makes sense to allow many different labellings for the same partitioning. In most cases the labels are not arbitrary strings, but words of a particular language, and these words have a certain meaning. Therefore one can allow different labellings where the labels are words in different languages. For example the days can be labelled in English: Thursday, Friday etc. and in German: Donnerstag, Freitag etc.
Labellings can be ordered hierarchically. For example there may be labellings BavarianHolidays and BerlinHolidays, which correspond to the different school holiday periods. Both labellings can be a sub-labelling of a labelling schoolHolidays. The difference between BavarianHolidays and schoolHolidays is that the labels in BavarianHolidays, which are not the label gap, are all labelled holiday in the labelling schoolHolidays. This offers for example the possibility to intersect a partitioning
Proceedings of the 11th International Symposium on Temporal Representation and Reasoning (TIME04)
1530-1311/04 $20.00  2004 IEEElabelled BavarianHolidays with another partitioning labelled BerlinHolidays. To do this, the labellings BavarianHolidays and BerlinHolidays are replaced by schoolHolidays in both cases, and the intersection of the partitions with label holiday is computed. This is a non-trivial operation which is beyond the scope of this paper. The details of the algebra of labelled partitionings have not yet been investigated.
4. Specifying Partitionings
Five different ways to specify partitionings are presented. Each way inuences the details of the functions which map coordinates to partitions and vice versa.
Standard Partitionings are specied by (i) an average length of a partition, (ii) an offset for the partition with coordinate 0, and (iii) a correction function. The correction function computes for a partition with coordinate n the difference between the reference time of the beginning of the partition with coordinate n according to the average length, and the real beginning of the partition with coordinate n. All basic time units, seconds, minutes etc. are modelled as standard partitionings. Other periodic temporal notions which can be modelled by standard partitionings are for example sunrises and sunsets, moon phases, the church year which starts with Easter, etc.
Regular Partitionings are characterized by an anchor date and a sequence of shifts in a given time unit. A typical example is the notion of a semester at a university. In the Munich case, the dates could be: anchor date: 2000/10 (October 2000). The shifts are: 6 months (with label winter semester) and 6 months (with label summer semester).
This denes a partitioning which extends into the future and the past. The partition with coordinate 0 is the winter semester 2000/2001.
Further examples for periodic temporal notions which can be encoded as regular partitionings are decades, centuries, the British nancial year which starts April 1 st, the dates of a particular lecture which is every week at the same time.
Duration Partitionings: Regular partitionings are a special case where the shifts are specied in terms of the same partitioning. A natural generalization of this would be to specify the shifts by durations. A duration is a list of pairs (number, partitioning). For example (3 month), (1 week) is a duration. A duration partitioning is specied by an achor date and a sequence of durations. For example, we could start with the anchor date 2000 and then dene partitions by the three durations (3 month, 1 week), (5 weeks, 10 days), (1 year).
The above notion of a duration is a mathematical concept worthwhile to be investigated separately. It can also play a role in temporal constraint networks   if the constraints for temporal distances is not specied in constant time units like seconds, but in time units like months, whose length depends on the position at the time axis.
Calendrical Partitionings are specied by an anchor date and then a nite sequence of partial dates. For example, the seasons can be dened with the anchor date 2000/3/21(spring begin). The partial dates are 6/21 (summer) 9/23(autumn) 12/21 (winter) +1/3/21 (spring again). This also denes an innite partitioning.
Another example could be a whole timetable for a semester in the university, where it is sufcient to specify the dates for one week, and then it is repeated every week.
Date Partitionings: In this version we provide the boundaries of the partitions by concrete dates. Therefore the partitioning can only cover a nite part of the time line.
An example could be the dates of the Time conferences: 1994/5/4 Time94 1994/5/4 gap 1995/4/26 Time95
1995/4/26... 2004/7/1 Time04 2004/7/3.
5. Operations with Partitionings shift: Notions like in two weeks time or three years from now etc. denote time shifts. They can be realized by a function which maps a time point t to a time point t  such that t  t is just the required distance of two weeks or three years etc. A function shift(t, m, P ) is dened where t is a reference time point, n is a real number, and P is a partitioning. The function shifts the time point t by m partitions of the partitioning P.
The denition of shift depends on the type of partitioning. The idea for standard partitionings is as follows: if for example the partitioning represents months, and t is the reference time of the current moment in time, then shift(t, 1, month) should calculate the reference time of 1 month in the future. The rst problem is that months have different lengths. For example, if t is in February, does in one months time mean in 28 days or in 31 days? This problem can be overcome and a very intuitive solution is obtained if the calculations are not done on the level of reference time points, but on the level of dates. If, for example, t represents 2004/1/15, then in one month time usually means 2004/2/15. That means the reference time must be turned into a date, the date must be manipulated, and then the manipulated date is turned back into a reference time. This is quite straight forward if the partitioning represents a basic time unit of a calendar system (year, month, week, day etc.), and this calendar system has a date format where the time unit occurs.
Proceedings of the 11th International Symposium on Temporal Representation and Reasoning (TIME04)
1530-1311/04 $20.00  2004 IEEE
The next problem is to deal with fractional shifts.
How can one implement, say, in 3.5 months time?
The idea is as follows: suppose the date format is year/month/day/hour/minute/second, and the reference time corresponds to, say, 2004/1/20/10/5/1. First we make a shift by three months and we end up at
2004/4/20/10/5/1. This is a day in May. From the date format we take the information that the next ner grained time unit is day. May has 31 days. 0.5  31 = 15.5. Therefore we need to shift the date rst by 15 days, and we end up at 2004/6/4/10/5/1. There is still a remaining shift of half a day. The next ner grained time unit is hour. One day has 24 hours. 0.5  24 = 12. Thus, the last date is shifted by 12 hours, and the nal date is now 2004/6/4/22/5/1. This is turned back into a reference time. advanceCoordinate(i, n, P, skipGap) advances the coordinate i of a partitioning P by n partitions. If skipGap
= f alse or there is no labelling dened for the partition, then the result is just i + n. If skipGap = true then all partitions labelled gap are ignored. The result is i + n where n  n is the number of ignored gap partitions. The advanceCoordinate function realizes notions like tomorrow or in two weeks time or last semester etc. nextCoordinateWithLabel: this function computes for a given coordinate the coordinate of the next/previous mth partition with the given label. The label of the partition with the given coordinate is ignored. The function can be used to realize notions like next Wednesday or Wednesday in three weeks or last summer or the summer 10 years ago etc.
If the partitionings become part of a calendar system, and concrete time intervals are introduced independently of partitionings, then functions are possible which let partitionings operate on intervals. For example new year can be dened as a function mapping an arbitrary interval I to the rst day partition of the year partitions contained in I (see
 ).
6. Summarytioning and gave examples of the kind of periodic temporal notions which can be encoded this way.
References
  Claudio Bettini, Sushil Jajodia, and Sean X. Wang. Time
Granularities in Databases, Data Mining and Temporal Reasoning. Springer Verlag, 2000.
  Francois Bry, Bernhard Lorenz, Hans Jurgen Ohlbach, and Stephanie Spranger. On reasoning on time and location on the web. In N. Henze F. Bry and J. Malusynski, editors, Principles and Practice of Semantic Web Reasoning, volume
2901 of LNCS, pages 6983. Springer Verlag, 2003.
  Nachum Dershowitz and Edward M. Reingold. Calendrical
Calculations. Cambridge University Press, 1997.
  B. Leban, D. Mcdonald, and D.Foster. A representation for collections of temporal intervals. In Proc. of the American
National Conference on Articial Intelligence (AAAI), pages
367371. Morgan Kaufmann, Los Altos, CA, 1986.
  M. Niezette and J. Stevenne. An efcient symbolic representation of periodic time. In Proc. of the rst International Conference on Information and Knowledge Management, volume 752 of Lecture Notes in Computer Science, pages 161169. Springer Verlag, 1993.
  Hans Jurgen Ohlbach. About real time, calendar systems and temporal notions. In H. Barringer and D. Gabbay, editors, Advances in Temporal Logic, pages 319338. Kluwer
Academic Publishers, 2000.
  Hans Jurgen Ohlbach. Calendar logic. In I. Hodkinson
D.M. Gabbay and M. Reynolds, editors, Temporal Logic:
Mathematical Foundations and Computational Aspec ts, pages 489586. Oxford University Press, 2000.
  Hans Jurgen Ohlbach. Fuzzy time intervals and relations the FuTIRe library. Technical report, Inst. f. Informatik, LMU Munchen, 2004. See http://www.pms.informatik.unimuenchen.de/mitarbeiter/ohlbach/systems/FuTIRe.
  Hans Jurgen Ohlbach.
The role of labelled partitionings for modelling periodic temporal notions. httpd://www.informatik.unimuenchen.de/mitarbeiter/ohlbach/homepage/publications/PRP/abstracts.shtml, 2004. to be published.
  Hans Jurgen Ohlbach and Dov Gabbay. Calendar logic. Journal of Applied Non-Classical Logics, 8(4), 1998.
  L. Vila and L. Godo. On fuzzy temporal constraint networks.
Mathware and Soft Computing, 1994.
The mathematical tool of partitionings, augmented with labels, together with suitable operations, is presented as a useful tool for unifying the treatment of many different periodic temporal notions. This ranges from the basic time units in calendar systems until concrete timetables which are dened for a certain period, usually a week, and then get repeated every week. The characteristics of the concrete partitioning is encoded in the two functions which map coordinates to partitions and vice vers. All other operations are generic. I proposed ve different ways to specify a partiProceedings of the 11th International Symposium on Temporal Representation and Reasoning (TIME04)
1530-1311/04 $20.00  2004 IEEEFirst Order Modal Temporal Logics with Generalized Intervals
Gkrard Becher
GREYCCNRS URA
1526
Universitk de Caen
F-14032 Caen Cedex email : becher@info.unicaen.fr
Abstract
The class of our temporal logics includes logics based on points, on standard intervals and on unions of convex intervals. More precisely, we define a firstorder modal logic L ( S ) for each finite subset S of the positive integers fulfilling the following condition: all elements of S, except the element 1, must be even.
The modal operators in C(S) correspond to the ( p, 9)relations (where ( p, q ) E S x S) which are the elements of the interval algebra d(S)defined by GCrard Ligozat in. Thus, formulae in L ( S ) are interpreted over a set of generalized intervals (also named p-intervals where p E S ) whose structure is described by the relations in A ( S ). In the particular case of L ( { 2 } ),we obtain for instance a first-order extension of Halpern and Shohams propositional interval modal logic.
The plan of the paper is the following: in section 2, we recall the notions of generalized intervals and of interval algebras as defined by P. Ladkin and G. Ligozat, in section 3, we define the syntax and semantics of our logics. A translation function into B T K, preserving satisfiability and validity, is given in section 4 and examples are proposed in section 5.
Following the work of G. Ligozat who described the interval algebras d(S) whose elements are relations on generalized intervals, we propose a class of first order modal temporal logics where the possible worlds are points, standard intervals or unions of convex intervals and where the accessibility relations are elements of A ( S ). These logics have standard syntax and semantics with the unique exception that, whereas predicates are generally interpreted on intervals, the terms are always interpreted on points which are considered as elements of the intervals. W e address also the problem of automated reasoning in such logics and define for that sake a satisfiability and validity preserving translation function into a standard two-sorted first order logic.
1 Introduction
Bacchus, Tenenberg and Koomen proposed in   a standard two-sorted first-order logic, denoted B T I I, with temporal and non-temporal terms, subsuming a number of other logics. The immediate advantages of such a logic are a clear semantics, a well-studied proof theory and a large degree of expressiveness. However, we think that one has to pay for that expressiveness by a certain verbosity. To see that, one may compare for instance the modal formula 4 in figure 4 with its translation into BTK given in section 5.
We present here a class of modal temporal logics which are, although less expressive than B T K, much more concise. Indeed, whereas modal logics, due to their natural concision, are well suited for knowledge representation, standard first order logics have the advantage of well-known proof theories. For that reason we define for the sake of reasoning a translation function from our logics into BTK preserving satisfiability and validity. A sound and complete proof method in the target logic is given for instance in. So, we cumulate advantages of concise languages and a standard proof theory in the target logic.
Although we assume that the reader is familiar with relation and interval algebras, we recall here the basic notions. For more details, see,   and.
2.1 Relation Algebras
Let A be an arbitrary set with three distinguished elements 0, 1 and l,let +,. and ; be binary operations on A and let - and  be unary operations on A ; the structure A = ( A, +, -, 0, 1, ;,, 1) is called a relation algebra with universe A if and only if s, 0( A, +,., --, 0, 1) is a Boolean algebrae(z ; y ) ; z = 2 ; (y ; z ) for any 2,y, z E Ae z
170
0-8186-7528/96 $5.00 0 1996 IEEE
The Interval Algebras A ( S )
2
; 1 = 1 ; 2 = 2 for every
2
EA
Labels(01, (111(2)b,  ltP, Figure 1: The labeled elements of A ( l, 2 )
0the formulas (x ; y). z = 0, (Z ; z ). y = 0 and(x ; 5). z = 0 are equivalent for any x,y,z E A
POIand intervals: we say that a point x1 belongs to such a p-interval (511,..., yp) if either p = 1 and x1 = y1 or else there is an odd integer IC such that 1 5 k < p and *
Yk
A relation algebra is proper if its universe is a set of binary relations on a set B (called the base of the algebra), and its operations coincide with usual settheoretic operations on these relations, in particular ; is the composition, "transposition and 1' the identity relation. A representation of a relation algebra A is an isomorphism from A onto a proper relation algebra
23. A partial ordering 5 is defined on the universe A of a relation algebra A by x 5 y iff x y = x. An utom is a minimal nonzero element in that ordering.
An algebra is atomic iff every nonzero element has an atom below it. Every finite algebra is atomic. In order to determine an atomic relation algebra, it is sufficient to specify its atoms, the identity element 1' and the two operations ; and ".
Well-known examples of representable atomic relation algebras are the Point Algebra PA (with exactly
3 atoms) and the Interval Algebra IA (13 atoms corresponding to the 13 Allen's relations [l]). Both are described in. It is also proved there that the representations of PA and IA are unique up to isomorphism.
2.2
21
< Yk+l.
Relations between p-intervals and q-intervals, called(p,q)-relations, are defined in   as non decreasing sequences of p integers between 0 and 2q, where each odd integer occurs at most once'. Such a relation
01
2
3
4
5...
29-1
Y3...
Yn
29
8
Y1
Y2
Figure 2: The regions determined by a q-interval. indicates for each point zi (1 5 i 5 p) of the pinterval (21,..., xp) the region of T containing this point. There are 29 1 regions determined by the qinterval ( y ~.,.., yq) and numbered from 0 to 2q (figure
2), points which are less than y1 are in region 0, y1 is the unique point in region 1, points between yl and y2 are in region 2, and so on...
If S is any non empty subset of the positive integers, the set of all (p, q)-relations, where (p, q ) E S x S, is cadled IT(S). One can find also in 1141 the definition of a transposition operation, globally defined on n[(S),of a composition operation defined on II(S) with values in P(rI(S))and of a unit element denoted
1's. It is also proved that P(IT(S)),with its usual boolean structure and the above operations, is a representable atomic relation algebra A(S) with n(S) as set oE atoms. It is a proper relation algebra if T is the set of rational numbers Q.Moreover, that proper algebra lis the unique (up to isomorphism) representation of A(S) on a denumerable base.
+
Interval algebras
GCrard Ligozat defines in   the notion of generalized intervals (or n-intervals) as increasing finite sequences of n points in some linear order T. Points are 1-intervals, standard intervals are 2-intervals, 3intervals can be seen for example as a point preceding a classical interval, and so on. Although the following results are proved by Ligozat for arbitrary pintervals, throughout this paper we restrict ourself to pintervals where p = 1 or p i s even. Such generalized intervals correspond either to points or to non convex intervals in the sense of Ladkin [ll]. This restriction is necessary because we want to be able to define without any ambiguity the following relation between pointsla different, although equivalent, definition can be found in ~31
171
For example A( 1) is the Point Algebra PA, d ( 2 ) the Interval Algebra IA, and A(1,2) is an algebra with 26 atoms expressing all possible relations between points and points, points and intervals, intervals and points or intervals and intervals. For more convenience, we have labeled each element of A ( 1, 2 ) in figure 1. For instance, the relation labeled <p is the element (1,2) of II(2, l ),that is a relation between a 2-interval ( a, b ) and a point p. This point determines three regions abe nested and may occur in any position where an existential or universal quantifier may occur. The following is an example of a formula in C(2)
Vz Married(s)
1b
Semantics
The semantics of L(S)is nearly a classical Kripke semantics except that the interpretation of a flexible function symbol is not constant over a world. This is due to the fact that even if we consider a temporal logic where predicates range over intervals, it is not reasonable to interpret terms on intervals too. What about the interpretation of the french President on the interval 1995 ? Hence, we always require that terms are interpreted on points. Formally, an interpretation
I for C(S) is given by:bp in A( 1, 2).numbered 0, 1 and 2. The left bound a of the 2interval is in region 1 (that is on p ) whereas the right one is in region 2 (figure 3). Thus, the label <p recalls that ( a, b ) has p as beginning point. In a symmetrical way, the relation labeled bp is a relation between a point p and a 2-interval ( a, b ) expressing that p is the beginning point of ( a, b ).
3
BacheZor(s)
+
2
3.2
Figure 3: The relation
1which says that if someone is married in the current interval of time io, then it will not be bachelor in every interval il such that io meets or precedes il. Once again, the ( p, q)-relations in d ( 2 ) are labeled with symbols. Thus the two relations m-for meets-and p-for precedes-are respectively the (2,2)-relations( 0, l ) and (0,O) in A(2) whereas the relation m p is their union.c------.
0
+- [ m + p ]
Temporal Logic associated to A(S)
0
In this section, we define the syntax and semantics of a first order temporal modal logic, denoted L ( S ), corresponding to a given relation algebra A(S), where S = (121,..., n,.} and for all i, 1 5 i 5 r, n, is either even or equal to 1.
Usually, modal logics are interpreted in a Kripke structure which is a set W of possible worlds structured by relations corresponding to the modal operators. In C(S), these possible worlds will be n-intervals(where n E S ) and the relations will be those of A(S).
Hence, we denote these operators [z] or (z), where x E d(S). One of the p-intervals (say WO) is distinguished as the current world in which all formulae are interpreted by default. A formula like [.](a means that Q, is true in all p-intervals 201 such that WO z 201.
Equivalently, (.)(a means that there is at least one such p-interval in which Q, is true.
3.1 Syntax
The syntax is that of a standard first order modal logic on a signature which is a set of symbols S =
Uz=o,n(CrUCfU I I r UHf) where Cr and II: (resp. Cf and IIf) are the sets of rigid (resp. flexible) function and predicate symbols of arity i.
Formulae of C(S)are classical first order modal logic formulae, constructed over the set of modal operators {[x],(x) I z E A ( S ) }. Modal operators canthe canonical representation of d(S) with base
Bs = U E S { (El,2 2,... I.p) E C
P I 3 1 < 22 <
*
0
0
0
0
0
*.< x p Ta non empty set D called the domain of I for every rigid function symbol f in EL a function f, : Dn c--) D for every rigid predicate symbol P in IIL a function
: ~n -+ {0,1).
Efor every flexible function symbol f in EL a function
: Q x ~n c--) D
Efor every
- flexible predicate symbol in IIL a function FI : Bs x Dn I-+ ( 0, l )
Given an interpretation I, a point t E Q and a valuation of the variables v, the interpretation of a term
U with respect to I, t and v is denoted I I u ~ ~  ~.
The truth value of a formula F (with respect to the interpretation I, a p-interval w and a valuation v ) is deduced from the truth values of its subformulae in the standard way. For atomic formulae, we say that( I,w,V )
P (u ~.,., tin) iff for every point t which belongs to w, ~ ( l l u l l f  t  v.,.., I I u ~ ~ ~  ~  ~=) 1 if P is rigid or I/ullltY,..., I I u ~ ~ ~  ~  ~=
) 1 if P is flexible.
E(, 172
It is noteworthy that all interpretations of a given language C(S) share the same canonical representation of d(S). Moreover, a certain pinterval will be distinguished in the base Bs of d(S) as representing the current world, denoted by WO. Both notions of consistency and validity will be relative to this current world.take in account the theory which describes the structure of the underlying set of points.
This is why all proofs in the target logic are made with the theory CO of the linear ordering on the rationatl as background theory. A resolution based proof method in the theory of dense linear ordering without endpoints can be found in   and 191. There is also in   a more general work by Bachmair and Ganzinger inproving Hines work. Finally we describe in [SI and   a connection based proof method in the frame of the linear order theory which can be used for reasoning in the target logic.
Definition 3.1 Let L ( S ) be a language as described above, and let
WObe a distinguished pinterval, wherep E S. A formula F E,C(S) is satisfiable iff there exists an interpretation I and a valuation v such that( I,W O, v) F. F is valid iff ( I,W O,v) F for every interpretation I and valuation v.
4.1
There is no particular restriction about the choice of W O,although we think that an ordinary 2-interval (if available) is the most natural one. It can be noticed that the semantics of the formulae depends on this choice of WO. For example, in,C( 1,a), if WO is a 2interval, then a formula like [n]F,where T is a (1,l)relation, is semantically incorrect.
4
Translation
In this section we consider the problem of reasoning in a logic C ( S ). instead of developing complex direct methods, we prefer, in the spirit of   or, to translate the formulae of L ( S ) into a classical first order logic where we dispose of a variety of well-known proof methods. For that sake, we use a traditional relational translation, expressing the accessibility relations between the possible worlds by first order predicates.
Ligozat indicates in  that the fact that a pinterval w = ( X I,...,xp)and a q-interval w = (y1,..., y p ) are in a (p,q)-relation R can be expressed by a formula E ( R,w, w) where the predicates = and < are acting on the terms 21,..., xp,y1,..., yp. In the same spirit, we can write with these same predicates the formula B ( t, w) expressing that a point t belongs to a given p-interval W.
4.2
< 22
A 2 2 = yi A yi
Definition 4.1 If t is a temporal term (that is a rational or a temporal variable) and U is a term in a language C(S), we define t r ( t,U ) recursively by:
0
0
0
< YZ
On the other hand, the fact that a point t belongs to a 4-interval w = (xi,xZrx3,x4) corresponds to the formula B ( t, 20) :
21.< t < 22 vx3t r ( t,x) = x if x is a variable t r ( t, f ( U l, *.., % ) )= i f f is rigid t r ( t,f ( %,..., U,)) if f is flexiblef(tT(t,Ul),...,tr(t,Un))
= f ( t,t@, w ),., tr(4 Un))
*
In the previous definition, the first argument of the translation function is always a temporal point.By opposition, the translation function for formulae has a tuple of temporal terms (corresponding to a p-interval) as first argument.
Definition 4.2 Let w = ( t l,...,t P ) be a tuple of temporal terms (rational numbers or temporal variables), the function T r ( w,F) where F is a formula of C(S) is recursively defined by:
<t < 24
Thus, all accessibility relations between the possible
0
T r ( w,P(u1,..., U, ) ) = V t B ( t, w)
+ P ( t r ( t,U I ),...,t r ( t,tin)) if P is rigid and at least one flexible symbol occurs in the terms ~ 1..,., un.worlds can be expressed in a first-order formalism withaid of the predicates =) and The translation function
We distinguish the translation function for terms and for formulae.
Exemple 4.1 The fact that a 2-interval w = ( 2 1, x ~ ) meets a 2-interval w = ( y l, yz) corresponds to the formula E ( m,w, w):
21
The target logic
It is a two-sorted first-order logic like that described in   with temporal terms and non-temporal terms.
In our case, temporal terms (terms of sort T ) are created by the translation and correspond to temporal points or bounds of the temporal intervals, whereas non- temporal terms (of sort U ) correspond to those which already exist in the source logic. Eventually, there may be more than one non-temporal sort. The arity of the symbols is not fixed, nor is the number of temporal subterms in a term. More precisely, this means that the same predicate symbol may exist in the signature with a sort Tn x U C ) Boo1 for different values of n.
<. Indeed one has to
173
[I1]
Vx
Bachelor(x)
[I1]
Vx
7
 M
VxVy
E + hJ
1
1
Bachelor(x)
Wed(a,y )
1
+ [qBachelor(x)
+ [d
Bachelor(x)
1
+ [b](Bachelor(x)A
Bachelor(y))
Bachelor(president (franc.))
[f] 3 x 3 ~ ( i ) ( x= preszdent(frunce)) A Wed(x,y)
[i]
3y
Wed(presadent(france),y)
Figure 4: Some formulae in C(1,2)
0e
0
T r ( w, P ( u l,..., U, ) ) = P(u1,...,u n ) if P is rigid and only rigid symbols occur in the terms u 1,..., un.whose domain is the disjoint sum of the domain of I and of the set Q of rational numbers. The existing interpretation functions are left unchanged and the predicates = and  < are interpreted respectively by equality and the strict ordering relation on Q.
For every formula F in C(S), for every q-interval w = ( 2 1,..., x q ) in Bs and for every valuation v, we prove that { I,w, v} F iff {I,u[t1/x1,..., t q / x q ] )
T r ( ( t 1,..., t q )F, ) where u [ t / x ]denotes the valuation of variables which is everywhere identical to U except for the variable t where v [ t / x ] ( t =
) x.
Thus, if we consider a satisfiable formula F in C ( S ), by definition there will be an interpretation I and a valuation U such that ( I,W O, v)
F which is equivalent to (I, ~ [ ~ I / Y.I.,.,t q / y p l ) I= T r ( ( t 1,..., t,), F ) where ( t l,...,t P ) is a tuple of variables and W O =, y p ) is the current world. Since the variables t l,..., t, are free variables in T r ( ( t 1,..., t P )F, ), this is equivalent to say that {I, v}
T r ( ( y 1,..., y,), F).
Hence Tr(w0,F ) is 7-satisfiable.
In the other direction, if Tr(w0,F) is 7-satisfiable then there is a countable first-order interpretation I whose temporal part is a model of 7- and a valuation
U such that (P, v)
Tr(w0,F). Since all countable models of 7 are isomorphic, one can construct an interpretation I with temporal domain Q and thus an interpretation I for L ( S ) satisfying F. The remainder of the reasoning is as above.
The preservation of the validity is a simple consequence of the preservation of satisfiability and of the 0 fact that Tr(wo,-.F)
= 1T r ( w o, F ).
T r ( w,P ( U 1,..., u n ) )= vt B ( t, w) -+ P ( t 1,..., t,, t r ( t, u l ),..., t r ( t, u, ) ) if P is flexible and at least one flexible symbol occurs in the terms u1,..., un.
Tr(w, P(U1,...,U,)) = P ( t 1,...,t,, u1,...,U,) if P is flexible and only rigid symbols occur in the terms u1,..., un.
0
T r ( w,F A G ) = T r ( w,F) A T r ( w,G)
0
T r ( w,1 P ) = i T r ( w,F )
0
0
T r ( w,[TIP)= v t i...Vth E ( T,w,20) -+ Tr(w, 8) where T is a ( p, q)-relation, t i,...,th are q new variables and w= (ti,...,td) is a q-interval.
T r ( w,( n ) F )= 3ti...3tb E ( n,w,w) A Tr(w, F) where T is a ( p, q)-relation, t i,..., th are q new variables and w= ( t i,..., t i ) is a q-interval.
Given a logic C(S),the result of the translation of a formula F of L ( S ) is the formula Tr(wo,F ) where WO is the current world.
P r o p o s i t i o n 4.1 Let F be a formula zn C(S). F as satzsjiable (resp. d a d ) af and only zf T r ( w 0,F ) zs 7satasjiable (resp. 7-valad) where 7 2s the theory of dense lanear order wathout endpoants.
Proof.
We indicate here the sketch of the proof.
The complete proof in the particular case of L(2,2) can be found in. The generalization to C(S) is straightforward.
Given an interpretation I of C(S), we construct a first-order interpretation I of the target language
5
An example
We consider here the language L ( l, 2 ) with 26 atomic modal operators corresponding to the 26 atoms in II(1,2) labeled as in figure 1.
In the example displayed in figure 4, we shall ab174
+ + + f + + +breviate by l1 the relation p m o d s
1I s d f 5 +h f i and consider that frunce is a rigid constant symbol whereas president is a flexible unary function symbol.
In C(1,2), it is possible to express the truth of a predicate on an interval as well as at a point. For instance formulae (1) and (2) say that if the state to be bachelor is true (resp. false) on an interval, then it true (resp. false) at all of its internal points2. This is the poznt-downward-hereditary property described in. In formula (3), we say, supposing for sake of simplicity that we are in a rather rigid society, that if two persons get married, then both were bachelor at all points preceding strictly the instant of their union.
Notice that we consider here the wedding as a punctual event. Next, we assert in formula (4) that until now, there was no bachelor President in France.
We can then deduce from these four formulae that no french President get ever married during his presidency (formula (5)). However, this cannot be expressed in,C(1,2) without the use of equality. We let the reader check that the formula (6) cannot be deduced from formulae (1) to (4) because it is perhaps possible that a guy became President and wedded at the same instant.
As an example of translation, we give here the result of the translation of the formula 4,where we consider that the current world is the 2-interval ( 0, l ).
+ + + + + +it is probable that a logic in which very short intervals can be distinguished from large intervals by some attribute would be even more suitable for natural langua,ge applications.
References
J. F. Allen, Maintaining knowledge about temporal interval. Communications of the A CM, Vol. 26(ll), pp. 832-843, 1983.
Y. Auffray and P. Enjalbert. Modal theorem proving: an equational viewpoint. Logic and Computatzon,Vol.
2(3), pp. 247-295, 1992.
F. Bacchus, J. Koomen, and J. Tenenberg. A nonreified Temporal Logic. Artzficial Intellzgence, Vol.
52, pp. 87-108, 1991.
L. Bachmair and H. Ganzinger. Rewrite techniques for transitive relations. Technical Report MPI-I-93249, Max-Planck-Institut fur Informatik, 1993. Short version in Proc. LICS94.
G. Becher. Cyclic Connections. To appear in Proc. of the Fifth Workshop on Theorem Proving wzth Analytic Tableaux and Related Methods, May 1996.
G. Becher. Demonstration Automatique en Logique
Temporelle et Algorithmes dE- Unification Rigzde.
PhD thesis, UniversitC de Caen, 1995.
W. Bledsoe and L. Hines. Variable Elimination and Chaining in a Resolution-based Prover for Inequalities. In S. Verlag, editor, Proc. 5th Conference on
Automated Deduction, pp. 70-87, Les Arcs, France, 1980.
Y. J. Halpern and Y. Shoham. A Propositional Modal
Logic of Time Intervals. In Proceedings of the 1st
IEEE Symposium on Logic In Computer Science, pp.
279-292. Computer Society Press, 1986.
L. M. Hines. Completeness of a Prover for Dense
Linear Orders. Journal of Automated Reasoning, Vol.
8, pp. 45-75, 1992.
B. J6nsson. Boolean Algebras with Operators 11.
American J. Mathematics, Vol. 74, pp. 127-162, 1952.
P. B. Ladkin. Time Representation: A Taxonomy of Interval Relations. In Proceedengs of AAAI-86, pp.
360-366, 1986.
P. B. Ladkin and R. D. Maddux. On Binary Constraint Problems. Journal of the ACM, May 1988.
G. Ligozat. Weak Representations of Interval Algebras. In Proceedings AAAI, pp. 715-720, 1990.
G. Ligoxat. On Generalized Interval Calculi. In Proceedzngs AAAI, pages 234-243, 1991.
H.-J. Ohlbach. Translation Methods for Non-Classical
Logics: an Overview. Bull. of the IGPL, Vol. 1(1),pp.
69-89, 1993.
Y. Shoham. Temporal Logics in AI: Semantical and Ontological Considerations. Artificial Intelligence, Vol. 33, pp. 89-104, 1987.
< t 2 5 0 -+ (Vt ti < t < t 2 -+
-, Bachelor(t l ?t2, president( t, f r a m e ) ) )
Conclusion
QtlQt2 t i
6
We think that the logics proposed here are suitable for a large class of applications, including natural language applications. Indeed, they are less expressive than full first order logic, but they are much more concise. In fact, their expressiveness depends obviously on S. A reasonable choice would be for instance
L ( l, 2 ),since it is then possible to assert the truth of predicates on standard 2-intervals as well as on points.
More sophisticated logics can be considered as well, but a concrete limitation will be the increasing number of modal operators.
However a number of problems are still remaining, in particular it is not possible in our logics to express that facts or events occur on a particular absolute date. We are currently working on a possible extension, where suclh absolute dates would correspond to indexed modal operators. An other challenging problem is the absence of the notion of size of the intervals:
2The relation
2(for instde) is a relation between points and 2-intervals which is true if the point is inside the 2-interval. b is the relation before between points.
175On First-Order Query Rewriting for Incomplete
Database Histories
Alexandre Decan? and Jef Wijsen
Universite de Mons-Hainaut, Mons, Belgium
Abstract. Multiwords are defined as words in which single symbols can be replaced by nonempty sets of symbols. Such a set of symbols captures uncertainty about the exact symbol. Words are obtained from multiwords by selection a single symbol from every set. A pattern is certain in a multiword W if it occurs in every word that can be obtained from W. For a given pattern, we are interested in finding a logic formula that recognizes the multiwords in which that pattern is certain.
This problem can be seen as a special case of consistent query answering(CQA). We show how our results can be applied in CQA on database histories under primary key constraints.
1
Motivation
An incomplete database DB is a set of possible databases. Under the certain answer semantics, a Boolean query q evaluates to true on such an incomplete database DB if q evaluates to true on every possible database in DB; otherwise q evaluates to false.
A database that violates primary key constraints naturally gives rise to an incomplete database: every possible database is obtained by selecting a maximal number of tuples from each relation without ever selecting two distinct tuples that agree on their primary key. In this setting, possible databases are called repairs, as they are obtained by repairing constraint violations.
Recently, progress has been made in computing certain answers to conjunctive queries under primary key constraints. This article makes a first step in extending these works to database histories.
Assume a discrete, linear time scale. The following database history shows the WorksFor relation at four successive time points t0, t1, t2, t3. The primary key
Name is violated at times t1 and t2. t0 Name Company
Ed
IBM
?t1 Name Company
Ed
MS
Ed
IBMt2 Name Company
Ed
MS
Ed
IBMt3 Name Company
Ed
MS
Corresponding author. Authors address: Universite de Mons-Hainaut, Institut dInformatique, Avenue du Champ de Mars 6, B-7000 Mons, Belgium; Email: alexandre.decan@umh.ac.be.
2
To make this history consistent, we have to delete one of the two tuples at t 1, and one of the two tuples at t2. Thus, there are four repairs for this database history; one such repair is shown next. t0 Name Company
Ed
IBMt1 Name Company
Ed
IBMt2 Name Company
Ed
IBMt3 Name Company
Ed
MS
The query Did MS recruit an IBM employee? can be expressed as the existential closure of the following formula in first-order temporal logic (FOTL): 1 q0 = WorksFor(x, IBM)  #WorksFor(x, MS)
The primary key arguments are underlined. It can be easily checked that q0 evaluates to true on each of the four repairs.
We are interested in the following problem: find a FOTL query q00 such that for every (possibly inconsistent) database history HIS, q00 evaluates to true on
HIS if and only if q0 evaluates to true on every repair of HIS. Such a query q00, if it exists, is called a consistent FOTL-rewriting of q0. The interest of consistent
FOTL-rewritings should be clear: they provide certain answers on inconsistent databases, without the need for computing repairs.
It can be verified that the following query q00 is a consistent FOTL-rewriting of q0 : q00 = IBM  ({IBM,MS} until MS ) where:
IBM = y(WorksFor(x, y)  y 0 (WorksFor(x, y 0 )  y 0 = IBM))
MS = y(WorksFor(x, y)  y 0 (WorksFor(x, y 0 )  y 0 = MS))
{IBM,MS} = y(WorksFor(x, y)  y 0 (WorksFor(x, y 0 )  y 0 = IBM  y 0 = MS))
Intuitively, it is certain that some employee x moved directly from IBM to MS if in the (possibly inconsistent) database history, there is one state where x worked certainly for IBM, some later state where x certainly worked for MS, and between these two states, x was employed by either IBM or MS.
Clearly, on databases that satisfy the primary key Name, q0 is equivalent to the following query q0 : q0  q0 = IBM  #MS
The queries IBM, {IBM,MS}, and MS can be obtained by following the rewriting scheme proposed in   or. In this article, the focus is on the rewriting from q0 into q00. To capture this rewriting, we look at each employees history as a sequence; for example, Eds history corresponds to the following sequence:
WEd = hIBM, {IBM,MS}, {IBM,MS}, MS i, 1
Since we deal only with Boolean queries, each variable is understood to be existentially quantified.
3expressing that IBM holds at time t0, {IBM,MS} at times t1 and t2, and MS at t3. Any sequence w obtained from WEd by replacing each occurrence of {IBM,MS} by either {IBM} or {MS} then corresponds to a repair. All these repair sequences w satisfy q0 if and only if WEd satisfies q00.
We thus come to the following abstraction. Assume a finite alphabet. A multiword is a word over the powerset alphabet 2 \ {}. Every multiword W gives rise to a set of possible words obtained from W by selecting one representative from each set. For example, the multiword W0 = h{a}, {a, b}, {a, b}, {b}i gives rise to four possible words: aaab, aabb, abab, and abbb. A subword w is certain in a multiword if it occurs in every possible word. For example, ab is certain in W0, but aa is not. Subwords can contain variables, which are placeholders for symbols of. For example, axx is certain in W0 if either aaa or abb is certain in W0. Given a subword w (possibly containing variables), let CERTAIN(w) denote the set of multiwords in which w is certain. We are interested in the following problem: given a subword w, is CERTAIN(w) FO-definable?
The article is organized as follows. Section 2 recalls some fundamental results about FO over words. Section 3 formalizes the problem we are interested in. Section 4 gives a straightforward algorithm for deciding CERTAIN(w) if w contains no variables. The algorithm is interesting because it immediately leads to the result that CERTAIN(w) is regular, as shown in Section 5. That section also provides sufficient conditions for FO-definability of CERTAIN(w). Section 6 deals with subwords that contain variables. Finally, Section 7 concludes the article.
2
Recall
We are not aware of existing work on words with uncertain symbols. On the other hand, some fundamental results on standard words will be used in this article:
Over words, linear temporal logic has the same expressive power as FO.
A regular language is FO-definable if and only if it is aperiodic.
Recall that a regular language L is aperiodic if there exists an integer k  0 such that for all words p, u, q, p  uk  q  L if and only if p  uk+1  q  L.
3
Problem Statement
We assume a finite alphabet  = {a, b, c,...} of symbols.
Definition 1. A word of length n  0 is a sequence a1 a2... an of symbols. The length of a word w is denoted by |w|. The empty word has length 0 and is denoted by . The concatenation of words v and w is denoted by v  w. The concatenation operator naturally extends to sets S, T of words: S  T = {v  w | v  S, w  T }. A word v is a subword of w, denoted w  v, if there exist (possibly empty) words p and q such that w = p  v  q.
4
Multiwords capture the notion of inconsistency and are defined next.
Definition 2. A multiword (over ) is a sequence W = hA1,..., An i where for each i  {1,..., n}, Ai   and Ai 6=. Thus, a multiword can be conceived as a word (in the sense of Def. 1) relative to the alphabet 2 \ {}.
For the multiword W = hA1,..., An i, we define: words(W ) = {a1 a2... an | i  {1,..., n} : ai  Ai }.
If v is a word, then we define:
W certain v if and only if for every w  words(W ), w  v.
We write M for the set of all multiwords (over ).
For example, the following multiword W0 contains two uncertain positions with values {a, b} and {c, d}. Curly braces are omitted at positions that are certain; for example, {a} is written as a.
W0 = ha, b, d, a, b, c, a, {a, b}, b, d, a, b, {c, d}, a, b, c, a, bi(1)
We have words(W0 ) = { abdabcaabdabcabcab abdabcaabdabdabcab abdabcabbdabcabcab abdabcabbdabdabcab }.
The underlined positions show that abdabcab is a subword of each word in words(W0 ). Hence, W0 certain abdabcab.
For a word w, we are interested in (the complexity of) the following language:
CERTAIN(w) := {W  M | W certain w}.
In particular, we want to answer the question:
Given w, is CERTAIN(w) FO-definable?
That is, is there a FO formula w such that
CERTAIN(w) = {W  M | W |= w }, where the logic formalism is FO over words [6, p. 124]?
For example, for the alphabet  = {a, b}, multiwords can be regarded as words with symbols taken in the alphabet {{a}, {b}, {a, b}}. This gives rise to three predicate symbols P{a}, P{b}, and P{a,b}. For instance, the multiword
W = h{a}, {a, b}, {a, b}, {b}i of length 4 is represented by the first-order structure ({1, 2, 3, 4}, <, P{a}, P{b}, P{a,b} ) where < is the natural order and each
PA contains the positions in W at which A occurs: P{a} = {1}, P{b} = {4}, P{a,b} = {2, 3}.
5
The following formula defines all the multiwords that contain a subsequence among h{a}, {b}i, h{a}, {a, b}, {b}i, h{a}, {a, b}, {a, b}, {b}i,... xy(x < y  P{a} (x)  P{b} (y)  z((x < z  z < y)  P{a,b} (z)))
It can be verified that this formula defines the language CERTAIN(ab). Recall that there exists an equivalent formula in linear time logic (LTL), since over words, LTL and FO have the same expressive power.
4
Deciding CERTAIN(w)
Given w, we give a procedure for deciding membership of CERTAIN(w). The procedure uses a construction defined in the statement of Lemma 2 and its correctness is shown in Theorem 1. The decision procedure is interesting because it can be used to show that CERTAIN(w) is regular (see Section 5).
Definition 3. Let w be a word. For all (possibly empty) words p and q, if w = p  q, then p is a prefix of w, and q a suffix. If u is a word, then uw denotes the maximal suffix of u that is a prefix of w. For a set S of words, we define
S w = {uw | u  S}.
Example 1. abcdcde = cd and abc = . Clearly, w w = w.
Lemma 1. If uw = q, then (u  a)w
= (q  a)w.
Proof. Assume uw = q. We can assume a (possibly empty) word u0 such that: u = u0  q,  q is a prefix of w, and Maximality: for every suffix s 6=  of u0, s  q is not a prefix of w. www
We need to show (u0  q  a)
= (q  a). Obviously, (q  a) is a suffix of w w w(u0  q  a). Assume |(u0  q  a) | > |(q  a) |. Then, there exists a suffix s 6=  of u0 such that s  q  a is a prefix of w, contradicting the above Maximality w w condition. We conclude by contradiction (u0  q  a)
= (q  a).
The construction for deciding membership of CERTAIN(w) is described in the statement of Lemma 2. For a given multiword W = hA1,..., An i, we construct a sequence hS0,..., Sn i such that S0 = {} and for each subsequent Si, u  Si w if and only if u 6= w and u = (p  a) for some p  Si1 and a  Ai. By
Theorem 1, W  CERTAIN(w) if and only if the last element Sn is the empty set.
The construction is illustrated next for the multiword
W0 = ha, b, d, a, b, c, a, {a, b}, b, d, a, b, {c, d}, a, b, c, a, bi
6shown earlier (see equation (1) on page 4) and the word w = abdabcab.
A1 = {a}
A2 = {b}
A3 = {d}
A4 = {a}
A5 = {b}
A6 = {c}
A7 = {a}
A8 = {a, b}
A9 = {b}
A10 = {d}
A11 = {a}
A12 = {b}
A13 = {c, d}
A14 = {a}
A15 = {b}
A16 = {c}
A17 = {a}
A18 = {b}
S0 = {}
S1 = {a}
S2 = {ab}
S3 = {abd}
S4 = {abda}
S5 = {abdab}
S6 = {abdabc}
S7 = {abdabca}
S8 = {a}
S9 = {ab}
S10 = {abd}
S11 = {abda}
S12 = {abdab}
S13 = {abdabc, abd}
S14 = {abdabca, abda}
S15 = {abdab}
S16 = {abdabc}
S17 = {abdabca}
S18 = {}
Lemma 2. Let W = hA1,..., An i be a multiword. Let w be a nonempty word.
Let hS0, S1,..., Sn i be a sequence such that S0 = {} and for every i  {1,..., n}, w
Si = (Si1  Ai )
\ {w}.
Let m  {1, 2,..., n}. For every word u  words(hA1,..., Am i), either uw
Sm or u  w.
Proof. Proof by induction on m.
Basis m = 1. Let u = b  words(hA1 i) such that b 1 w (i.e. w 6= b). Then, S1 w contains (  b)
= bw.
Step. Assume w.l.o.g. Sm = {p1,..., pk } and Am+1 = {a1,..., al }. Then, Sm+1 = {(p1  a1 )w,..., (pi  aj )w,..., (pk  al )w
} \ {w}.
Let u  words(hA1,..., Am+1 i). We can assume v  words(hA1,..., Am i) and j  {1,..., l} such that u = v  aj. Two cases can occur: v  w. Obviously, u  w. v 1 w. By the induction hypothesis, v w  Sm. We can assume w.l.o.g. w i  {1,..., k} such that pi = v w. By Lemma 1, uw = (v  aj )
= w w(pi  aj ). If (pi  aj )
= w, then u  w; otherwise Sm+1 contains uw.
This concludes the proof.
Lemma 3. Let W = hA1,..., An i, w, and hS0, S1,..., Sn i be as in Lemma 2.
Let i  {1,..., n}. For every p  Si, there exists u  words(hA1,..., Ai i) such that u 1 w and uw = p.
7
Proof. Proof by induction on i.
Basis i = 1. Easy.
Step. Assume p  Si+1. We can assume q  Si and a  Ai+1 such that p = q  a.
By the induction hypothesis, there exists u  words(hA1,..., Ai i) such that u 1 w and uw = q. Then, u  a  words(hA1,..., Ai+1 i). It suffices to show w that u  a 1 w and that (u  a)
= p.
Assume u  a  w. Then necessarily, w = q  a. But then p = w, a contradiction. We conclude by contradiction that u  a 1 w. w w
By Lemma 1, (u  a)
= (q  a)
= pw. Since p is a prefix of w, w p
= p.
This concludes the proof.
Theorem 1. Let W = hA1,..., An i, w, and hS0, S1,..., Sn i be as in Lemma 2.
Then, W  CERTAIN(w) if and only if Sn = {}.
Proof. If part. Assume Sn = {}. Lemma 2 implies that W  CERTAIN(w).
Only-if part. Assume Sn 6= {}. Lemma 3 implies that W 6 CERTAIN(w).
As a small optimization, it is not hard to verify that Theorem 1 remains valid if every Si that contains  is replaced by {}. Formally, define:

{} if   Si ; bSi c =
Si otherwise.
Then, the sequence hS0,..., Sn i defined by S0 = {} and for each i  {1,..., n}, w
Si = b(Si1  Ai )
\ {w}c satisfies: W  CERTAIN(w) if and only if Sn = {}.
5
FO-definability
Assume a nonempty word w over alphabet. We show that CERTAIN(w) is regular and, under certain conditions, aperiodic. Theorem 1 suggests the following construction of a deterministic finite automaton that accepts CERTAIN(w).
Let P 0 be the set of prefixes of w, and let P = P 0 \{, w}. We define DFA (w) as the following deterministic finite automaton (Q,, S0, F, ):
1. The finite set Q of states is 2P  {{}}. Note that {} is the only state containing .
2. The alphabet  is the powerset alphabet 2 \ {}.
3. The start state is S0 = {} and F = {} is the set of accepting states.
4. The transition function  : Q    Q is defined by:(S, A) = b(S  A)w
\ {w}c.
For example, Fig. 1 shows DFA (abb) for the alphabet  = {a, b}. Theorem 1 and the construction of DFA () immediately lead to the following result.
8
{a, b}
{a, ab}
{b}
{b}
{a}
{a}
{a, b}
{b}
>{}
{a}
{a}
{a}
{b}
{ab}
{b}
{a}
{a, b}
{a, b}
{a, b}
Fig. 1. DFA (abb) with  = {a, b}.
Theorem 2. Let w be a nonempty word and W = hA1,..., An i a multiword(both relative to the alphabet ). Then, W  CERTAIN(w) if and only if DFA (w) accepts W. Hence, CERTAIN(w) is regular.
A regular language is FO-definable if and only if it is aperiodic. Since our driving motivation is consistent FO-rewriting, we are interested in aperiodicity results for CERTAIN(w). The following theorem shows that CERTAIN(w) is aperiodic if the first (or the last) symbol of w occurs only once in w. Our proof technique explicitly relies on the condition that the first (or the last) symbol of w is unique. This uniqueness condition is not necessary for FO-definability, however; for example, CERTAIN(aa) is FO-definable. We conjecture that CERTAIN(w) is aperiodic for any word w.
Theorem 3.
1. If the last symbol of w occurs only once in w, then CERTAIN(w) is aperiodic.
2. If the first symbol of w occurs only once in w, then CERTAIN(w) is aperiodic.
Proof. We prove the first item; the proof of the second item is symmetrical. Let w = w0  a where a does not occur in w 0. Let k = |w|. It suffices to show that for all multiwords P, U, Q:
P  U k+1  Q  CERTAIN(w) if and only if P  U k+2  Q  CERTAIN(w).
That is, for all multiwords P, U, Q:
P  U k+1  Q 1certain w  P  U k+2  Q 1certain w.
Let U = hA1,..., An i. The proof is obvious if n = 0. Next assume n > 0.
9
Assume P  U k+1  Q 1certain w. We can assume the existence of p words(P ), u1,..., uk+1  words(U ), and q  words(Q) such that the word m = p  u1  u2...  uk+1  q satisfies m 1 w. Two cases can occur:
1. The symbol a does not occur in u2...  uk+1. Let m0 be the word obtained from m by duplicating the subword u2 as follows: t1s1
}|
{ z }| { z m0 = p  u1  u2  u2...  uk+1 q
{z
}
| t2
Assume m0  w. Since m 1 w, any subword w of m0 must start in s1 and end in t1. Since |w| = k, w must actually end in t2. But then a must occur in u2...  uk+1, a contradiction. We conclude by contradiction that m0 1 w.
Since m0  words(P  U k+2  Q), P  U k+2  Q 1certain w.
2. a occurs in u2...  uk+1. Then, we can assume a word v with |v  a| = |U | and words o and r such that: m=povarq
Let m0 be the word obtained from m by duplicating the subword v  a as follows: t3s3z }| { z }| { m = p  o  v  av  a  r  q
0
Assume m0  w. Since m 1 w, any subword w of m0 must start in s3 and end in t3. But then w contains two occurrences of a, a contradiction.
We conclude by contradiction that m0 1 w. It is easy to verify that m0 words(P  U k+2  Q). It follows P  U k+2  Q 1certain w.
Assume P U k+2 Q 1certain w. We can assume p  words(P ), u1,..., uk+2 words(U ), and q  words(Q) such that the word m = p  u1...  uk+1  uk+2  q satisfies m 1 w. Let m0 be the word obtained from m by omitting the subword u1 as follows: t4s4
}|
{ z}|{ z m0 = p  u2...  uk uk+1  uk+2  q
| {z } t5
Clearly, m0  words(P  U k+1  Q). Two cases can occur:
1. m0 1 w. Then, P  U k+1  Q 1certain w.
10
2. m0  w. Since m 1 w, any subword w of m0 must start in s4 and end in t4.
Since |w| = k, w must actually end in t5. Then a must occur in u2...  uk.
We can assume a word v with |v| = |U | and words o and r such that: m = p  u1  o  a  v  r  q
Let m00 be the word obtained from m by omitting the subword v as follows: s6t6z }| { z}|{ m00 = p  u1  o  a  r  q
Assume m00  w. Since m 1 w, the subword w of m00 must start in s6 and end in t6. But then w contains two occurrences of a, a contradiction.
We conclude by contradiction that m00 1 w. It is easy to verify that m00 words(P  U k+1  Q). Consequently, P  U k+1  Q 1certain w.
This concludes the proof.
Since aperiodic regular languages are expressible in FO, we have the following result.
Corollary 1. If the symbol a does not occur in w, then CERTAIN(a  w) and CERTAIN(w  a) are FO-definable.
6
Words With Variables
We define v-words as words in which variables can replace symbols. These variables are placeholders for symbols. For example, the v-word xax represents any word of length 3 in which the first and the last symbol are equal, and the second symbol is a.
We assume a countable set vars = {x, y, z, x1, y1, z1,...} of variables disjoint from the alphabet.
Definition 4. A v-word is a sequence s1 s2... sn where for each i  {1,..., n}, si    vars. The notions of length and concatenation (see Def. 1) naturally extend to v-words.
The relation  is extended as follows. A valuation is a total function  : vars     that is the identity on. For the v-word v = s1 s2... sn, we define (v) = (s1 )  (s2 )...  (sn ). Note that if v contains no variables (i.e. v is a word), then (v) = v. If w is a word and v a v-word, then we define: w  v if and only if for some valuation, (v) is a subword of w.
The relation certain directly carries over to v-words: if W is a multiword and v a v-word, then W certain v if and only if for every w  words(W ), w  v.
The problem statement in Section 3 carries over to v-words. For example, CERTAIN(xx) contains some multiword W if each w  words(W ) contains two successive occurrences of the same symbol. Assume a binary alphabet  =
11
{a, b}. Clearly, CERTAIN(aa)  CERTAIN(bb)  CERTAIN(xx), and the inclusion is strict: for W1 = ha, {a, b}, bi, we have W1 6 CERTAIN(aa)  CERTAIN(bb) and W1  CERTAIN(xx).
Theorem 4 shows that CERTAIN(xx) is not FO-definable.
Theorem 4. Let  be a finite alphabet with ||  2. Then, 1. CERTAIN(xx) is in P;
2. CERTAIN(xx) is not FO-definable.
Proof. For the first item, let W = hA1,..., An i. We construct, in polynomial time, a sequence hB1,..., Bn i where B1 = A1 and for each k  {2,..., n}, {} if Bk1 = {}
Bk = Ak \ Bk1 if |Bk1 | = 1
Ak otherwise
It is easy to show, by induction on increasing j, that for each j  {1,..., n}, Bj = {a  Aj | hA1,..., Aj1, {a}i 1certain xx}.
Then, W  CERTAIN(xx) if and only if Bn = {}.
For the second item, for every i  0, let i times
}|
{ z
Wi = h{a}, {a, b},..., {a, b}, {b}i.
It is easy to verify that Wi  CERTAIN(xx) if and only if i is odd. The latter condition is not FO-definable.
7
Conclusion
Every multiword defines a set of possible words. A subword w is certain in a multiword W if it occurs in every possible word of W. Given w, a significant question is whether CERTAIN(w), i.e. the set of multiwords in which w is certain, is FO-definable. We showed the following results:
1. CERTAIN(w) is regular if w is variable-free.
2. CERTAIN(w) is FO-definable if w is variable-free and the first or the last symbol of w occurs only once in w.
3. CERTAIN(xx) is not FO-definable.
These results are useful in consistent first-order rewriting under primary keys in historical databases. For example, our results imply that the following FOTL query q1 (Did some employee remain in the same company for two successive time points?) has no consistent first-order rewriting: q1 = xy(WorksFor(x, y)  #WorksFor(x, y)).
12
On the other hand, the following FOTL query q2 (Did MS recruit an IBM employee who had worked for IBM for more than k time instants? ) has a consistent first-order rewriting: q2 = x(WorksFor(x, IBM) #1 WorksFor(x, IBM)...
#k WorksFor(x, IBM)  #k+1 WorksFor(x, MS)), i timesz }| { where #  = ##... #. Moreover, there exists an effective procedure for constructing a consistent first-order rewriting of q2. This follows from Theorem 3 and the fact that the translation from an aperiodic regular language into FO is effective. So far, we have not studied algorithmic simplifications that may apply in our framework.
The results presented in this article are preliminary. In particular, we are currently addressing the following tasks: i
1. Show the conjecture that CERTAIN(w) is FO-definable if w is variable-free.
2. Show the conjecture that CERTAIN(w) is regular for any v-word w.
3. Find a syntactic characterization of the v-words w for which CERTAIN(w) is FO-definable.
References
1. M. Arenas, L. E. Bertossi, and J. Chomicki. Consistent query answers in inconsistent databases. In PODS, pages 6879. ACM Press, 1999.
2. A. Fuxman and R. J. Miller. First-order query rewriting for inconsistent databases.
J. Comput. Syst. Sci., 73(4):610635, 2007.
3. D. M. Gabbay, A. Pnueli, S. Shelah, and J. Stavi. On the temporal basis of fairness.
In POPL, pages 163173, 1980.
4. L. Grieco, D. Lembo, R. Rosati, and M. Ruzzi. Consistent query answering under key and exclusion dependencies: algorithms and experiments. In O. Herzog, H.J. Schek, N. Fuhr, A. Chowdhury, and W. Teiken, editors, CIKM, pages 792799.
ACM, 2005.
5. J. A. W. Kamp. Tense Logic and The Theory of Linear Order. PhD thesis, University of California, Los Angeles, 1968.
6. L. Libkin. Elements of Finite Model Theory. Springer, 2004.
7. R. McNaughton and S. Papert. Counter-free Automata. MIT Press, Cambridge, MA, 1971.
8. M. P. Schutzenberger. On finite monoids having only trivial subgroups. Information and Control, 8(2):190194, 1965.
9. J. Wijsen. On the consistent rewriting of conjunctive queries under primary key constraints. In M. Arenas and M. I. Schwartzbach, editors, DBPL, volume 4797 of Lecture Notes in Computer Science, pages 112126. Springer, 2007.Distributed States Logic
Carlo Montangero
Laura Semini
Dipartimento di Informatica, Universita di Pisa, monta,semini @di.unipi.it

Abstractexample is the computation below, where the oblique arrow denotes a communication.
We introduce a temporal logic to reason on global applications. First, we define a modal logic for localities that embeds the local theories of each component into a theory of the distributed states of the system. We provide the logic with a sound and complete axiomatization. Then, we extend the logic with a temporal operator. The contribution is that it is possible to reason about properties that involve several components in a natural way, even in the absence of a global clock, as required in an asynchronous setting.
1. Introduction
The current trend towards global computing needs software that works in an open, concurrent, distributed, high latency, securitysensitive environment. Besides, this software must be reliable, scalable, and shipped today. In response to the challenges posed by so demanding requirements, there is an increasing interest in the seamless integration of asynchronous communication in programming, coordination, and specification languages. Indeed, message passing, eventbased programming, callbacks, continuations, dataflow models, workflow models etc. are ubiquitous in global computing. Notable examples in this direction are the delegatebased asynchronous calling model of the Microsoft.NET Common Language Runtime liin Polyphonic C#. As another example, braries, and Oikos tl   deals with asynchronous communications in coordination and specification languages.
As a contribution to the response to the new challenges, we are developing YALL, an extension of temporal logic to deal with distributed systems. YALL has operators to name system components and to relate, causally, properties holding in distinguished components, in an asynchronous setting. A typical YALL formula might be: m(1) m LT nfiffff





fl
fl

fl
fl
fl





fl
fl
fl
fl
We proceed in two steps. First, we define DSL (Distributed
States Logic), a modal logic for localities that embeds the theories describing the local states of each component into a theory of the distributed states of the system. There is no notion of time or state transition at this stage. DSL has a sound and complete axiom system. Then, we define YALL by adding temporal operators. Since DSL carries over all meaningful propositional rules, like and simplification, in such a way that they can be exploited orthogonally to temporal operators, the exploitation of the local theories becomes smooth and robust, while proving distributed properties. The final contribution is that in YALL it is easy to reason about properties that involve several components, even in absence of a global clock, as required in an asynchronous setting.
The major problem with DSL is the frame structure. The usual choices to build a Kripke model for formulae like (1) to be: are to consider the set of worlds

) the set of the states of a computation, i.e. the union of all the states of the system components, like the circles in the following figure. This approach was taken in.






fl


fl
fl
"
#


where operator LT is similar to Unitys (leads to), and m and n express locality. Formula (1) says that a property holding in component, causes properties and to hold in future states of components and, respectively. An








!



fl

fl

fl
fl

fl
The problem of this choice is that it is not possible to reason on logical relations between formulae like the premises or the consequences of (1). In particular, a formula like n m n(2)






which would permit to weaken the consequences of (1) would not be a legal formula, since no world can satisfy m. the conjunction n



) the set of global states, or snapshots, of the system, where each world is a set of states, one for each component.
These sets must satisfy some constraints to be coherent with the communications between the subsystems.


Proceedings of the Ninth International Symposium on Temporal Representation and Reasoning (TIME02)
1530-1311/02 $17.00  2002 IEEE


Let be the set of states of component, with for,,, and. The frame, where if and only if is a singleton set, with, satisfies the conditions (4)(6) above. We call these frames, frames on, and call the set of distributed states, from which play a central the name of the logic DSL. The frames on role in the paper, since they are used to build the models for
YALL formulae. Some examples follow. x


fl
fl
) +
+
fl, +.
0+
x
7x
7
7
Myz
;

^

7

/
Mq
Gx
M
?, A
~
xx
Mp
x
9
T


7
^


fl
)
fl
1
1
fl, fl
fl
-1
2
01
1
3
5

Tx
9g
9
P
P
P
9

p
9gg
7, ^
Examples of worlds are, while would not be a legal world.
This choice is not well suited in the case of asynchronous communication. Think of the case of property holding and holding only in states, for only in state. The following formula would be valid in the model m n(3)
7
6
7+
?
)
A, 6
;
9
1
-+
)
;
B
B, 9
=
1
=+, 
;
D
1
E
G
E
J


6px
=
7
x
yx
xbe built on and Examples. Let the set, then the frame on can be represented as:
^
xx
M
6
9
=, ^inferring a remote knowledge which is meaningless in an asynchronous setting. Moreover, it would be natural to say follows. In this case, one that world could assert that n LT m holds, if and hold in and, respectively, even though no causal relationship exists between these two states. Similar problems arise if we use most logics for distributed systems (see, for instance  ), where components communicate via some form of synchronization and, therefore, it is not possible to express the asymmetric nature of causality we are interested in.
6
-+
6
01
9
+, M
6

=
x
=
-1
9
=x
^
-1
-+
As shown in the next sections, we can get the desired properties by using the powerset of the set of all system states as the semantic domain of DSL. This choice, together with an appropriate nextstate relation, makes YALL a very expressive language, that fully meets the pragmatic expectations of a designer.
!
For the sake of readability, we often let, range over, with, and use,, m and n.,,, If we take, then the distributed state satisfies m n. m m holds, while
The implication m the converse does not. Indeed, for, and,, we have m m, but not m. In YALL, this nonequivalence is useful to specify that an event can have different future effects in a component, without constraining them to occur m m. in the same state. Finally, m mn if and The formula mn is false. In fact, only if there exists an such that, but and are disjoint. Conversely, mm is satisfiable, and it is equivalent to m. The formula m is satisfied by all the distributed states such that.

+

Mq


Q
1xx


^
^
+p
1xpx
6
i
M
6
6
=
i
=
M
=
^
6

6
9
=
V


=
V
V
V
^
^



^
+
M
6x
9
2. DSL

=

^
6
i
M
6
6
=
i
=
M
6

=t
M


=

We assume a countable set of propositional letters. The DSL formulae over a finite set of compoare defined by: nents
L
6
M

9
9
P
P
Q
P
=
M
6



9
9, P
P
P
T
9
=t
M



V
V
V
^
V
^
V
V
V
W
W
V
M
Y
V
Y
Y
[
V
Y
Y
\mi
^

Y
Y
V
Vis the propositional constant false, and m i for are unary location operators. With mi we denote the dual of mi, i.e., mi mi. With we denote true.

M
`
[b
Pa
Vc
Vbpxx
\for DSL formulae is a tuple
A model, with ranging over. The satisfy the following conditions: reachability relations
Semantics.
+
T
P
Pt
Mx
Ve
+x
Mqzy
Axiom system. DSL has the following axiomatization.f

9
V
1x
g
6ye
\
9
M
=where
Pt
+
1
Yy
P
P
9g

9k
i
9l
9naxioms of the propositional calculus m m m mm mn


V
V
V
V
^, ^
bg

b
b


V
V
7b

k

9p
l
g l
9(4)pl gb
7
bb
7

k

9p
l
gl
9p
nl
7(5)(6)
Mgn
7

k

9p
lqr
gn
Pl
9nforp g
7

G
Mq
[m
Example. Some examples of formulae that can be demm (axiom 4), rived from the axioms follow: m mm m,m m m,m m.
The semantics of DSL formulae is given by:
V
V
b


V
Vk
t
Meb

V
V
V
V
V
^
^

9
b

Vf
;




b
fk
t
Miff
9p k
Soundness is easy to see. We prove completeness.
i


Vf k
t
M
9

V
Viff not iff iff
Vf k
t
M
9


Vand and ^
\fk
t
M

9
fk
9
t
Mmi
Vfrlk
t
M
9
k
P

9lp g

V
^fk
t
M
Completeness. Let be the canonical model for DSL. We recall that worlds in 
9
9g
9
P
P
P
9g
V,  f

9lt
M
7
Proceedings of the Ninth International Symposium on Temporal Representation and Reasoning (TIME02)
1530-1311/02 $17.00  2002 IEEE
9
T
i
are maximal consistent sets of DSL formulae (DSL
MCS in the following), and that if and only. We need to show that, for all, if mi satisfies conditions (4)(6).
Cond (4). We prove:
Suppose mi. is a DSL  MCS and hence (see DSL1) mi mi. But, hence mi. Thus, by modus ponens,.
Cond (5). We prove that and imply.
It is sufficient to prove that. In fact, and are
DSL  MCS and it is not the case that, thus. Let. is a DSL  MCS and hence (see DSL1) it includes mi mi. But, hence mi.. As, we
Thus, by modus ponens, mi conclude that.
Cond (6). We prove that implies, for.. As is a DSL  MCS, it includes
Assume mi mj (DSL2). As, then mj. As

LT
k

9
Vplg
LT
LT
V

7pbk
pl
LT
LT
LT
LT
LT
LTg


7k

9pl

gl
9pl
LTg
LT
LT
V
7pb
7kl


Vbb

V
V

pkk

9plb
g
V
V
7
ppll

k

9pl
lg
9pn
7
Mgln
7lnln
Mlnln
Vp
Discussion, examples, and comparison with related work(e.g.  ) can be found in.
Acknowledgments We gratefully thank Massimo
Franceschet, Angelo Montanari, and Francesca Scozzari for interesting discussions on a draft of the paper. The work was supported by Projects Sahara and Degas.kl


V
V
b
Vbk


9pl
V
bplg

7
V
pbll
9pn
Referencesg
V
7pn
k

9plqrgn
P


7
l
9pn
G
Mqg

;
l
9pnkg

;bkb

9plbpgl
[
[
7

 l
9, thenpng, which is an absurd.p n
[
;
3. Adding time: a fragment of YALL
YALL extends DSL adding temporal operators. We consider here only operator LT, that expresses a liveness condition, and is similar to Unitys (leads to).

W
W
V
V
V
LT
M
Y
Vwhere
^
V
^p
x
9
P
Y
Semantics. YALL models are built on structures like the one at point ) above. The arrows between states denote transitions and communications, and define a causal dependency relationship. We introduce a partial order rela, where if and only if causally tion depends on. For example, in the named structure,.



^g
^
p
9g


)
+
+
9

, )
9
+

01
9
+
9, 
01
9pg

A modelis a tuple f

T x
9g
9
P
P
P
9
Eg, where 
9
9i, 
^
^
^
^prp
9
P
p
9 g

^
E
^
^prp
9
P
p
9 g
  C. Areces. Logic Engineering. The Case of Description and Hybrid Logics. PhD thesis, Univ. of Amsterdam, 2000.
  K. Chandy and J. Misra. Parallel Program Design: A Foundation. Addison-Wesley, Reading Mass., 1988.
  H.-D. Ehrich, C. Caleiro, A. Sernadas, and G. Denker. Logics for specifying concurrent information systems. In Logic for Databases and Information Systems, pages 167198.
Kluver Academic Publishers, 1998.
  R. Fagin, J. Halpern, Y. Moses, and M. Vardi. Reasoning
About Knowledge. MIT Press, 1995.
  G. Ferrari, C. Montangero, L. Semini, and S. Semprini.
Mark, a reasoning kit for mobility. Automated Software Engineering, 9(2):137150, Apr 2002.
  S. Katz and D. Peled. Interleaving set temporal logic. Theoretical Computer Science, 75(3):263287, 1990.
  Lodaya, Ramanujam, and Thiagarajan. Temporal logics for communicating sequential agents: I. Int. Journal of Found. of Computer Science, 3(2):117159, 92.
  A. Masini and A. Maggiolo-Schettini. TTL: A formalism to describe local and global properties of distributed systems.
Theor. Informatics and Applic., 26(2):115149, 1992.
  A. Montanari. Metric and Layered Temporal Logic for Time
Granularity. PhD thesis, University of Amsterdam, 1996.
  C. Montangero and L. Semini. Distributed states logic.
Technical Report TR-02-05, Dipartimento di Informatica, 2002. At www.di.unipi.it/ricerca/TR/tr.html.
  C. Montangero and L. Semini. Composing Specifications for Coordination. In Proc. COORDINATION 99, LNCS
1594, pages 118133, 1999.
  Pinter and Wolper. A temporal logic for reasoning about partially ordered specifications. In Proc. 3 ACM Principles of Distributed Computing, pages 2837, 1984.
  R. Ramanujam. Locally linear time temporal logic. In Proc.
IEEE Symp. on Logic In Computer Science, pages 118
127. IEEE Computer Society, 1996.
  L. Semini and C. Montangero. A Refinement Calculus for
Tuple Spaces. Science of Computer Programming, 34:79
140, 1999.
  P. S. Thiagarajan and J. G. Henriksen. Distributed versions of linear time temporal logic: A trace perspective. In Lectures on Petri Nets I: Basic Models, Advances in Petri Nets, LNCS 1491, pages 643681, 1998.
Letbe a model, and fthe set of its initial states:
)
V
Vft
Mt
M
P
V
V
)
^ft
M
LTwhere t
M
P
Vt
Mimplies
)
V
^r
^
^t
M
Pis the DSL satisfiability relation.
Rules. We present the most useful rules of the logic. In the first rule (necessitation) we use for the sake of comprehension.
Proceedings of the Ninth International Symposium on Temporal Representation and Reasoning (TIME02)
1530-1311/02 $17.00  2002 IEEEMonitoring Usage-control Policies in Distributed Systems
David Basin, Matus Harvan, Felix Klaedtke, and Eugen Zalinescu
ETH Zurich, Computer Science Department, Switzerland
AbstractWe have previously presented a monitoring algorithm for compliance checking of policies formalized in an expressive metric first-order temporal logic. We explain here the steps required to go from the original algorithm to a working infrastructure capable of monitoring an existing distributed application producing millions of log entries per day. The main challenge is to correctly and efficiently monitor the trace interleavings obtained by totally ordering actions that happen at the same time. We provide solutions based on formula transformations and monitoring representative traces. We also report, for the first time, on statistics on the performance of our monitor on real-world data, providing evidence of its suitability for nontrivial applications.
I. Introduction
Determining whether the usage of sensitive data complies with regulations and policies is a growing concern for companies, administrations, and end users alike. In the context of IT systems, this question amounts to whether one can implement processes that monitor other processes. In previous work,, we have demonstrated that metric first-order temporal logic (MFOTL) is a good candidate for monitoring data usage to determine policy compliance. In particular, the metric temporal operators allow one to formalize both qualitative and quantitative temporal relationships between actions and, as the logic is first-order, we can also formulate dependencies between the finite but unbounded number of agents and data elements in IT systems. We have given a monitoring algorithm for MFOTL   and many usagecontrol policies can be naturally formulated in the fragment that the monitor handles efficiently.
In this paper, we extend our previous work by deploying and evaluating our monitoring approach in a real-world concurrent and distributed setting. This is in contrast to our previous analysis, which we carried out in a nondistributed setting where we used log files filled with synthetically generated actions. In the following, we describe our monitoring setup and the challenges we faced. We begin with an abstract description of the systems that we handle.
System Model. The types of entities in our systems are data, (data) stores, agents, and actions. Data is stored in distributed data stores such as databases and repositories and created, read, modified, propagated, combined, and deleted by actions initiated by agents. Agents are either humans or applications, including database triggers.
Agents always access the data directly from a store and never indirectly from another agent. Whenever an agent
Figure 1.
System Extensionwants to use some data, it accesses the appropriate store, uses the data, and discards it afterwards. For subsequent usage, it must access the store again. Before discarding the data, the agent may write it, possibly after processing it in some way, into the same or a different store. In this way, data can propagate between stores. A consequence of this restriction on the interaction between system entities is that the use of data is always observable at the data stores.
Systems are governed by (usage-control) policies, which state requirements on the usage of the data. For example, only agents with particular credentials may modify data, or data must be deleted after two years from a given store.
Agents may or may not comply with policies.
Logging and Monitoring. Given a system that is an instance of the above system model, we must extend it to support logging and monitoring. To determine whether a policy is violated we usually need to relate actions that are carried out in different parts of the system. Moreover, the ordering of actions and the time elapsed between them is important. To relate actions and the times when they happen, we log them locally, annotating each action with a timestamp, and merge these logs after some pre-processing.
We then monitor this merged stream of logged actions. These system extensions are depicted in Figure 1.
Challenges and Contributions. Individual logs are totally ordered and timestamped using local clocks. However, even assuming clock synchronization, we have only a partial order on system actions   as multiple actions with the same timestamp may occur in different logs. Our main theoretical challenge is to monitor such a partially ordered set of actions, which is, in general, an intractable problem. In Section III, we identify a subclass of formulas that describe properties that are insensitive to the ordering of actions labeled by the same timestamp and for which it suffices to monitor a particular merging of the logs, namely, the merging that assumes that actions with equal timestamps happen simultaneously. Furthermore, in casethe given formula is outside this class we provide means to meaningfully monitor this merge by approximating the described property.
A practical challenge is to deploy adequate logging mechanisms. The mechanisms should be complete in that they log all occurrences of policy-relevant system actions. They should also be accurate in that if an action is logged then it has happened in the system and the corresponding log entry accurately describes the action, e.g, it describes the involved data and the associated timestamp is the actual time when the action happened. Incomplete or inaccurate logging may lead to false positives and false negatives when monitoring the system.
In Section IV, we explain how we handle these practical challenges in our case study. Where possible, we use existing logging mechanisms and extract policy-relevant information from the produced log entries. For system components where no logging was available, we either added logging directly to the components or we extended the components with proxy mechanisms that logged actions. However, proxies have limitations: agents do not necessarily access a store over a proxy and proxies see requested actions but not necessarily all the effects on the involved data. In our case, the interactions could be accurately observed but not for all agents, which led to accurate but incomplete logs.
Summarizing, we see our contributions as follows. We provide solutions for efficiently monitoring partially ordered logs, which is a central problem in monitoring real-time concurrent distributed systems. Moreover, we evaluate the performance of our monitoring approach and demonstrate its effectiveness on a real-world application.
Organization. The remainder of this paper is structured as follows. In Section II, we give background on MFOTL and our monitor. In Section III, we show how we handle the interleavings of multiple streams of logged actions from different log producers. In Section IV, we report on our case study. In Section V, we discuss related work and in Section VI, we draw conclusions. The Appendices AD contain additional proof details. Additional details on the case study are given in Appendix E.
II. Preliminaries
We briefly review metric first-order temporal logic(MFOTL) and describe how we use it to monitor systems.
Syntax and Semantics. Let I be the set of nonempty intervals over N. We will write an interval I  I as [b, b0 ) :=
{a  N | b  a < b0 }, where b  N, b0  N  {}, and b < b0.
A signature S is a tuple (C, R, ), where C is a finite set of constant symbols, R is a finite set of predicates disjoint from C, and the function  : R  N associates each predicate r  R with an arity (r)  N. In the following, let S = (C, R, ) be a signature and V a countably infinite set of variables, assuming V  (C  R) =.(D,, v, i) |= t t0(D,, v, i) |= t t0(D,, v, i) |= r(t1,..., t(r) )(D,, v, i) |= ()(D,, v, i) |= (  )(D,, v, i) |= (x. )(D,, v, i) |= ( I )(D,, v, i) |= (#I )(D,, v, i) |= ( SI )(D,, v, i) |= ( UI )v(t) = v(t0 ) v(t) < v(t0 )
 v(t1 ),..., v(t(r) )  rDi(D,, v, i) 6|=(D,, v, i) |=  or (D,, v, i) |=(D,, v[x/d], i) |=, for some d  |D| i > 0, i  i1  I, and (D,, v, i  1) |= i+1  i  I and (D,, v, i + 1) |= for some j  i, i   j  I, (D,, v, j) |=, and (D,, v, k) |=, for all k  [ j + 1, i + 1) iff for some j  i,  j  i  I, (D,, v, j) |=, and (D,, v, k) |=, for all k  [i, j)iff iff iff iff iff iff iff iff iff
Figure 2.
Semantics of MFOTL
Formulas over the signature S are given by the grammar
::= t1 t2 fifi t1 t2 fifi r(t1,..., t(r) ) fifi () fifi (  ) fifi (x. )( I ) fifi (#I ) fifi ( SI ) fifi ( UI ), where t1, t2,... range over the elements in V  C, and r, x, and I range over the elements in R, V, and I, respectively.
To define MFOTLs semantics, we need the following notions. A structure D over S consists of a domain |D|, and interpretations cD  |D| and rD  |D|(r), for each c  C and r  R. A temporal structure over S is a pair (D, ), where D = (D0, D1,... ) is a sequence of structures over S and  = (0, 1,... ) is a sequence of natural numbers (i.e., timestamps), where:(1) The sequence  is monotonically increasing (i.e., i i+1, for all i  0) and makes progress (i.e., for every i  0, there is some j > i such that  j > i ).(2) D has constant domains, i.e., |Di | = |Di+1 |, for all i  0.
We denote the domain by |D| and require that |D| is strict linearly ordered by a relation <.(3) Each constant symbol c  C has a rigid interpretation, i.e., cDi = cDi+1, for all i  0. We denote cs interpretation by cD.
A valuation is a mapping v : V  |D|. We abuse notation by applying a valuation v also to constant symbols c  C, with v(c) = cD. For a valuation v, a variable x, and d  |D|, v[x/d] is the valuation mapping x to d and not altering the other variables valuation.
The semantics of MFOTL, (D,, v, i) |=, is given in Figure 2, where (D, ) is a temporal structure over the signature S, with D = (D0, D1,... ),  = (0, 1,... ), v a valuation, i  N, and  a formula over S. Note that the temporal operators are labeled with intervals I and a formula of the form ( I ), (#I ), (SI ), or (UI ) is only satisfied in (D, ) at the time point i, if it is satisfied within the bounds given by the interval I of the respective temporal operator, which are relative to the current timestamp i.
Terminology and Notation. We use standard syntactic sugar such as I  := (trueSI ) and ffI  := (trueUI ), where true := x. x  x. We also use non-metric operators like ff  := ff[0,). We omit parentheses where possible, III. Monitoring Concurrently Logged Actions
In this section, we first prove the intractability of monitoring where logs are produced in a concurrent setting. We then show how to partially overcome this obstacle by monitoring a single log where all actions with equal timestamps are assumed to have happened at the same point in time. Proof details are given in the Appendices AD.
Definition 1. Let (D1, 1 ), (D2, 2 ), and (D, ) be temporal structures. (D, ) is an interleaving of (D1, 1 ) and (D2, 2 ) if there are strictly monotonic functions f1, f2 : N  N with(1) img( f1 )  img( f2 ) = N, (2) img( f1 )  img( f2 ) =, and k(3) ki =  fk (i) and rDi = rD fk (i), for all k  {1, 2}, i  N, r  R.
We denote by (D1, 1 ) (D2, 2 ) the set of all interleavings of the temporal structures (D1, 1 ) and (D2, 2 ).
Since there are usually multiple interleavings of two temporal structures, we formulate policy violations in terms of a set of temporal structures.
Definition 2. Let T be a set of temporal structures.(1) T weakly violates the formula  at time point i  N if for some (D, )  T and some valuation v, it holds that(D,, v, i) 6|=.(2) T strongly violates the formula  at time point i  N if for all (D, )  T, there is some valuation v such that(D,, v, i) 6|=.
Unfortunately, even in a propositional setting, determining whether the set of interleavings weakly or strongly violates a formula is intractable.
Theorem 3. Let (D1, 1 ) and (D2, 2 ) be temporal structures, i  N, and  a quantifier-free sentence with only
Boolean and non-metric past operators that neither contains the equality symbol  nor the ordering symbol.
1. Determining whether the set of interleavings (D1, 1 )(D2, 2 ) weakly violates  at i is NP-complete.
2. Determining whether the set of interleavings (D1, 1 )(D2, 2 ) strongly violates  at i is coNP-complete../
We assume that the actions for publishing and approving reports are logged in relations. Specifically, for each time point i  N, we have the unary relations PUBLISH i and APPROVEi such that (1) x  PUBLISH i iff report f is published at time point i and (2) x  APPROVEi iff report x is approved at time point i. Observe that there can be multiple approvals at the same time point for different reports. Furthermore, every time point i has a timestamp i  N.
The corresponding temporal structure (D, ) with D =(D0, D1,... ) and  = (0, 1,... ) of a sequence of logged publishing and approval actions is as follows. The only relational symbols in Ds signature are publish and approve, both of arity 1. The domain of D consists of all reports. The ith structure in D is timestamped with i and contains the relations PUBLISH i and APPROVEi.
To detect policy violations, our monitor   iteratively processes the temporal structure (D, ) representing the stream of logged actions. This can be done offline or online.
At each time point i, it outputs the valuations satisfying the negation of the formula publish(x)  [0,11) approve(x).
Note that we drop the outermost quantifier since we are not only interested in whether the policy is violated but also which data is responsible for the reported violations.
In general, we assume that policies formalized in MFOTL are of the form ff, where  is bounded. Since  is bounded, the monitor need only take into account a finite prefix of (D, ) when determining the satisfying valuations of  at a time point i. To effectively determine all these valuations, we also assume here that predicates have finite interpretations in (D, ), i.e., the relation rD j is finite, for every predicate r and every j  N. Furthermore, we require that  can be rewritten to a temporal-subformula-domainindependent formula, a generalization of the standard notion of domain-independent database queries../ff x. publish(x)  [0,11) approve(x).
Log Interleavings. Intuitively, an interleaving of logs preserves the ordering of the logged actions with respect to their timestamps, but allows for all possible orderings of actions with equal timestamps that are recorded by different log producers. To define this, let img( f ) denote the set {y
Y | f (x) = y, for some x  X}, for a function f : X  Y.
Furthermore, we assume in this section that all temporal structures have the same signature (C, R, ), equal domains, and that constant symbols are equally interpreted. Note that any two temporal structures in which the common constant symbols are equally interpreted can easily be extended so that their extensions fulfill this requirement../e.g., unary operators (temporal and Boolean) bind stronger than binary ones. A formula  is bounded if the interval I of every temporal operator UI occurring in  is finite. We use standard terminology like atomic formula and subformula.
System Monitoring. We illustrate our use of MFOTL and our monitoring algorithm   for compliance checking by the simple policy stating that reports must be approved within at most 10 time units before they are published:
Note that both decision problems are well defined as does not contain future operators. We therefore only need to examine the finite prefixes with length i + 1 of the interleavings to determine whether  is weakly or strongly violated at the given time point i.
Collapsing Interleaved Logs. We first give conditions with respect to an arbitrary set of temporal structures for when it suffices to monitor a single temporal structure. We then identify a natural temporal structure for the set of interleavings of two temporal structures, which we use for
In the following, the set T in the above definition will be the set of interleavings of two temporal structures. For the temporal structure (C, ), we will use the so-called collapse:
Definition 5. Let (D, ) and (C, ) be temporal structures.(C, ) is a collapse of (D, ) if there is a monotonic surjective function f : N  N such that(1) if i =  j then f (i) = f ( j), for all i, j  N, (2)  f (i) = i, for all i  N, and S(3) rC j = i f 1 ( j) rDi, for all j  N and r  R.
Intuitively, the structures of the temporal structure (D, ) with equal timestamps are collapsed into a single structure. The collapse is uniquely defined and we denote it by col(D, ). Furthermore, the collapses of temporal structures in the set of interleavings of two given temporal structures are all isomorphic.
Before we identify formulas for which the collapse of an interleaving of given temporal structures can be correctly used for monitoring, we give practical reasons that justify its use for monitoring. First, observe that the collapse can be incrementally obtained from an arbitrary interleaving of two given temporal structures. Hence, monitoring the collapse can be done efficiently. Second, note that the actual ordering of actions logged with equal timestamps in a concurrent system cannot be known. Hence, it does not make sense to consider just one arbitrary interleaving.
Assuming that equally timestamped actions have happened at the same point in time naturally hides the differences between interleavings. Moreover, reasonable policies for a concurrent system should not care about the ordering of equally timestamped actions in case of accurate and precise clocks. In other words, if the collapsed temporal structure is not sufficient for the policy on the set of interleavings, then the policy might not be the intended one for the system. Finally, monitoring the collapsed temporal structure is practically more efficient than monitoring an interleaving.
This is because the monitor is invoked less often since time points with equal timestamps are merged to a single one.
Hence, the monitor processes the logged actions with equal timestamp in a single invocation.
Monitoring the Collapse. Intuitively, collapse-sufficient formulas are formulas that do not yield false positives and false negatives when monitoring the collapse of an interleaving:
Definition 6. Let  be a formula. For k  {1, 2}, we say thathas the property (Ck) if (C, ) fulfills the condition (Ck) in./
Monitoring the collapse of a collapse-sufficient formula is correct with respect to strong violations. Since the formula has property (C2), violations found in (C, ) imply that the set of interleavings strongly violates the formula. The converse is ensured by the property (C1): if no violation is found in (C, ) then all interleavings are policy compliant.
Furthermore, by monitoring (C, ) we also detect when the set of interleavings weakly violates the given formula. The reason is that if a formula is strongly violated by the set of interleavings then it also weakly violated, since the set of interleavings is always nonempty.
Example 7. The formula ffx.publish(x)  [0,11) approve(x) is not collapse-sufficient. Suppose that a report x is pub1 lished in (D1, 1 ) at time point i, i.e., x  publishDi and only approved in (D2, 2 ) at the equally timestamped time
2 point j, i.e., x  approveD j with 2j = 1i. Then there is an interleaving (D, )  (D1, 1 ) (D2, 2 ) where the approval action comes (pointwise) strictly after the publish action.
As a result, we cannot handle this formula correctly by monitoring the collapsed temporal structure (C, ) of an interleaving of the given temporal structures (D1, 1 ) and(D2, 2 ).
A slightly stronger policy can be efficiently monitored.
Namely, the policy that requires that an approval action must happen timewise strictly before the publish action, i.e., ff x. publish(x)  [1,11) approve(x). This formula is collapse-sufficient. Similarly, ff x. publish(x)
[0,1) [0,11) approve(x) is also collapse-sufficient. It formalizes the slightly weaker policy where publish actions must be timewise but not pointwise previously approved.
Note that stutter-invariance   is a necessary condition for collapse-sufficiency. However, it is not a sufficient condition.
For example, the formula ff x. p(x)  q(x) is stutteringinvariant but not collapse-sufficient.
A Collapse-sufficient Fragment. In the following, we present a fragment of collapse-sufficient formulas. Our fragment is defined in terms of an algorithm that identifies formulas that have property (C1) or property (C2).
The algorithm labels the atomic subformulas of the given formula and propagates these labels bottom-up to the formulas root using a fixed set of inference rules. The labels represent invariants, which capture the relation between violations found in a collapsed temporal structure (C, ) at some time point and violations found in its pre-images(D, )  col1 (C, ) at a time point with an equal timestamp, where col1 (C, ) denotes the set of temporal structures(D0, 0 ) with col(D0, 0 ) = (C, ). Note that (D, ) (D0, 0 ) ( col1 (C, ), where (C, ) is the collapse of an interleaving of./
Definition 4. The temporal structure (C, ) is sufficient for the formula  on the set T of temporal structures if for all valuations v, the following conditions are fulfilled:(C1) If (C,, v, 0) |=  then (D,, v, 0) |=, for all (D, )  T.(C2) If (C,, v, 0) 6|=  then (D,, v, 0) 6|=, for all (D, )  T.
Definition 4 with respect to  and (D, ) (D0, 0 ), for every(D, ), (D0, 0 ), and (C, ), where (C, ) is the collapse of an interleaving of (D, ) and (D0, 0 ). Moreover,  is collapsesufficient if it has the properties (C1) and (C2)../monitoring.t  t0 : (|= ) r(t1,..., t(r) ) : (|= )
: (|= )
: (|= )
: (|= )
I  : (|= )
: (|= )
I  : (|= )t  t0 : (6|= ) r(t1,..., t(r) ) : (6|= )
: (6|= )
: (6|= )
: (|= )
0<I
I  : (|= )
: (6|= )
I  : (6|= )
: (|= )
0IJ
I  J  : (|= )
Figure 3.
Selection of Inference Rulesthe temporal structures (D, ) and (D0, 0 ).
The labels and their corresponding invariants are as follows for a formula :(|= ): For all valuations v and all i  N, if (C,, v, i) |= then for every (D, )  col1 (C, ) and every j  N with i =  j, it holds that (D,, v, j) |=.(|= ): For all valuations v and all i  N, if (C,, v, i) |= then for every (D, )  col1 (C, ), there is some j  N with i =  j such that (D,, v, j) |=.(6|= ): For all valuations v and all i  N, if (C,, v, i) 6|= then for every (D, )  col1 (C, ) and every j  N with i =  j, it holds that (D,, v, j) 6|=.(6|= ): For all valuations v and all i  N, if (C,, v, i) 6|= then for every (D, )  col1 (C, ), there is some j  N with i =  j such that (D,, v, j) 6|=.
The first symbol (|= or 6|=) in a label states whether the formula is satisfied in the collapsed temporal structure (C, ).
The second symbol ( or ) states whether the formula is satisfied at some equally timestamped time point or at all equally timestamped time points in all temporal structures(D, )  col1 (C, ).
Due to space limitations, Figure 3 shows only some of our inference rules. All rules can be found in Appendix C, where we also prove their soundness.
First, consider the rules in Figure 3 for atomic formulas.
An atomic formula t  t0 depends only on the valuation and therefore can be labeled (|= ) and (6|= ). An atomic formula of the form r(t1,..., t(r) ) can be labeled (|= ) and (6|= ).
We only explain the labeling (|= ). The explanation for the label (6|= ) is analogous. The interpretation of a predicate in a collapsed temporal structure (C, ) at a time point i is the union of the predicates interpretations at all time points j in a temporal structure (D, )  col1 (C, ) for which  j equals i. Therefore, if a  rCi then a  rD j, for some j  N with j = i. Note that a  rD j does not necessarily hold for all these js; hence, we cannot label r(t1,..., t(r) ) with (6|= ).
The next two rules in Figure 3 express that the invariants corresponding to the labels (|= ) and (6|= ) imply the invariants corresponding to (|= ) and (6|= ), respectively.
Next, we consider the inference rules for the temporal operator I. We first justify the inference rule that allowsus to propagate the label (|= ) from  to I. If I  is satisfied in the collapsed temporal structure (C, ) at time point i then  is satisfied at some previous time point j  i in (C, ) with i   j  I. Because  is labeled with (|= ), all time points with timestamp  j in the temporal structure(D, )  col1 (C, ) also satisfy, and hence, all time points with timestamp i satisfy I  in (D, ). When  is labeled with (|= ), possibly only a single time point k in (D, ) with k =  j satisfies. If 0  I then I  might not be satisfied at time points before k, even if these time points have the timestamp i. So, we can label I with (|= ) but not with (|= ). However, if 0 < I then  is satisfied in (C, ) at a time point j with the timestamp  j < i. Hence I is satisfied in (D, ) at all time points with the timestamp i. This allows us to label I  with (|= ). Finally, consider the rule where  is labeled (6|= ). If I  is violated in the collapsed temporal structure (C, ) at timestamp i then is violated at all previous points in the temporal structure(D, )  col1 (C, ) that satisfy the metric constraints given by I. But then I  is also violated in (D, ) at all time points with the timestamp i. Hence we can label I  with (6|= ).
We can try to label a formula solely based on inference rules that involve only a single Boolean or temporal operator.
However, with more specialized inference rules like the one for I  J  given in Figure 3, we are more likely to succeed in propagating labels to the root of the formula.
Intuitively, with the nesting of the operators I and  J, and when 0  I  J, the ordering of equally timestamped time points becomes irrelevant since from a given time point, we can freely choose any of these time points that satisfy the metric constraints given by the intervals I and J. Hence, a labeling (|= ) for  allows us to label I  J  with (|= ).
Finally, we remark that there are no inference rules for the temporal operators I and #I because these operators inherently rely on the relative ordering of the structures in a temporal structure.
Based on the labels at the root of the formula, we can determine if the formula has the property (C1) or the property (C2). The conclusions we can draw are stated in the following lemma, which follows from the soundness of the inference rules.
Lemma 8.
1. If  can
2. If  can
3. If  can
4. If  can
Let  be a formula. be labeled by (|= ) then  has property (C1). be labeled by (6|= ) then  has property (C2). be labeled by (|= ) then   has property (C1). be labeled by (6|= ) then ff  has property (C2).
Based on this lemma, we obtain the following theorem.
Theorem 9. If the formula  can be labeled by (|= ) and (6|= ) then it is collapse-sufficient. Moreover, we can determine in linear time in the formulas length whether can be labeled by (|= ), (|= ), (6|= ), and (6|= ).
Note that formulas of the form ff  are already collapsesufficient if  can be labeled by (6|= ) and ff  can be labeled by (|= ). Even if only one of these labellings can be derived, monitoring ff  on the collapsed temporal structure of an interleaving is still useful. For example, if  is labeled by (6|= ) then violations that are found on the collapsed temporal structure relate to strong violations on the set of interleavings. However, we might miss some violations.
Example 10. We illustrate our algorithm and its inference rules by applying it to the formula ff x. publish(x)
[0,11) approve(x). We first remove some syntactic sugar and obtain the formula ff x. publish(x)  [0,11) approve(x). We start by labeling the atomic subformulas. Both publish(x) and approve(x) are labeled with (|= ) and (6|= ). According to the inference rules for the temporal operator I we label [0,11) approve(x) with (|= ) and (6|= ). We cannot label it with (|= ) since the interval contains 0. Moreover, the subformula publish(x) is labeled with (6|= ) and(|= ). The subformulas publish(x)  [0,11) approve(x) and x. publish(x)  [0,11) approve(x) are labeled (|= ) and(6|= ). We conclude that the formula ff x. publish(x)
[0,11) approve(x) has the property (C2). It does not have the property (C1), as shown in Example 7.
The formula ff x. publish(x)  [1,11) approve(x) has both properties (C1) and (C2). The labeling starts similarly but [1,11) approve(x) is additionally labeled with (|= ) since the interval of the temporal operator does not contain 0. This label propagates to the root of the formula. We conclude thatff x. publish(x)[1,11) approve(x) also has property (C1).
Policy Approximation. In Example 7, we have seen that we can obtain collapse-sufficient policies by strengthening or weakening the original policy. In the following, we present a systematic approach along these lines by overapproximating and under-approximating policies.
Let  be a formula in positive normal form. We obtain the weakened formula w by replacing each atomic subformula r(t1,..., t(r) ) that occurs positively in  by
I I 0 r(t1,..., t(r) ), for some intervals I and I 0 with 0
I  I 0. Analogously, in the strengthened formula  s, we replace each negative occurrence of an atomic subformula r(t1,..., t(r) ) by I I 0 r(t1,..., t(r) ).
Theorem 11. Let w and  s be weakened and strengthened formulas of the formula  in positive normal form. The formulas   w and  s   are valid. Moreover, 1. if  s is collapse-sufficient then  has property (C1), and 2. if w is collapse-sufficient then  has property (C2).
Weakened and strengthened formulas are more likely to be collapse-sufficient, since their subformulas of the form I I 0 r(t1,..., t(r) ) can be labeled with (|= ), while r(t1,..., t(r) ) can only be labeled with the weaker label (|= ).
Simultaneously weakening and strengthening always results in a collapse-sufficient formula. However, the resulting formula does not necessarily relate to the original formula.
Figure 4.
Nokias Data-collection Campaign
Finally, note that by inserting the temporal operators [0,1) and [0,1) around positively occurring atomic subformulas, the ordering of equally timestamped actions becomes irrelevant. This is desirable in systems where the clocks used to timestamp the actions are synchronized but too coarse-grained. Taking this idea further, by putting temporal operators [0,b) and [0,b) around these subformulas with b  1, we take into account that the timestamps in a temporal structure are inaccurate and might differ from their actual value by the threshold ba situation that occurs in practice.
IV. Practical Experience
In this section, we describe the implementation of our monitoring approach within Nokias Data-collection Campaign, which is a real-world application with realistic usage-control policies. Furthermore, we report on the monitors performance and our findings.
Scenario. The campaign,1 which was launched in 2009, collects contextual information from cell phones of about
180 participants. This sensitive data includes phone locations, call and SMS information, and the like. The data collected by a participants phone is propagated into the databases db1, db2, and db3. The phones use WLAN to periodically upload their data to database db1. Every night, the synchronization script script1 copies the data from db1 to db2. Furthermore, triggers running on db2 anonymize and copy the data to db3, where researchers can access and analyze the anonymized data. The participants can access and delete their own data using a web interface to db1.
Deletions are propagated to all databases: from db1 to db2 by the synchronization script script2, which also runs every night, and from db2 to db3 by database triggers. Figure 4 summarizes the various usages of data in the campaign.
Within the campaign, data is organized by records and can easily be identified. When uploading data from a phone into db1, a unique identifier is generated for each record.
This identifier together with an identifier of the participant who contributed the data is attached to the record.
Policies. The collected data is subject to various policies in order to protect the participants privacy. For example, there are access control rules and policies governing
1 Seehttp://research.nokia.com/page/11367 for details.
Table I. policy delete ins-1-2 ins-2-3del-1-2
Policy Formalizations in MFOTL
MFOTL formalizationff user. data. delete(user, db2, data)  user  script2ff user. data. insert(user, db1, data)  data 0 unknown
[0,1s) [0,30h] user0. insert(user0, db2, data)  delete(user0, db1, data)ff user. data. insert(user, db2, data)  data 0 unknown
[0,1s) [0,60s) user0. insert(user0, db3, data)ff user. data. delete(user, db1, data)  data 0 unknown

[0,1s) [0,30h) user0. delete(user0, db2, data)([0,1s) [0,30h) user0. insert(user0, db1, data))
([0,30h) ff[0,30h) user0. insert(user0, db2, data))the process of propagating the data between databases. In particular, any insertion or deletion of data in db1 must be propagated to db2 within 30 hours, and from db2 to db3 within 1 minute. Furthermore, only the latest version of the synchronization scripts may be used and the scripts may not run longer than 6 hours. Finally, access to the databases is restricted to selected user accounts and the account script1 may be used only while the script script1 is running.
We present here just a few representative policies in Table I. Details about all the 14 policies are given in Appendix E. The predicates insert and delete correspond to the equally-named database commands. The arguments of these predicates are the agent that initiated the action, the name of the database where the action was carried out, and an identifier of the involved data.
Note that all policy formalizations in Table I are collapse-sufficient. However, some policies have slightly weaker or stronger variants that are not collapsesufficient. For example, we obtained ins-2-3 from the policy all data inserted into db2 must also be inserted into db3 within 60 seconds by weakening the formulaff users. data. insert(user, db2, data)data 0 unknown
[0,60s) user0. insert(user0, db3, data). Intuitively, ins-2-3 is the policy formalization that we actually intended: we do not want to distinguish the relative ordering of the insertions into db2 and db3 when they are logged with the same timestamp. This is because the 1 second timestamp granularity that is used may not be fine-granular enough: the database triggers may be activated within milliseconds.
Logging Mechanisms. We extended the data-collection setup with mechanisms to log policy-relevant actions. We installed logging mechanisms for the three databases, the script script1, and the SVN repository, assuming synchronized clocks for timestamping. We now discuss details of these logging mechanisms.
As logs for the database db1 were not available, we implemented a proxy to inspect interactions of participants and phones with db1. The proxy logs what data is inserted and deleted. To observe the insertion of new data, we monitor the network traffic when the phone uploads data. For deletions, we use a custom front-end that logs the requests for deleting data. For practical reasons, we could deploy these mechanisms only for 2 out of the 180 participants.
Hence, we have only partial logging for db1, which only
Table II. log
1
2
3
4
5
6
7
8
9
# time points
29,672
10,870
6,601
20,330
8,114
9,218
7,327
86,892
86,764total
# actions
1,462,700
969,520
1,019,428
962,766
687,402
630,287
554,733
936,249
986,249
Log Statistics
# insert actions db2 db3
82,486
678,840
678,840
23,828
472,369
472,369
33,229
492,411
492,411
12,918
468,844
468,844
7,067
339,674
339,647
4,207
311,882
311,835
3,251
275,208
275,199
47,786
400,490
400,475
30,118
434,268
434,259 db1
# other actions
22,534
954
1377
11,298
12,160
1,366
1,014
87,498
87,604affects 2 out of the 14 policies.
The databases db2 and db3 reside physically on a single
PostgreSQL server, which logs the SQL queries. We extract relevant actions from these PostgreSQL logs. The main challenge is to determine what data is processed in a query since only the query itself is logged. Fortunately, most relevant queries are made by automated scripts or database triggers and contain enough information to determine what data is used. For example, an insert or delete query initiated by a synchronization script includes the identifier of the used data record. Hence, a simple syntactic analysis of these queries suffices to log the relevant actions in sufficient detail.
When the analysis failed to extract the data, we identified the data with the constant unknown.
Evaluation. To evaluate the performance of our monitor on different data sets, we split the logs into smaller files, where each file corresponds to roughly 24 hours of log entries. Table II provides details about the collapsed temporal structures corresponding to these logs. Observe that the number of insert actions is significantly larger than the number of other actions. None of the log files used contains more than 100 delete actions. Table III shows the monitors running times and memory usage for each policy and log file. For the experiments, we used a desktop computer with a 1150 MHz AMD Phenom 9600B Quad-Core CPU.
Monitoring invariants like the policy delete is fast: the monitor needed no more than 10 seconds for a 24-hours log file. More complex policies involving temporal operators with large time windows, take more time to monitor. For example, for the policy ins-1-2, the monitor took more than
4 hours in some cases. The policy del-1-2 with an even larger time window, however, could be quickly monitored.
The reason here is that the log files used contain only few delete actions. Although we monitored the logs offline, the running times indicate that an online monitoring approach is possible, since the running times are less than the time period covered by the logs. The memory requirements are also modest. For the policies delete and ins-2-3, the monitor does not require more than 10 MB of RAM. For ins-1-2 and del-1-2, the monitor used under 200 MB of RAM, which is also acceptable due to the large time windows.
Findings. The monitor reported the following policy violations. First, some static access control policies like delete were violated. These violations were due to testing, Table III. policy delete ins-1-2 ins-2-3 del-1-2log 1
10 s / 4 MB
231 m / 161 MB
9 m / 8 MB
24 s / 176 MBlog 2
7 s / 4 MB
44 m / 103 MB
3 m / 7 MB
16 s / 139 MB
Monitor Performance  Running Times / Memory Usagelog 3
7 s / 4 MB
67 m / 107 MB
5 m / 8 MB
13 s / 87 MBlog 4
6 s / 4 MB
24 m / 102 MB
4 m / 8 MB
11 s / 79 MBdebugging, and other improvement activities going on while the system was running. Second, an earlier version of one of the synchronization scripts contained a bug, which was not detected in previous tests. Only a subset of the insertions were propagated between the databases. Third, while the campaign was running, the infrastructure was migrated to another server. After the migration, the deployment of the scripts was delayed, which caused policy violations.
Overall, the main reason for these violations is that we monitored an experimental system still under development.
In this case study the monitor proved to be a powerful debugging tool. For commercial systems, it can detect policy violations thereby protecting the users privacy and increasing users trust in using the systems. Our findings also show that policy monitoring makes sense even in systems where users are honest and interested in honoring the policies.
V. Related Work
The usage-control architecture described by Pretschner et al.   and the UCONABC architecture of Park and Sandhu   both utilize monitoring techniques. However, the two architectures are only conceptual and have neither been deployed nor evaluated in a real-word setting.
Goodloe and Pike   recently surveyed the state of the art for monitoring distributed systems. We restrict ourselves here to the most related work. Bauer et al.   examine a setting where actions are totally ordered and system requirements are given in a propositional linear-time temporal logic. Both assumptions are too restrictive in our setting. However, their monitoring architecture additionally includes a component that analyzes the cause of a failure, which is fed back into the system. Genon et al.   present a monitoring algorithm for propositional LTL, where events are partially ordered. They use symbolic exploration methods to cope with the interleavings of events. It is unclear how their algorithm extends to a first-order setting.
Moreover, in our approach, we consider formulas in a richer logic for which monitoring a single trace is sufficient. In contrast to these works and ours, Sen et al.   present a distributed monitoring approach, where multiple monitors are implemented locally and communicate with each other.
These monitors are generated from a propositional past-time linear-time distributed temporal logic. A potential bottleneck is the monitors communication overhead.
Finally, research on checking temporal integrity constrains,   of stored data and temporal triggers   in databases is related to our monitoring algorithm. In fact,  log 5
5 s / 4 MB
9 m / 71 MB
2 m / 8 MB
8 s / 58 MBlog 6
4 s / 4 MB
5 m / 65 MB
2 m / 7 MB
7 s / 53 MB
4 s
3 m
1 m
12 slog 7
/ 4 MB
/ 57 MB
/ 7 MB
/ 111 MBlog 8
6 s / 4 MB
73 m / 115 MB
2 m / 8 MB
21 s / 184 MBlog 9
6 s / 4 MB
48 m / 111 MB
1 m / 6 MB
11 s / 102 MBour monitoring algorithm extends Chomickis monitor   by handling bounded future operators. These temporal operators are extremely useful for formalizing usage-control policies, which usually contain obligations. We are not aware of any implementation and experimental evaluation of Chomickis monitoring algorithm.
VI. Conclusion
We theoretically and practically tackled the problem of monitoring the usage of data in concurrent distributed systems. We provided means to efficiently monitor concurrently generated logs. We also deployed and evaluated a monitoring architecture in a real-world application, Nokias
Data-collection Campaign. Our case study demonstrates the feasibility and benefits of monitoring the usage of sensitive data.
As future work we plan to develop monitoring techniques for more complex systems with more agents, actions, and databases. The challenges will be to handle less accurate and less complete logging, and to provide monitoring algorithms that scale up from millions to billions of log entries per day.
Our future work also includes developing monitoring techniques that can also be used for policy enforcement, i.e., preventing policy violations.
Acknowledgments. This work was supported by the Nokia Research Center, Switzerland. The authors thank
Imad Aad, Debmalya Biswas, Olivier Bornet, Olivier
Dousse, Juha Laurila, and Valtteri Niemi for valuable input.
References
  D. Basin, F. Klaedtke, S. Muller, and B. Pfitzmann, Runtime monitoring of metric first-order temporal properties, in Proceedings of the 28th IARCS Annual Conference on Foundations of Software Technology and Theoretical Computer
Science (FSTTCS), ser. Leibniz International Proceedings in Informatics (LIPIcs), vol. 2. Schloss Dagstuhl - Leibniz
Center for Informatics, 2008, pp. 4960.
  D. Basin, F. Klaedtke, and S. Muller, Monitoring security policies with metric first-order temporal logic, in Proceeding of the 15th ACM Symposium on Access Control Models and Technologies (SACMAT). ACM Press, 2010, pp. 2334.
  A. S. Tanenbaum and M. van Steen, Distributed Systems:
Principles and Paradigms. Prentice Hall, 2002.
  L. Lamport, Time, clocks, and the ordering of events in a distributed system, Commun. ACM, vol. 21, no. 7, pp. 558
565, 1978.
  S. Abiteboul, R. Hull, and V. Vianu, Foundations of Databases: The Logical Level. Addison Wesley, 1994.
  L. Lamport, What good is temporal logic? in Proceedings of the IFIP 9th World Computer Congress, ser. Information
Processing, vol. 83. North-Holland, 1983, pp. 657668.
Appendix
A. Additional Proof Details: Intractability Results
We remark that related intractability results for LTL on so-called partially ordered traces are given in. However, the setting is different from ours. In particular, it is unclear how to describe the set of interleavings of two timestamped traces using partially ordered traces as defined in.
Moreover, we reduce SAT and TAUT, respectively, to the respective decision problem for proving its hardness. In, the global-predicate-detection decision problem is used.
The decision problem in Theorem 3(1) is in NP as a nondeterministic Turing machine can first guess the violating interleaving up to the given time point and then verify its guess in polynomial time. Note that the Turing machine does not need to guess a valuation, as the input formula is a quantifier-free sentence and this contains no variables.
Hardness is established by polynomially reducing SAT to the decision problem in Theorem 3(1) as shown below.
Analogously, the coNP-hardness of the decision problem in Theorem 3(2) is shown by polynomially reducing TAUT to it, also explained below. This problem is in coNP since its complement is in NP.
Reduction from SAT. We show NP-hardness of the decision problem in Theorem 3(1) by reduction from SAT.
To fix notation, we recall that a propositional formula over a set of atomic propositions P is satisfiable if there is an assignment  of propositions to truth values  (denoting false) and > (denoting true), i.e.  : P  {, >}, such that() = >, where  is extended from atomic propositions to formulas as expected. The SAT problem asks whether a given propositional formula is satisfiable. SAT is NP-hard.
Suppose P = {p0,..., pn1 }, with n  0, is a set of atomic propositions. Let S be the signature (C, R, ) with C = {c}, R = {q0, r0,..., qn1, rn1 }, and (qi ) = (ri ) = 1, for any
0  i < n. The two temporal structures (D1, 1 ) and (D2, 2 ) over S are given by: |D| = {c}, cD = c, 1i = 2i = i for any i  N, and for any k  {1, 2} and i, j  N with 0  i < n, (
Dkj
{c} if k = 1 and i = j, qi =otherwise, ( k
D
{c} if k = 2 and i = j, ri j =otherwise.
Given a propositional formula  over P, the MFOTL formula pq is obtained by replacing each occurrence of  a proposition pi in  with  ri (c)   qi (c). Thus, given a propositional formula, the reduction constructs the two prefixes of length n of (D1, 1 ) and (D2, 2 ) and the MFOTL formula pq. This reduction is linear in the size of. Its correctness is shown by Lemma 13. The following remarks and lemma will be needed.
Remark. For any interleaving (D, )  (D1, 1 ) (D2, 2 ), the functions f1 and f2 in Definition 1 satisfy fk (i)  {2i, 2i +
1} where k  {1, 2}. Moreover, these functions are unique,./
  I. Aad and V. Niemi, NRC data collection campaign and the privacy by design principles, in Proceedings of the International Workshop on Sensing for App Phones (PhoneSense), 2010.
  A. Pretschner, M. Hilty, and D. Basin, Distributed usage control, Commun. ACM, vol. 49, no. 9, pp. 3944, 2006.
  J. Park and R. Sandhu, The UCONABC usage control model, ACM Trans. Inform. Syst. Secur., vol. 7, no. 1, pp. 128174, 2004.
  A. Goodloe and L. Pike, Monitoring distributed real-time systems: A survey and future directions, NASA Langley
Research Center, Tech. Rep. NASA/CR-2010-216724, July
2010.
  A. Bauer, M. Leucker, and C. Schallhart, Model-based runtime analysis of distributed reactive systems, in Proceedings of the 2006 Australian Software Engineering Conference(ASWEC). IEEE Computer Society, 2006.
  A. Genon, T. Massart, and C. Meuter, Monitoring distributed controllers: When an efficient LTL algorithm on sequences is needed to model-check traces, in Proceedings of the 14th
International Symposium on Formal Methods (FM), ser. Lect.
Notes Comput. Sci., vol. 4085. Springer, 2006, pp. 557572.
  K. Sen, A. Vardhan, G. Agha, and G. Rosu, Efficient decentralized monitoring of safety in distributed systems, in Proceedings of the 26th International Conference on Software
Engineering (ICSE). IEEE Computer Society, 2004, pp. 418
427.
  J. Chomicki, Efficient checking of temporal integrity constraints using bounded history encoding, ACM Trans.
Database Syst., vol. 20, no. 2, pp. 149186, 1995.
  U. W. Lipeck and G. Saake, Monitoring dynamic integrity constraints based on temporal logic, Inform. Syst., vol. 12, no. 3, pp. 255269, 1987.
  A. P. Sistla and O. Wolfson, Temporal triggers in active databases, IEEE Trans. Knowl. Data Eng., vol. 7, no. 3, pp.
471486, 1995.
  T. Massart, C. Meuter, and L. Van Begin, On the complexity of partial order trace model checking, Inform. Process. Lett., vol. 106, no. 3, pp. 120126, 2008.
  N. Markey and P. Schnoebelen, Model checking a path, in Proceedings of the 14th International Conference on Concurrency Theory (CONCUR), ser. Lect. Notes Comput. Sci., vol.
2761. Springer, 2003, pp. 248262../
Lemma 13. Let  be a propositional formula. It holds that is satisfiable if and only if (D1, 1 ) (D2, 2 ) weakly violates pq at time point 2n.
Proof: Suppose first that  is satisfiable. Then there is a truth value assignment  such that () = >. Let (D, ) be the interleaving determined by the functions f1 and f2 given by(
2i if (pi ) = >, f1 (i) =
2i + 1 otherwise, and( f2 (i) =
2i
2i + 1if (pi ) =, otherwise../
Let v be an arbitrary valuation. From Lemma 12, we obtain that (D,, v, 2n) |= pq, that is, (D,, v, 2n) 6|= pq.
Suppose now that (D1, 1 ) (D2, 2 ) weakly violates pq at time point 2n. Then there is an interleaving (D, ) and a valuation v such (D,, v, 2n) 6|= pq. Let f1 and f2 the be functions determined by (D, ) as in Definition 1. Let  be a truth value assignment such that (pi ) = > if and only if f1 (i) = 2i. Using again Lemma 12, we get that  is a satisfying assignment for../
Proof: Suppose first that  is a tautology. Let (D, ) be an arbitrary interleaving in (D1, 1 ) (D2, 2 ) and f1, f2 be functions as in Definition 1. Let  be a truth value assignment such that (pi ) = > if and only if f1 (i) = 2i.
Let v be an arbitrary valuation. Using Lemma 12, we obtain that (D,, v, 2n) 6|= pq. Hence (D1, 1 ) (D2, 2 ) strongly violates pq at time point 2n.
Suppose now that (D1, 1 ) (D2, 2 ) strongly violates pq at time point 2n. Let  be an arbitrary truth value assignment.
Let (D, ) be the interleaving determined by the functions f1 and f2 given by(
2i if (pi ) = >, f1 (i) =
2i + 1 otherwise,./
Proof: We use structural induction on the form of.
The only interesting case is the base case, the other cases follow directly from the induction hypotheses. Thus let  = pi  P.
Suppose that (D,, v, 2n) |= (ri (c) qi (c)). That is, there is a time point j  2n such that (D,, v, j) |= ri (c) and such that there is a time point j0  j for which (D,, v, j0 ) |=
D0
D qi (c). Then c  ri j and c  qi j. From the definition of an interleaving and the definitions of the interpretations of the predicates qi and ri, it follows that j = f2 (i) and j0 = f1 (i).
Then, as f1 (i), f2 (i)  {2i, 2i + 1}, f1 (i), f2 (i), and j0  j, we get that f1 (i) = 2i and f2 (i) = 2i + 1. Thus (pi ) = >.
Suppose that () = >. Then f1 (i) = 2i and f2 (i) = 2i + 1.
We have (D,, v, 2i) |= qi (c) and (D,, v, 2i+1) |= ri (c). Thus(D,, v, 2i + 1) |= ri (c)   qi (c) and clearly (D,, v, 2n) |=

 ri (c)   qi (c).
Lemma 14. Let  be a propositional formula. It holds that is a tautology if and only if (D1, 1 ) (D2, 2 ) strongly violates pq at time point 2n.././
Lemma 12. Let  be a propositional formula,  a truth value assignment, v a valuation, and (D, ) an interleaving of (D1, 1 ) (D2, 2 ) given by the functions f1 and f2 such that (pi ) = > iff f1 (i) = 2i, for any i with 0  i < n. It holds that () = > if and only if (D,, v, 2n) |= pq.
Reduction from TAUT. We show coNP-hardness of the decision problem in Theorem 3(2) by reduction from TAUT.
We recall that a propositional formula  over a set of atomic propositions P is a tautology if () = > for any assignment  of propositions to truth values. The TAUT problem asks whether a given propositional formula is a tautology. TAUT is coNP-hard.
We use the same reduction as for the decision problem in Theorem 3(1). The correctness of the reduction follows from the following lemma../that is, if g1, g2 : N  N are strictly monotonic functions satisfying conditions (1)(3) in Definition 1 then either g1 = f1 and g2 = f2, or g1 = f2 and g2 = f1. Furthermore, for any strictly monotonic functions f1 and f2 satisfying conditions(1) and (2) in Definition 1 and with f1 (i), f2 (i)  {2i, 2i + 1} for 0  i < n, there is a unique temporal structure (D, ) such that f1 and f2 also satisfy condition (3). In other words, the functions f1, f2 determine an interleaving of (D1, 1 ) and(D2, 2 )and( f2 (i) =
2i
2i + 1if (pi ) =, otherwise.
There is a valuation v such (D,, v, 2n) 6|= pq. Using again
Lemma 12, we get that  is a satisfying assignment for.
Hence  is a tautology.
B. Additional Proof Details: Derivation Rules
Figure 5 lists all the inference rules for label propagation.
Lemma 15 (see below) shows the soundness of these rules.
When considering formulas in positive normal form, as required in Theorem 11, the Boolean operator  and the temporal operators release RI and trigger TI are seen as primitives, instead of being defined as syntactic sugar. We recall that  RI  abbreviates ( SI ) and  TI abbreviates ( UI ). Figure 6 lists propagation rules for formulas that use these operators. Their soundness follows from the soundness of rules in Figure 5 and the mentioned equivalences. For instance, the correctness of the rule
: (|= )  : (|= )
0 < I, 0  J( RI )  ( J ) : (|= ) follows from unfolding the abbreviation ( RI )  ( J ),  which is  ( SI )  (ff J ), and the following derivation:
: (|= )
: (|= )
: (6|= )  : (6|= )
0 < I, 0  J( SI )  (ff J ) : (6|= )
( SI )  (ff J ) : (|= )
Finally, for convenience, Figure 7 lists some inference rules for formulas for which the main operator is one of the temporal operators I, I, I, and ffI. These rules can be derived from the rules in Figure 5 by simply applying the definition of syntactic sugar. For instance, the rule
: (|= )
I  : (|= )can be derived from x  x : (|= ) x. x  x : (|= )  : (|= )(x. x  x) SI  : (|= )
Note that I  is syntactic sugar for (x. x  x) SI.
We now show the soundness of the inference rules in Figure 5.
Lemma 15. Let  be a formula. If  can be labeled with `, then  satisfies the invariant `, where `
(|= ), (6|= ), (6|= ), (|= ).
Proof: Let (C, ) be the collapse of an interleaving of two given temporal structures.
We proceed by induction on size of the derivation tree assigning label ` to. We make a case distinction based on the rule applied to label the formula, that is, the rule at the root of the tree. However, for clarity, we generally group cases by the formulas form.
For readability, and without loss of generality, we already fix an arbitrary valuation v, an arbitrary time point i, and an arbitrary temporal structure (D, )  col1 (C, ).
We first consider the weakening rules.is labeled with (|= ) and (|= ). Suppose that(C,, v, i) |=. By the induction hypothesis,  satisfies the invariant (|= ), thus (D,, v, j) |=  for any j with  j = i. By the definition of (C, ), there is at least one j with  j = i. Hence  satisfies the invariant (|= ). is labeled with (6|= ) and with (6|= ). This case is analogous to the previous one.
0
0
= t  t, where t and t are variables or constants. In this case  is labeled with (|= ) and (6|= ).is labeled with (|= ). Suppose that (C,, v, i) |=.
Then v(t) = v(t0 ). Clearly, (D,, v, j) |=  for any time point j, as  only depends on the valuation.
The invariant (|= ) is hence satisfied. is labeled with (6|= ). This case is analogous to the previous one.
= t  t0, where t and t0 are variables or constants.
This case is analogous to the previous one.
= r(t1,..., t(r) ), where t1,..., t(r) are variables or constants. In this case  is labeled with (|= ) and (6|= ).is labeled with (|= ). Suppose that (C,, v, i) |=.
S
Then (v(t1 ),..., v(t(r) ))  rCi. As rCi = { j| j =i } rD j, there is a j with  j = i such that (v(t1 ),..., v(t(r) )) rD j. Therefore (D,, v, j) |=. Thus  satisfies the invariant (|= ).is labeled with (6|= ). Suppose that (C,, v, i) 6|=. Then for any j with  j = i we have that(v(t1 ),..., v(t(r) )) < rD j, that is, (D,, v, j) |=. Thussatisfies the invariant (6|= ).
=. If  is labeled with `, then  is labeled with
`, where ` is (|= ), (6|= ), (6|= ), or (|= ) when ` is(6|= ), (|= ), (|= ), or (6|= ) respectively.is labeled with (|= ). Suppose that (C,, v, i) |=. By the induction hypothesis,  satisfies the invariant (6|= ). As (C,, v, i) 6|=, we have that(D,, v, k) 6|=, that is, (D,, v, k) |=, for all k with k = i. Thus  satisfies the invariant (|= ).
The other cases are similar.
=. There are four rules to be analyzed.,, and  are labeled with (|= ). Suppose that(C,, v, i) |=. Then (C,, v, i) |=  and(C,, v, i) |=. By the induction hypothesis,  andsatisfy the invariant (|= ). Hence, for all j withj = i, we have (D,, v, j) |=  and (D,, v, j) |=.
Thus (D,, v, j) |=  and (D,, v, j) |=  for all j with  j = i. Hence,  satisfies the invariant (|= ).
The other cases are similar.
= x.. There are four rules, one for each label: if is labeled with `, then  is labeled with `.
` is (|= ). Suppose that (C,, v, i) |= x.. Then there is a d  |D| such that (C,, v[x/d], i) |=. As  satisfies the invariant (|= ), we have (D,, v[x/d], j) |= for all j with  j = i. That is, (D,, v, j) |= x. for all j with  j = i. Hence  satisfies the invariant(|= ).
The other cases are similar.
=  SI. We have three rules to analyze.,, and  are each labeled with (|= ). By the induction hypothesis,  and  satisfy the invariant(|= ). Suppose that (C,, v, i) |=. Then, for some j  i with i   j  I, we have (C,, v, j) |=  and(C,, v, k) |=  for all k  [ j + 1, i + 1). Let i0 be an arbitrary time point such that i0 = i. As  satisfies the invariant (|= ), for the largest j0 with  j0 =  j we have (D,, v, j0 ) |=. Clearly, i0   j0  I. From the definition of (C, ), for any k0  [ j0 + 1, i0 + 1), there is a k  [ j + 1, i + 1) such that k0 = k. Then, as satisfies the invariant (|= ), for any k0  [ j0 +1, i0 +1), we have (D,, v, k0 ) |=. As  satisfies the invariant(|= ), for all k  [ j + 1, i + 1) and all k0 with k0 = k, : (|= )
: (|= ) t  t0 : (|= )t  t0 : (6|= )r(t1,..., t(r) ) : (|= )
: (|= )
: (6|= )
: (|= )
: (6|= )
: (6|= )
: (6|= ) t  t0 : (|= )t  t0 : (6|= )r(t1,..., t(r) ) : (6|= )
: (6|= )
: (|= )
: (6|= )
: (|= )
: (|= )  : (|= )
: (|= )
: (|= )  : (|= )
: (|= )
: (6|= )  : (6|= )
: (6|= )
: (6|= )  : (6|= )
: (6|= )
: (|= ) x.  : (|= )
: (|= ) x.  : (|= )
: (6|= ) x.  : (6|= )
: (6|= ) x.  : (6|= )
: (|= )  : (|= )
SI  : (|= )
: (6|= )  : (6|= )
SI  : (6|= )
: (6|= )  : (6|= )
SI  : (6|= )
: (6|= )  : (6|= )
0 < I, 0  J( SI )  (ff J ) : (6|= )
: (|= )  : (|= )
UI  : (|= )
: (6|= )  : (6|= )
UI  : (6|= )
: (6|= )  : (6|= )
UI  : (6|= )
: (6|= )  : (6|= )
0 < I, 0  J( UI )  ( J ) : (6|= )
: (|= )
I  : (|= )
: (|= )
0<I
I  : (|= )
: (|= )
I  : (|= )
: (|= )
0<I
I  : (|= )
: (|= )
0IJ
I  J  : (|= )
Figure 5.
Inference Rules
: (6|= )  : (6|= )
: (6|= )
: (6|= )  : (6|= )
: (6|= )
: (|= )  : (|= )
: (|= )
: (|= )  : (|= )
: (|= )
: (6|= )  : (6|= )
RI  : (6|= )
: (|= )  : (|= )
RI  : (|= )
: (|= )  : (|= )
RI  : (|= )
: (|= )  : (|= )
0 < I, 0  J( RI )  ( J ) : (|= )
: (6|= )  : (6|= )
TI  : (6|= )
: (|= )  : (|= )
TI  : (|= )
: (|= )  : (|= )
TI  : (|= )
: (|= )  : (|= )
0 < I, 0  J( TI )  ( J ) : (|= )
Figure 6.
Inference Rules for Formulas in Positive Normal Form
: (|= )
I  : (|= )
: (6|= )
I  : (6|= )
: (|= )
I  : (|= )
: (6|= )
I  : (6|= )
: (|= )
I  : (|= )
: (6|= )
I  : (6|= )
: (6|= )
I  : (6|= )
: (6|= )
0<I
I  : (6|= )
: (|= )ffI  : (|= )
: (6|= )ffI  : (6|= )
: (6|= )ffI  : (6|= )
: (6|= )
0<IffI  : (6|= )
: (6|= )
0IJ
I ff J  : (6|= )
Figure 7.
Derived Inference Ruleswe have (D,, v, k0 ) |=. Hence (D,, v, i0 ) |=  SI, and thus  satisfies the invariant (|= ).,, and  are each labeled with (6|= ). By the induction hypothesis,  and  satisfy the invariant(6|= ). Suppose that (C,, v, i) 6|=  and that, by absurdity,  does not satisfy the invariant (6|= ). That is, there is an i0 with i0 = i such that (D,, v, i0 ) |=.
Then there is a j0  i0 with i0   j0  I such that(D,, v, j0 ) |=  and for all k0  [ j0 +1, i0 +1) we have(D,, v, k) |=. By the definition of (C, ), there is a j with  j =  j0. As  satisfies the invariant (6|= ), we have that (C,, v, j) |=. Similarly, we have that(C,, v, k) |=  for all k  [ j + 1, i + 1). That is, (C,, v, i) |=, which is a contradiction.and  are labeled with (6|= ), and  is labeled by(6|= ). By the induction hypothesis,  and  satisfy the invariants (6|= ) and (6|= ) respectively. As before, suppose that (C,, v, i) 6|=  and that, by absurdity, does not satisfy the invariant (6|= ). That is, for all i0 with i0 = i we have (D,, v, i0 ) |=. Consider the largest such i0. Then there is a j0  i0 with i0  j0  I such that (D,, v, j0 ) |=  and for all k0  [ j0 + 1, i0 +
1) we have (D,, v, k0 ) |=. By the definition of(C, ), there is a j with  j =  j0. As  satisfies the invariant (6|= ), we have that (C,, v, j) |=. Take k  [ j + 1, i + 1) arbitrarily. If (C,, v, k) 6|=, as satisfies the invariant (6|= ), then there is a k0 with k0 = k such that (D,, v, k0 ) 6|=. This contradicts our assumption that (D,, v, i0 ) |=, since such k0 must be in the interval [ j0 + 1, i0 + 1). We thus have that (C,, v, k) |=  for all k  [ j + 1, i + 1). Hence(C,, v, i) |=, which is a contradiction.
=  UI. This case is analogous to the previous one.
= ( SI )  (ff J ) with 0 < I and 0  J.  and are labeled with (6|= ), and  is labeled by (6|= ). By the induction hypothesis,  and  satisfy the invariants(6|= ) and (6|= ) respectively. Suppose that (C,, v, i) 6|= and that, by absurdity,  does not satisfy the invariant(6|= ). That is, there is an i0 with i0 = i such that(D,, v, i0 ) |=. Then there is a j0  i0 with i0   j0  I such that (D,, v, j0 ) |=  and for all k0  [ j0 + 1, i0 + 1) we have (D,, v, k0 ) |= ; and for all j00  i0 with  j00 i0  J we have (D,, v, j00 ) |=.
By the definition of (C, ), there is a j with  j =  j0. Assatisfies the invariant (6|= ), we have that (C,, v, j) |=. Take k  [ j + 1, i) arbitrarily. If (C,, v, k) 6|=, as satisfies the invariant (6|= ), then there is a k0 with k0 = k such that (D,, v, k0 ) 6|=. This contradicts our assumption that (D,, v, i0 ) |=. Indeed, such a k0 must be in the interval [ j0 + 1, i00 + 1) where i00 is the largest such that i00 = i. If k0  i0 then (D,, v, i0 ) 6|=  SI.
If k0 > i0 then (D,, v, i0 ) 6|= ff J, as 0  J. We thus have that (C,, v, k) |=  for all k  [ j + 1, i + 1). Hence(C,, v, i) |=  SI.
As (D,, v, i0 ) |= ff J  and 0  J, it follows that for all k0  i0 with k0 = i0 we have (D,, v, k0 ) |=. We have seen that (D,, v, k0 ) |=  for all k0  [ j0 + 1, i0 + 1).
Because  j0 < i0 (as 0 < I), it also follows that for all k0  i0 with k0 = i0 we have (D,, v, k0 ) |=.
Hence (D,, v, k0 ) |=  for all k0 with k0 = i0. As satisfies the invariant (6|= ), we obtain that (C,, v, i) |=. Similarly, we obtain that (C,, v, k) |=  for all k > i such that k  i  J. Hence (C,, v, i) |= ff J.
We showed that (C,, v, i) |=, which is a contradiction.
Thus  satisfies the invariant (6|= ).
= ( UI )  ( J ) with 0 < I and 0  J. This case is analogous to the previous one.
= I. There are two rules to analyze. For both rules,  is labeled with (|= ). Suppose that (C,, v, i) |=.
Then there is a j  i with i   j  I such that(C,, v, j) |=. As, by the induction hypothesis, satisfies the invariant (|= ), there is a j0 with  j0 =  jsuch that (D,, v, j0 ) |=. is labeled with (|= ). Take i0 to be the largest k such that k = i. Clearly, i0   j0  I and j0  i0.
Hence (D,, v, i0 ) |= I  and  satisfies the invariant(|= ).
0 < I and  is labeled with (|= ). Take i0 arbitrarily such that i0 = i. Clearly, i0   j0  I and, as 0 < I, i0   j0 > 0, thus j0 < i0. Hence (D,, v, i0 ) |= I.
Thus  satisfies the invariant (|= ).
= I. This case is analogous to the previous one.
= I  J  with 0  I  J. There is only one rule to consider:  is labeled with (|= ) and  is labeled by(|= ). Suppose that (C,, v, i) |=. Then there is a j  i with i   j  I and there is a k  j with k   j  I such that (C,, v, k) |=. As, by the induction hypothesis satisfies the invariant (|= ), there is a k0 with k0 = k such that (D,, v, k0 ) |=. Take i0 arbitrarily such that i0 = i. If k0  i0 then 0  k0 i0 = k i  k  j  J.
As 0  J, we have k0  i0  J. Thus (D,, v, i0 ) |=  J and, as 0  I, (D,, v, i0 ) |= I  J. The case when k0 < i0 is similar. Hence  satisfies the invariant (|= ).
C. Additional Proof Details: Theorem 9
The implication in Theorem 9 follows directly from
Lemma 8, which in turn follows the correctness of the derivation rules (Lemma 15) and from the following lemma.
Lemma 16. Let  be a formula.
1. If  satisfies the invariant (|= ), then  has property (C1).
2. If  satisfies the invariant (6|= ), then  has property (C2).
3. If  satisfies the invariant (|= ), then   has property (C1).
4. If  satisfies the invariant (6|= ), then ff  has property (C2).
1.
2.
3.
4.
Proof: We fix a temporal structure (C, ).
Suppose  satisfies the invariant (|= ) and that(C,, v, 0) |=  for some valuation v. Then, for any(D, )  col1 (C, ) and every j  N with 0 =  j, it holds that (D,, v, j) |=. By the definition of collapsed temporal structure, we have 0 = 0. Hence satisfies (C1).
This case is analogous to the previous one.
Suppose  satisfies the invariant (|= ) and that(C,, v, 0) |=   for some arbitrary valuation v. Then, for every (D, )  col1 (C, ), there is some j  N with 0 =  j such that (D,, v, j) |=. It follows that(D,, v, 0) |=. Hence   satisfies (C1).
This case is analogous to the previous one.
Complexity of the Labeling Procedure. We now prove the other part of Theorem 9, which states that a formula can be labeled in time linear in its length, that is, in O(||).
We start with some definitions and then present a simple labeling algorithm and analyze its complexity.
For a formula, we define its immediate subformulas isub() to be: (i) {} if  =,  = x.,  = I, or = #I ; (ii) {, } if  =,  =  SI, or  =  UI ; and (iii)  otherwise. For a rule r, we denote `(r) the label of the conclusion of the rule.
We assume that the data structure used to represent formulas is a tree corresponding to the formulas syntax tree and that each node in the tree also stores 4 bits representing the 4 different labels. Initially these bits are set to 0, meaning that no label is associated with the corresponding subformula.
1
2
3
4
5
6add labels() foreach   isub() add labels() foreach rule r if matches(, r) then add label(, `(r))
The function matches(, r) checks if the formula  pattern matches a rule r. The order of rules is arbitrary, with the exception that the weakening rules are checked last. So, for instance if  received label (|= ), then  will match the appropriate weakening rule and it will also be labeled with (|= ). As rules have constant size, and only at most the first two levels of the tree representing the formula  need to be inspected, we conclude that the function executes in constant time.
The function add label(, `) simply adds the label ` to. Clearly, this operation can be performed in constant time.
Note that the execution of the lines 2 and 46 takes constant time: |isub()|  2 for any, there is a fixed, constant number of rules, and the functions matches and add label execute in constant time. Furthermore, the function add labels is executed exactly || times, once for each subformula of. Hence the whole labeling procedure of can be done in linear time in the size of.
D. Additional Proof Details: Theorem 11
We first show that w is weaker than, or more precisely, that the formula   w is valid. We proceed by structural induction on.
0
0
0
0
= t  t,  = t  t,  = (t  t ),  = (t  t ), or 0 r(t1,..., t(r) ), where t, t, and ti with 1  i  (r) are variables or constants. Then w =, and the statement clearly holds. w
= r(t1,..., t(r) ). Then  =  J  J 0 r(t1,..., t(r) ), for
0 some intervals J and J with 0  J  J 0. Let (D, ) be a temporal structure, v a valuation, and i a time point.
Suppose that (D,, v, i) |=. As 0  I  J, we clearly have (D,, v, i) |=  J  J 0, that is, (D,, v, i) |= 0.
=,  = x.,  =
I,  = #I,  =  SI, or  =  UI. These cases follow directly from the induction hypotheses. We only present the case  =././
SI. We have w = w SI w. Let (D, ) be a temporal structure, v a valuation, and i a time point. Suppose that(D,, v, i) |=. Then there is a j  i with i   j  I such that (D,, v, j) |=  and (D,, v, k) |=  for any k  [i + 1, j + 1). Using the induction hypotheses for and, we obtain that (D,, v, j) |= w and (D,, v, k) |= w for any k  [i + 1, j + 1). Hence (D,, v, i) |= w.
The proof of the dual case, that is, that the formula  s is valid, is similar. It is based on the remark that the formula

 J  J 0 r(t1,..., t(r) )  r(t1,..., t(r) ) is valid.
Finally, we prove statement (1). Statement (2) is similar.
Let (C, ) be the collapse of two temporal structures (D1, 1 ) and (D2, 2 ). Suppose that  s is collapse-sufficient and that(C,, v, 0) |=  s, for some arbitrary valuation v. It follows that (D,, v, 0) |=  s for any (D, )  (D1, 1 ) (D2, 2 ).
As  s   is valid, we have that (D,, v, 0) |=, for any(D, )  (D1, 1 ) (D2, 2 ).
E. Additional Details on Practical Experience
In this section, we describe in detail all our policies in Nokias Data-collection Campaign, their MFOTL formalization, and the resources needed for monitoring.
Policies in Nokias Data-collection Campaign. We first describe the domain and relations used for formalizing the policies. Then we describe the policies in natural language and give their formalization.
The domain, that is, the values that can occur as a parameter of a system actions are the databases db1, db2, db3, all database accounts, all data identifiers, the constant unknown, all possible names for the synchronization scripts, all possible subversion URLs, all possible subversion revision numbers, and the subversion status values latest, old, mod, and nosvn.
We represent actions in the system as elements in relations. We explain now the relations used. The elements of the relations for the predicates select, insert, delete, and update correspond to database operations with equallynamed SQL commands. The parameters are the user executing the operation, the name of the database, and an identifier of the involved data. The elements in the relations for the predicates start and stop indicate the starting and finishing of a synchronization script and contain the name of the script as their only parameter. After the script script1 starts, it logs details about its SVN status in the relations for the predicate svn. The parameters are the name of the script, its SVN status determined by the command svn status -u -v, the SVN URL, and the SVN revision number. Possible values for SVN status are latest for the latest version, old for an older version, mod for a locally modified version, and nosvn if the script has not been checked out from the subversion repository. The relations for the predicate commit represent committing a new script version into the subversion repository. The parameters are the SVN URL and revision number.
Table IV. policy delete insert select update script1 runtime svn svn2 ins-1-2 ins-2-3 ins-3-2del-1-2del-2-3 del-3-2
Policy Formalizations in MFOTL
MFOTL formalizationff user. data. delete(user, db2, data)  user  script2ff user. data. insert(user, db2, data)  user  script1ff user. data. select(user, db2, data) user  script1  user  script2  user  triggersff user. data. update(user, db2, data)ff db. data. select(script1, db, data)  insert(script1, db, data) delete(script1, db, data)  update(script1, db, data)( [0,1s) [0,1s) end(script1)) S ([0,1s) [0,1s) start(script1))
[0,1s) [0,1s) end(script1)ff script. start(script)  ( [0,1s) [0,1s) end(script))  [1s,6h) end(script)ff script. start(script)  [0,1s) [0,10s) url. rev. svn(script, latest, url, rev)ff script. status. url. rev. svn(script, status,  url, rev)
[1s,) commit(url, rev0 )  rev0  revff user. data. insert(user, db1, data)  data 0 unknown
[0,1s) [0,30h] user0. insert(user0, db2, data)  delete(user0, db1, data)ff user. data. insert(user, db2, data)  data 0 unknown
[0,1s) [0,60s) user0. insert(user0, db3, data)ff user. data. insert(user, db3, data)  data 0 unknown
[0,60s) [0,1s) user0. insert(user0, db2, data)ff user. data. delete(user, db1, data)  data 0 unknown

[0,1s) [0,30h) user0. delete(user0, db2, data)([0,1s) [0,30h) user0. insert(user0, db1, data))
([0,30h) ff[0,30h) user0. insert(user0, db2, data))ff user. data. delete(user, db2, data)  data 0 unknown
[0,1s) [0,60s) user0. delete(user0, db3, data)ff user. data. delete(user, db3, data)  data 0 unknown
[0,60s) [0,1s) user0. delete(user0, db2, data)
In the following, we informally state the policies in natural language and for the more involved policies, we provide additional explanations. The MFOTL formalization of the policies is shown in Table IV. The policies are: delete: Only user script2, representing the synchronization script script2, may delete data in db2 by executing the SQL delete command. insert: Only user script1, representing the synchronization script script1, may insert data in db2 by executing the SQL insert command. select: Only a limited set of users (script1, script2, triggers) may read data from db2 by executing the SQL select command. update: No SQL update commands are allowed in db2, only insertion and deletions. script1: Database operations may be executed under the user account script1 only while the script script1 is running. The motivation for this policy is that the account script1 should only be used by the script, so if the account is used while the script is not running, the account may have been compromised. The database operation can happen while the script is running, including the boundaries. That is, the time points when an operation happens and when the script starts or ends may have equal time stamps. The semantics of the S operator includes the script start, but excludes the script end. Therefore, the script end is allowed with the additional disjunct at the end of the formula. runtime: The synchronization scripts must run for at least 1 second and for no longer than 6 hours. svn, svn2: The synchronization scripts are maintained in an SVN repository. We require that when started, the synchronization scripts are the latest version available
Table V. policy delete insert select update script1 runtime svn svn2 ins-1-2 ins-2-3 ins-3-2 del-1-2 del-2-3 del-3-2log 1
10 s / 4 MB
13 s / 4 MB
10 s / 4 MB
10 s / 4 MB
14 s / 4 MB
12 s / 9 MB
10 s / 4 MB
12 s / 16 MB
231 m / 161 MB
9 m / 8 MB
7 m / 5 MB
24 s / 176 MB
10 s / 4 MB
10 s / 4 MBlog 2
7 s / 4 MB
8 s / 4 MB
7 s / 4 MB
6 s / 4 MB
9 s / 4 MB
8 s / 9 MB
7 s / 4 MB
9 s / 16 MB
44 m / 103 MB
3 m / 7 MB
3 m / 5 MB
16 s / 139 MB
6 s / 4 MB
6 s / 4 MB
Monitor Performance  Running Times / Memory Usagelog 3
7 s / 4 MB
10 s / 4 MB
7 s / 4 MB
8 s / 4 MB
10 s / 4 MB
8 s / 6 MB
7 s / 4 MB
9 s / 16 MB
67 m / 107 MB
5 m / 8 MB
5 m / 5 MB
13 s / 87 MB
7 s / 4 MB
7 s / 4 MBlog 4
6 s / 4 MB
8 s / 4 MB
6 s / 4 MB
6 s / 4 MB
9 s / 4 MB
8 s / 9 MB
6 s / 4 MB
9 s / 16 MB
24 m / 102 MB
4 m / 8 MB
4 m / 6 MB
11 s / 79 MB
6 s / 4 MB
6 s / 4 MBin the repository (largest SVN revision number). We use two different formalizations, svn and svn2. The policy svn uses the status parameter of the relation svn. The policy svn2 compares the revision number parameter of the relation svn with the committed revision numbers obtained from the subversion log via the commit relation. Computing the latest revision number is done by the logging mechanism for the policy svn, but by the monitor for the policy svn2. Monitoring both policies allows us to compare how efficiently the monitor copes with these different formalizations and to observe the impact of offloading the monitor by doing pre-computations in the logging mechanisms. ins-*: Data uploaded by the phone into db1 must be propagated to all databases. In particular, ins-1-2 requires that data uploaded into db1 must be inserted into db2 within 30 hours after the upload, unless it has been deleted from db1 in between. Furthermore, ins-2-3 and ins-3-2 require that data may be inserted into db2 iff it is inserted into db3 within 1 minute. The time limit from db1 to db2 is 30 hours because the synchronization scripts run once every 24 hours and can run for up to 6 hours. The time limit from db2 to db3 is only 60 seconds as this synchronization is implemented by database triggers that start immediately upon a change in db2. Note that these policies require propagation of new data between db2 and db3 in both directions. However, between db1 and db2 only one direction is required. The reason is the incomplete logging for db1. del-*: Data deleted from db1 must be consistently deleted from all databases. The policies del-2-3 and del-3-2 are analogous to the policies ins-2-3 and ins-3-2, respectively. The formalization of the policy del-1-2 is more involved: If data is deleted from db1, then this data must also be deleted from db2 within
30 hours. However, if the data has just been uploaded to db1 and not yet propagated to db2, then it simply should not be propagated to db2 in the future either.
Since the propagation would happen in at most 30 hours, we can simply consider the past and the futurelog 5
5 s / 4 MB
6 s / 4 MB
5 s / 4 MB
4 s / 4 MB
6 s / 4 MB
5 s / 7 MB
5 s / 4 MB
7 s / 16 MB
9 m / 71 MB
2 m / 8 MB
2 m / 5 MB
8 s / 58 MB
5 s / 4 MB
4 s / 4 MBlog 6
4 s / 4 MB
5 s / 4 MB
4 s / 4 MB
4 s / 4 MB
6 s / 4 MB
5 s / 7 MB
4 s / 4 MB
6 s / 16 MB
5 m / 65 MB
2 m / 7 MB
2 m / 5 MB
7 s / 53 MB
4 s / 4 MB
4 s / 4 MB
4 s
5 s
4 s
4 s
5 s
4 s
4 s
6 s
3 m
1 m
1 m
12 s
4 s
4 slog 7
/ 4 MB
/ 4 MB
/ 4 MB
/ 4 MB
/ 4 MB
/ 7 MB
/ 4 MB
/ 16 MB
/ 57 MB
/ 7 MB
/ 5 MB
/ 111 MB
/ 4 MB
/ 4 MBlog 8
6 s / 4 MB
8 s / 4 MB
7 s / 4 MB
6 s / 4 MB
9 s / 4 MB
7 s / 20 MB
7 s / 4 MB
8 s / 16 MB
73 m / 115 MB
2 m / 8 MB
2 m / 5 MB
21 s / 184 MB
6 s / 4 MB
6 s / 4 MBlog 9
6 s / 4 MB
8 s / 4 MB
6 s / 4 MB
7 s / 4 MB
8 s / 4 MB
7 s / 21 MB
7 s / 4 MB
8 s / 16 MB
48 m / 111 MB
1 m / 6 MB
1 m / 5 MB
11 s / 102 MB
6 s / 4 MB
6 s / 4 MB
30 hours to determine whether data has been and will be propagated to db2 or not.
Monitor Performance. Table V shows the monitors running times and memory usage for all policies in Table IV and all log files in Table II.
Our reason for splitting the available stream of logged actions into smaller chunks (i.e., log files) is to evaluate our monitor on different data sets with different characteristics. Each of our chunks corresponds to a time span of approximately 24 hours. We point out that monitoring such chunks separately may reveal different violations than monitoring the whole stream of actions. This is because, policy conformance at a time point may depend on actions that have been logged in another (timewise subsequent or prior) chunk, as the time window of a temporal operator may overpass the time span of a chunk. Except for the policy del-1-2, all policy violations on the whole stream are also detected on a chunk. However, due to splitting, additional violations may be reported. We were not concerned about these issues, as our main focus was on evaluating the performance of the monitor. Moreover, we have manually checked that all violations reported in Section IV are indeed violations on the whole stream.L OLA: Runtime Monitoring of Synchronous
Systems
Ben DAngelo
Sriram Sankaranarayanan
Bernd Finkbeiner
Henny B. Sipma
Cesar Sanchez
Sandeep Mehrotra
Will Robinson
Zohar Manna
Computer Science Department, Stanford University, Stanford, CA 94305
{bdangelo,srirams,cesar,sipma,manna}@theory.stanford.edu
Department of Computer Science, Saarland University finkbeiner@cs.uni-sb.de
Abstract We present a specication language and algorithms for the online and ofine monitoring of synchronous systems including circuits and embedded systems. Such monitoring is useful not only for testing, but also under actual deployment. The specication language is simple and expressive; it can describe both correctness/failure assertions along with interesting statistical measures that are useful for system proling and coverage analysis.
The algorithm for online monitoring of queries in this language follows a partial evaluation strategy: it incrementally constructs output streams from input streams, while maintaining a store of partially evaluated expressions for forward references. We identify a class of specications, characterized syntactically, for which the algorithms memory requirement is independent of the length of the input streams. Being able to bound memory requirements is especially important in online monitoring of large input streams. We extend the concepts used in the online algorithm to construct an efcient ofine monitoring algorithm for large traces.
We have implemented our algorithm and applied it to two industrial systems, the PCI bus protocol and a memory controller. The results demonstrate that our algorithms are practical and that our specication language is sufciently expressive to handle specications of interest to industry.
I. I NTRODUCTION
Monitoring synchronous programs for safety and liveness properties is an important aspect of ensuring their proper runtime behavior. An ofine monitor analyzes traces of a system post-simulation to spot violations of This research was supported in part by NSF grants CCR-0121403, CCR-02-20134, CCR-02-09237, CNS-0411363, and CCF0430102, by ARO grant DAAD19-01-1-0723, by NAVY/ONR contract N00014-03-1-0939, by the Siebel Graduate Fellowship, and by the BMBF grant 01 IS C38 B as part of the Verisoft project.
Synopsys, Inc.the specication. Ofine monitoring is critical for testing large systems before deployment. An online monitor processes the system trace while it is being generated.
Online monitoring is used to detect violations of the specication when the system is in operation so that they can be handled before they translate into observable and cascading failures, and to adaptively optimize system performance.
Runtime monitoring has received growing attention in recent years,,. While static verication intends to show that every (innite) run of a system satises the specication, runtime monitoring is concerned only with a single (nite) trace. Runtime monitoring can be viewed as an extension of testing with more powerful specication languages.
The ofine monitoring problem is known to be easy for purely past or purely future properties. It is well known that for past properties, the online monitoring problem can be solved efciently using constant space and linear time in the trace size. For future properties, on the other hand, the space requirement generally depends on the length of the trace, which suggests that online monitoring may quickly become intractable in practical applications with traces exceeding 106 simulation steps.
In this paper, we present a specication language, intended for industrial use. The language can express properties involving both the past and the future. It is a functional stream computation language like L USTRE   and E STEREL, with features that are relevant to our problem at hand. It is parsimonious in its number of operators (expressions are constructed from three basic operators), but the resulting expressiveness surpasses temporal logics and many other existing formalisms
Proceedings of the 12th International Symposium on Temporal Representation and Reasoning (TIME05)
1530-1311/05 $20.00  2005 IEEEincluding nite-state automata.
We provide a syntactic characterization of efciently monitorable specications, for which the space requirement of the online monitoring algorithm is independent of the size of the trace, and linear in the specication size. An analysis of some industrial specications provided by Synopsys, Inc. showed that a large majority of these specications lie in this efciently monitorable class. For the ofine monitoring problem, we demonstrate an efcient monitoring strategy in the presence of mixed past/future properties.
We have implemented our algorithm and specication language in a system called L OLA. L OLA accepts a specication in the form of a set of stream expressions, and is then run on a set of input streams. Two types of specications are supported: properties that specify correct behavior, and properties that specify statistical measures that allow proling the system that produces the input streams. An execution of L OLA computes arithmetic and logical expressions over the nite input and intermediate streams to produce an output consisting of error reports and the desired statistical information.
A. Related Work
Much of the initial work on runtime monitoring (cf.,,  ) was based on temporal logic. In, non-deterministic automata are built from LTL to check violations of formulas over nite traces and the complexity of these problems is studied. LTL based specications have already been pursued in tools such as the Temporal
Rover   and Java PathExplorer. One limitation of this approach is that the logic must be adapted to handle truncated traces. The approach taken in   considers extensions of LTL for the case of truncated paths with different interpretations (weak and strong) of the next operator at the end of the trace. The choice of handling success/failure on a nite trace frequently depends on the situation being modeled.
Another important difference between runtime verication and static verication is that liveness properties can never be violated on a nite trace. An appealing solution is to extend the specication language to compute quantitative measures based on the trace. Temporal properties can be specied in L OLA, but one of the main goals is to go beyond property checking to the collection of numerical statistics. For example, instead of checking the property there are only nitely many retransmissions of each package, which is vacuously true over nite traces, we desire to evaluate queries like what is the average number of retransmissions. Ourrst approach to combine the property proving with data collection appeared in. Following this trend, runtime veriers can be used not only for bug-nding, but also for proling, coverage, vacuity and numerous other analyses.
L OLA models runtime verication as a stream computation. The denition of L OLA output streams in terms of other streams resembles synchronous programming languages (notably L USTRE, E STEREL, Signal  ), but there is a signicant difference: these languages are designed primarily for the construction of synchronous systems. Therefore, output values for a time instant are computed directly from values at the same and previous instants. This assumption makes perfect sense if we desire that the systems we specify be executable, and therefore be causal. However, runtime specications are descriptive in nature. They include future formulas whose evaluation may have to be delayed until future values arrive. This requires stronger expressiveness in the language and the corresponding evaluation strategies.
Other efforts in run-time verication include, which studies the efcient generation of monitors from specications written as extended regular expressions, and, which studies rewriting techniques for the efcient evaluation of LTL formulas on nite execution traces, both online and ofine. In, an efcient method for the online evaluation of past LTL properties is presented. This method exploits that past LTL can be recursively dened using only values in the previous state of the computation. Our efciently monitorable specications generalize this idea, and apply it uniformly to both verication and data collection.
The system that most closely resembles L OLA is Eagle. Eagle allows the description of monitors based on greatest and least xed points of recursive denitions. Many logical formalisms used to describe properties, including past and future LTL formulas, can be translated to Eagle specications. These are then compiled into a set of rules that implements the monitor.
L OLA differs from Eagle in the descriptive nature of the language, and in that L OLA is not restricted to checking logical formulas, but can also express numerical queries.
II. L OLA OVERVIEW
In this section we describe the specication language.
The monitoring algorithms will be presented in Section III.
A. Specication Language: Syntax
A L OLA specication describes the computation of output streams from a given set of input streams. A
Proceedings of the 12th International Symposium on Temporal Representation and Reasoning (TIME05)
1530-1311/05 $20.00  2005 IEEEstream  of type T is a nite sequence of values from
T. We let (i), i  0 denote the value of the stream at time step i.
Denition 1 (L OLA specication) A L OLA specication is a set of equations over typed stream variables, of the form s1...
= e1 (t1,..., tm, s1,..., sn )...sn = en (t1,..., tm, s1,..., sn ),  where s1,..., sn are called the dependent variables and t1,..., tm are called the independent variables, and e1,..., en are stream expressions over s1,..., sn and t1,..., tm. Independent variables refer to input streams and dependent variables refer to output streams.
A L OLA specication can also declare certain output boolean variables as triggers. Triggers generate notications at instants when their corresponding values become true. Triggers are specied in L OLA as triggerwhere  is a boolan expression over streams.
A stream expression is constructed as follows:
If c is a constant of type T, then c is an atomic stream expression of type T ;
If s is a stream variable of type T, then s is an atomic stream expression of type T ;
Let f : T1 T2   Tk fi T be a k -ary operator.
If for 1  i  k, ei is an expression of type Ti, then f (e1,..., ek ) is a stream expression of type T ;
If b is a boolean stream expression and e1, e2 are stream expressions of type T, then ite(b, e1, e2 ) is a stream expression of type T ; note that ite abbreviates if-then-else.
If e is a stream expression of type T, c is a constant of type T, and i is an integer, then e[i, c] is a stream expression of type T. Informally, e[i, c] refers to the value of the expression e offset i positions from the current position. The constant c indicates the default value to be provided, in case an offset of i takes us past the end or before the beginning of the stream.
In our implementation we partition the dependent variables into output variables and intermediate variables to distinguish streams that are of interest to the user and those that are used only to facilitate the computation of other streams. However, for the description of the semantics and the algorithm this distinction is not important, and hence we will ignore it in this paper.
Example 1 Let t1, t2 be stream variables of type boolean and t3 be a stream variable of type integer. The following is an example of a L OLA specication with t1, t2 and t3 as independent variables: s1 s2 s3 s4 s5 s6 s7 s8 s9 s10
=
=
=
=
=
=
=
=
=
=true t3 t1  (t3  1)((t3 )2 + 7) mod 15 ite(s3, s4, s4 + 1) ite(t1, t3  s4, s3 ) t1 [+1, false] t1 [1, true] s9   + (t3 mod 2) t2  (t1  s10 [1, true])
Stream variable s1 denotes a stream whose value is true at all positions, while s2 denotes a stream whose values are the same at all positions as those in t3. The values of the streams corresponding to s3,..., s6 are obtained by evaluating their dening expressions placewise at each position. The stream corresponding to s7 is obtained by taking at each position i the value of the stream corresponding to t1 at position i + 1, except at the last position, which assumes the default value false. Similarly for the stream for s8, whose values are equal to the values of the stream for t1 shifted by one position, except that the value at the rst position is the default value true. The stream specied by s9 counts the number of odd entries in the stream assigned to t3 by accumulating (t3 mod 2). Finally, s10 denotes the stream that gives at each position the value of the temporal formula t1 Until t2 with the stipulation that unresolved eventualities be regarded as satised at the end of the trace.
B. Specication Language: Semantics
The semantics of L OLA specications is dened in terms of evaluation models, which describe the relation between input streams and output streams.
Denition 2 (Evaluation Models) Let  be a L OLA specication over independent variables t1,..., tm with types T1,..., Tm, and dependent variables s1,..., sn with types Tm+1,..., Tm+n. Let 1,..., m be streams of length N +1, with i of type Ti. The tuple 1,..., n  of streams of length N + 1 with appropriate types is called an evaluation model, if for each equation in si = ei (t1,..., tm, s1,..., sn ), 1,..., n  satises the following associated equations: i (j) = val (ei )(j)
Proceedings of the 12th International Symposium on Temporal Representation and Reasoning (TIME05)
1530-1311/05 $20.00  2005 IEEEfor 0  j  Nwhere val (e)(j) is dened as follows. For the base cases: val (c)(j) = c. val (ti )(j) = i (j). val (si )(j) = i (j).
For the inductive cases: val (f (e1,..., ek )(j) = f (val (e1 )(j),..., val (ek )(j)). val (ite(b, e1, e2 ))(j) = if val (b)(j) then val (e1 )(j) else val (e2 )(j). val (e[k,  c])(j) = val (e)(j + k) if 0  j + k  N, c otherwise.
The set of all equations associated with  is denoted by.
Example 2 Consider the L OLA specication
: s = t1   + ite(t2 [1, true], t3, t4 + t5 ).
The associated equations  are(j
1), 2
1 (j + 1) + ite  3 (j), j  [1, N ), 4 (j) + 5 (j)(j) =
2 (N  1), j = N, ite  3 (N ), (N
)
+(N
)
4
5j = 0.
1 (1) + 3 (0)
A L OLA specication is well-dened if for any set of appropriately typed input streams, all of the same length, it has exactly one evaluation model.
Example 3 Consider the L OLA specication
1 : s1 = (t1  10).
For the stream 1 : 0,..., 100, the associated equations are 1 (j) = (1 (j)  10). The only evaluation model of 1 is the stream 1 (i) = true iff i  10. In fact, this L OLA specication is well-dened, since it denes a unique output for each possible input. However, the specication
2 : s2 = s2  (t1  10)is not well-dened, because there are many streams 2 that satisfy 2, for some input stream. Similarly, the specication
3 : s3 = s3is not well-dened, but for this specication the reason is that it has no evaluation models.
To avoid ill-dened specications we dene a syntactic restriction on L OLA specications guaranteeing that any well-formed L OLA expression is also well-dened.
Denition 3 (Dependency Graph) Let  be a L OLA specication. A dependency graph for  is a weighted and directed multi-graph G = V, E, with vertex set
V = {s1,..., sn, t1,..., tm }. An edge e : si, sk, w labeled with a weight w is in E iff the equation for i (j) in  contains k (j + w) as a subexpression of the RHS, for some j (or e : si, tk, w for subexpression k (j +w)). Intuitively, the edge records the fact that si at a particular position depends on the value of sk, offset by w positions. Note that there can be multiple edges between si and sk with different weights on each edge.
Vertices labeled by ti do not have outgoing edges.
Example 4 Consider the L OLA specication over independent integer variables t1, t2 :s2    t1,. s1 = s2   + ite  s2, s2 s2 = (s1 + t2  ).
Its dependency graph, shown in Figure 1, has three edges from s1 to s2, with weights 1, 0, 1, and one zero weighted edge from s2 back to s1. There is one edge from s1 to t1, and one from s2 to t2.
A walk of a graph is a sequence v1,..., vk+1 of vertices, for k  1, and edges e1,..., ek, such that ei : vi, vi+1, wi . The walk is closed iff v1 = vk+1.
The total weight of a walk is the sum of weights of its edges.
Denition 4 (Well-Formed Specications) A L OLA specication is well-formed if there is no closed-walk with total weight zero in its dependency graph.
Theorem 1 Every well-formed L OLA specication is well-dened.
All proofs will be available in an extended version of this document. The following alternative characterization of well-formedness is useful for algorithmic purposes and for the ofine monitoring algorithm.
Proceedings of the 12th International Symposium on Temporal Representation and Reasoning (TIME05)
1530-1311/05 $20.00  2005 IEEE
@ABC
GFED t1 o
1
@ABC
GFED s1 l
1,0,1, GFED
@ABC s
2
2
0
@ABC
/ GFED t2
Fig. 1: Dependency graph for the specication of Example 4.
Theorem 2 A L OLA specication is well-formed iff no strongly connected component in G has both a positive and a negative weighted cycle.
The converse of Theorem 1 is not true: not every welldened L OLA specication need be well-formed. For instance, the specication s = s  s is well-dened, but not well-formed.
C. Statistics and Context-free Properties
We shall now demonstrate the use of our specication language for computing statistical properties over trace data. Numerical properties over traces are essential as(1) components of correctness properties that involve counts, maxima or minima over trace data, and (2) estimating performance and coverage metrics in the form of averages.
L OLA can be used to compute incremental statistics, i.e., measures that are dened using an update function f (v, u) where u represents the measure thus far, and v represents the new incoming data. Given a sequence of values v1,..., vn, with a special default value d, the statistic over the data is dened in the reverse sense as v = f (v1, f (v2,..., f (vn, d)))or in the forward sense as v = f (vn, f (vn1,..., f (v1, d)))
Examples of such statistical measures include count with fcount (v, u) = u+1, sum with fsum (v, u) = v +u, max with fmax (u, v) = max (u, v), among many others; the statistical average can be incrementally dened as a pair consisting of the sum and the count.
Given an update function f and a data-stream v, the following L OLA queries compute the statistic in the forward and reverse senses respectively: stat f = f (stat f [1, d], v), stat r = f (stat r [1, d], v).
For most common incremental statistical measures, either of these L OLA queries compute the same result.
The choice of a monitoring strategy can dictate the use of one over another as will be evident in the subsequent section.
The use of numeric data also increases the expressiveness of the language; it enables the expression of context-free properties. Commonly encountered contextfree properties include properties such as every request has a matching grant. In programs, we may use such properties to verify that every lock acquired has been released, or that every memory cell allocated is eventually freed exactly once.
Example 5 Consider the property: the number of as must always be no less than the number of bs. This property can be expressed in L OLA as s = s  + ite((a  b), 1, 0)
+ ite((b  a), 1, 0) trigger(s  0)
Integer streams in a L OLA specication enable the expression of context-free properties by being used as counters to model stacks. For instance, a two alphabet stack with alphabet symbols 0 and 1 can be modelled by a counter. Each pop is implemented by dividing the counter by 2, thereby eliminating the least signicant bit.
Each push is modelled by a multiplication by 2 followed by addition, thereby setting the least signicant bit. Thus, with one (unbounded) counter, a L OLA specication can express context-free properties.
It can be shown that L OLA specications with only boolean streams cannot express context-free properties.
III. M ONITORING A LGORITHM
In this section, we rst describe the setting for the monitoring problem considered in the paper. We then describe our monitoring algorithm using partial evaluation of the equational semantics.
A. Monitoring Setup
We distinguish two situations for monitoring  online and ofine monitoring. With online monitoring, system behaviors are observed as the system is run under a test/real-life setting. In a simulation setting, we can assume that the monitor is working in tandem with the simulator, with the monitor processing a few trace positions while the simulator waits, and then the monitor waiting while the simulation proceeds to produce the Proceedings of the 12th International Symposium on Temporal Representation and Reasoning (TIME05)
1530-1311/05 $20.00  2005 IEEEnext few positions. On the other hand, ofine monitoring assumes that the system has been run to completion, and the trace data was dumped to a storage device. This leads to the following restriction for online monitoring: the traces are available a few points at a time starting from time 0 onwards, and need to be processed online to make way for more incoming data. In particular, random access to the traces is not available.
B. Online Monitoring Algorithm
In online monitoring we assume that the trace is available one position at a time, starting from time 0.
The length of the trace is assumed to be unknown and large.
Let t1,..., tm be independent (input) stream variables, and s1,..., sn be dependent (output) stream variables.
Let j  0 be the current position where the latest trace data is available from all the input streams.
Evaluation Algorithm: The evaluation algorithm maintains two stores of equations:
Resolved equations R of the form i (j) = c, or i (j) = c, for constant c.
Unresolved equations U of the form i (j) = ei for all other stream expressions ei.
Initially both stores are empty. At the arrival of input stream data for a particular position j, 0  j  N, that is, when 1 (j),..., m (j) become available, the following steps are carried out:
1) The equations 1 (j) = c1,..., m (j) = cm are added to R, 2) The associated equations for 1 (j),..., n (j) are added to U, 3) The equations in U are simplied as much as possible; if an equation becomes of the form i (j) = c, it is removed from U and added to R. If c is true and the corresponding output variable si is marked as a trigger, then a violation is reported.
4) For each stream ti ( also si ), there is a non-negative constant ki such that i (j ki ), if present in R can be safely removed. The constant ki  0 is dened as
k is non-negative and. ki = max k ti [k, d] is a subexpression.
Intuitively, for any position j, j + ki is the latest value in the future whose computation requires the value of i (j).
Example 6 To illustrate the last point, consider the specication, s = s  + t.
Let  be the input stream. The value of ki for s is 3 and for t is zero. This indicates that for any input stream, the value  (j) can be removed from R at position j itself. Similarly any (j)  R may be removed from R at (or after) position j + 3.
Equations in U are simplied using the following rules:
1) Partial evaluation rules for function applications such as, true  e  e, 0 + x  x
2) Rewrite rules for if-then, ite(true, e1, e2 )  e1
3) Substitution of resolved positions from R. If i (j) = c  R, then every occurrence of i (j) in U is substituted by c and possibly simplied further.
We illustrate the operation of the algorithm on a simple example.
Example 7 Let t1, t2 be two input boolean stream variables. Consider the specication
: s = t2  (t1  s[1, false]),  which computes t1 Until t2. The associated equations for  are:

2 (j)  (1 (j)  (j + 1)) j + 1  N(j) = otherwise.
2 (j)
Let the input streams, 1 and 2 be given by
1
2false truefalse falsetrue falsetrue falsetrue falsetrue falsetrue false
At position 0, we encounter false, true. The equation for (0) is(0)
= 2 (0)  (1 (0)  (1))true  (false  (1))trueand thus (0) = true is added to the resolved store R.
At position 1, we encounter false, false and thus we can set (1) = false, which is also added to R. From j = 2 until j = 5, we encounter true, false. At each of these positions the equations (j) = (j + 1) are added to U. The equation store U now has the equations(2) = (3), (3) = (4),..., (5) = (6).
Proceedings of the 12th International Symposium on Temporal Representation and Reasoning (TIME05)
1530-1311/05 $20.00  2005 IEEE
At position 6, we encounter true, false with the added information that the trace has ended. We set (6) = false and add it to R. This lets us resolve the equations in U and set all the positions from 2 to 6 to false.
Note that the equation associated with i (j) on the LHS is added only after the current position reaches j, even if the term i (j) appears on the RHS of some equation before position j is reached.
The algorithm above works in time and space that is linear in the length of the trace and the size of the specication. Since the memory usage can be as large as the length of the trace in the worst-case, the method may not work for long simulations and large traces.
Example 8 Consider the following L OLA specication: ended = false[1, true] s = ite(ended, t, s[1, true])in which the output stream  takes the same value everywhere that the input stream  takes at the end of the trace. The partial evaluation algorithm maintains the unresolved (0),..., (N ). Such specications cannot be monitored efciently. Furthermore, if the variable s appears in other expressions, the evaluation of the corresponding streams need to be delayed until  can be resolved.
In the next section we characterize an efciently monitorable set of L OLA specications based on the properties of their dependency graphs. The partial evaluation algorithm will be shown to work efciently for such specications.
C. Efciently Monitorable Specications
We present a class of specications that are efciently monitorable. These specications are guaranteed to limit the number of unresolved equations in the memory to a pre-determined constant that depends only on the size of the specication and not on the size of the trace.
Denition 5 (Efciently Monitorable Specications)
A L OLA specication is efciently monitorable (EM) if its worst case memory requirement under our online monitoring algorithm is constant in the size of the trace.
Example 9 Consider the specication Every request must be eventually followed by a grant before the trace ends, which can be expressed as follows: reqgrant = ite(request, evgrant, true) evgrant = grant  evgrant[1, false] trigger ( reqgrant)
The specication encodes the temporal assertion
(request  (grant)). Another way that produces the same result is waitgrant =
grantrequest waitgrant[1, false]ff fftrigger ended  waitgrant
The stream waitgrant records if the monitor is currently waiting for a grant. The monitor waits for a grant whenever it encounters a request and stops waiting if there is a grant. If the trace ends while the monitor is still waiting, it triggers an error. The latter formulation is efciently monitorable, while the former is not. For instance, at every time instance, waitgrant(i) is instantly resolved given its previous value, and those of the input streams. Thus, the simple partial evaluation algorithm monitors the latter with very little, constant, buffering.
The following theorem characterizes efciently monitorable L OLA specications.
Theorem 3 If the dependency graph of a L OLA query has no positive cycles then it is efciently monitorable.
The converse of the theorem above does not hold in general. However, in the absence of an alternative syntactic characterization of EM specication, we shall henceforth use the term EM specication to denote queries whose dependency graphs do not contain positive cycles.
Given graph G, that does not have any positive weight cycles, we construct a graph G+, obtained by removing all negative weight edges from G. Furthermore, among all the edges in G between two nodes si and sj, we choose to add only that edge to G+ which has the maximum positive weight. The graph G+ has no self loops or multiple edges, and hence is a weighted directed acyclic graph (DAG). For each node si  G+, we dene i as follows:edge from si, 0, if there is no outgoing
 w(ej )i =e
: ss j i j, ow. max j + w(ej ) is an edge in G+
Example tion: s1 s2 s3
10 Consider the following L OLA specica= t1 [1, false]  s3 [7, false]
= ite(s1 [2, true], t2, t2  )
= (s2 [4, true]  5)
The dependency graph G is shown in Figure 2. The values of the  function are as follows:(t1 ) = (t2 ) = 0, (s1 ) = 1, (s2 ) = 3, (s3 ) = 7.
Proceedings of the 12th International Symposium on Temporal Representation and Reasoning (TIME05)
1530-1311/05 $20.00  2005 IEEE
7
@ABC
GFED s3v
4
@ABC
/ GFED s2
2
2,1

@ABC
GFED t2
@ABC
/ GFED s1
1

@ABC
GFED t1(a) Dependency graph G.
@ABC
GFED s3
4
@ABC
/ GFED s2
2
2

@ABC
GFED t2
@ABC
/ GFED s1
1

@ABC
GFED t1(b) Derived graph G+.
Fig. 2: The dependency graph G for Example 10 and its derived graph G+.
The signicance of the  function is clear through the following theorem.
Theorem 4 The partial evaluation algorithm resolves any trace position i (j) before time j + i.
The memory requirement is therefore constant in N for an efcient specication. This number of unresolved positions in U is upper-bounded by O(1 +    + n ).
For instance, computing the  values for the queries in Example 9, we nd that (waitgrant) = 0. This shows that the value of waitgrant resolves immediately, given its previous value and the inputs. Our experimental results in the subsequent section show that requiring specications to be efciently monitorable is not unreasonable in practice. Furthermore, streams involved in positive cycles can be discarded or even rewritten(as shown in Example 9) for the purposes of online monitoring.
The framework developed generalizes naturally to an ofine monitoring algorithm. Please refer to the full version of this paper available online.
IV. A PPLICATIONS
There are numerous applications of this formalism. In this section, we describe two such applications obtained directly from the industry. Synopsys, Inc. provided some circuit simulation dumps, along with specications written in the industry standard System Verilog Assertions(SVA). We were able to hand-translate the SVA queries directly into L OLA specications, a process that is potentially mechanizable.
Our OC AML-based implementation of L OLA reads a trace le and the specication le. It implements the online monitoring algorithm described in Section III with some direct optimizations. We have incorporated facilities for displaying dependency graphs of specications.
The following two case studies were considered:a) Memory Controller: A Verilog model for a memory controller was simulated yielding 13 input streams. The corresponding SVA assertions were handtranslated into a L OLA specication. The specication had 21 intermediate streams and 15 output streams, all of which were declared triggers. Properties enforced included mutual exclusion of signals, correct transfers of address and data, and timing specications (e.g. signal stability for 3 or 4 cycles). The specications were not
EM : the dependency graph had three positive-sum cycles, each encoding a temporal until operator. Figure 3 shows the performance of L OLA on these traces. b) PCI: We hand translated SVA assertions describing the PCI 2.2 specications for the master. A circuit implementing the master was simulated for varying times to produce a set of traces to plot the performance. The specication had 15 input streams, 161 output streams and 87 trigger streams. Our initial implementation contained three positive weight cycles. We were able to remove these by rewriting the queries carefully. Running times can also be found in Figure 3. Bugs were deliberately introduced into the circuit in order to evaluate the effectiveness of runtime verication. L OLA reports numerous useful trigger violations for the longest trace.
V. C ONCLUSIONS
We have presented L OLA, a formalism for runtime verication based on a functional language over nite streams equipped with a partial evaluation-based strategy for online evaluation. Our formalism combines runtime verication of boolean temporal specications with statistical measures to estimate coverage and specify complex temporal patterns. By evaluating our system on industrial strength specications, we have demonstrated that L OLA can express relevant properties. Using dependency graphs, we have characterized efciently monitorable queries that can be monitored online efciently in terms of space. Based on our case-studies so far, the restriction to efciently monitorable specications seems
Proceedings of the 12th International Symposium on Temporal Representation and Reasoning (TIME05)
1530-1311/05 $20.00  2005 IEEE
# simulation steps
5000
10000
20000
50000
100000
200000
500000
1000000
Controller example
# clock pos. edges time (sec)
250
0.18
500
0.35
1000
0.71
2500
1.78
5000
3.47
10000
6.83
25000
17.02
50000
33.70
PCI example
# clock pos. edges
834
1667
3334
8334
16667
33334
83334
166667time
4.62
8.87
19.04
29.47
52.53
99.17
236.96
467.98
Fig. 3: Running times for both examples. All timings were measured on an Intel Xeon Processor running Linux
2.4 with 2Gb RAM.practical.
In the future, we intend to study automatic techniques for rewriting non-EM specications into efciently monitorable ones where possible, and in further collaboration with industry study the applicability of these techniques for larger case studies. We expect that for such use some syntactic sugar needs to be added to L OLA to facilitate specication of common constructs. Also the error reporting needs to be improved by synthesizing explanations for each violation. Extensions to handle synchronous systems with many clocks, asynchronous systems, and distributed systems are also under consideration.
R EFERENCES
  K. Havelund and G. Rosu, Eds., Runtime Verication 2001(RV01), ser. ENTCS, vol. 55. Elsevier, 2001., Runtime Verication 2002 (RV02), ser. ENTCS, vol. 70, no. 4. Elsevier, 2002.
  O. Sokolsky and M. Viswanathan, Eds., Runtime Verication
2002 (RV03), ser. ENTCS, vol. 89, no. 2. Elsevier, 2003.
  N. Halbwachs, P. Caspi, P. Raymond, and D. Pilaud, The synchronous data-ow programming language LUSTRE, Proc. of IEEE, vol. 79, no. 9, pp. 13051320, 1991.
  G. Berry, Proof, language, and interaction: essays in honour of Robin Milner. MIT Press, 2000, ch. The foundations of Esterel, pp. 425454.
  I. Lee, S. Kannan, M. Kim, O. Sokolsky, and M. Viswanathan, Runtime Assurance Based on Formal Specications, in Proc. of the International Conference on Parallel and Distributed
Processing Techniques and Applications, 1999.
  D. Drusinsky, The temporal rover and the ATG rover, in SPIN
Model Cheking and Software Verication, 2000, pp. 323330.
  K. Havelund and G. Rosu, Synthesizing monitors for safety properties, in Proc. of TACAS02. Springer, 2002, pp. 342
356.
  Z. Manna and A. Pnueli, Temporal Verication of Reactive
Systems: Safety. New York: Springer, 1995.
  O. Kupferman and M. Y. Vardi, Model checking of safety properties, Formal Methods in System Design, vol. 19, no. 3, pp. 291314, 2001.
  K. Havelund and G. Rosu, An overview of the runtime verication tool java pathexplorer, Formal Methods for Systems
Design, vol. 24, no. 2, pp. 189215, 2004.
  C. Eisner, D. Fisman, J. Havlicek, Y. Lustig, A. McIsaac, and D. V. Campenhout, Reasoning with temporal logic on truncated paths, in Proc. of CAV03, ser. LNCS, vol. 2725.
Springer, 2003, pp. 2739.
  B. Finkbeiner, S. Sankaranarayanan, and H. B. Sipma, Collecting statistics over runtime executions, in.
  T. Gautier, P. Le Guernic, and L. Besnard, SIGNAL: A declarative language for synchronous programming of realtime systems, in Proc. Conference on Functional Programming
Languages and Computer Architecture. Springer, 1987, pp.
257277.
  K. Sen and G. Rosu, Generating optimal monitors for extended regular expressions, in.
  G. Rosu and K. Havelund, Rewriting-based techniques for runtime verication, Journal of Automated Software Engineering(to appear).
  H. Barringer, A. Goldberg, K. Havelund, and K. Sen, Rulebased runtime verication, in Proc. of 5th International Conference VMCAI04, ser. LNCS, vol. 2937. Springer, 2004, pp.
4457.
  System verilog assertion homepage, 2003, [Online] Available: http://www.eda.org/sv-ac.
Proceedings of the 12th International Symposium on Temporal Representation and Reasoning (TIME05)
1530-1311/05 $20.00  2005 IEEEINSTITUT NATIONAL DE RECHERCHE EN INFORMATIQUE ET EN AUTOMATIQUE
Logical time and temporal logics:
Comparing UML MARTE/CCSL and PSL
N 7459
December 7, 2010apport de recherche
ISRN INRIA/RR--7459--FR+ENG
Thme COM
ISSN 0249-6399inria-00540738, version 1 - 7 Dec 2010
Rgis Gascon  Frdric Mallet  Julien DeAntoniinria-00540738, version 1 - 7 Dec 2010
Logial time and temporal logis:
Comparing UML MARTE/CCSL and PSL
Rgis Gason, Frdri Mallet, Julien DeAntoni
Thme COM  Systmes ommuniants
Projet AOSTEinria-00540738, version 1 - 7 Dec 2010
Rapport de reherhe n 7459  Deember 7, 2010  22 pages
Abstrat:
The UML Prole for Modeling and Analysis of Real-Time and Embedded systems (MARTE) provides a means to speify embedded systems.
The Clok Constraint
Speiation Language (CCSL) allows the speiation of ausal, hronologial and timed properties of MARTE models.
Due to its purposedly broad sope of use, CCSL has anexpressiveness that an prevent formal veriation.
However, when addressing hardwareeletroni systems, formal veriation is an important step of the development. The IEEE
Property Speiation Language (PSL) provides a formal notation for expressing temporal logi properties that an be automatially veried on eletroni system models.
We want to identify the part of MARTE/CCSL amenable to support the lassial analysis methods from the Eletroni Design Automation (EDA) ommunity. In this paper, we ontribute to this goal by omparing the expressiveness of CCSL and the Foundation Language of PSL. We show that none of these languages is subsumed by the other one. We identify the CCSL onstruts that annot be expressed in temporal logis and propose restritions of these operators so that they beome tratable in temporal logis. Conversely, we also identify the lass of PSL formulas that an be enoded in CCSL. We dene translations between these fragments of CCSL and PSL using automata as an intermediate representation.
Key-words:
High-level design, Linear temporal logi, Language equivalene, Automatonbased approah
Unit de recherche INRIA Sophia Antipolis
2004, route des Lucioles, BP 93, 06902 Sophia Antipolis Cedex (France)
Tlphone : +33 4 92 38 77 77  Tlcopie : +33 4 92 38 77 65
Temps logique et logiques temporelles:
Comparaison de UML MARTE/CCSL et PSL
Rsum :
Le prol UML MARTE (Modeling and Analysis of Real-Time and Embeddedsystems) permet la spiation de systmes embarqus. Le langage assoi CCSL (Clok
Constraint Speiation Language) est ore la possibilit de spier des proprits ausales, hronologiques et temporelles sur les modles MARTE. En raison de son large spetre d'appliations, CCSL a une grande expressivit qui emphe l'appliation de ertaines tehniques de vriation formelle. Cependant, la vriation formelle est une tape importante du dveloppement dans le domaine des ffhardware eletroni systems.
Pour e faire, lestandard IEEE PSL (Property Speiation Language) fourni des notations formelles pour l'expression de proprits en logique temporelles qui peuvent tre automatiquement vrie sur le modle du systme letronique.
Nous voulons identier le fragment de MARTE/CCSL suseptible de supporter les mthodes d'analyses lassiques utilises dans la ommunaut EDA (Eletroni Design Autoinria-00540738, version 1 - 7 Dec 2010mation). Dans e papier, nous ontribuons  e but en omparant l'expressivit de CCSL et du fragment de PSL orrespondant  la logique temporelle linaire. qu'auun de es langages n'est inlus dans l'autre.
Nous montrons
Nous identions les onstruteurs de
CCSL qui ne peuvent tre exprims par les logiques temporelles propositionnelles et proposons en onsquene des restritions de es oprateurs de manire  les rendre exprimable dans PSL. Riproquement, nous identions la lasse de proprits de PSL qui peuvent tre odes dans CCSL. Nous dnissons des tradution entre es deux fragment utilisant des automates omme reprsentation intermdiaire.
Mots-ls :
Coneption haut niveau, Logique temporelle linaire, quivalene de langages, Approhe  base d'automates.
Logial time and temporal logis: Comparing UML MARTE/CCSL and PSL
3
1 Introdution
The UML Prole for Modeling and Analysis of Real-Time and Embedded systems (MARTE [8) provides a mean to speify several aspets of embedded systems, ranging from large software systems on top of an operating system to spei hardware designs. The Clok Constraint Speiation Language (CCSL [1) oers a general set of notations to speify ausal, hronologial and timed properties on these models and has been used in various subdomains [6, 5, 2. From this speiation, it is possible to simulate the behavior of a CCSL speiation at the model level. CCSL has been formally dened; however, due to its broad sope of use CCSL has an expressiveness that an prevent formal veriation, sine the speied system an be, by intention, non-deterministi, innite, unbound. Very wide speiations at the system level should be progressively rened into more preise desriptions down to a point where ode generation, shedulability, formal analysis beome possible.
MARTE/CCSL oers a support at all the renement steps.
In the domain of hardware eletroni systems, whih one of the subdomains targetedinria-00540738, version 1 - 7 Dec 2010by MARTE, formal veriation is an important step of the development. To allow simulation and formal veriation of suh systems, the IEEE Property Speiation Language(PSL [10) provides a formal notation for the speiation of eletroni system behavior, ompatible with multiple eletroni system design languages (VHDL, Verilog, SystemC, SystemVerilog).
Even though a MARTE/CCSL speiation overs a broad sope and several subdomains, the intent remains to oer exhaustive veriation apabilities when fousing on spei aspets within a subdomain. When fousing on hardware eletroni systems, MARTE provides a support to apture strutural or behavioral, funtional or non-funtional aspets.
Its time model and CCSL, as part of MARTE, are natural andidates to express safety properties on MARTE models. Two questions arise. Is MARTE expressive enough to apture an abstrat view of hardware systems ? Is CCSL expressive enough to express properties usually modeled in PSL ? Some eorts has been made to answer the rst question [9, 13.
We are addressing here the seond question.
The main ontribution of this paper is then the omparison of PSL and CCSL expressiveness. The rst result is that none of these languages subsume the other one. Consequently, we identied the CCSL onstruts that annot be expressed in temporal logis and proposed restritions to these operators so that they beome tratable in temporal logis. Conversely, we also identify a lass of PSL formulas that an be enoded in CCSL. Then, We dene translations between these fragments of CCSL and PSL using automata as an intermediate representation. These transformations make possible the ombined use of both formalisms to adequately address the right level, CCSL at the model level and PSL at the implementation level. They also oer a way to provide an exhaustive analysis support for a lass of CCSL speiations.
The remaining of this paper is organized as follows. In Set. 2 we introdue CCSL and PSL and determine whih kind of properties annot be expressed in eah language.
Wedene in Set. 3 the lass of Boolean automata whih is used in Set. 4 to dene translations between fragments of CCSL and PSL. Set. 5 ontains onluding remarks and future work.
RR n 7459
R. Gason, F. Mallet, J. DeAntoni
4
2 Denitions of the languages
We dene here the languages that we onsider in this paper and give rst omparisons related to their expressive power.
2.1 Clok Constraint Speiation Language
CCSL is the ompanion language of MARTE UML prole for the design of embedded systems. It ombines onstruts from the general net theory and from the synhronous languages. CCSL oers a set of ausal and timed patterns lassially used in embedded systems.
More formally, the language CCSL is based on the notion oflokswhih is a general nameto denote a totally ordered sequene of event ourenes, alled the Instants do not arry values. CCSL denes a set oflok relations :instantsof the lok.c1is a sublokinria-00540738, version 1 - 7 Dec 2010r ::= c1  c2 | c1 # c2 | c1  c2 | c1 4 c2. wherec 1, c2represent loks of the system. Informally,  c 1  c2means thatc2, c1 # c2 that the instants of the two loks never our at the same time and c1  c2 nth ourrene of c1 stritly preedes the nth ourrene of c2 for every n  N.
The relation c1 4 c2 is the non strit version of the preedene relation. ofthat the CCSL is a high level multilok language and the original semantis does not require totally ordered models.
However, at lower level or for simulation purposes, one needs torepresent the exeution as a totally ordered sequene. In this ontext, a possible semantis, introdued in [1, identies loks with Boolean variables evolving along time.
In thebelongs to a set of propositions VAR and CCSL models
VAR are nite or innite sequenes of elements in 2. The set of instants of the lok cremaining, we will onsider thatcc holds. be a CCSL model. For suh a sequene, we denote in the following by || the length of  and we assume that || =  when  is an innite word. We also use the notations (i) th element of  and  i for the sux of  starting at the ith position. To evaluate the for the iorresponds to the set of positions where the variable
Letsatisfation of preedene relations, we need to know the number of ourrenes of the loks at eah position of.
We dene the funtionsuh that for everyiNandc  VARwehave(c, i) = |{j  Ns.t.jiandc  (j)}|.
The satisfation of CCSL relations is dened by:
|=ccsl c1  c2i for everythe oinidene relation
=
0  i  ||, if c1  (i) then c2  (i). We also dene
|=ccsl c1 = c2 i  |=ccsl c1  c2 andsuh that
|=ccsl c2  c1.
|=ccsl c1 # c2i for every
0  i  ||we havec1 6 (i)orc2 6 (i).
INRIA
Logial time and temporal logis: Comparing UML MARTE/CCSL and PSL
|=ccsl c1  c2 i for every 0  i  || have  (c1, i) >  (c2, i).
|=ccsl c1 4 c2i for every
0  i  ||suh thatwe have(c1, i) > 0and(c2, i) > 0we(c1, i)   (c2, i).
CCSL an also express more ompliated relations between loks by usingtions.
5lok deniCCSL lok denitions allows one to dene a lok by ombination of other loksgiven as arguments. A lok denition is of the formexpressionc, ewherec  VARandeis alokdened by the following grammar:e := c | e + e | e  e | ee|ee|ee | e H bw | e $e n | e  e | e  ec  VAR, n  N and bw : N  B is a binary word. The expressions e1 + e2 and e1  e2 represent respetively the union and intersetion of e1 and e2. The strit and non strit sample expressions are denoted respetively by e1 e2 and e1 e2. The delay th ourrene of e. operation e1 $e2 n is a variation of sampling that samples e1 on the n
2
The expression e1 e2 is the preemption (e1 up to e2 ), e H bw represents the ltering operation. Finally, e1  e2 (resp. e1  e2 ) represents the fastest (resp. slowest) of the loks that are slower (resp. faster) than both e1 and e2. This orresponds to greatest lower boundinria-00540738, version 1 - 7 Dec 2010whereand lowest upper bound.
Given a lok expressioniholds at positionof.eand a CCSL modelwe note, i |=ccsl e i the expression eto expressions in To dene this relation, we extend the funtiona natural way:(e, i) = |{j  Ns.t.jiand, j |=ccsl e}|.
The satisfation relation for expressions is dened by:, i |=ccsl cic  (i)., i |=ccsl e1 + e2i, i |=ccsl e1  e2i, i |=ccsl e1ie2, i |=ccsl e1, i |=ccsl e1or, i |=ccsl e2.and, i |=ccsl e2.
, i |=ccsl e2, 
0  j < i, k 6|=ccsl e2.there is, i |=ccsl e1e2suh that, j |=ccsl e1and for everyj < k < iwe havesuh that, j |=ccsl e1and for everyj < k < iwe havei
, i |=ccsl e2, 
RR n 7459
0  j  i, k 6|=ccsl e2.there is R. Gason, F. Mallet, J. DeAntoni
6, i |=ccsl e1 $e2 n
, j |=ccsl e1
there is a positionk  {1,..., n} e2suh thatandthere are exatly, i |=ccsl e1
0jini 1,..., i n (i n = i ), ik |=ccsl e2.distint positionsj < ik  iwe haveandsuh that for everyi
, i |=ccsl e1, for everyj<i, i |=ccsl e H bw, j 6|=ccsl e2.we haveiinria-00540738, version 1 - 7 Dec 2010
, i |=ccsl e
 bw ( (e, i)) = 1., i |=ccsl e1  e2i either
  (e1, i) >  (e2, i) and, i |=ccsl e1, or(c1, i) <  (c2, i)and, i |=ccsl e2, or(e1, i) =  (e2, i)and, i |=ccsl e1, i |=ccsl e1  e2and, i |=ccsl e2.i either
  (e1, i) >  (e2, i) and, i |=ccsl e2, or(e1, i) <  (e2, i)and
or(c1, i) =  (c2, i)and we have, i |=ccsl e1,, i |=ccsl e1or, i |=ccsl e2.
A CCSL speiation is a list of denitions and relations seen as a onjuntion of onstraints. We an represent it by a triple
C  VAR
Def
Rel
A modelhC, Def, Relisuh thatis a set of loks,  is a set of denitions, is a set of relations.over
2Csatises the speiation ifor every denitionc, ein
Defwe havec  (i)i, i |=ccsl e, INRIA
Logial time and temporal logis: Comparing UML MARTE/CCSL and PSLevery relation in Relis satised by
7.
From the basis CCSL language, one an dene other expressions and relations.
Forinstane, the following expressions will be useful in the following:c1  c2is the dierene of loksenoded with the denitionc $c nc1andc1, c + c2c2.
The denitionand the relationc, c1  c2an bec # c2.is a partiular ase of delay expression that we denotec $ n.
This expressionrepresents the usual synhronous delay operation. The resulting expression starts at thenthourrene of Alternane relationinria-00540738, version 1 - 7 Dec 2010c1, c1 $ 1.cand then oinides withc1 = c2
Similarly,  c.is dened by the relationsc1 = c2is dened byc1 4 c2c1 4 c2 andandc2  c1wherec2  c1.
2.2 Property Speiation Language
The IEEE standard PSL [10 is a textual language to build temporal logi expressions. PSL assertions are used for instane in hadware design and they an be validated by modelheking or equivalene heking tehniques. Compared with the lassial linear temporal logi LTL, PSL provides sugaring onstruts to build expressions in an easier and more onise way. However PSL is as expressive as LTL. As it would be tedious to onsider the dierent sugaring operators of PSL in formal reasoning, we use in this paper the minimalore language dened in [3.
Let
VARbe a set of propositions (Boolean variables) that aims at representing signalsof the system.
PSL atomi formulas are alled
Sequential Extended Regular Expressions(SERE). SEREs are basially regular expressions built over the Boolean algebra:b ::= x | x | b  b | b  b wherex  VARis a Boolean variable. We also onsider the standard operators
1andthat an be dened from the grammar above. The set of SEREs is dened by:r ::= b | r  r | r  r | r wherebis a Boolean formula.onatenation,  r1  r2
The operators have their usual meaning: r1  r2 is the r is the Kleene star operator. From these regularthe union andexpressions, PSL linear properties
2 are dened by:
::= r |    |  | X | U | r.
1 x  y is equivalent to x  y
2 PSL standard also denes a RR n 7459and x  y to (x  y)  (y  x). branhing time part that we do not onsider here.
R. Gason, F. Mallet, J. DeAntoni
8whereris a SERE. The operators
X(next) and U (until) are the lassial temporal logi
F  U (eventually) and G  Foperators. We also use the lassial abbreviationsr   is a ffsux onjuntion operator meaning that there must r and that  must be satised at the position orresponding(always). The formulaexist a nite prex satisfying to the end of this prex.
The semantis of PSL is dened in suh a way that properties an be interpreted over innite words as well as nite or trunated words. This is important for some appliation domains of PSL suh that simulation or bounded model-heking. Similarly to CCSL, the VAR that represents the set models of PSL are nite or innite sequenes over elements of 2 of variables that holds at eah position.
VAR and p  VAR, we note
For every X  2
X |=b p i p  X
|=b is obvious.
The remaining of the Boolean satisfation relation(possibly empty) prex of the model. Soand
X |=b pip 6 X.
SEREs refer to a niteis supposed to be nite in SERE satisfationrelation (whih is not the ase in PSL satisfation relation). The SERE satisfation is denedinria-00540738, version 1 - 7 Dec 2010by indution as following:
|=re bi
|| = 1
|=re r1  r2and(0) |=b b,  i there exist
|=re r1  r2i
|=re r1
|=re r i either  =and 2 |=re r.
1, 2andsuh that
= 1 2
1 |=re r1andand
2 |=re r2.
|=re r2.or there exist
1, 2suh that
1 6=,  = 1 2, 1 |=re r
Finally, the satisfation of PSL properties is dened as following.
|=psli
6|=psl, |=psl 1  2
|=psl Xii
|=psl 1
|| > 1andand
|=psl 2, 1 |=psl, |=psl 1 U2 i j have  |=psl 1,  there is |=psl r   i and 2 |=psl,  there is a nite prex
|=psl r r.
0  i < ||i for every nite prex
1suh thatof
1ofi |=psl 2 and 2and for everysuh thatthere is a nite word
2
0j<iwe
= 1 2, 1 |=re r suh that
1 2 |=re
The addition of SEREs in PSL does not add expressiveness to the lassial temporal logi
LTL. Indeed, SEREs an be translated into LTL formulas. However, this would imply an exponential blowup of the size of the formulas.
INRIA
Logial time and temporal logis: Comparing UML MARTE/CCSL and PSL
9
2.3 Comparing PSL and CCSL
Sine CCSL and PSL share ommon models, we an ompare their expressive power. Let be a CCSL speiation over a set of variables of variables
V  VAR.isand every model of S
S.
We will say that also a model of VS  VARandis enoded by (or simulated by)
The onverse simulation relation is a bit dierent.
Sa PSL formula over a seti
VS  V
CCSL models have the propertiesthat one an add an unbounded amount of empty states between two relevant states and left the satisfation unhanged. This an easily be proved by indution on the struture of a CCSL speiation.
Lemma 1. i  ||
S
Letthe modelbe a CCSL speiation. For every modelsatisfying
Sand every
0dened byinria-00540738, version 1 - 7 Dec 2010(j) = (j) for every j < i(i) =(j) = (j  1) for every i < j  || + 1 also satises
S.
This property is a onsequene of the multilok aspet of CCSL. Even with the semantis we have introdued, it is not possible to ompletely link the exeution of a CCSL speiation to a global lok. However, the states where no loks hold are irrelevant in CCSL point of view as they do not make the system evolve. So it is not really a problem to disard them.
Atually, this is what is done in the CCSL simulator TimeSquare. We will say that simulated by of Si
V  VSand every model of S with no irrelevant statesisis also a model.
By examining the denitions PSL and CCSL, we an already make the following observations. Some CCSL relations or expressions impliitly introdue unbounded ounters. Forc1 and c2 (or at least the c1 4 c2. The orrespondinginstane, one have to store the number of ourrenes of the loks dierene between them) to enode the preedene relationlanguage is made of all the words suh that every nite prex ontains more ourrenes ofc1thanc2.
Suh a language is neither regular nor
-regularand annot be enoded in PSL whih is as expressive as LTL and regular expressions. The same remark holds for the expressionsc1  c2andc1  c2.
On the other hand, the dierent CCSL relations and expressions only states safety onstraints. As a speiation is a onjuntion of suh onstraints the result is always a safety property. CCSL annot express liveness like the reahabily property
Fp.
A similar problemours for the next operator in ase of nite exeutions. There is no way to express that the model must have a next position whih an be stated by
Xin PSL. To summarize, thepreliminary omparison of expressiveness of CCSL and PSL gives the following results.
Lemma 2. (I) There are PSL formulas that annot be enoded in CCSL.(II) There are CCSL speiations that annot be enoded in PSL.
RR n 7459
R. Gason, F. Mallet, J. DeAntoni
10
It is now lear that PSL and CCSL are not omparable in their whole denition. However, we will see in the remaining of this paper that we an dene large fragments of these languages that an be enoded in eah other. To that aim we will rst introdue a intermediate lass of automata well tted to dene translations between these fragments.
3 Boolean automata
Translating diretly PSL properties into CCSL is not obvious. For example, let us onsider the following PSL formula:
G(p0  (p1 Up2 )).
One an try to translate this property by onsidering its general meaning whih is ffthere is alwaysp1in an interval starting withp0and ending withp2 .
It is more diult to dene amodular approah by omposing atomi translations from PSL operator to CCSL. We use an automaton based approah. We introdue in this setion a lass of automata manipulatinginria-00540738, version 1 - 7 Dec 2010
Boolean variables that we will use to establish relations between PSL and CCSL fragments.
3.1 Denition
We onsider automata that handle propositional variables in VAR.
The transitions of theseautomata are labeled by Boolean formulas interpreted like guard.automaton
Qis a struture
A = hQ, q0, F, A, V, iis a set of states and F Qand
V  VAR
AQq0  Q
Formally, a Booleansuh that:an initial state,  are respetively the set of nal and aepting states,  is a set of propositions, : Q  Bool (V )  Q formulas over VAR.is a transition relation where Bool (V )is the set of Boolean
We use the denitions of Set. 2.2 for Boolean formulas. A Boolean automaton is deterministi i for every state in Q there do not exist two outgoing transitions labeled withsuh that    is satisable.and
A onguration of A is a pair hq, Xi omposed of a state in Q and a subset of V. Wenote hq, Xihq, X  i i there is a transition qq  suh that X |=b. A run of A is a V sequene  : N  (Q  2 ) suh that (0) is of the form hq0, X0 i (one starts in the initial i(i + 1). A nite run is aepting state) and for every i  N, there exists i suh that (i) i it ends in a nal state. An innite run is aepting i it visits innitely often an aepting state (Bhi ondition). The language aepted by
2V orresponding to aepting runs.
Ain made of the words on the alphabet
Boolean automata an be omposed as following. Consider two automata
A2 = hQ2, (q0 )2, V2, 2 i. hQ, q0, V, i suh that: and The produt automaton
A = A1  A2
A1 = hQ1, (q0 )1, F1, V1, 1 iis the struture
INRIA
Logial time and temporal logis: Comparing UML MARTE/CCSL and PSL
11
Q = Q1  Q2  {0, 1} where the last omponent of eah state (in {0, 1}) is only needed for the Bhi aeptane ondition,  q0 = h(q0 )1, (q0 )2, 0i,  F = F1  F2  {0, 1}and
A = Q1  A2  {1}, V = V1  V2,  inria-00540738, version 1 - 7 Dec 2010
For everyhq1, q2, iiandhq1, q2, i i
1
Qin
2
there exist
ifi=0theni = 1iq1  A1, ifi=1theni = 0iq2  A2.q1 q1andq2 q2we haves.t.hq1, q2, iihq1, q2, i iis equivalent toi
1  2, Note that the last omponent of eah state is not needed when every state is aepting(A1
= Q1and
A2 = Q2 ),  whih will be the ase in the following.
3.2 CCSL and Boolean automata
Sine CCSL express only safety, the aeptane ondition of automata annot be enoded.
However, if every run is aepting we an enode a deterministi Boolean automaton into a CCSL speiation.
Lemma 3.
Every deterministi Boolean automaton suh that every exeution is aeptingan be simulated by a CCSL speiation.
Proof.
Consider a Boolean automaton
A = hQ, I, V, i.
The sets of aepting and nalstates are not needed sine every exeution is aepting. So, we forget them here.
We dene the set of loks denitions.
C = V  Q.
To enode
A,  we need the following CCSL
We dene a global lok and a lok orresponding to the set of states
Qasfollowing:(1) Glob, c
XcQ,  andcC where PcXclok
Iq
X.
X |=b.
X
Xq q
RR n 7459
X.
Similarly, we will note
For ease of presentation, we note
For every stateorresponding to the inoming transitions of(2) Iq,  qqQis the CCSL union of all the loks in CCSL intersetion of all the loks inis a transition qq  in A suh that
Xq  (
YpXp)  (
Xp6Xqq  Q \ {q0 },  q:
 p).
X
QcX c theq i therewe dene the R. Gason, F. Mallet, J. DeAntoni
12
Now we build the set of CCSL relations. First we express that at every position in the run, exatly one state of the automaton holds. This orrespond to the relations(3) cQ = Globq # qandfor everyq, q   Q (q 6= q  ).
We also impose that the global lok always oinides with a valid transition in order to avoid unexpeted behaviours:(4) Glob =
X
IQ.qQ
The transition relation is suh that every state alternates with its inoming transitions. This means that for everyqQ q0 = Iq 0(5)
The relation is symmetri forq0
Iq = q.andsine the exeution starts in this state. The alternane isinria-00540738, version 1 - 7 Dec 2010not strit on the side of the inoming transition sine it is allowed to return to the same step (loops).i  N, We have to show that a modelof A c  Xi.runsuh that for everysatises the CCSL speiation obtained i there is a for every
First we observe that for any modelq  (i + 1)for everyi  N.and omplete (f(2)).
Iqwe havec  (i)i(i) = hqi, Xi isatisfying the CCSL speiation, if The alternane relations allows a lokhas oured between the last ourene of denitions of the dierentcVqqand the urrent position (fand
Iq  (i) then
Iqto our only if(5)).
However, the A whih is deterministi
Iq belongs to (i) for every i  N. So, to (i + 1) is q. By (3), exatly oneare dened w.r.t. transition relation of This implies that exatly one
Iq  (i) the only element of Q that an belonb element of Q must hold at eah position. This onludeifthe demonstration.
We proeed by indution on the position of the sequenes. Suppose that we are given
). For every i  N we note (i) = hqi, vi i. We show for every i  N position j < i and variable c  VAR we an build  (resp.  ) suh that(resp.c  (j)andithat for everyc  Xj,  qi + 1  (i + 1)iqi + 1is the state of(i + 1).
Q that an belong to (0) is q0. Indeed, q  Q from ouring beause of alternane
A is always q0.
At the begining of any model, the only lok in no lok
Iqhas oured whih prevent the otherrelations (see
Now letuntil position(5)).
Similarly, the initial sate ofbe a model of the CCSL speiation. We suppose that the property holdsiand that we haveqi  (i)and the state of(i)isqi.
Sine the transitionsuh that qq  andrelation is omplete and deterministi, there is a unique q  Q
As a onsequene, Iq  (i) whih implies that q  (i + 1) as we shown before.q  and setting c  Xi
We an do the orresponding move in A by hoosing the transition q(i) |=.
INRIA
Logial time and temporal logis: Comparing UML MARTE/CCSL and PSL
13c  (i)  V. By indution, one an build a run  of A suh that for every i  N, for c  VAR we have c  (i) i c  (i).
Conversely, let  be a run of A. We suppose that the property holds until position i, (i) = hqi, vi i and qi  (i). The demonstration is symmetrial. There is a unique transition ieveryqi+1 suh that vi |=  beause the transition relation is deterministi and omplete. qi
Let set (i) suh that for every c  VAR we c  (i) i (i) = hqi, vi i and vi (c) =. By onstrution, we must have Iq i+1  (i) and so qi+1  (i + 1). Thus, one an build by indution  verifying the property.
The onverse translation is not possible.
CCSL speiations annot be enoded by
Boolean automata for the same reasons that prevent enoding CCSL speiations into PSL properties. Some relations or operators like preedene annot be enoded by using nite state systems (see Set. 2.3).
3.3 PSL and Boolean automata inria-00540738, version 1 - 7 Dec 2010
It is well known that one an build a nite automaton or a Bhi automaton that aepts respetively the nite and innite models of a given PSL formula. Given a PSL formula,  the onstrution dened in [3 an easily be adapted to build a Boolean automata aepting the set of models of.
This onstrution itself is a slight extension of the automaton for LTLoriginally dened by [12. We do not develop this onstrution now sine the onstrution in the proof of upoming Lemma 6 will follow the same main steps.
Lemma 4.
From any PSL propertieslanguage aepted by
Aone an build a Boolean automatais exatly the set of models of Asuh that the.
The onverse translation is easy sine the denition of LTL is inluded in PSL. By using the onstrution in [11 one an enode the behaviour of a Boolean automaton into a LTL formula.
Lemma 5.
From any Boolean automatonset of models of A
A,  one an build a PSL formulais exatly the set of runs of Asuh that the A.
4 Translations between CCSL and PSL fragments
We dene in this setion large fragments of CCSL and PSL that an be simulated in eah other. We dene the translations between these fragments using intermediate Booelan automata enoding.
4.1 From PSL to CCSL
Lemma 3 states that Boolean automata an be enoded in CCSL when every run is aepting.
Thus we restrit ourselves to the lass of PSL formulas that an be translated into this sublass of Boolean automata. We onsider the safety fragment of PSL dened similarly to [4 by restriting the use of negations. A PSL formula belongs to
RR n 7459safety PSLformulas
R. Gason, F. Mallet, J. DeAntoni
14i (S1) subformulas of the form
1 U2andrnever our under an even number ofnegations, and (S2) SEREs never our under an odd number of negations. Note that one an dene safety fragments of PSL by restriting temporal modalities but this one is more general. For the nite ase, we also have to restrit the denition of the next operator to its weak variant (s.t. the formula is satised also if the model has no next position).
Lemma 6.
For every property in safety PSL, one an build an automaton suh that everyexeution is aepting.
Proof.
In [3 is desribed a way to build automata from PSL properties. We reall belowthe main steps of this onstrution and show that the restritions we have made allow us to obtain an automaton suh that every run respeting the transition relation is aepting.inria-00540738, version 1 - 7 Dec 2010
First, one an easily build a nite automaton aepting the set of nite words that orresponds to a given SERE. Indeed, SERE are essentially regular expressions. So we f
VAR assume that for every SERE r there is a nite automaton Ar = h2, Qr, Ir, Fr, rf i suh that   L(Ar ) i  |=re r. From this automaton one an build a Bhi automaton
Ar = h2VAR, Qr, Ir, Qr, Qr, r i suh that   L(Ar ) i  |=psl r. The transition relation r f is obtained by adding the following rules to r :hqf, X, qf i  rfor everyqf  Frand
X  2VAR.
This automaton has only aepting and nal states. Indeed, aording to PSL satisfation relation, every prex that an be extended to an expression satisfying the SERE must be aepted.
Then we proeed by indution on the struture of the formula. The result of the onstrution is an alternating automata. This allows running automata for the SERE atomi formulas in parallel of the temporal logi part. Then, it is known that an alternating Bhi automaton an be translated into a standard Bhi automaton [7.
The base ase is given above. So we suppose that for every subformula  of  we an build
A = h2VAR, Q, I, A, F, r i suh that suh that every run is aeptingan automaton
L(A ) i  |=psl. There are atually two onstrutions beause the ase where is of the form (r  ) must be treated separately. In that ase, A is built f
VAR, Qr, Ir, Fr, rf i and A = h2VAR, Q, I, Q, Q,  i from the nite automaton Ar = h2 andthe formula as follows.the set of states is the union ofthe set of initial states isthe set of nal states is the union ofthe set of aepting states is the union of Qrand
Qand an additional stateqt, Ir, qt, Q rand
F,  qt, Q rso
F = Qand
A,  beauseso
F = Q, A = Qbeause
A = Q, INRIA
Logial time and temporal logis: Comparing UML MARTE/CCSL and PSL
For everyqf  Frand
X  2VAR
15we have
^(qf, X) =q    (q0, X)q r (q,X) whereq0
For every
ifis the initial state ofq  Qr \ Frr (q, X)and
A.
X  2VARis dened then(q, X) =
^qq r (q,X),  inria-00540738, version 1 - 7 Dec 2010
(q, X) = qt,  otherwisefor every
nallyq  Qthe transition relation oinides with(qt, X) = qtfor every, X  2VAR.
Note that we only have to onsider negated ourrenes ofrby denition of the safetyfragment.
For the other ases, Ais dened as follows. The set of states is omposed ofthe set of states of the automatathe set of states of the automatathe set of subformulas of The initial state is(p, X) =.i
Arfor every SERE
A(r)for every subformulaq0ris the initial state of Ar.(1  2, X) = (1, X)  (2, X).(1  2, X) = (1, X)  (2, X).(, X) = (, X).(X, X) =.(1 U2, X) = (2, X)  ((1, X)  1 U2 ).
Where the overlined expressions are interpreted as follows:
RR n 7459,  ris dened reursively:p  X. whereourring inand their negation (we identify
The transition relation(r, X) = (q0r, X)rwithourring in )., R. Gason, F. Mallet, J. DeAntoni
16a  b = a  b, a  b = a  b,  (q0r, X) = (q0r, X)where(r)(q0r, X) = (q0
=,  q0r, X)is the initial state of the automatonwhere(r)q0is the initial state offor every subformula (we still identifywith
Note that beause we onsider the safety fragment the ases
Ar, A(r), ).(q0r, X) and (q0r, X) neverour (see restritions of negation).
In the general onstrution, the aepting states would be those of the form the states of the automata
A(r)and
Ar.
1 U2or
However, for formulas in the safety fragmentthe onstrution above is partiular. For every run of the automaton obtained it annot be the ase that an innite branh does not enounter one of those nal states.inria-00540738, version 1 - 7 Dec 2010
We proeed by indution. If we are in a state of the form in the asesrorare aepting. property.(r  )p, the branh is nite.and its(, X) goes
Now we suppose that every subformula of In almost all ases, the dierent branhes ofstrit subformulas of.
Similarly,  we are done sine all the states of the orresponding automata negation satisfy the to states labeled by
In that ases we an use the indution hypothesis to onlude. Theonly remaining ase is whenis of the form
1 U2or
1 U2.
The rst ase annot arisesine we are in the safety fragment. In the seond ase the transition rule is the follows:(1 U2 ) = (1 U2 ) = (2, X)  ((1, X)  (1 U2 )).
We an use the indution hypothesis on the branh orresponding to
2.
For the otherbranh, we an prove by indution thateither we reah a position when 2and
1hold and then we an use the indutionhypothesis, or(1 U2 )
So we an setis visited innitely often. Sine this state is aepting we are also done.
A = F = Q.
By onstrution, every state of the alternating Bhi automaton obtained is nal and aepting. If we use the powerset onstrution of [7 to build an equivalent non-alternating automaton, the sets of nal and aepting states are also equal to the whole set of states.
So every run of the resulting automaton is aepting.
The proof is given in Appendix
??is a variant of the onstrution in [3. We just haveto ensure that every exeution is aepting. By Lemmas 6 and 3 we an enode every safety
PSL formula into CCSL speiations.
Lemma 7.
Every safety PSL formula an be enoded by a CCSL speiation.
INRIA
Logial time and temporal logis: Comparing UML MARTE/CCSL and PSL
17p0 p0  p1  p2p1  p2q0q1 p1p0  p1
Figure 1: Boolean automaton for
G(p0  (p1 Up2 ))
For instane, Figure 1 represents the automaton orresponding to the formula(p1 Up2 )) after simpliations. This automaton hV, Def, Reli suh that V = {p0, p1, p2 } andinria-00540738, version 1 - 7 Dec 2010
Def =
Rel =
Q, q0 + q1
Glob, Q + p0 + p1 + p2, (q0  p0 ) + (q0  p0  p1 ) + (q1  p1 ),, Iq0, Iq, ((q  p )  (p + p )) + (q  (p + p ))
0
1
0
1
2
1
0
1(
Glob = Q,  q0 # q1q0 = Iq0, G(p0orresponds to the CCSL speiation, Glob = Iq0 + Iq1, Iq1 = q1, ).
4.2 From CCSL to PSL
To obtain a fragment of CCSL that an be enoded in PSL, we restrit the preedene relations and the operatorsc 1  c2andc1  c2.
We dene a preedene relation suh thatn and 4n where(c2, i) <  (c1, i)the advane of the fastest lok is bounded. We denote these relationsn  N.
A modelsatisesc 1  n c2i for everyiNwe have
4n is dened similarly with non strit inequalities. We dene c1 n c2 and c1 n c2 that restrit the dierene of the loks c1 and c2 to be bounded by n. Suh expressions are partiular sine they also imposes impliit onstraints(c2, i) + m.
The relationsimilar variantson the parameters. However, this is the most onvenient way of dening a syntati fragment of CCSL that an be translated into CCSL.
We allbounded CCSLthe language obtained by replaing in CCSL the preedenerelations, greatest lower bound and lowest upper bound operators by their bounded variants.
This language is a fragment of CCSL. Indeed, the operators an be dened in full CCSL:c1  n c2is equivalent topreedene ase is similar.
RR n 7459c1  c2andc2 4 c1wherec1, c1 $ n.
Non strit
R. Gason, F. Mallet, J. DeAntoni
18c, c1 n c2c, c 1  c2is equivalent to the onjuntion ofwith the relationsc1 4 c2 and c2 4 c1 where c1, c1 $ n and c2, c2 $ n. This equivalene make lear the relations impliitly imposed on the parameters of the expression. The operatorc1 n c2an be dened similarly.
These restritions allow us to establish the following results.
Lemma 8. (I) Every bounded CCSL speiation an be enoded by a Boolean automata.(II) Every bounded CCSL speiations an be enoded by a PSL formula.
Proof. (I) We proeed by indution on the struture of CCSL speiations. As every state in the resulting automata are nal and aepting, we do not mention them. First, let usonsider CCSL relations.
For every Boolean formulainria-00540738, version 1 - 7 Dec 2010
Boolean automaton with a self loop labeled by
The subloking relation
Similarly, the exlusion relation
The bounded preedene relationnc 1  c2we denote byan be enoded byc1 # c2that store the advane ofc1 on c2. c2 is truean be enoded by an automaton with
So one needs to move to the next state whenc1  c2
0c1  c2
1
0c2  c1 c1  c2c 1  3 c2c1 4n c2 is similar an additional loop labeled c1  c2
1 bak to state 0.and a transition from state
A denition of the form
Ae
3c1  c2
Figure 2: Boolean automaton foron statec1  c2
2c1  c2
The onstrution for the relationisc1  c2c2  c1 c1  c2c1n = 3. c1  c2
If
B(c1 c2 ).and to stay in the same state when both (or none)c1  c2
B(c1 c2 ).an be enoded byc 1  n c2are true. Fig. 2 is the automaton forwherethe single statestates. These states simulate the inrementation and derementation of a ountertrue, to move bak when B.c, ean be enoded by the produt automaton
Ae  Bceis dened below.e is of the form e1 + e2
B((e1 e2 )e).then
Aean be obtained by making the produt of Ae1, Ae2and
The automaton fore1  e2is built similarly by replaing the third automaton by
B((e1 e2 )e).
INRIA
Logial time and temporal logis: Comparing UML MARTE/CCSL and PSL
19e2 is a bit more omplex. Consider two opies A and A of theprodut automaton Ae1  Ae2. We denote by q0, q1... the states of A and q0, q1...the states of A suh that qi and qi represent the same state in the dierent opies.
The enoding ofe1
To build the automaton Ae we use A to simulate the part where e1 has not ourredyet and A the part where e1 has ourred and we wait for the next ourrene of e2.
So, we have to move from A to A when e1 is true. Then we move bak to A and seteto true whentransformations on()()e2 is true.
A and A.qj in A we replae the label by
For every transition qi e1 e transition qiqj from A to A.qj qi
For every transitione2 e transition qiinria-00540738, version 1 - 7 Dec 2010
This automaton is obtained by making the followingqjfromin
Awe replae the label byto
A.
Ae1  eand add thee2  eand add the Obviously if the Boolean formula of a label redues to false then the orresponding transition is removed (or not added).
The enoding ofe1e2e2.
The dierene is that whenare true thene is also true and we stay in e1 is true and e2 is false. Sois very lose to the asewe are in the rst opy and bothe1ande2e1the same opy. We only move to the seond opy when the step()has to be replaed byqj in A we replae the label by
For every transition qi e1 e2 e e1 e2 e transitions qiqj and qi  qj.e1  eand add thetwo
The enoding ofe1 $e2 nholds we have to wait foropies of Ae1  Ae2.e1 n+1is a generalization of the previous onstrution. Whennpositions wheree2holds. This an be done with
Another point of view is that a ounter is enoded in the states ofthe resulting automaton. In the same way than the onstrution for the asee1e2we add transitions between the dierent opy as following:
from the rst opy to the seond when from theith
from then+1th to the rst when e2 ours and this orresponds to the transitionswhereeto thei + 1thwhene2e1ours,  ours for
2  i  n + 1,  must our.expression an also be enodede1 H bw. Suppose that bw = u  v. The similarly with |u| + |v| opies of Ae1. Eah opy isbwin a natural way. The transition from a opy to the Now we onsider the ltering operation assoiated with positions in RR n 7459
R. Gason, F. Mallet, J. DeAntoni
20next one is done whene1holds and after the last opy we jump to theone (periodi part). The variable position inbwis equal toeours ie1

e is of the form e1 e2 an easily
A = Ae1  Ae2  B((e1 e2 )e) as following.
We add a sink stateqswith a loop
We replae every transition e2 qs. transition qqq
The way of enodinge1 n e2be obtained from the produteqs qs. in A (q, q  6= qs )
This operation prevents future ourrenes ofours in a opy whose orresponding
1.
The automaton when automatoneas soon ainria-00540738, version 1 - 7 Dec 2010
2n + 1e2byq  qe2has oured.states. The expressionec1n = 2.c1  c2  ec2c1  c2  e c1  c2  e
2c1  c2  e
The aseeandee1 n e2c2.
Soc2  c1  e c1  c2  eis quite similar. Forc1  c2  e
1n=2
2 c2  c1  ec1  c2  e
Figure 3: Boolean automaton foris greater thanc1  c2  e
0 c2  c1  ec1  c2  ec1c1  c2  e c1  c2  e
1 c2  c1  e
To do this weis true. The left part is symmetrial.c1  c2  e c1  c2  ec2.
The right part (positive labels)orresponds to positions where the number of ourrenes of is true in this part whenandholds when the variable that has the lessourrenes holds. Fig 3 is the automaton forcand we add theis lose to the bounded preedene relation sine weneed to store the dierene between the ourrenes of need here(|u| + 1)thc1  c2  ec1 2 c2the automaton is obtained by swithingin the transitions that are not loops in Fig. 3.
The global automaton orresponding to a given CCSL speiation is the produt of all the automata orresponding to the dierent denitions and relations.
The set of modelsorresponding to suh an automaton is the same than the set of models of the CCSL speiation. A areful analysis of the dierent steps shows that this onstrution stritly follows
CCSL semantis.(II)
This seond part is a diret onsequene of(I)and Lemma 5, even if the PSLformula obtained by omposing the two transformations is not minimal.
We an denea diret translation from bounded CCSL to PSL. However, the result of the translation remains ompliated.
We still have to enode the ounters of relations like preedene, ltering, delay... whih is tedious when using only propositional variables.
INRIA
Logial time and temporal logis: Comparing UML MARTE/CCSL and PSL
21
Here we have arbitrarily hosen to bound the preedene operators. There are examples where the ontext already bounds the dierene between the arguments of a preedene relation (see for instane the denition of alternane in Set. 2.1). So, bounded CCSL is not the largest fragment that an be enoded in PSL. Determining whether the state spae of a CCSL speiation is nite is an open question.
Moreover it seems very diult todetermine a syntati fragment orresponding to suh CCSL speiations.
5 Conlusion
In this paper, we have ompared the expressiveness of CCSL and PSL, two formal languages used for similare purposes but at dierent levels. We have identied the CCSL onstruts that annot be expressed in PSL and the lass of PSL formulas that annot be stated in CCSL. We have also dened the ommon fragments between CCSL and PSL so that onean be translated into the other. A suient ondition to translate CCSL speiations intoinria-00540738, version 1 - 7 Dec 2010
PSL is to bound the integer ounters used to ount the number of ourrenes of loks.
Preisely, the relative advane of the loks put in relation by these CCSL onstruts must be bounded. This translation is an important step towards the formal veriation of a CCSL speiation and the exploration of its state spae. In the future, we an also take benets of the intermediate translation to automata to establish omparison with other languages.
Conversely, we have dened the translation of PSL safety properties into CCSL. CCSLannot express the lass of liveness properties. CCSL has not been designed for this purpose.
However, it an be interesting to apture all the expressive power of PSL in a higher level desription language. A solution to ll the gap ould be to introdue temporal modalities in a CCSL -like language while keeping the multi-loks aspets. CCSL is indeed a language that is still evolving. We are urrently dening a minimal kernel from whih all the relations and expressions introdued in this paper (and possibly others) an be derived.
In thisdevelopment, we should maintain the orrespondenes with the other languages involved in system design suh as PSL.
Referenes
[1 C. Andr. Syntax and semantis of the lok onstraint speiation language. Tehnial
Report 6925, INRIA, 2009.
[2 C. Andr, F. Mallet, and J. DeAntoni. VHDL observers for lok onstraint heking. In
Industrial Embedded Systems (SIES), 2010 International Symposium on, pages 98107, July 2010.
[3 D. Bustan, D. Fisman, and J. Havliek. Automata onstrution for PSL.
Tehnialreport, IBM Haifa Researh Lab, 2005.
[4 R. Lazi. Safely freezing LTL. In
RR n 7459
In FST&TCS'06,  pages 381392. Springer, 2006.
R. Gason, F. Mallet, J. DeAntoni
22
[5 F. Mallet, C. Andr, and J. DeAntoni. Exeuting AADL models with UML/Marte. In
ICECCS'09 - UML&AADL'09,  pages 371376, Potsdam, Germany, June 2009. IEEE
Computer Press.
[6 F. Mallet, M.-A. Peraldi-Frati, and C. Andr. timing requirements. In
ISORC'09, Marte CCSL to exeute East-ADLpages 249253, Japan, Tokyo, Marh 2009. IEEE
Computer Press.
[7 S. Miyano and T. Hayashi. Alternating nite automata onputer Siene, 32(3):321  330, 1984.
[8 OMG.
UML Prole for MARTE, v1.0.
-words. Theoretial ComObjet Management Group, November 2009.formal/2009-11-02.
[9 P. Peil, J. Medina, H. Posadas, and E. Villar.
Generating heterogeneous exeutablespeiations in SystemC from UML/MARTE models.inria-00540738, version 1 - 7 Dec 2010
Software Engineering, 6:6571, 2010.
Innovations in Systems and 10.1007/s11334-009-0105-4.
[10 IEEE standard for Property Speiation Language (PSL), IEEE std 1850-2005.
[11 A. Sistla and E. Clarke. The omplexity of propositional linear temporal logi.
J. ACM, 32(3):73374, 1985.
[12 M. Vardi and P. Wolper. An automata-theoreti approah to automati program veriation (preliminary report). In
LICS'86,  pages 332344. IEEE, 1986.
[13 J. Vidal, F. de Lamotte, G. Gogniat, P. Soulard, and J.-P. Diguet. A o-design approah for embedded system modeling and ode generation with UML and MARTE. In
DATE,  pages 226231, 2009.
INRIAinria-00540738, version 1 - 7 Dec 2010
Unit de recherche INRIA Sophia Antipolis
2004, route des Lucioles - BP 93 - 06902 Sophia Antipolis Cedex (France)
Unit de recherche INRIA Futurs : Parc Club Orsay Universit - ZAC des Vignes
4, rue Jacques Monod - 91893 ORSAY Cedex (France)
Unit de recherche INRIA Lorraine : LORIA, Technople de Nancy-Brabois - Campus scientifique
615, rue du Jardin Botanique - BP 101 - 54602 Villers-ls-Nancy Cedex (France)
Unit de recherche INRIA Rennes : IRISA, Campus universitaire de Beaulieu - 35042 Rennes Cedex (France)
Unit de recherche INRIA Rhne-Alpes : 655, avenue de lEurope - 38334 Montbonnot Saint-Ismier (France)
Unit de recherche INRIA Rocquencourt : Domaine de Voluceau - Rocquencourt - BP 105 - 78153 Le Chesnay Cedex (France)diteur
INRIA - Domaine de Voluceau - Rocquencourt, BP 105 - 78153 Le Chesnay Cedex (France) http://www.inria.fr
ISSN 0249-6399Knowledge-Based Temporal Interpolation
Yuval Shahar
Section on Medical Informatics, Knowledge Systems Laboratory
Medical School Office Building (MSOB) x215
Stanford University, Stanford, CA 94305 USA
Abstractweeks of grade-I1 bone-marrow toxicity in the context of therapy for potential complications of a bonemarrow transplantation event (Figure 1).
Solving the TA task involves the solution of several subtasks (see Section 2). One of these tasks is the temporal-interpolation task: bridging gaps between point- or interval-based temporal predicates of a similar-type that are temporally disjoint, to create longer intervals (see Figure 1). Temporal interpolation requires, among other knowledge types, some measure of temporal persistence of temporal predicates(denoting either raw data or abstract concepts). For instance, if we measured hemoglobin levels on
Tuesday and on Friday, both being abstracted as LOW, was the patients hemoglobin level on Thursday also
LOW? In fact, the very notion of an episode implies some form of bounded persistence of concepts over time, preventing the clumping together of similar, but distinct instances of the same concept. The concept of persistence was addressed previously; we discuss the relationship of such work to ours in Section 6. In this paper, we present the knowledge-based temporalinterpolation model and computational module.
Temporal interpolation is the task of bridging gaps between time-oriented concepts in a context-sensitive manner. It is a subtask important for solving the temporal-abstraction task-abstraction of intervalbased, higher-level concepts from time-stamped data.
We present a knowledge-based approach to the temporal-interpolation task and discuss in detail the precise knowledge required by that approach, its theoretical foundations, and the implications of the approach. The temporal-interpolation computational mechanism we discuss relies, among other knowledge types, on a temporal-persistence model. The temporalpersistence model employs local temporal-persistence functions that are temporally bidirectional (i.e., extend a belief measure in a predicate both into the future and into the past) and global, maximal-gap temporalpersistence functions that bridge gaps between intervalbased predicates. We investigate the quantitative and qualitative properties implied by both types of persistence functions.
We have implemented our approach and evaluated it in several different domains. We discuss its implications for acquisition, maintenance, reuse, and sharing of temporal-abstraction knowledge.
2. Knowledge-based temporal abstraction
The framework we employ for solving the TA task is the knowledge-based temporal-abstraction (KBTA) method [ 11. The KBTA method is a general problemsolving method   for interpreting data in timeoriented domains, with clear semantics for both the m e t h o d and its domain-specific knowledge requirements. The KBTA method comprises a knowledge-level representation of the TA task and of the knowledge required to solve that task. The KBTA method has a formal model of input and output entities, their relations, and properties associated with these entities-the KBTA ontology.
The KBTA method decomposes the TA task into five parallel subtasks:( 1) temporal-context restriction: creation of relevant contexts for interpretation of data (e.g., effect of a drug), crucial for focusing and limiting the scope of the inference
1. Temporal-abstractionand temporal interpolation
Time-stamped data often need to be abstracted in a context-sensitive manner into more abstract, intervalbased concepts, meaningful for a specific domain of application and a particular task. We term this interpretation task the temporal-abstraction (TA) task. For instance, most clinical tasks require measurement and capture of numerous patient data.
An automated, knowledge-based decision-support tool that assists physicians should provide short, informative, context-sensitive summaries, at various desirable levels of abstraction, of time-oriented clinical data stored on electronic media. Data abstraction assists both physicians and automated decision-support systems. A meaningful summary characterizes significant features over periods of time, such as 2
0-8186-7937-9/97
$10.000 1997 IEEE
102
PAZ protocol
BMT
I
0
50
-I
Exnected CGVHD
1
100
400
200
Time (days)
Figure 1: Typical inputs to and outputs of the temporal-abstraction task in a clinical domain. The figure presents examples of abstractions of platelet and granulocyte values during administration of the PAZ clinical protocol for treating patients who have chronic graft-versus-host disease (CGVHD). The time line starts with a bone-marrow transplantation (BMT) event. k 4 = event; * = platelet counts; A = granulocyte counts;
= open context interval; H= closed abstraction interval; M[n] = myelotoxicity(bone-marrow-toxicity) grade n.h(2) vertical temporal inference: inference from values of contemporaneous input data or abstractions(e.g., results of several blood tests conducted during the same day) into values of higher-level concepts (e.g., classification into bone-marrow toxicity Grade 11)(3) horizontal temporal inference: inference from similar-type propositions that hold over different time intervals (e.g., joining different-value abstractions of the same parameter that hold over two meeting time intervals and computing the value of the new abstraction)
4) temporal interpolation: bridging of gaps between similar-type but temporally disjoint point- or interval-based propositions to create longer intervals(e.g., joining two disjoint episodes of anemia, occurring during different days, into a longer episode)(5) temporal-pattern matching: creation of intervals by matching patterns over disjoint intervals over which hold propositions of various types.
The five subtasks of the KBTA method are solved by five temporal-abstraction mechanisms(nondecomposable computational modules), which depend on four domain-specific knowledge types: structural, classification (functional), temporalsemantic (logical), and t e m p o r a l - d y n a m i c(probabilistic) knowledge. Values for the four knowledge types are specified as the domain's temporal-abstraction ontology., The KBTA method has been implemented in the RESUME system and evaluated encouragingly in several medical and engineering domains.
In this paper, we analyze one of the key TA subtasks: context-specific temporal interpolation. First, we define briefly the KBTA ontology, and then discuss the temporal-interpolation mechanism which uses that ontology and analyze its theoretical foundations and the implications of the approach for acquisition and maintenance of temporal-dynamic knowledge.
3. The knowledge-based temporalabstraction ontology
The KBTA temporal model includes both time intervals and time points. Timepoints are the basic temporal primitives, but propositions can be interpreted only over time intervals. Therefore, all propositions are fluents   and in our model must be interpreted over a particular time period. The KBTA ontology contains the following entities:
1.
Time stamps, z i E T, comprise the basic primitives of time. A time-standardization function, fs(q ), can map a time stamp into an integer amount of any pre-defined temporal granularity unit G, E r (e.g., hour). Time stamps are measured in Gi units with respect to a zeropoint time stamp. A finite positive or negative amount of Gi units is a time measure.
2. A time interval is an ordered pair of time stamps that denote the endpoints, [Istart, Z.end], of the interval. A zero length interval in which Z.start =
Z.end is a time point.
103
3.
4.
5.
6.
7.
8.
9.
An interpretation context 5 E E is a proposition representing a relevant state of affairs (e.g., the drug insulin exerts its effect during this interval), within which certain parameters may be interpreted differently. Two relations, IS-A and SUBCONTEXT, are defined over the set of interpretation contexts. Basic interpretation contexts are atomic propositions. Composite interpretation contexts are created by the temporal intersection of a basic or a composite interpretation context and one of its subcontexts, and enable a definition of increasingly specific interpretation contexts.
A context interval is a structure <{, I> (i.e., interpretation context 5 holds during I>.
An event proposition or event e E E is the occurrence of an external willful act or process, such as the administration of a drug. Events are instantiated event schemata; an event schema has a series aiof event attributes (e.g., drug dose) that must be mapped to attribute values vi.
A PART-OF (or subevent) relation is defined over event schemata.
An event interval is a structure <e, I> represents the occurrence of event e during I.
A parameter schema or parameter n E n is a measurable or describable state of the world.
Parameters may represent raw input data (e.g., hemoglobin level) or abstractions from the raw data (e.g., state of hemoglobin). Parameter schemata have various properties, such as a domain V, of possible symbolic or numeric values and measurement units. An extended parameter is a combination <7c, <>of a parameter
TC and an interpretation context 6. An extended parameter can have a value v E V n, which is typically known only at runtime (i.e., parameter values require a context). A parameter proposition is the combination of a parameter, a parameter value, and an interpretation context, <n, v, {> (e.g., the state of hemoglobin is LOW in the context of chemotherapy). Parameter propositions can have special properties, such as temporal persistence.
A parameter interval <n,v, 4, I> represents the fact that the value v of parameter TC in a specific context 5 holds during interval I.
An abstraction function e E 0 is a unary or multiple-argument function that takes one or more parameters as input and returns an abstract parameter. The abstract parameter may be one of three abstraction types: state, gradient, and rate. An additional abstraction type is pattern which defines a temporal pattern of several other parameters. An abstraction of a parameter (e.g., state(n)) is a Darameter (e.g.. both thehemoglobin value and the state of hemoglobin value are different parameters).
10. An abstraction is a parameter interval <n,v, 5. I> where rcis an abstract parameter.
11. An abstraction goal y E Y is a proposition that indicates an intention relevant to the TA task(e.g., the intention to control a diabetes patients blood-glucose values).
12. An abstraction-goal interval is a structure <y, h,where vis an abstraction goal that is posted during the interval I.
13. Interpretation contexts are induced or inferred dynamically from event, parameter, or abstraction-goal propositions.
The time intervals over which the inducing propositions hold impose temporal constraints on the interval in which the inferred context will be valid (e.g., the interpretation context of the effect of an AZT therapy event might begin 2 days following its start and end 2 weeks after its termination).
The TA ontology of a domain describes all potentially relevant (for the TA task) events, parameters, contexts, abstraction-goals, and relations(e.g., induction of contexts). The TA task is thus the following: Given a set of event, parameter, and goal intervals and the domains TA ontology, produce an interpretation-a set of new abstractions that can answer any temporal query about all the abstractions derivable from the transitive closure of the input data and the domains TA ontology. (A temporal query is a set of temporal and value constraints over the components of a set of parameter and context intervals.)
4. The temporal-interpolationmechanism
The temporal-interpolation subtask can be solved by temporal-interpolation a k n o w 1e d g e - b a s e d mechanism. The temporal-interpolation mechanism accepts as input two parameter points, two parameter intervals, or a parameter interval and a parameter point, and returns as output an abstraction, interpreted over a superinterval of the inputs time points or intervals, interpolating over the gap between these time intervals.
Primary interpolationaccepts two parameter points and returns an abstraction interval. Secondary interpolation accepts two parameter intervals (or a parameter interval and a parameter point), and returns an abstraction (super)interval. Both interpolation types are relevant to primitive parameters and to all abstraction types (e.g., gradient)). Thus, secondary gradient interpolation infers, from two gradientabstraction intervals of parameter n, a gradientabstraction superinterval of TC whose value, unless otherwise specified, is one of the six default values we have predefined [Shahar et al., 19921: S A M E, 104tuples of the form (n,V I,v2, v3, 5), meaning that, for parameter n (assuming that 7c includes its abstraction type), when an abstraction interval with parameter value V I meets an abstraction interval with parameter value v 2, in the context 5, the value of the parameter of the joined abstraction interval should be ~ 3 That. is, V I
0 v 2 = v 3. The 0 operator is the horizontal-join(qualitative sum) operator. In a horizontal-inference table, it is assumed that concatenated abstractions are of the same abstraction type (e.g., state). In the specific(but quite common and important) case of secondary gradient interpolation, we have defined a rather intuitive qualitative algebra over the six values (e.g., SAME 0 SAME = SAME; INCREASING 0 SAME =
NONDECREA S I N G ; NONDECREASING
0
DECREASING = NONMONOTONIC) that can easily be shown to be closed (i.e., the result is always within the six values) and associative (i.e., the order of performing join operations does not affect the final result). In the case of other abstraction types, such as state, both the values of the abstractions and the result of the join operation are specific to the domain(e.g., HIGH 0 MODERATE = ABOVE-AVERAGE)) and might not be closed, but still need to be associative. In the case of joining different values, both the temporalsemantic knowledge (inferential property) and the temporal-dynamic knowledge (A function) that are used for the interpolation are those specific to the output value v3.
Secondary state, gradient, and rate interpolation require additional conditions to preserve consistency, apart from an upper bound on the temporal gap between intervals. An interpolation-inference table defines the interpolation operation for every relevant parameter (e.g., hemoglobin-state) and value combination (e.g., INCREASING and SAME). An interpolation-inference table represents horizontalclassification knowledge, persistence knowledge, and the special temporal conditions that should hold between the temporal elements of the involved abstractions for successful interpolation.
For example, we need to check that, when we use secondary temporal interpolation to join two
INCREASING abstractions for a that are true over two intervals I 1, 1 2, into a INCREASING abstraction for over a superinterval l j, the value of n has indeed increased, or at least has not decreased below a certain predefined threshold during the time gap [Zl.end, Z2.startI (see Figure 1). In other words, we have to check that Il.end. n <12. start. ni-C,, where C, represents a measurement variation for n i t h e maximal decrement in parameter n,below which a change in n will not be considered as a decrease. C, can be interpreted as a measurement error of n, or as a natural random variation of 7~ over time, or as a significant change of n,for a particular task, depending on the context. In
INCREASING, DECREASING, NONDECREASING, NONINCREASING, and NONMONOTONIC.
Temporal interpolation requires that the temporal distance between the two time points or intervals of the parameter propositions be less than a certain time gap.
Within that time gap, a certain value of the parameter is then be assumed to hold.
The maximal allowed gap is a domain-, task-, and context-dependent function (e.g., the maximal allowed gap for LOW hemoglobin in the domain of oncology, the task of caring for patients using protocols, and the interpretation context of patients receiving X-ray therapy). The arguments of the maximal-gap function also include a measure of the rate of change of the parameter before and after the time gap; as an approximation, we use the length of the intervals before and after the gap. A maximal-gap function A is a function A (x,v, L(I1), L&), of a parameter x(assuming that n includes its abstraction type) and lengths L(Z1), L ( Z 2 ) of the intervals 11 and 12, to be joined in the context 5 into an interval with a n abstraction value v. The A function returns the length of the maximal temporal gap that still allows interpolation between 11 and I 2. For instance, in any context, joining two intervals where the hemoglobinstate abstraction was classified as LOW into a longer interval whose hemoglobin-state abstraction is classified as LOW depends on the time gap separating the two intervals, on the particular context, and on the length of time in which the LOW property was known both before and after the time gap. Primary interpolation is the initial constructor of abstraction intervals, since it joins two separate time points T I and T 2 into a new interval [TI,T 2 ], over which v is true fore)r.
Thus, a necessary requirement for primary interpolation is that L([T1, T23) < A(x, V, 0, 0, where L(I) is the length of I.
A prerequisite to an interpolation operation is that the value v of the parameter a is has the value TRUE for the concatenable inferential property [Shoham, 19871 in the context 5 (i.e., the parameter propositions involved can indeed be joined). This prerequisite involves temporal-semantic knowledge. We summarize the temporal-semantic knowledge for a domain in an inference-properties table, a relation in which every tuple (n,v, 4, U, 5> represents the knowledge that the temporal-semantic property 4 E Q, for value v, of parameter n, in the context 5, has the truth value U (UE {TRUE,FALSE}) (nis assumed here to include its abstraction type).
Similarly, deciding what is the value of the resulting abstraction when joining two abstraction intervals with different values, V I and v 2, of the same parameter n requires using horizontal classification knowledge. A horizontal-inference table is a relation that includes
4, 105general, C, is a function of n, fc(n), that is defined either by the domain expert or through analysis of the distribution of K In principle, f,.(n) might also use a context argument 5 and the initial value of n,Z1.end.n(e.g., what is considered as a significant variation in the value of the hemoglobin-value parameter might have a different value within the interpretation context BONEMARROW DEPRESSION, and furthermore, when the last hemoglobin value known is abstracted as VERYmeasured, there is no particular reason to assume that a parameter proposition was not true before time t o.
Thus, t might actually have a negative value. We need this extension if we are to include an approximation of the past value of a parameter, for purposes of interpretation, as opposed to forecasting a future value of the parameter. Thus, our model includes both forward decay and backward decay in belief. The function describing this decay is equivalent to a statistical survival function.
In practice, the important question for performing an interpolation using a local persistence function is how long t can be before the belief in the parameter proposition v, E P (i.e., its probability) drops below a certain context-specific threshold (Pth (Figure 2).
LOW).
Primary temporal interpolation for the INCREASING gradient abstraction, requires that T2.n - T1.n 2 C,.
Primary temporal interpolation for the DECREASING gradient abstraction requires that T1.n - T2.n 2 C., Primary temporal interpolation for the SAME gradient abstraction requires that lT2.n - T1.d I
C,.
Using the C, property, we can ignore minor absolute changes in the value of n that are less than a certain threshold when we wish to identify general qualitative trends.
5.2. Global persistence functions
Global (A) maximal-gap functions bridge the gap between two propositions. A functions are an extension of p functions, and, in special cases, as we show in this section, they can be constructed from the latter functions. The A function returns the maximal time gap that still allows us to join the propositions into an abstraction that is believed to be true, with a sufficient, task-specific, predefined degree of belief in the proposition, during the gap (and thus over a superinterval of the input propositions, given that both were true for some time before and after the gap).
Thus, the A functions are a global extension of the local(p) persistence functions, since they assume both forward and backward decay of the propositions involved.
Figure 2 presents a graphic view of the A function as an interpretation of a decay in the belief in the truth of a proposition. For instance, in the case that the abstractions parameter values are identical-that is, the propositions are the same before and after the gap interval-and the forward and decay times are relatively independent, we are interested in whether, at all points inside the gap interval, either of the values, approximated by the forward belief decay in proposition q, BELfomard(q),or by the backward belief decay, BELbackward(v,),is true with a probability p 2 qth. As the time gap At between the two abstractions increases, the belief that either the backward- or forward- decay value is true will eventually fall below the predefined threshold value nh (see Figure 2).
If the local (p) persistence function is an exponential-decay survivor function and the backwardand forward-decay rates are independent, we can compute the A function. Assume that the probability p ( t ) of the parameter proposition cp being true is e-ht, a function of the time t since the reference time in which
P was true, regardless of the length of the time interval
Zduring which cp was true.
5. Local and global persistence functions
The maximal-gap A functions, which allow interpolation between point and interval primitive and abstract parameters, can be interpreted as creating a default abstraction during the maximal-gap interval.
Like all conclusions inferred by the temporalabstraction mechanisms, the inference that creates such default abstractions is nonmonotonic and can be overridden by additional data or by other inferences.
The maximal-gap functions represent domain- and task-dependent knowledge regarding the rate of change of a parameter proposition <n,V, 0 over time, or the persistence of the truth of that proposition over a temporal gap. In general, however, we distinguish two types of persistence functions: Local (p) persistence functions and global (A) functions. For the purpose of the following discussion, we assume that the context 5 and the value of n, unless mentioned explicitly, are known.
5.1. Local persistence functions
Local (p ) persistence functions represent the local persistence of the truth of a parameter proposition, given a single parameter point or interval: p(n, L(Z), t), where L(Z) is the length of the interval Z during which the parameter proposition is known to hold, and tis the time since an endpoint of I. The p function returns a degree of belief-a probability distribution-in the proposition <n,v> being true at time to + t, given that
<n,v, was true at endpoint b. The p function extends a proposition temporally in both directions: to the future and to the p a s t. Assuming that time to is a random (first) time in which the proposition was
10601
I
I
4
11
02
12
I
1 -.(Ah *
0b
Time
Figure 2: Local and global persistence functions. The maximal time gap A t returned by a global A function is used to decide whether the parameter propositions ql and R, attached to intervals I, and /*, can be joined (possibly, if they do not denote the same value of the relevant parameter, into a new proposition rp3 = ql 63 v)2). The time gap At can be interpreted-in the case that ql R, and that the truth values of the propositions are relatively independent-as the maximal time gap in which the belief produced by either the local forward or backward decay (represented by a local persistence p function) stays above the predefined confidence threshold flh. Bel(cp) = degree of belief in 9;flh = the task- and context-specific belief threshold value.
We can generalize this analysis. Assume that the longer q is known to be true in the past or in future, the longer we are likely to keep believing it or to believe that it already existed in the past, before we measured it(this assumption will be discussed in Section 5.3). One(not necessarily the only) way to represent that assumption would be to modify the decay rate A by assuming that it is inversely proportional to the length of the relevant intervals, L(Zi), which we denote simply as 4. Let
BEL ( p )= e[-WLiIt, j = 1,2.
Let the forward decay rate be A1 and the backward decay rate be 4. Then, we need to know the maximal gap At such that, in the point of minimal belief, p ( t ) is at or above the threshold fib. Note that the minimum point of BELforward(q) or BELbackward(q) is when the values of the forward- and backward-decay functions are equal (see Figure 2).
Thus, at the minimal p(t), BELforward(q) = BELbackward(q), that is,,-alt = e-Az(Ar-r
), So, if p(t) is minimal, and as before,  so, when p ( t ) is minimal, BELforward(q) = BELbackward(q)*t = [a24a1+a2)] At;then,[-AI/L~I~=,[-h.LLz](Ar-rbut p ( t ) 2 q t h implies, after substituting for t in BELforward(qh that
);that is, when p ( t ) is minimal,  e - [ ( A i * W ( A i + ~ 2 ) l A ~2 cpth = e-K,  t = [(Lli22)/(AlL2+4Ll)lAt.and thus
Substitute for t in BELfo,,d(q), [(a, +a2)4a1*a2)] K, K = -invth.
At I
In other words, the A function for two parameter points, A(z, 0, 0), or for two parameter intervals when the duration of the intervals has no effect on the persistence of the propositions, is a constant determined by the forward- and backward-decay rates and the desired level of confidence.and assume that
P(t) 2 (Pth:
At I
[ ( A ~ ~ ~ ~ + ~ ~ L ~ L K~=) -In%.
~ A ~ A ~ L ~ ] K, For instance, if A1 =A2 then
=Aand L(Z1) = L(Z2) = L, At S [( aL2+aL2)/A2L]K; that is, 107
At I [2LlA]K, K = -In%.
In other words, if exponential decay rates decrease(equally) linearly forward and backward as a function of the duration of the proposition, then the maximal time gap allowing us to join equal-length abstractions would be proportional to a linear function of the length of either interval, with the rest of the factors kept constant. The duration of the gap would be inversely proportional to the uniform decay rate.
These simplified examples serve to show that even though the decay rates A, are in general unknown, and the decay function is perhaps difficult to compute, the resulting global A function (using a belief threshold) might be a simple constant or polynomial, and thus can be more easily described, computed, or acquired, than the underlying local-persistence function.
Furthermore, if there is evidence for a particular type of decay function (e.g., logarithmic), we can compute the latter's coefficients by acquiring from the domain expert a few maximal-gap values-that is, several examples of At. We might even check the expert's consistency (or the adequacy of the decay
@nction) by repeating the calculation for several other examples. Alternatively, we can simply acquire a table of typical At values for various common L(Z1) and L(Z2) values, and can interpolate between these values, or extrapolate from them, when necessary.
Due to the dependence between the forward decay of a parameter proposition attached to one time point and the backward decay of that proposition at a later time point, and, therefore, an implied joint distribution of the forward and backward belief values, we usually need the actual global (A) function, in addition to (or instead of) the local (p) persistence function. (In the example above, we in fact computed a lower bound for the A function.) In practice, the domain expert often knows several A function values (such as what is the maximal time gap allowed in order to join two parameter points for several parameter values in each context), even if she cannot define any particular, precise, local-decay function p (except, possibly, for specifying the forward and backward local decay times
At corresponding to reaching the local threshold value q&). Knowing only the global A function still enables interpolation between two point-based or intervalbased parameter propositions. In view of the preceding discussion, in many domains, knowing only the values needed to maintain Bel(q) above the threshold value q7,th-that is, the (simpler) A function-would be a common state of affairs.
5.3. A typology of persistence functions
Global (A) persistence functions can have four qualitative types, depending on whether the A function is either (1) positive monotonic or (2) negativemonotonic, with respect to (a) the length of the first parameter interval L(Z,) or (b) the length of the second parameter interval L(Z,) (see Figure 2). For example, the maximal allowed gap might be the same or longer, the longer the interval before the gap; the global persistence function would then be positive monotonic relative to the length of that interval.
Theoretically, there are positive-positive (PE'), positive-negative (PN), negative-positive (NP), and negative-negative (NN) monotonic A functions. We refer to these categories as qualitative persistence types.
Formally, PP A functions are functions such that
L(Z') > L(Z) => V i [A(Z', 9 2 A(Z, i) A A(i, Z') 2 A(i, 41.
NN A functions are functions such that
L(Z')> L(Z) => Vi [A(Z',i) I A(Z, i) A A(i, Z') 5 A(i, Z)], where L(Z) is the length of interval Z and A(Z, i) stands for A(L(4, L(i)).
In the case of local (p) persistence functions, whether representing backward or forward local persistence, we can categorize functions qualitatively into positive (P) and negative (N) categories with similar meaning (i.e., whether the longer I, the longer or shorter the relevant validity interval, before or after
4.
Most A functions, in practice, seem to be of the PP type, In other words, the longer we know that a parameter proposition was true either before or after a time gap, the longer we would allow that gap to be while maintaining our belief that the parameter proposition stayed true throughout that gap (i.e., its probability was always above a certain threshold). (For instance, the proposition denoting the MODERATEANEMIA value of the hemoglobin-state parameter usually would be associated with a PP A function, as would be the proposition denoting the DEEP-COMA value of the consciousness parameter).
Negative-monotonic A functions occur when a longer duration of either I, or of Z2 lowers the probability that the abstraction was true during the gap, and the longer the lengths, the shorter the allowed At.
For instance, knowing about a longer Z, interval of an almost-fatal cardiac arrhythmia (say, ventricular fibrillation) actually lowers the probability that the(following) gap interval had the same characterization, given the same Z2 interval and assuming that the patient is alive. Most of the negative-monotonic functions emerge from a total-length constraint on the time allowed for the abstraction (or an analogous probabilistic distribution on the expected total time), or from a total cardinality constraint on the number of events allowed.
We often can limit ourselves, as a first approximation, to the common PP A functions. Note
108that the exponential-decay local (p) functions that were given as an example in Section 5.2 for decay functions dependent on the length of either of the two intervals implied, with the independence assumption, a PP-type
A function. However, there is also an important computational advantage in adhering to PP A functions. lemma 1: PP A functions are associative. (The order of joining intervals and points cannot change the resulting set of abstractions.)
Proof Assume a situation where parameter points
T I, T2, and T3 exist in that temporal order. If we can form both the parameter interval [ T I,T 2 ] and the parameter interval [Tz,T3 1, then, if we can eventually form the interval [ T I,T3 1, we can do so by forming initially either subinterval, since the A function is PP.
That is, if we can join one point to another point, we can certainly join that point-forwards or backwards, as necessary-to an interval starting or ending, respectively, with the other point. For instance, if we join points T1 and 7'2, we could certainly also join pointT1 to the interval [T2,T3], since
The dynamic knowledge about the domain does not necessarily need to include complete, closed, definitions of A functions-partial tables may suffice, or the actual ' functions might be approximated. But knowing whether a maximal-gap function is positive(PP) or negative (NN) is important for estimating the value of that function from a few examples or for interpolating that value from several discrete entries in a table. This qualitative-persistence type is easy to acquire, since domain experts usually have an excellent intuition about whether, qualitatively, a longer duration of a parameter proposition before or after a gap increases or decreases the probability of the proposition being true during a longer gap, even if the probabilities involved are in fact unknown.
6. Related work
L([Ti, T21) I
A(0,O)=> L ( [ T i,Tzl) I
N O, L([T2,T31)), since the A function is PP, and therefore A(0,O) I
L([T2, T31)).
A similar argument holds for any four consecutive points.
Thus, the claim is true for any sequence of primary or secondary interpolations, since A functions are applied only when there are no intervening points between the two intervals or points to be joined. Ci
The associativity property is important for datadriven systems, in which the order of the parameter intervals the system reasons with might be arbitrary.
This property is necessary also to guarantee that the final abstractions do not depend on the order of arrival of the input data. lemma 2: NN A functions are not associative.
Proof It is easy to construct a case for consecutive parameter points T I,T2, and T3, where, if we create the interval [ T I,T2], we no longer can join it to T3, and if we create the interval [T2, T 3 ],the A function value will prevent our joining it to T I (e.g., a total-sum constraint does not allow creating the interval [ T I,T3 ] with high enough probability). c11
NP and PN functions cannot be associative for similar reasons. Whether such functions can even exist is doubtful, and we leave it as an open research question. It would seem that appropriate semantic restrictions on the nature of A functions might preclude the existence of PN and NP functions.
In the case of p (local) persistence functions, we can categorize functions into P and N categories with similar meaning (i.e., whether the longer I, the longer or shorter the validity interval before or after I>.
Several temporal logics include some form of a persistence axiom for facts, that states that a proposition stays true until known to be otherwise. The p local-persistence function can be viewed as an extension of McDermott's persistence assumption   and of McCarthy's inertia principle [ l o ]. Both, however, include infinite persistence as a default.
McDermott [SI suggested that a fact does not cease to be true unless we explicitly hear that it no longer is true. Since this assumption is not always realistic, McDermott introduced the idea of a typical lifetime of a fact. Thus, an event causes persistence of a fact. Our p function belief threshold creates a value- and contextspecific validity time for a parameter proposition, but p functions extend temporally in both directions.
Tawfik and Neufeld [ l l ] have computed the relevance of time-stamped knowledge in a temporal
Bayesian framework, modeling relevance as a Markov process and looking only at a single predicate and a forward projection. Their analysis can be viewed as providing bounds on relevance due to a local persistence function, with certain independence assumptions.
Dean and Kanazawa   proposed a model of probabilistic temporal reasoning about propositions that decay over time. They modeled explicitly the probability of a proposition P being true at time t, P(<P, t > ), given the probability of <p, t-A>. The assumption is that there are events of type Ep that can cause proposition p to be true, and events of type ETP that can cause it to be false. Thus, one can define a survivorfunction for P(<P, D) given <p, t - b, such as an exponential decay function. Our p function model is somewhat similar. However, Dean and Kanazawa's main intention was not to solve an interpretation task(such as the TA task) but to solve a projection task, in particular in the context of the planning task. Thus, unlike in our model, persistence is only considered forwards in time. In a later work, Kanazawa  
109presented a logic of time and probability, Lep.
Propositions asserted in Lcp were stored in a time network, which maintained probabilistic dependencies among various facts, such as the time of arrival of a person at a place, or the range of time over which it is true that the person stayed in one place, and was used to answer queries about probabilities of facts and events over time.
Two other somewhat similar approaches are de
Zegher-Geets time-oriented probabilistic functions(TOPFs) in the I D E F I X system   for summarization of medical records, and Blums [ 151 time-dependent database access functions and proxy variables to handle missing data in the context of the Rx project for automated discovery in clinical databases. The goals of these systems were also closer in nature to the TA task-that is, interpretation of time-stamped data. When de Zegher-Geets TOPFs represent the probability of a state or disease given a previous identical state, they simulate a forward p function; in addition, states in IDEFIX can have an expected length attribute.
Russ [I61 has analyzed the computational cost of limited temporal persistence, and has shown the improvements enabled by data abstraction. Since the KBTA method operates at multiple levels of abstraction, it often capitalizes automatically on such improvements.
7. Discussion and conclusions
The knowledge requirements for the temporalinterpolation mechanism include (1) structural knowledge: the qualitative-dependency aspect of the ABSTRACTED-INTO relation; domain time units; ( 2 ) classification knowledge: classification of domainspecific gradient and, in particular, rate abstraction values (e.g., SLOW, FAST) as changes per time unit; horizontal-classification knowledge, that is, the horizontal-inference table; (3) temporal-dynamic knowledge: maximal-gap (A) functions and local (p) persistence functions, both specific to each parameter proposition (which includes an explicit context); significant change values C, or functions fc(z)for the relevant parameters in various contexts; additional temporal constraints for completing the interpolationinference table; and (4) temporal-semantic knowledge: truth values for the concatenable property [Shoham, 19871 for input and inferred parameters.
Temporal-dynamic knowledge about a domain does not necessarily need to include complete definitions of A functions-partial functions may suffice, and knowing whether a maximal-gap function is PP or NN might complete the picture. The qualitative type of a persistence function is easy to acquire from domain experts. Furthermore, one of the insights underlying our model is that higher-level abstractions are morepersistent. Since temporal interpolation operates simultaneously at all abstraction levels, the more stable abstract conclusions often mask faster changes (and uncertainties) in lower-level abstractions and raw data.
The bidirectional temporal persistence model we present is relevant when data is abstracted and interpreted retrospectively, as is the goal of the TA task. Furthermore, both p and A functions are context sensitive and are thus represented explicitly. Finally, as shown in Sections 5.2, the use of global (A) persistence functions facilitates acquisition of temporal-dy namic,knowledge.
The RESUME system, implementing the KBTA method, was evaluated in several domains, such as various areas of clinical-medicine   and traffic control   with highly encouraging results. The RESUME system is also a component of the current
EON project, a component-based architecture for guideline-based clinical therapy [ 171, in which it perfoms the TA task as part of a temporal-abstraction server. The results of employing &SUME in various domains emphasized not only the validity of the methodology, but the advantages of explicit representation of temporal-abstraction knowledge for acquiring, maintaining, and reusing that knowledge. In the case of the traffic-control domain, the results have also indicated the usefulness of the KBTA method(inclding the interpolation model) for both temporal abstraction and linear spatial abstraction within the same application, using essentially a 1 : 1 correspondence between linear time and linear space(each highway was considered as a timeline, and spatial abstractions such as 1500 meters of severe conjestion in zone 1 at time 0 were formed. The(static) output was abstracted over time to produce temporal abstractions such as increasing congestion in zone one over time interval [0, Smin]).
The current knowledge-based temporalinterpolation model has three major limitations. From the soundness aspect, the threshold cutoff assumed by the model is convenient in practice, but might potentially lead to unsound conclusions (from the domains point of view) of higher-level abstractions that use the result of the interpolation (which is assumed to hold with certainty once its probability is higher than a domain-specific threshold). Thus, a confidence value should still be attached to the conclusion. From the completeness point of view, the model cannot conclude values of the parameter during the gap in the specific case when the values before and after the gap are different and also are not part of a horizontal-join relation. Finally, from the knowledge acquisition point of view, even when using the results of the analysis in Section 5.2, considerable amounts of knowledge might still need to be acquired from human experts. (Currently, we are using a graphic knowledgeacquisition tool that uses three-dimensional tables to
110represent A functions   and that is generated automatically by the P R O ~ G E - I 1 set of tools.
To address these limitations, w e are planning to (1) construct a Bayesian-semantics framework f o r t h e
10.
J. McCarthy, Applications of circumscription to formalizing commonsense knowledge, Artificial
Intelligence 28(1) (1986) 89-116.
11. A. Y. Tawfik and E. M. Neufeld, Irrelevance in uncertain temporal reasoning, Proceedings ofthe Third
International Workshop on Temporal Representation and Reasoning (TIME 96) (Key West, Florida, 1996)interpolation operation, (2) attempt to learn local and global interpolation functions from large temporal databases (given some domain knowledge, such as the abstraction hierarchy and classification functions, and the temporal-semantic properties of relevant parameters), and (3) to test the automatically acquired functions using methodologies that have been shown to b e valuable in similar cases.
196-202.
12. T. Dean and K. Kanazawa, Probabilistic temporal reasoning, in: Proceedings of the Eight National
Conference on Artificial Intelligence, Minneapolis, MN (1986) 524-528.
13. K. Kanazawa, A logic and time nets for probabilistic inference, Proceedings, Ninth National Conference on
Artificial Intelligence, Los Angeles, CA (MIT Press, Cambridge, MA, 1991) 360-365.
14. I.M. De Zegher-Geets, A.G. Freeman, M.G. Walker, R.L. Blum, and Wiederhold, G., Summarization and display of on-line medical records. M.D. Computing 5(1988) 38-46.
15. R.L. Blum, Discovery and representation of causal relationships from a large time-oriented clinical database: The RX project, in D.A. Lindberg and P.L.
Reichartz, eds., Lecture Notes in Medical Informatics, vol. 19 (Springer-Verlag, New York, 1982).
16. T.A. Russ, Use of data abstraction methods to simplify monitoring, Artijicial Intelligence in Medicine 7 (6)(1995) 497-514.
17. M.A. Musen, S.W. Tu, A.K. Das, and Y. Shahar, EON:
A component-based approach to automation of protocol-directed therapy. Journal of the American
Medical Association 3 (6) (1996) 367-388.
18. A. Stein, M.A. Musen, and Y. Shahar, Knowledge acquisition for temporal abstraction. Proceedings of the 1996 AMIA Annual Fall Symposium (formerly the Symposium on Computer Applications in Medical
Care), Washington, DC (Hanley & Belfus, Philadelphia, 1996) 204-208.
19. S.W. Tu, H.Eriksson, J. Gennari, Y. Shahar, and M.A.
Musen, Ontology-based configuration of problemsolving methods and generation of knowledgeacquisition tools: Application of PROTEGE-I1 to protocol-based decision support. Artijicial Intelligence in Medicine 7 (3) (1995) 257-289.
20. K.M. Albridge, J. Standish, and J.F. Fries, Hierarchical time-oriented approaches to missing data inference, Computers and Biomedical Research 21 (1984), 349366.
Acknowledgments
This work has been supported by grants LM05708 and LM06245 from the National Library of Medicine and IRI-9528444from the National Science Foundation.
Computing resources were provided by the CAMIS project, funded under grant No. LM05305 from the National Library of Medicine.
References
1. Y. Shahar, A framework for knowledge-based temporal abstraction, Artificial Intelligence 90 (1997) (in press).
2. H. Eriksson, Y. Shahar, S.W. Tu, A.R. Puerta, and M.A.
Musen, Task modeling with reusable problem-solving methods, Artijicial Intelligence 79 (2) (1995) 293--326.
3. Y. Shahar and M.A. Musen, Knowledge-based temporal abstraction in clinical domains, Artificial Intelligence in Medicine 8(3) (1996) 267-298.
4. Y. Shahar and M. Molina, Knowledge-based spatiotemporal abstraction, in Proceedings of the AAAI-96
Workshop on Spatial and Temporal reasoning (Portland, Oregon, 1996) 21-30.
5. J. McCarthy and P. Hayes, Some philosophical problems from the standpoint of artificial intelligence, in: Machine
Intelligence (University Press, Edinburgh, UK, 1969).
6. Y. Shahar, S.W. Tu, and M.A. Musen, Knowledge acquisition for temporal-abstraction mechanisms.
Knowledge Acquisition 4, (1992) 217-236.
7. Y. Shoham, Temporal logics in AI: Semantical and ontological considerations, Artificial Intelligence 33( 1)(1987) 89-104.
8. D.V. McDermott, A temporal logic for reasoning about processes and plans, Cognitive Science 6(2) (1982) 101155.
9. T. Dean and D.V. McDermott, Temporal database management, Artificial Intelligence 32 (1987) 1-55.
111