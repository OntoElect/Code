Believing Change and Changing Belief
Peter Haddawyhaddawy@cs.uwm.edu
Department of Electrical Engineering and Computer Science
University of Wisconsin-Milwaukee
Milwaukee, WI 53201
Abstract
We present a first-order logic of time, chance, and probability that is capable of expressing the relation between subjective probability and objective chance at different times. Using this capability, we show how the logic can distinguish between causal and evidential correlation by distinguishing between conditions, events, and actions that 1) in uence the agent's belief in chance and 2) the agent believes to in uence chance. Furthermore, the semantics of the logic captures commonsense inferences concerning objective chance and causality. We show that an agent's subjective probability is the expected value of its beliefs concerning objective chance. We also prove that an agent using this representation believes with certainty that the past cannot be causally in uenced.
1 Introduction
The ability to distinguish evidential from causal correlation is crucial for carrying out a number of different types of problem solving. To perform diagnosis we must be able to identify the factors that caused an observed failure in order to determine how to repair the faulty device. If we cannot distinguish causal from evidential correlation, we may end up treating the symptoms rather than the causes of the fault. When reasoning about plans, an agent may have goals that involve achieving a specified state of the world, or achieving a specified state of knowledge, or a combination of both.
In order to effectively reason about such goals, we need to distinguish actions that in uence the state of the world from those that only in uence our state of knowledge of the world.
In this paper we extend Haddawy's 3] logic of time, chance, and action L by adding a subjective probability operator. We show how the resulting first-order logic of time, chance, and probability, L, can distinguish between causal and evidential correlation by distinguishing between conditions and events that 1) in uence the agent's belief in chance and 2) the agent believes to in uence chance. Furthermore, the semantics of the logic captures some commonsense inferences tcatcp
This work was partially supported by NSF grant #IRI9207262.concerning causality and the relation between objective chance and subjective probability. We prove that an agent's subjective probability is the expected value of its beliefs concerning objective chance. We also prove that an agent whose beliefs are represented in this logic believes with certainty that the past cannot be causally in uenced. On the other hand, an agent can execute actions that in uence its subjective beliefs about the past.
2 Ontology
We brie y present the ontology of the logic, which includes the representation of time, facts, events, objective chance, and subjective probability. For simplicity of exposition, we will omit the representation of actions and will treat them as events. For a more detailed development of chance, facts, events, and actions see 3].
Time is modeled as a collection of world-histories, each of which is one possible chronology or history of events throughout time. A totally ordered set of time points provides a common reference to times in the various world-histories.
We represent an agent's beliefs with subjective probabilities. Since beliefs may change with time, subjective probability is taken relative to a point in time. We represent it by defining a probability distribution over the set of world-histories at each point in time. So an agent can have beliefs concerning temporally qualified facts and events.
We represent causal correlation with objective chance. Objectively, actions and events can only affect the state of the world at times after their occurrence.
That is to say, at each point in time, the past is fixed| no occurrences in the world will cause it to changeff but at each point in time the future might unfold in any number of ways. So relative to any point in time, only one objectively possible past exists, but numerous possible futures exist. Thus we represent objective chance by defining a future-branching tree structure on the world-histories and by defining probabilities over this tree. Like subjective probability, chance is taken relative to a point in time. By defining chance in this way, conditions in the present and past relative to a given time are either certainly true of certainly false.
So actions and other events can only affect the chances of future facts and events. This property distinguishes objective chance from subjective probability. Subjectively the past can be uncertain but objectively it is completely determined.
The present characterization of objective chance is not to be confused with the frequentist interpretation of probability 10, 11] which is often called objective probability. Frequentist theories define probability in terms of the limiting relative frequency in an infinite number of trials or events. The current work does not rely on relative frequencies for its semantics. Rather it models objective chance by formalizing the properties that characterize objective chance.
Thus while frequentist theories have diculty assigning meaningful probabilities to unique events like afish jumping out of the water at a given location and time, our model has no problem in assigning nontrivial probabilities to such events. Our model of objective chance and subjective probability is motivated by the subjectivist theories of objective chance 6, 8, 9], which define chance in terms of properties that one would expect a rational agent to believe objective chance to possess.
This distinction between the frequentist theory of probability and our conception of objective chance puts the present work in sharp contrast with Bacchus's 1] logic of statistical probabilities which models exactly relative frequency type probabilities. One telling difference between the two logics is that Bacchus's logic Lp assigns only probability 0 or 1 to unique events (more precisely, to all closed formulas). The present logic can assign any chance value to unique events in the future, while events in the past are assigned only chance values
0 or 1, as required by our definition of objective chance.
It is reasonable to expect the subjective beliefs of a rational agent concerning objective chance to obey certain constraints. Skyrms 7, Appendix 2] has argued for a constraint he calls Millers' principle. This asserts that an agent's subjective belief in a proposition, given that he believes the objective chance to be a certain value, should be equal to that value. Skyrms argues that this is a plausible rule for assimilating information about chance. We will call this relation the subjective/objective Miller's principle.
The world is described in terms of facts and events.
Facts tend to hold and events tend to occur over intervals of time. So facts and events are associated with the time intervals over which they hold or occur in the various world-histories. Facts are distinguished from events on the basis of their temporal properties. A fact may hold over several intervals in any given world-history and if a fact holds over an interval then it holds over all subintervals of that interval.
Events are somewhat more complex than facts.
First, one must distinguish between event types and event tokens. An event type is a general class of events and an event token is a specific instance of an event type. Event tokens are unique individuals { the interval over which an event token occurs is the unique interval associated with the event token and an event token can occur at most once in any world-history. The present work deals with event types, which for brevity are simply referred to as events.
3 The Logic of Time, Chance, and Probability
3.1 Syntax
The language of L contains two predicates to refer to facts and event types occurring in time:
HOLDS (FAfi t1fi t2) is true if fact FA holds over the time interval t1 to t2, and OCCURS (EVfi t1 fi t2) is true if event EV occurs during the interval t1 to t2. Henceforth we will use the symbol t, possibly subscripted, to denote time pointsff ff, , and ff to denote formulasff andfi and  to denote probability values.
In addition to the usual first-order logical operators, the language contains two modal operators to express subjective probability and objective chance. The operators are subscripted with a time since according to the ontology subjective probability and objective chance are taken relative to a point in time. We write P (ff) to denote the subjective probability of ff at time t and we write pr (ff) to denote the objective chance of ff at time t. Probability is treated as a sentential operator in the object language. So the probability operators can be arbitrarily nested and combined with one another, allowing us to write complex sentences like: \I believe there was a one in a million chance of my winning the lottery, yet I won."
P 3 (pr 2 (OCCURS (winfi t1fi t2)) = 10;6^
OCCURS (winfi t1fi t2)) = 1fi where t1 < t2 < t3. We also allow conditional probability sentences such as P (ffj) = fi, which is interpreted as shorthand for P (ff ^ ) = fi ff P ().
The language of L is fully first-order, allowing quantification over time points, probability values, and domain individuals. A formal specification of the syntax is provided in the full paper 2]. tcpttttttttcp
3.2 Semantics
We describe only the more interesting aspects of the models of L. The models are completely specified in the full paper. A model is a tuple hWfi D, FN, NFN, PFN, FRL, ERL, NRL, FA, EVENTS, EV, R, X, PR, PR, F i, where:
 W is the set of possible world-histories, called worlds.
 D is the non-empty domain of individuals.
 FA is the set of facts, a subset of 2(<ff<)ff. A fact is 0 a set of htemporal interval, worldi pairs: fhht1fi t1 ifi w1ifi :::fi hht fi t0 ifi w ig. If fa is a fact and hht1 fi t2ifi wi 2 fa then fa holds throughout interval ht1 fi t2i in world-history w.
 EVENTS is the set of event tokens, a subset of(<<)  W. An event token is a single htemporal interval, worldi pair.
 EV is the set of event types, a subset of 2EVENTS. An event type is a set of event tokens: fhht1fi t01 ifi w1ifi :::fi hht fi t0 ifi w ig. If ev is an event and hht1 fi t2ifi wi 2 ev then ev occurs during interval ht1fi t2i in world-history w. tcpos
Wnnnnnn
1. HOLDS (rf (trm 1 fi :::fi trm )fi ttrm1 fi ttrm 2)]]
= true iff hh ttrm 1 ]fi ttrm 2] ifi wi 2 F (rf )( trm 1]fi :::fi trm ]
):
2. OCCURS (re(trm 1 fi :::fi trm )fi ttrm 1 fi ttrm 2)]]
= true iff hh ttrm 1 ]fi ttrm 2] ifi wi 2 e for some e 2 F (re)( trm 1 ]fi :::fi trm ]
):
0
3. prttrm (ff)]]
= o ttrm](fw 2 R ttrm]
: ff]
= trueg).
4. Pttrm (ff)]]
= s ttrm](fw0 : ff]
= trueg).
Mfiwfign
Mfiwfig
Mfiwfig
Mfiwfig
Mfiwfign
Mfiwfign
Mfiwfig
Mfiwfig
Mfiwfig
Mfiwfign
Mfiwfig
Mfiwfigww
Mfiwfigw
0
Mfiw fig
Mfiwfig
0
Mfiw fig
Mfiwfig
Figure 1: Semantic definitions
 R is an accessibility relation defined on <W W.
R(tfi w1fi w2) means that world-histories w1 and w2 are indistinguishable up to and including time t.
If R(tfi w1fi w2) we say a world-history w2 is Raccessible from w1 at time t. The set of all worldhistories R-accessible from w at time t will be designated R. For each time t, the R partition the world-histories into sets of equivalence classes indistinguishable up to t.
 X is a -algebra over W 1, containing all the sets corresponding to wff's in the language, as well as all R-equivalence classes of world-histories.
 PR is the objective probability assignment function that assigns to each time t 2 < and worldhistory w 2 W a countably additive probability distribution o defined over X.
 PR is the subjective probability assignment function that assigns to each time t 2 < and worldhistory w 2 W a countably additive probability distribution s defined over X.
Given the models described above, the semantic definitions for the well-formed formulas can now be defined. Denotations are assigned to expressions relative to a model, a world-history within the model, and an assignment of individuals in the domain to variables.
The denotation of an expression ff relative to a model
M and a world-history w, and a variable assignment g is designated by ff]. Figure 1 shows the less familiar semantic definitions. The remainder are provided in the full paper. w tw tow tsw t
Mfiwfig
3.2.1 Semantic Constraints
In order to obtain the properties discussed in the ontology, we impose eight constraints on the models.
The future-branching temporal tree is defined in terms of the R relation over world-histories. To capture the property that the tree does not branch into the past, we say that if two world-histories are indistinguishable up to time t2 then they are indistinguishable up to any earlier time:(C1) If t1t2 and R(t2fi w1fi w2) then R(t1fi w1fi w2).
A -algebra over W is a class of subsets that contains
W and is closed under complement and countable union.
1
Since R just represents the indistinguishability of histories up to a time t, for a fixed time R is an equivalence relation, i.e., re exive, symmetric, and transitive:(C2) R(tfi wfi w)
If R(tfi w1fi w2) then R(tfi w2fi w1)
If R(tfi w1fi w2) and R(tfi w2fi w3) then R(tfi w1fi w3)
As mentioned earlier, facts and events differ in their temporal properties. This distinction is captured by the following two semantic constraints. If a fact holds over an interval, it holds over all subintervals, except possibly at the endpoints:(C3) If t1 t2 t3t4fi t1 6= t3 fi t2 6= t4 fi fa 2 FA and hht1fi t4ifi wi 2 fa then hht2 fi t3ifi wi 2 fa :
An event token occurs only once in each world-history:(C4) If evt 2 EVENTS, hht1fi t2ifi wi 2 evt, and hht3 fi t4ifi wi 2 evt then t1 = t3 and t2 = t4.
If two worlds are indistinguishable up to a time then they must share a common past up to that time. And if they share a common past up to a given time, they must agree on all facts and events up to that time. To enforce this relationship, we impose the constraint that if two world-histories are R-accessible at time t, they must agree on all facts(events) that hold(occur) over intervals ending before or at the same time as t:(C5) If t0 t1 t2 and R(t2 fi w1fi w2) then hht0 fi t1ifi w1i 2
A iff hht0 fi t1ifi w2i 2 A, where A is a fact or event.
The ontology discussed two desired characteristics of objective chance. The first is that the chance at a time t be completely determined by the history up to that time. The second desired characteristic is that the chance of the present and past should be either zero or one, depending on whether or not it actually happened.
These two properties follow as meta-theorems from the following two constraints:(C6) For all 0 X 2 X fi tt0fi and wfi w0 such that
R(tfi wfi w )fi(R ) > 0 ! (X ) = (X jR ). w tw t
0w t0
0w tw t0
0(C7) (R ) > 0.
Meta-theorem 1 The probability of the present and w tw tpast is either zero or one. w t(R ) = 1 w t
1.
2.
3.w t w t w t
Theorem 7 Objective Miller's Principle (OMP)(R ) > 0(C7)(R ) = (R jR ) Modus Ponens: (C6),1(R ) = 1 def of c-prob w t w t w tw tw tw ttcpt
Defining the probabilities in this way makes good intuitive sense if we look at the meaning of R. R designates the set of world-histories that are objectively possible with respect to w at time t. It is natural that the set of world-histories that are objectively likely with respect to w at time t should be a subset of the ones that are possible. w t
Meta-theorem 2 If two worlds are indistinguishableup to time t then they have identical probability distributions at that time.
If R(tfi wfi w0) then (X ) = (X ) w t
0w t(R ) > 0(C2), (C7)(R ) = (X jR ) Modus Ponens: (C6),1(X jR ) = (X jR ) (C2)(R ) = 1
Meta-theorem 1(X ) = (X ) def of c-prob
1.
2.
3.
4.
5.w t w t w t w t
0 w t
0w t
0 w tw tw tw t
0w tw t
0w tw t
In the ontology, we argued that subjective probability and objective chance should be related to one another by Millers' principle. This relation is enforced by the following constraint, which says that the probability of a set of worlds X, given some R equivalence class, should just be the objective chance in that equivalence class.(C8) s (X jR ) = o (X ) w tw tw t
4 Theorems
We first provide several simple theorems that will be used in later proofs. Then we prove two forms of Miller's principle and provide two associated expected value properties. Proofs not provided here appear in the full paper.
Theorem 3 From ff $  infer pr (ff) = pr (): tt
Theorem 4 Stronger sentences have lower probability.
From ff !  infer P (ff)  P ().
Theorem 5 Certainty cannot be conditioned away from.
P (ff ^ ) = P () ! P (ff ^  ^ ff ) = P ( ^ ff )
Theorem 6 The present and past are objectively certain.
Let be a fact or event:
HOLDS (fffi t fi t0 ) or OCCURS (fffi t fi t0 ) then
8tfi t fi t0 (t0  t) ! pr ( ) = 0 _ pr ( ) = 1] ttttffffffffttfffft
All instances of the following sentence schema are valid in L.
8fifi t0fi t1 (t0  t1 ) ! pr 0 (ff j pr 1 (ff) = fi) = fi
Proof:fft
The semantic constraints on objective chance give us a version of Miller's principle that relates objective chance at different times. It says that the chance of a sentence ff at a time, given that the chance of ff at the same or a later time is fi, should be fi.t
We first prove an expected value property and then use it to prove Miller's principle. Let tfi t0 be two time points t  t0 and consider the R-equivalence classes of worlds at time t0. Let the variable r range over these equivalence classes. The r form a partition of W, so the probability of a set X can be written as the integral over this partition:
Z o (X ) = o (X jr) o (dr)ff
Since the history up to time t0 determines the probability at time tZ0, this can be written as o (X ) = o (X ) o (dr)fiff where o denotes the probability at time t0 in equivalence class r. Since the probability at a given time is assumed to be constant over all worlds in an Requivalence class, the probability at a given time is the expected value
Z of the probability at any future time: o (X ) o (dw0 ): o (X ) =
Next we show that Miller's principle is valid in the probability models. By the expected value property, o (ZX \ fw0 : o (X ) = fig) = o (X \ fw0 : o (X ) = fig) o (dw00):
Now, by semantic constraints (C6) and (C7) it follows that
8 w 2fw0 : o (X ) = figfi o (fw0 : o (X ) = fig) = 1
8 w 62fw0 : o (X ) = figfi o (fw0 : o (X ) = fig) = 0:
So we can restrict the integral to the set fw0 :Z o (X ) = fig:
= o (X \ fw0 : o (X ) = fig) o (dw00): w tw tr
Wr
Ww tw tr t0w tr t0w t0w t
0w t
Ww tw t0w t0
0
00w t0
0w t
Ww t0w t0w t0
0w t0
0w t0w t0w t0
0
0
0w
00w t0t0
0 w 0 ow0 X tf( )=ffg
:
0w t
And by the above property again o (XZ\ fw0 : o (X ) = fig) = fi, so
= fiff o (dw00): w t0
00w t0f
0( )=ffg
0 w 0 ow0 X t
:w t
= fi ff o (fw0 : o (X ) = fig):
By the semantic definitions it follows that
P (ff ^ P (ff) = fi) = fi ff P (P (ff) = fi):
And by a slight generalization of the proof it follows that
8(t  t0) P (ff ^ P (ff) ff fi) ff fi ff P (P (ff) ff fi):
2
From the Objective Miller's Principle it follows directly that current chance is the expected value of current chance applied to current or future chance. w ttw t0t0
0ttt0t0tt0
Theorem 8 Objective Expected Value Property
All instances of the following sentence schema are valid in L.
8fifi fi t1fi t2 (t1  t2 ) ! pr 1 (pr 2 (ff) ff fi) ff  ! pr 1 (ff) ff fi ff  ] tcpttt
As discussed in the ontology, the current subjective probability of a sentence, given that the current or future chance is some value should be that value. The following theorem shows that this property follows from the semantics of the logic.
Theorem 9 Subjective/Objective Miller's Principle (SOMP)
All instances of the following sentence schema are valid in L.
8fifi t0fi t1(t0  t1 ) ! P 0 (ffjpr 1 (ff) = fi) = fi
Proof: We first prove an expected value property and tcpttthen use it to prove
Miller's principle. Let tfi t0 be two
0 time points t  t and consider the R-equivalence classes of worlds at time t0. Let the variable r range over theseequivalence classes. The r form a partition of W, so the probability of a set X can be written as the integral over this partition:s (X ) =
Zw trs (X jr) s (dr) w tff
Ww t
Zw tro (X ) s (dr) r tff
Ww twhere o denotes the objective chance at time t in equivalence class r. Since the chance at a given time is assumed to be constant over all worlds in an Requivalence class, the subjective probability at any time is the expected value of the subjective probability applied to the objective chance at that time: r ts (x) =
Zo (X ) s (dw0)w tw t
W
0w t
Next we show that the Subjective/Objective Miller's principle is valid in the probability models. By the above subjective/objective expected value property, s (ZX \ fw0 : o (X ) = fig) = o (X \ fw0 : o (X ) = fig) s (dw00)
By Objective Miller's Principle, s (XZ\ fw0 : o (X ) = fig) =fi o (fw0 : o (X ) = fig) s (dw00) w tw t0w t
0
00w t0
0w t
Ww tw t0w t
0
00w t0
W
0w t
Finally, by the subjective/objective expected value property, s (X \ fw0 : o (X ) = fig) =fi s (fw0 : o (X ) = fig)
So by the semantic definitions it follows that
8tfi t0 (t  t0 ) ! P (ffjpr (ff) = fi) = fi w tw t0w t
0w t0t
0t0tt0
Theorem 10 Subjective/Objective
Value Property
Expected
All instances of the following sentence schema are valid in L.
8fifi fi t1fi t2 (t1  t2) !
P 1 (pr 2 (ff) ff fi) ff  ! P 1 (ff) ff fi ff  ] tcpttt
5 Distinguishing Evidential and Causal
Correlation
We wish to distinguish between two situations in which an agent may believe that two conditions are correlated.
An agent may believe that two conditions are correlated because one is simply evidence for another and an agent may believe that they are correlated because one causes the other.
Let stand for the formula HOLDS (fffi t fi t0 ) or OCCURS (fffi t fi t0 ) and let ! stand for the formula
HOLDS (fi t fi t0 ) or OCCURS (fi t fi t0 ). We represent evidential correlation as correlation in the subjective probability distribution, which is the standard approach in Bayesian decision theory.
Denition 11 We say that ! is evidence for orff
By semantic constraint (C8), this can be written ass (X ) =
And by a slight generalization of the proof it follows that
8tfi t0 (t  t0 ) ! P (ffjpr (ff) ff fi) ff fi
2
From the subjective/objective Miller's principle it follows directly that subjective probability is the expected value of current subjective probability applied to present or future chance.fffifffffiagainst iff
Pnow ( j !) =
6 Pnow ( )fifi(1)
It follows from this definition that ! is not evidence for or against iff
Pnow ( j !) = Pnow ( )
We represent causal correlation by reference to the objective chance distribution. We represent an agent's belief that ! causally in uences by saying that there is some value for the objective chance of such that the agent's belief in given the objective chance of just before ! holds or occurs is not the same as the agent's belief given also knowledge of !. In other words, knowledge of ! overrides knowledge of the objective chance of.
Denition 12 We say that ! is a cause of iff
9fi Pnow ( j pr ( ) = fi ^ !) 6= fi:(2)
Note that this does not necessarily imply that
Pnow ( j!) 6= Pnow ( ). Thus we may have causal correlation without evidential correlation and, conversely, we may have evidential correlation without causal correlation. It follows from this definition that ! is not a cause of iff
8fi Pnow ( j pr ( ) = fi ^ !) = fi: tfftff
5.1 Example
We now present an example demonstrating the use of the definitions and theorems. We wish to describe the following situation. You have a coin that may be biased
3:1 towards heads or 3:1 towards tails. You believe there is an equal probability of each. You can observe the coin. If the coin looks shiny, this increases your belief that the coin is biased towards heads. You also have a magnet that you can use to in uence the outcome of the coin toss. Turning on the magnet biases the coin more toward heads. We can describe the situation with the following set of sentences in which \heads" is the event of the coin landing heads, \shiny" is the event of the coin being observed to be shiny, and \magnet" is the fact that the magnet is on.(now < t0 < t1 < t2 < t3 < t4 )
Turning on the magnet in uences the chance of heads.
Pnow (OCCURS (Headsfi t2fi t3)j(3) pr 1 (OCCURS (Headsfi t2fi t3)) = 3=4 ^
HOLDS (Magnetfi t1 fi t4)) = 7=8
Pnow (OCCURS (Headsfi t2fi t3)j(4) pr 1 (OCCURS (Headsfi t2fi t3)) = 1=4 ^
HOLDS (Magnetfi t1 fi t4)) = 1=2
The probability that the coin is biased toward heads and the probability that the coin is biased toward tails are equal.2
Pnow (pr 1 (OCCURS (Headsfi t2fi t3)) = 3=4) =(5)
Pnow (pr 1 (OCCURS (Headsfi t2fi t3)) = 1=4) = 1=2
Observing the coin doesn't in uence the chance of heads.(6)
8fifi t (t > now) !
Pnow (OCCURS (Headsfi t2fi t3) j pr (OCCURS (Headsfi t2fi t3)) = fi ^
OCCURS (Shinyfi t0 fi t2)) = fi
Observing the coin gives us knowledge of its bias.
Pnow (pr 0 (OCCURS (Headsfi t2fi t3)) = 3=4 j(7)
OCCURS (Shinyfi t0 fi t2)) = 5=8
Pnow (pr 0 (OCCURS (Headsfi t2fi t3)) = 1=4 j(8)
OCCURS (Shinyfi t0 fi t2)) = 3=8
Turning on the magnet does not give us knowledge of the coin's bias.
8fi Pnow (pr 1 (OCCURS (Headsfi t2fi t3)) = fi j(9)
HOLDS (Magnetfi t1 fi t4)) =
Pnow (pr 1 (OCCURS (Headsfi t2fi t3)) = fi)
The coin is either biased toward heads or toward tails.
8t pr (OCCURS (Headsfi t2fi t3 )) = 3=4 _(10) pr (OCCURS (Headsfi t2fi t3)) = 1=4(11) ttttttttttt
It would be more appropriate to say that our belief that the current chance is 3/4 or 1/4 is 1/2 and that in the absence of events that will inuence the chance, chance will remain unchanged till time t1. Such an inference would require some kind of theory of persistence, which is beyond the scope of this paper.
2
Using this information, we can make several useful inferences. First we can derive the unconditional probability that the coin will land heads. From (5) by SOMP we have
Pnow (OCCURS (Headsfi t2fi t3)) =(12)(1=2)(3=4) + (1=2)(1=4) = 1=2
Next, we can use the above information to derive the probability that the coin will come up heads given that it is observed to be shiny. Instantiating (6) withfi = 3=4 and t = t0 and multiplying the result by (7) we get
Pnow (OCCURS (Headsfi t2fi t3)^(13) pr 0 (OCCURS (Headsfi t2fi t3)) = 3=4 j
OCCURS (Shinyfi t0 fi t2)) =(5=8)(3=4) = 15=32
And instantiating (6) with fi = 1=4 and t = t0 and multiplying the result by (8) we get
Pnow (OCCURS (Headsfi t2fi t3)^(14) pr 0 (OCCURS (Headsfi t2fi t3)) = 1=4 j
OCCURS (Shinyfi t0 fi t2)) = (3=8)(1=4) = 3=32
From (10), (13), and (14) by the law of total probability we get
Pnow (OCCURS (Headsfi t2fi t3) j(15)
OCCURS (Shinyfi t0 fi t2)) = 9=16
We can also derive the probability of heads given that we activate the magnet. From (3), (5), and (9) we get
Pnow (OCCURS (Headsfi t2fi t3)^(16) pr 2 (OCCURS (Headsfi t2fi t3)) = 3=4 j
HOLDS (Magnetfi t1fi t4)) = (1=2)(7=8) = 7=16
From (4), (5), and (9) we get
Pnow (OCCURS (Headsfi t2fi t3)^(17) pr 2 (OCCURS (Headsfi t2fi t3)) = 1=4 j
HOLDS (Magnetfi t1fi t4)) = (1=2)(1=2) = 1=4
From (10), (16), and (17) by the law of total probability we get
Pnow (OCCURS (Headsfi t2fi t3) j(18)
HOLDS (Magnetfi t1fi t4)) = 11=16 tttt
5.2 The temporal ow of causality
Using our definition of causal in uence and SOMP we can now show that an agent whose beliefs are represented with L believes that the past cannot be in uenced. tcp
Theorem 13 Let be a fact or event:
0
0
HOLDS (fffi t fi t ) or OCCURS (fffi t fi t ) and let ! be a fact or event:
HOLDS (fi t fi t0 ) or OCCURS (fi t fi t0 ).
Then all instances of the following sentence schema are valid in L.
8fifi tfi t fi t0 fi t fi t0 (t0  t ) ^ (t  t ) !
P ( jpr ( ) = fi ^ !) = fifffffffififitcpfftfffitfffifffififffi
Proof: We prove a slightly more general result of whichthe above sentence is an instance. By the Subjective/Objective Miller's Principle, 8fifi tfi t0fi t fi t0 (t0  t0 ) ^ (t  t0) !(19)
P ( ^ pr ( ) = fi) = fi ff P (pr ( ) = fi)
Since valid formulas have probability one, it follows by
Theorem 6 that, 8fifi tfi t0fi t fi t0 fi t fi t0 (t0  t0 ) ^ (t  t0) !(20)
P ( ^ pr ( ) = fi ^ pr ( ) = 0 _ pr ( ) = 1]) =fi ff P (pr ( ) = fi ^ pr ( ) = 0 _ pr ( ) = 1])
Since pr ( ) = 0 and pr ( ) = 1 are mutually exclusive, we have
8fifi tfi t0fi t fi t0 (t0  t0 ) ^ (t  t0) !(21)
P ( ^ pr ( ) = fi ^ pr ( ) = 0) +
P ( ^ pr ( ) = fi ^ pr ( ) = 1) =fi ff P (pr ( ) = fi ^ pr ( ) = 0) +fi ff P (pr ( ) = fi ^ pr ( ) = 1)
Now we have three cases to consider: i) fi = 0, ii) fi = 1, iii) 0 < fi < 1.fffffft0tfffifffifft0tt0t0tt0tt0t0t0t0t0fffftt0tt0fft0 t0tt0t0tt0t0
Case i)
Expression (21) reduces to(22)
8tfi t0fi t fi t0 fi t fi t0 (t0  t0 ) ^ (t  t0) !
P ( ^ pr ( ) = 0) = 0 ff P (pr ( ) = 0)
So by Theorem 4 and universal generalization, 8tfi t0fi t fi t0 fi t fi t0 (t0  t0 ) ^ (t  t0) !(23)
P ( ^ pr ( ) = 0 ^ !) = 0 ff P (pr ( ) = 0 ^ !)fffffififft0tfffft0tfififft0tt0t
Case ii)
Expression (21) reduces to(24)
8tfi t0fi t fi t0 (t0  t0 ) ^ (t  t0) !
P ( ^ pr ( ) = 1) = P (pr ( ) = 1)
So by Theorem 5 and universal generalization, 8tfi t0fi t fi t0 fi t fi t0 (t0  t0 ) ^ (t  t0) !(25)
P ( ^ pr ( ) = 1 ^ !) = P (pr ( ) = 1 ^ !)fffffft0tfftfffififft0tt0tt0
Case iii)
For 0 < fi < 1, P (pr ( ) = fi) = 0. So by Theorem 4 and universal generalization, 8fifi tfi t0fi t fi t0 fi t fi t0(26)
0
0
0(t  t ) ^ (t  t ) ^ (0 < fi < 1) !
P ( ^ pr ( ) = fi ^ !) = P (pr ( ) = fi ^ !)
Therefore we have proven that the following sentence is valid(27)
8fifi tfi t0fi t fi t0 fi t fi t0 (t0  t0 ) ^ (t  t0) !
P ( jpr ( ) = fi ^ !) = fi from which it follows that the past cannot be in uenced.
2 t0tfffifffifft0tfftfft0fitfifft0
6 Related Work
Three outstanding subjective theories of objective chance from the philosophical literature are those of van
Fraassen 9], Lewis 6], and Skyrms 7]. van Fraassen's model of objective chance is more constrained than
Lewis's model which is more constrained than Skyrms's model. Thus, in van Fraassen's model, chance has more inherent properties than in either Lewis's or Skyrms's models. van Fraassen's theory is the only one of the three that is cast in a temporal framework. All three are semantic theories and do not provide logical languages.
The model of objective chance used in L is based on van Fraassen's 9] model of objective chance. He presents a semantic theory that models subjective probability and objective chance, using a future-branching model of time points. van Fraassen places two constraints on objective chance:
1. The chance of a past is either 0 or 1, depending on whether or not it actually occurred.
2. Chance at a time is completely determined by history of the world up to that time.
From these assumptions, he shows the following relation between subjective probability and objective chance
P (X jY ) = E C (X )]fi where P is the subjective probability at time t, C is the objective chance at time t, E is the expected value given Y, and provided the truth of Y depends only on the history up to t. This relation entails both Miller's principle and Lewis's principal principle, discussed below. Note that van Fraassen does not show that a similar relation holds between objective chances at different times. In van Fraassen's models, objective chance can change with time but truth values cannot.
Lewis's 6] theory of objective chance is based on his assertion that... we have some very firm and definite opinions concerning reasonable credence (subjective probability) about chance (objective chance). These opinions seem to me to afford the best grip we have on the concept of chance.
He describes a number of intuitive relationships between subjective probability and objective chance and shows that these are captured by his principal principle:
Pr(Ajpr (A) = fi ^ E ) = fifi where Pr is subjective probability, pr is objective chance, and E is any proposition compatible with pr (A) = fi and admissible at time t.
The interesting thing here is the proposition E. The constraint that E be compatible with pr (A) = fi means that Pr(E ^ pr (A) = fi) > 0. Admissibility is less readily defined. Lewis does not give a definition of admissibility but he does characterize admissible propositions as \the sort of information whose impact on credence about outcomes comes entirely by way of credence about the chances of those outcomes." So objective chance is invariant with respect to conditioning on tcpt
Yttt
Yttttadmissible propositions. This concept of invariance under conditioning is the central notion of Brian Skyrms's theory of objective chance.
Skyrms 7] works with the notion of resiliency. A probability value is resilient if it is relatively invariant under conditionalization over a set of sentences. The resiliency of Pr(q) being fi is defined as 1 minus the amplitude of the wiggle about fi:
The resiliency of Pr(q) being fi is 1;maxjfi;
Pr (q)j over p1 fi :::fi p, where the Pr 's are gotten by conditionalizing on some Boolean combinationof the p 's which is logically consistent with q.
Skyrms then defines propensity (objective chance) as a highly resilient subjective probability.
Independent of his resiliency notion, Skyrms requires that propensities and subjective probabilities be related by Miller's principle:
Pr(Ajpr(A) = fi) = fifi where Pr is a subjective probability and pr is a propensity. He shows that Millers' principle entails that subjective probabilities are equal to the expectation of the subjective probabilities applied to the objective probabilities. But Skyrms 7, p158] points out that, counter to intuition, independence in every possible objective distribution does not imply independence in the subjective distribution. This observation provided the motivation for our use of the two probabilities to distinguish causal from evidential correlation.
Halpern 4, 5] presents a probability logic that can represent both statistical and subjective probabilities.
Statistical probabilities represent proportions over the domain of individuals, while propositional probabilities represent degrees of belief. The two probability operators in the language can be nested and combined freely with other logical operators. So the language is capable of representing sentences like \The probability is.95 that more than 75% of all birds can y." The models for the language contain a domain of individuals, a set of possible worlds, a single discrete probability function over the individuals, and a single discrete probability function over the possible worlds. The first probability function is used to assign meaning to the statistical probability operator, while the second is used to assign meaning to the propositional probability operator. Although he does not place constraints within the logic on the relation between the two probabilities, he does discuss a form of Miller's principle that relates subjective and objective probabilities. His version of the principle states that \for any real number r0 the conditional probability of ff(a), given that the probability of a randomly chosen x satisfies ff is r0, is itself r0." He points out that this could be used as a rule for inferring degrees of belief from statistical information.
Bacchus 1] presents a logic essentially identical to that of Halpern. He goes further than Halpern in exploring the inference of degrees of belief from statistical probabilities. According to his principle of direct inference, an agent's belief in a formula is the expected jnijvalue with respect to the agent's beliefs of the statistical probability of that formula, given the agent's set of accepted objective assertions.
References  F. Bacchus. Representing and Reasoning With
Probabilistic Knowledge. MIT Press, Cambridge, Mass, 1990.  P. Haddawy. Believing change and changing belief. Technical Report TR-94-02-01, Dept. of Elect. Eng. & Computer Science, University of Wisconsin-Milwaukee, February 1994. Available via anonymous FTP from pub/tech_reports at ftp.cs.uwm.edu.  P. Haddawy. Representing Plans Under Uncertainty: A Logic of Time, Chance, and Action, volume 770 of Lecture Notes in Arti cial Intelligence.
Springer-Verlag, Berlin, 1994.  J.Y. Halpern. An analysis of first-order logics of probability. In Proceedings of the International
Joint Conference on Arti cial Intelligence, pages
1375{1381, 1989.  J.Y. Halpern. An analysis of first-order logics of probability. Arti cial Intelligence, 46:311{350, 1991.  D. Lewis. A subjectivist's guide to objective chance. In W. Harper, R. Stalnaker, and G. Pearce, editors, Ifs, pages 267{298. D. Reidel, Dordrecht, 1980.  B. Skyrms. Causal Necessity. Yale Univ. Press, New Haven, 1980.  B. Skyrms. Higher order degrees of belief. In
D.H. Mellor, editor, Prospects for Pragmatism, chapter 6, pages 109{137. Cambridge Univ. Press, Cambridge, 1980.  B.C. van Fraassen. A temporal framework for conditionals and chance. In W. Harper, R. Stalnaker, and G. Pearce, editors, Ifs, pages 323{340. D. Reidel, Dordrecht, 1980.  J. Venn. The Logic of Chance. MacMillan, London, 1866. (new paperback edition, Chelsea, 1962).  R. von Mises. Probability, Statistics and Truth.
Allen and Unwin, London, 1957.